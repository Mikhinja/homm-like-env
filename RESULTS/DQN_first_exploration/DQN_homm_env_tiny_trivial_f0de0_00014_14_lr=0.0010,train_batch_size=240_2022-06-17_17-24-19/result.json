{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.38335564732551575, "min_q": -0.7374136447906494, "max_q": 1.424058437347412, "mean_td_error": -0.11683666706085205}, "td_error": [0.4342454671859741, 1.3770942687988281, -0.4923521876335144, 0.6848067045211792, -0.9441908597946167, -0.7731726169586182, 0.22501838207244873, 0.6790206432342529, -0.17392463982105255, -1.6899609565734863, -1.3721500635147095, -0.4647151529788971, -0.7131750583648682, 0.09962743520736694, 2.8618829250335693, -0.7612775564193726, 0.3372230529785156, -0.39972972869873047, 2.129345655441284, -0.458475261926651, 0.09903731942176819, -1.167864441871643, -0.09660916030406952, -0.2149236798286438, -1.2592999935150146, 2.1125974655151367, -0.01639479398727417, 1.823324203491211, 0.22984963655471802, 0.29596173763275146, -0.4926515221595764, -0.2860074043273926, -0.471706748008728, 0.13876986503601074, -0.09083807468414307, 2.151038646697998, -1.8039894104003906, 1.561109185218811, -1.217469334602356, -0.8351012468338013, -0.9816246628761292, 0.30609533190727234, -0.5800585746765137, -1.40066659450531, -0.44691580533981323, 2.350513458251953, 0.3221532106399536, -1.5678911209106445, -0.5077998638153076, -0.9241324663162231, 1.052943229675293, -1.7057137489318848, -0.4964609146118164, 0.14088863134384155, 0.3687453866004944, 0.2834235429763794, -0.6541187167167664, -0.38370269536972046, -0.4181709885597229, 2.129345655441284, 0.49590975046157837, 2.6417622566223145, 0.36006343364715576, -0.17847126722335815, 0.13876986503601074, -0.5372804403305054, 0.044540464878082275, 1.889924168586731, -1.4491443634033203, 0.833608090877533, 0.11170336604118347, -2.1727101802825928, 2.0596299171447754, -1.5667065382003784, 1.5887855291366577, -0.9441908597946167, -0.40091848373413086, 2.9348511695861816, -0.562580943107605, -0.5939221978187561, 0.34827402234077454, -0.28796371817588806, -0.2601504921913147, 1.8113577365875244, -1.3109406232833862, -0.9561880230903625, -0.6153764724731445, 0.22739174962043762, -1.0837711095809937, -5.271170139312744, 0.6371324062347412, 2.2387804985046387, 2.4318981170654297, -0.02154955267906189, 0.4045112133026123, -0.2551143169403076, 0.4045112133026123, -0.2261260747909546, 1.49675452709198, -0.22133690118789673, 2.5420515537261963, -0.281330943107605, -0.14796078205108643, 2.2682337760925293, -0.2507448196411133, 0.3142872452735901, 0.07568979263305664, 0.20193743705749512, -0.8941525220870972, 0.08811193704605103, -1.2102444171905518, 1.6668813228607178, 1.6651365756988525, 0.1665891408920288, -5.448631286621094, -0.7181077003479004, -0.6423779726028442, 0.5974530577659607, -0.3992652893066406, -1.2862539291381836, -4.6367878913879395, 0.19549506902694702, -0.5602771639823914, -0.6472381949424744, -2.486867666244507, 0.5800670981407166, 2.5751640796661377, 0.59552001953125, -0.7001792788505554, 1.8113577365875244, -1.6164058446884155, 2.5755810737609863, 0.2022641897201538, -1.225337028503418, -0.9960233569145203, 1.5599545240402222, 1.7060118913650513, -0.11708301305770874, 0.13915568590164185, 1.052943229675293, -0.7000910043716431, -0.3192175030708313, -0.1424298882484436, -0.11233651638031006, 0.20193743705749512, -0.8602919578552246, 1.561109185218811, -0.5095094442367554, -1.0281085968017578, -1.2862539291381836, -0.6012605428695679, 1.8639655113220215, 0.46302199363708496, 0.308093398809433, 0.6371324062347412, 2.25273060798645, 0.1477261781692505, 1.6580883264541626, -0.7402126789093018, 1.8567451238632202, -0.6755673885345459, -0.17332780361175537, -0.7959758639335632, -0.6197913289070129, -1.3149471282958984, 2.0739123821258545, 0.044540464878082275, -0.3117116391658783, -1.0022168159484863, 1.3493256568908691, -1.556066632270813, 0.21671968698501587, -0.5056087374687195, -1.004128098487854, -0.562580943107605, 1.3875350952148438, -0.3117116391658783, 1.7060118913650513, 0.46302199363708496, -0.10882788896560669, -0.25943517684936523, -0.7976952791213989, -0.11708301305770874, -0.037391841411590576, -0.278989315032959, 0.29070043563842773, -0.9494142532348633, 0.41421598196029663, 0.32157373428344727, -0.3891528844833374, -0.9205135107040405, 0.33316394686698914, -0.17332780361175537, -0.7910832166671753, -0.12868475914001465, -5.317528247833252, -0.4417349398136139, -0.7583404779434204, 1.2769386768341064, -0.42538148164749146, -1.7970318794250488, -9.667182922363281, 1.3560106754302979, -0.20256608724594116, -0.7362066507339478, -5.613223075866699, -0.917972981929779, -0.7411599159240723, -0.9716936945915222, 0.15989941358566284, 0.5081781148910522, -0.6364362239837646, 0.9037212133407593, -0.676080048084259, 1.6087186336517334, 2.4318981170654297, -5.9823455810546875, -1.6164058446884155, 1.575080394744873, 2.2682337760925293, 1.8113577365875244, 0.09450995922088623, -1.1835744380950928, -1.8635430335998535, -1.0011699199676514, 0.6846721172332764, 0.46302199363708496, 2.2132833003997803, -1.0288666486740112, 0.29596173763275146, -0.07216548919677734, -0.4926515221595764, -0.18021699786186218, 0.044540464878082275, -1.5463224649429321, -0.5850151777267456, 0.41861462593078613, 0.22739174962043762, -1.3690361976623535, -0.4552941620349884], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 1024, "num_env_steps_trained": 240, "num_agent_steps_sampled": 1024, "num_agent_steps_trained": 240, "last_target_update_ts": 1024, "num_target_updates": 1}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 1024, "num_agent_steps_trained": 240, "num_env_steps_sampled": 1024, "num_env_steps_trained": 240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 240, "timesteps_total": 1024, "agent_timesteps_total": 1024, "timers": {"training_iteration_time_ms": 184.92, "learn_time_ms": 85.962, "learn_throughput": 2791.937, "synch_weights_time_ms": 18.99}, "counters": {"num_env_steps_sampled": 1024, "num_env_steps_trained": 240, "num_agent_steps_sampled": 1024, "num_agent_steps_trained": 240, "last_target_update_ts": 1024, "num_target_updates": 1}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-04", "timestamp": 1655478064, "time_this_iter_s": 4.269047975540161, "time_total_s": 4.269047975540161, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4.269047975540161, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 49.68571428571429, "ram_util_percent": 56.557142857142864}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.361607313156128, "min_q": 0.6565154790878296, "max_q": 4.010368347167969, "mean_td_error": -0.7949033975601196}, "td_error": [0.9837627410888672, -0.39984607696533203, -5.772709369659424, -0.6810498237609863, -0.8379553556442261, -0.6061913967132568, -1.4644501209259033, -0.37896227836608887, -1.2146090269088745, -1.3853627443313599, -5.243102073669434, -0.554246187210083, 1.5470926761627197, 1.4226622581481934, -1.2146090269088745, -0.05607914924621582, -0.9381165504455566, 0.08677792549133301, -0.15558195114135742, 0.3951263427734375, -0.4797375202178955, 0.7185742855072021, -0.12447047233581543, -0.4889504909515381, 1.053139328956604, -1.041733741760254, -1.0848641395568848, -4.984225273132324, -0.06816482543945312, 0.673635721206665, -5.507731914520264, -0.3080430030822754, 1.4384753704071045, -5.243102073669434, -0.10460567474365234, -0.7870025634765625, -5.772709369659424, -1.2862565517425537, -0.6781656742095947, -0.6229038238525391, -0.5967938899993896, -1.4995858669281006, -1.0982470512390137, 1.1342236995697021, -0.3742790222167969, -0.9378376007080078, -0.45110440254211426, -0.9938368797302246, -0.5579578876495361, -0.4373433589935303, 0.1513843536376953, -0.6198043823242188, -0.07566380500793457, -0.04546809196472168, -0.4484984874725342, -1.6776695251464844, 1.4801509380340576, -1.681584119796753, 0.9203236103057861, 1.2702572345733643, -0.288163423538208, -0.5692746639251709, 1.0748963356018066, -0.2897219657897949, 1.054469108581543, 0.5130544900894165, -0.6136622428894043, -0.5539062023162842, -0.5601403713226318, -0.08222842216491699, -0.0042705535888671875, -0.5806927680969238, -0.3811221122741699, -1.0498404502868652, 0.27361106872558594, 0.693291187286377, -4.984225273132324, -1.2133979797363281, -0.4889504909515381, -1.3426434993743896, 1.003152847290039, -1.1859445571899414, -0.8459048271179199, -0.9462969303131104, -1.9059998989105225, 1.6212399005889893, 1.3247663974761963, 1.5618830919265747, -1.1647944450378418, -11.030498504638672, -1.0102264881134033, -0.490405797958374, -0.36267828941345215, -0.944250226020813, -1.2906628847122192, -0.8022074699401855, -1.2129309177398682, 1.1449857950210571, -0.7671236991882324, 1.1154100894927979, -0.7878437042236328, -0.21952080726623535, -0.9612541198730469, 1.9112839698791504, -0.8673014640808105, -0.4374828338623047, -0.6951286792755127, -0.8738622665405273, -11.282344818115234, -1.7914475202560425, -1.7680342197418213, -2.391268253326416, -0.6584315299987793, -0.9398081302642822, -1.4377999305725098, 1.1598129272460938, -1.254488229751587, -0.876915693283081, 1.375449538230896, 1.375449538230896, -4.64719295501709, 0.8117368221282959, -0.04946708679199219, -1.5428255796432495, -0.9044020175933838, -4.64719295501709, -6.2378740310668945, -0.07566380500793457, -0.659156322479248, -1.7813868522644043, -0.5716404914855957, -0.5375123023986816, -0.07135534286499023, -0.9834930896759033, -0.3650224208831787, -0.27471065521240234, -0.4750556945800781, -0.6297070980072021, -0.5965709686279297, -0.26100897789001465, -7.2307329177856445, -0.5462744235992432, -0.7469866275787354, -0.8182344436645508, -1.0737762451171875, -0.2627072334289551, -0.9909465312957764, -1.0377358198165894, -0.8786025047302246, -0.45119738578796387, -0.185225248336792, -1.2976970672607422, -0.42937541007995605, -1.280432939529419, -0.3445863723754883, -0.06918954849243164, -0.8996114730834961, -0.07905197143554688, -1.3550387620925903, 0.3951263427734375, 1.0271408557891846, -0.3907132148742676, -0.659156322479248, -0.3445863723754883, 1.2671008110046387, -0.8151328563690186, -2.5111870765686035, 1.528663158416748, -1.2619242668151855, 0.9388749599456787, 2.2463550567626953, -1.7914475202560425, -1.7448090314865112, 0.7185742855072021, -0.9304547309875488, -0.5079655647277832, 0.1511852741241455, -0.1745750904083252, -10.26459789276123, 0.892902135848999, 0.08677792549133301, 0.7107241153717041, -1.0242009162902832, -0.6327426433563232, -2.1833643913269043, 0.9950534105300903, -0.9496228694915771, -0.8739736080169678, -6.2378740310668945, -0.6554141044616699, -0.4980645179748535, -0.06870603561401367, 1.5470926761627197, -1.8445968627929688, 0.7151198387145996, 0.30576300621032715, -0.5468337535858154, 0.27361106872558594, -0.7642908096313477, -0.5009417533874512, -0.6107587814331055, -0.992335319519043, 0.8262615203857422, -1.5819838047027588, -11.282344818115234, 0.2854483127593994, 0.022869110107421875, 1.4273738861083984, -0.3032042980194092, -1.2102396488189697, -0.45110440254211426, -0.03958606719970703, 0.27361106872558594, -0.04946708679199219, -0.10128819942474365, 0.9386777877807617, 0.1313772201538086, -1.3857731819152832, 1.134493112564087, -1.2708559036254883, 0.6913232803344727, -1.0121574401855469, -0.7002625465393066, -0.08289957046508789, -0.18533587455749512, -1.164579153060913, 0.8605220317840576, -1.01932692527771, -2.3298630714416504, -0.3678133487701416, -0.9398081302642822, -1.3186795711517334, -0.4394998550415039, -0.5516998767852783, 1.8784456253051758, -0.4017372131347656, 1.1154100894927979, 1.02219557762146, -6.787474632263184, -1.2427599430084229], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 2048, "num_env_steps_trained": 4080, "num_agent_steps_sampled": 2048, "num_agent_steps_trained": 4080, "last_target_update_ts": 2048, "num_target_updates": 3}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 2048, "num_agent_steps_trained": 4080, "num_env_steps_sampled": 2048, "num_env_steps_trained": 4080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 2048, "agent_timesteps_total": 2048, "timers": {"training_iteration_time_ms": 354.831, "learn_time_ms": 58.072, "learn_throughput": 4132.769, "synch_weights_time_ms": 19.385}, "counters": {"num_env_steps_sampled": 2048, "num_env_steps_trained": 4080, "num_agent_steps_sampled": 2048, "num_agent_steps_trained": 4080, "last_target_update_ts": 2048, "num_target_updates": 3}, "done": false, "episodes_total": 0, "training_iteration": 2, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-10", "timestamp": 1655478070, "time_this_iter_s": 5.388428688049316, "time_total_s": 9.657476663589478, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 9.657476663589478, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.31428571428572, "ram_util_percent": 56.91428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.8057973384857178, "min_q": 0.8104881644248962, "max_q": 4.7885918617248535, "mean_td_error": -0.263152539730072}, "td_error": [-1.6149513721466064, 0.906726598739624, -1.07362699508667, -1.232856035232544, -5.415755271911621, -0.5417988300323486, -0.18569421768188477, -0.9637055397033691, 1.2066960334777832, 0.416215181350708, -0.21852636337280273, -0.4665398597717285, -0.15368247032165527, -0.005395174026489258, 0.2815520763397217, 0.45163631439208984, 0.585090160369873, 0.12815499305725098, -0.5585470199584961, 0.2665109634399414, -0.2924513816833496, -0.9530482292175293, -0.17048239707946777, 0.45416736602783203, -0.565664529800415, -11.089315414428711, 1.428131341934204, -0.7073178291320801, -0.21819186210632324, 1.9565272331237793, 0.024109840393066406, -0.5231165885925293, 0.35291218757629395, -0.29976963996887207, -0.9699463844299316, -0.5322967767715454, 2.074308156967163, -1.7395057678222656, -10.225025177001953, -0.5835835933685303, 2.2822279930114746, 0.14459681510925293, 2.4657068252563477, 1.8413236141204834, 0.12177729606628418, -0.09753942489624023, 0.1185007095336914, 1.771367073059082, -0.22826623916625977, 0.028840065002441406, 1.376800775527954, -1.0893983840942383, -11.089315414428711, -0.4726942777633667, 0.08563733100891113, 0.03182411193847656, -0.47323036193847656, 1.435382604598999, -1.606762170791626, 0.7696430683135986, -0.6426880359649658, -1.23817777633667, 1.9722564220428467, 0.11823010444641113, 1.073490858078003, 1.032332181930542, -0.5786404609680176, 0.4203958511352539, -6.527746200561523, 1.17024564743042, -0.06000399589538574, 0.017950057983398438, -0.6030306816101074, -1.21756911277771, 0.3481616973876953, 0.4442286491394043, 2.0264463424682617, 0.1864790916442871, 0.2927124500274658, 1.0634907484054565, -1.296532154083252, -0.9120521545410156, 0.3597691059112549, 1.9722564220428467, -1.046156644821167, -1.0399413108825684, -1.351954698562622, -0.5069077014923096, -10.225025177001953, -0.5918588638305664, 0.026169300079345703, -0.311464786529541, -0.3280351161956787, -5.487639427185059, 1.539750337600708, -1.2872533798217773, 1.1407363414764404, -0.14150261878967285, -1.6403149366378784, 0.13474655151367188, 1.026841163635254, -0.264629602432251, 1.0431225299835205, -0.9410839080810547, 2.4837875366210938, -0.375274658203125, 1.7283830642700195, 0.6304831504821777, -0.6493425369262695, 0.38452601432800293, 0.1844930648803711, -0.9841644763946533, 0.1653459072113037, -4.541898727416992, 2.2377309799194336, -6.581269264221191, 0.2869032621383667, -0.10840845108032227, 0.9270504713058472, 2.3072128295898438, 2.0697507858276367, -5.252648830413818, 0.203416109085083, 1.539750337600708, 1.4468493461608887, 0.08086133003234863, -0.7465982437133789, -0.5069077014923096, 0.36392664909362793, -0.20323419570922852, 1.574155569076538, -0.08168363571166992, -1.1753833293914795, -0.7860909700393677, 2.244849920272827, -0.03665566444396973, 0.6723694801330566, 0.22395634651184082, 1.0091526508331299, 0.2073040008544922, -0.1530146598815918, -0.4714798927307129, -5.403686046600342, 0.3976864814758301, -0.3402984142303467, 1.1191363334655762, 0.08295011520385742, -0.6769487857818604, 0.4482433795928955, -5.980365753173828, 1.3176023960113525, -0.03716444969177246, 0.24947547912597656, 1.2018873691558838, -0.6514320373535156, 0.6987900733947754, -0.6511237621307373, 0.022815465927124023, -0.5994057655334473, -0.15225934982299805, 0.4853024482727051, -5.604022979736328, -0.09753942489624023, 1.8856709003448486, -1.991962194442749, 1.539750337600708, 0.416215181350708, -0.04493236541748047, -0.08066320419311523, -0.43179821968078613, -0.39009881019592285, -0.040654659271240234, -0.9310364723205566, -0.0385589599609375, 0.29766130447387695, 1.0470774173736572, 0.4442286491394043, -4.26521110534668, 1.7542521953582764, -0.08413267135620117, -0.3594179153442383, 0.47071123123168945, 0.07103276252746582, -0.5785033702850342, -0.3721628189086914, -0.375274658203125, 0.6565184593200684, -0.0680081844329834, -0.20321249961853027, -0.5415792465209961, -0.373630166053772, 0.38389062881469727, 0.6381442546844482, 1.2020479440689087, 0.09821820259094238, 1.4608983993530273, 0.09178757667541504, -1.5158249139785767, 0.24276232719421387, 0.01922130584716797, -0.7748208045959473, 2.0602846145629883, -0.03422284126281738, -0.5762844085693359, 0.2628159523010254, 2.1484296321868896, -0.739809513092041, -0.7764103412628174, 2.239665985107422, -0.007735729217529297, 0.6723694801330566, -1.351954698562622, 1.330021858215332, 0.04148292541503906, -0.29942870140075684, -0.16236162185668945, 0.5764882564544678, -0.04934120178222656, -0.1627647876739502, 0.783001184463501, 0.24534034729003906, -0.5790021419525146, 0.14133334159851074, 1.988661766052246, 2.1143932342529297, -0.9472484588623047, -0.2328815460205078, -0.13163542747497559, 0.2638895511627197, -0.24988126754760742, -0.12661004066467285, 2.551729440689087, -0.05797147750854492, -5.980365753173828, 1.489989995956421, 0.11976075172424316, 0.06960344314575195, -0.6848986148834229, 0.21195578575134277, -0.5414423942565918], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 3072, "num_env_steps_trained": 7920, "num_agent_steps_sampled": 3072, "num_agent_steps_trained": 7920, "last_target_update_ts": 3072, "num_target_updates": 5}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 3072, "num_agent_steps_trained": 7920, "num_env_steps_sampled": 3072, "num_env_steps_trained": 7920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 3072, "agent_timesteps_total": 3072, "timers": {"training_iteration_time_ms": 325.981, "learn_time_ms": 58.414, "learn_throughput": 4108.61, "synch_weights_time_ms": 19.788}, "counters": {"num_env_steps_sampled": 3072, "num_env_steps_trained": 7920, "num_agent_steps_sampled": 3072, "num_agent_steps_trained": 7920, "last_target_update_ts": 3072, "num_target_updates": 5}, "done": false, "episodes_total": 0, "training_iteration": 3, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-15", "timestamp": 1655478075, "time_this_iter_s": 5.036527633666992, "time_total_s": 14.69400429725647, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 14.69400429725647, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 30.5, "ram_util_percent": 57.025}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.122278928756714, "min_q": 0.7907025814056396, "max_q": 5.539857387542725, "mean_td_error": 0.1761907935142517}, "td_error": [-1.0039453506469727, 1.3771405220031738, 0.20061445236206055, 1.8395354747772217, -0.24210596084594727, 1.2228412628173828, -0.3865041732788086, -0.5442895889282227, 1.466153621673584, 1.1527221202850342, 0.32735538482666016, 1.3121815919876099, 1.2783167362213135, 1.9513192176818848, -4.947375297546387, -0.1587965488433838, 1.8267393112182617, -0.007427215576171875, -0.9104621410369873, -0.23972082138061523, -0.004127025604248047, 1.6778595447540283, -0.18532729148864746, 1.8370108604431152, -0.10840487480163574, -0.47701478004455566, -0.4028453826904297, 0.4663233757019043, 0.055886030197143555, 4.164903163909912, -0.7199163436889648, -0.3027338981628418, 1.1736769676208496, 0.07191014289855957, -4.966271877288818, 1.5390000343322754, -0.6279046535491943, 2.677035331726074, -4.630026817321777, -0.23279833793640137, 0.06894993782043457, 0.16572833061218262, 1.5543701648712158, -0.544048547744751, 0.6057186126708984, -1.087432861328125, 0.32735538482666016, -0.22665905952453613, -0.010022163391113281, -0.8012490272521973, 1.9451394081115723, 0.16998672485351562, 1.9758567810058594, 2.199018716812134, 2.0091779232025146, 1.5636365413665771, 0.04853653907775879, 0.11666440963745117, -0.5543651580810547, -0.4033224582672119, -0.47287583351135254, -0.7609260082244873, 1.41127610206604, 1.466153621673584, -1.1527678966522217, 1.40513277053833, -0.483547568321228, -0.14945220947265625, 1.9732661247253418, 1.6930248737335205, 1.6991004943847656, -0.4384117126464844, 0.050423622131347656, 1.055375576019287, 1.9623546600341797, 1.519923448562622, 1.7904667854309082, -1.0092368125915527, -0.27497196197509766, -0.7390867471694946, 1.1527221202850342, 1.1986788511276245, 0.2305154800415039, 1.0611975193023682, -0.005815982818603516, -10.721437454223633, -0.024658679962158203, -0.4033224582672119, 1.3882687091827393, 1.1338963508605957, -0.4511927366256714, 2.3118157386779785, 0.3560609817504883, -0.6699061393737793, 2.0806713104248047, 1.3484306335449219, 2.242811679840088, 0.26622772216796875, 0.1570732593536377, 0.8979812860488892, 0.20315313339233398, -0.3871304988861084, 1.466153621673584, 1.5115463733673096, -0.16562986373901367, 0.6441588401794434, -0.7823219299316406, 1.2861721515655518, 1.631073236465454, -0.605556845664978, 1.2855417728424072, 1.5676460266113281, 0.9977343082427979, 2.3159968852996826, 2.468024253845215, -0.36671972274780273, 0.30385541915893555, -0.005815982818603516, -0.4637746810913086, 1.8608472347259521, -0.48633766174316406, 2.0380122661590576, -9.579358100891113, -0.1023414134979248, -0.057340383529663086, 0.1924149990081787, 0.8634233474731445, 1.3554191589355469, 1.683091163635254, 1.5636365413665771, -0.23300480842590332, 1.4410731792449951, 1.3347704410552979, -0.024658679962158203, -0.3353440761566162, -0.6504228115081787, -0.7461831569671631, 1.6930248737335205, 1.755577564239502, 1.474867582321167, 1.40513277053833, -0.3763556480407715, -5.901913642883301, -0.27425169944763184, 0.20147943496704102, 1.592400074005127, -0.41275501251220703, 2.4737510681152344, 2.0405123233795166, -1.0941716432571411, -5.424503326416016, -4.984940528869629, -0.7479630708694458, -0.597484827041626, -0.1888420581817627, -1.243941307067871, 0.3300971984863281, -0.2557816505432129, -0.5530092716217041, -0.5671508312225342, 0.09771728515625, 1.3521968126296997, 1.8697538375854492, 0.14196109771728516, -1.4101195335388184, -0.053644657135009766, 0.23889732360839844, 1.4905650615692139, 1.8978357315063477, 1.5952808856964111, 0.47238922119140625, -1.1457105875015259, -0.5395362377166748, -0.317990779876709, 1.7090942859649658, 0.1759333610534668, 0.17505550384521484, 1.9212150573730469, 0.17505550384521484, 2.108126640319824, -0.597484827041626, -0.6073088645935059, -0.25481486320495605, 1.4655245542526245, 1.9518852233886719, 2.3118157386779785, -5.111656665802002, -0.13571739196777344, -0.5735893249511719, 0.14622068405151367, 0.12816429138183594, 2.3705368041992188, 1.4655245542526245, 0.0893716812133789, -1.3986403942108154, -0.23551154136657715, -0.2688627243041992, 1.8463873863220215, -1.0442302227020264, -0.179854154586792, -5.046328544616699, 1.5115463733673096, 0.09006834030151367, 1.4162651300430298, 0.17476797103881836, -0.25954484939575195, -5.901913642883301, -0.38820815086364746, -0.42507290840148926, 2.2397620677948, -1.1590244770050049, 0.3285508155822754, -0.8904991149902344, 2.239337921142578, 0.14809536933898926, 0.041436195373535156, -0.6248335838317871, 1.7448053359985352, 0.40064001083374023, -0.7607829570770264, -0.3785996437072754, 1.1924118995666504, 1.2312589883804321, -0.352968692779541, 1.7138347625732422, -0.6635124683380127, -0.2653684616088867, 2.0378589630126953, 0.012664556503295898, 1.7138347625732422, 1.2612738609313965, 0.13341665267944336, -11.178617477416992, 0.8538312911987305, -0.06861329078674316, -0.4647097587585449, 0.04578852653503418, 1.8608472347259521, 0.1942582130432129, 2.101609945297241], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 4096, "num_env_steps_trained": 11760, "num_agent_steps_sampled": 4096, "num_agent_steps_trained": 11760, "last_target_update_ts": 4096, "num_target_updates": 7}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -72.09597000479698, "episode_reward_mean": -40.46106187041317, "episode_len_mean": 240.42857142857142, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026], "episode_lengths": [233, 252, 253, 218, 238, 243, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5633657411975023, "mean_inference_ms": 22.405103288006952, "mean_action_processing_ms": 0.1300137993227846, "mean_env_wait_ms": 5.514872875923976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -72.09597000479698, "episode_reward_mean": -40.46106187041317, "episode_len_mean": 240.42857142857142, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026], "episode_lengths": [233, 252, 253, 218, 238, 243, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5633657411975023, "mean_inference_ms": 22.405103288006952, "mean_action_processing_ms": 0.1300137993227846, "mean_env_wait_ms": 5.514872875923976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 4096, "num_agent_steps_trained": 11760, "num_env_steps_sampled": 4096, "num_env_steps_trained": 11760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 4096, "agent_timesteps_total": 4096, "timers": {"training_iteration_time_ms": 362.427, "learn_time_ms": 59.971, "learn_throughput": 4001.952, "synch_weights_time_ms": 19.789}, "counters": {"num_env_steps_sampled": 4096, "num_env_steps_trained": 11760, "num_agent_steps_sampled": 4096, "num_agent_steps_trained": 11760, "last_target_update_ts": 4096, "num_target_updates": 7}, "done": false, "episodes_total": 7, "training_iteration": 4, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-21", "timestamp": 1655478081, "time_this_iter_s": 5.493377923965454, "time_total_s": 20.187382221221924, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 20.187382221221924, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 37.45, "ram_util_percent": 57.375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.079401731491089, "min_q": 0.2879135310649872, "max_q": 5.882375717163086, "mean_td_error": -0.18970887362957}, "td_error": [1.6772398948669434, -0.8490619659423828, 0.32363033294677734, -0.6471155881881714, 0.7321617603302002, 1.3138744831085205, -7.777472972869873, 2.3445258140563965, 1.3646645545959473, 0.3372378349304199, 0.8831119537353516, -0.07306718826293945, -5.50647497177124, 0.6832499504089355, -0.8873291015625, -0.8199448585510254, 0.026992321014404297, -0.9355740547180176, -1.2617007493972778, 0.7484112977981567, 0.2558884620666504, -0.7665109634399414, -0.884934663772583, -0.8518016338348389, 0.013620376586914062, -0.5842618942260742, -0.16737699508666992, -0.8638248443603516, 1.1178574562072754, -0.11274147033691406, -1.0607707500457764, 1.6743226051330566, 0.0023040771484375, -0.43251633644104004, 0.963545560836792, -1.1617379188537598, -0.8291277885437012, -1.0216038227081299, -0.5174868106842041, -6.9522857666015625, 0.09502935409545898, -0.5104653835296631, -0.24364089965820312, -0.29783201217651367, -0.42946529388427734, 2.289839744567871, 1.2970595359802246, 0.11908560991287231, 1.8789539337158203, 0.027952909469604492, 1.289339303970337, 0.9377977848052979, -0.04023909568786621, 1.6689163446426392, -0.35678601264953613, -0.6144251823425293, 1.5735478401184082, -0.8770500421524048, -1.3768391609191895, 0.9112398624420166, 1.4540090560913086, 1.0838689804077148, -1.657618522644043, -0.544562816619873, 1.5852047204971313, 0.0894777774810791, 1.7565951347351074, -0.4024944305419922, 1.5145554542541504, 1.595142126083374, -0.9108719825744629, -0.8924365043640137, -0.030076026916503906, -0.0061872005462646484, 0.09134244918823242, 1.147784948348999, 1.8063600063323975, -0.6582231521606445, -0.3313274383544922, 1.181438684463501, 2.3454222679138184, 0.1744539737701416, -1.3423471450805664, -0.9250507354736328, 1.798245906829834, 2.289839744567871, 0.9654996395111084, 1.5727720260620117, -1.1463594436645508, 1.58164644241333, -1.060939073562622, -0.29364681243896484, -0.5037493705749512, -0.43122220039367676, -0.5945532321929932, 0.6502704620361328, -0.37134599685668945, -0.5721423625946045, 0.49957704544067383, 1.0715253353118896, -0.9663870334625244, 1.4623262882232666, 1.6297188997268677, 1.5727720260620117, -0.1607823371887207, -1.2992055416107178, -0.49405622482299805, -0.871800422668457, 0.07060670852661133, 1.3038585186004639, -0.8425166606903076, 0.08870244026184082, 0.957735538482666, -0.8011548519134521, -0.7924937605857849, -4.758596420288086, 1.6636240482330322, -0.9125630855560303, 1.8040893077850342, 1.2026677131652832, -10.819024085998535, -0.7871994972229004, -1.0866916179656982, -0.4018235206604004, 0.8057465553283691, 1.1215641498565674, 0.9336897134780884, 0.7481259703636169, 1.3634967803955078, 1.00079345703125, -0.6169815063476562, 0.9073085784912109, 1.4671120643615723, -0.5102252960205078, 1.7781944274902344, -0.11358213424682617, -1.2160451412200928, -0.07542562484741211, 1.1700000762939453, -0.2119917869567871, 0.7031819820404053, 1.5852047204971313, -0.4018235206604004, -1.0201525688171387, 1.1719987392425537, 2.085221290588379, 1.084742546081543, -0.6612000465393066, -0.2458500862121582, 0.05417680740356445, -1.0208055973052979, -1.059356689453125, -0.712336540222168, -0.177825927734375, 1.1215641498565674, -1.1288440227508545, -0.1512589454650879, -10.626678466796875, 1.8960599899291992, 2.480731964111328, 1.2007132768630981, -0.025378704071044922, -0.7121280431747437, 0.4714008569717407, 1.3865337371826172, 1.5454204082489014, -0.04023909568786621, -1.4515409469604492, 1.0675283670425415, 1.285987377166748, -0.12626886367797852, -0.641281008720398, -0.19839000701904297, -1.1414899826049805, 0.4878087043762207, -0.9541771411895752, 1.2625560760498047, 1.9883697032928467, -0.760669469833374, -1.1354715824127197, 1.147784948348999, 1.8335142135620117, -1.7941064834594727, -0.39823341369628906, -1.0786609649658203, -0.3643968105316162, -0.8417320251464844, 0.963545560836792, 1.0675283670425415, 0.31323933601379395, -0.6623115539550781, -0.37337541580200195, -0.8616092205047607, -11.244597434997559, 0.35004544258117676, 0.1437239646911621, 1.6360328197479248, -1.0625858306884766, 0.9770851135253906, -0.3840293884277344, -0.33590102195739746, -0.7707536220550537, -0.5357589721679688, -1.415487289428711, -1.8592166900634766, -0.22856569290161133, -0.1696629524230957, 0.43427515029907227, 1.5561332702636719, -0.24646902084350586, -0.35965919494628906, -1.3892905712127686, -0.60205078125, 1.4563117027282715, -0.3726322650909424, 1.5988597869873047, -0.796905517578125, 1.7759370803833008, 1.4937657117843628, -0.9882674217224121, -0.3190896511077881, 1.0932636260986328, -1.1663920879364014, -0.9207468032836914, -1.7953425645828247, -0.5061957836151123, -5.603549480438232, 1.5455043315887451, -0.22429466247558594, -0.061064720153808594, 0.388883113861084, -1.3494024276733398, 1.0917859077453613, 0.14809775352478027, -10.788331985473633, -10.206918716430664, 1.4496526718139648, -0.5956330299377441, -0.6015939712524414, 1.0602821111679077], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 5120, "num_env_steps_trained": 15600, "num_agent_steps_sampled": 5120, "num_agent_steps_trained": 15600, "last_target_update_ts": 5120, "num_target_updates": 9}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 5120, "num_agent_steps_trained": 15600, "num_env_steps_sampled": 5120, "num_env_steps_trained": 15600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 5120, "agent_timesteps_total": 5120, "timers": {"training_iteration_time_ms": 292.094, "learn_time_ms": 59.205, "learn_throughput": 4053.682, "synch_weights_time_ms": 19.591}, "counters": {"num_env_steps_sampled": 5120, "num_env_steps_trained": 15600, "num_agent_steps_sampled": 5120, "num_agent_steps_trained": 15600, "last_target_update_ts": 5120, "num_target_updates": 9}, "done": false, "episodes_total": 16, "training_iteration": 5, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-26", "timestamp": 1655478086, "time_this_iter_s": 5.153872489929199, "time_total_s": 25.341254711151123, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 25.341254711151123, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.77142857142857, "ram_util_percent": 57.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.159003257751465, "min_q": 0.23754435777664185, "max_q": 6.511402606964111, "mean_td_error": -0.14307069778442383}, "td_error": [1.0697250366210938, 0.22279977798461914, -0.0995631217956543, -0.25275182723999023, -0.37950217723846436, -6.926616191864014, -1.031982660293579, -0.8347654342651367, 0.9644427299499512, 1.836989164352417, 1.7480473518371582, 1.347332239151001, -0.6540186405181885, -1.1168254613876343, -0.5924282073974609, 1.921919822692871, -1.2374706268310547, -0.8489890098571777, 0.037706851959228516, 1.2737176418304443, 0.2197115421295166, 0.9288320541381836, 3.074957847595215, -1.074432134628296, 0.44805657863616943, -0.39477038383483887, -0.6861534118652344, 0.08398866653442383, 1.9408211708068848, -5.965930938720703, -1.0424342155456543, 0.7272863388061523, -1.1555049419403076, -0.571803092956543, -0.7953462600708008, -10.72939682006836, 0.4586939811706543, 1.4237399101257324, -0.7585911750793457, 0.016103267669677734, -0.263582706451416, 0.20426487922668457, -0.7250518798828125, 1.373178482055664, 1.3094096183776855, -0.8347654342651367, 0.2837104797363281, 0.7588691711425781, -1.7871031761169434, -0.263582706451416, -0.2653779983520508, 0.8856953382492065, 1.9801809787750244, 0.8042972087860107, 1.0198743343353271, 0.20461416244506836, -1.676447868347168, -0.15199899673461914, 1.568011999130249, 1.7825369834899902, -1.7367780208587646, -0.8938281536102295, 1.4792556762695312, -1.9694182872772217, 1.4509663581848145, -0.7297043800354004, -0.3573155403137207, -5.044623851776123, -0.32578766345977783, 0.7885241508483887, 0.028187274932861328, 2.079212188720703, -0.3752003312110901, 1.321431040763855, 1.6993732452392578, -0.6425046920776367, -0.19946861267089844, -0.36687731742858887, -0.9429984092712402, -1.049177646636963, -1.0323677062988281, -5.7035346031188965, 0.11484313011169434, -0.43510961532592773, 0.32678794860839844, -0.38863563537597656, -0.31399106979370117, 0.630748987197876, -0.5567722320556641, 1.606645107269287, -0.6068050861358643, 1.6976966857910156, 0.8057713508605957, 0.9739422798156738, 1.916100263595581, -4.937958717346191, -0.5204628705978394, 1.7779743671417236, -0.8225760459899902, -0.4487168788909912, -0.8047127723693848, 1.3886330127716064, 1.8918144702911377, 1.562990427017212, 0.15747332572937012, -0.5330166816711426, -0.7806758880615234, -0.07276773452758789, -0.42255544662475586, 1.5140272378921509, 1.9801809787750244, 0.7738804817199707, -2.2082228660583496, -0.1308434009552002, -0.16840887069702148, -1.7700302600860596, -1.1599502563476562, -0.10522222518920898, 1.2159631252288818, 0.22442007064819336, 1.6173019409179688, 0.13700389862060547, -0.9822678565979004, -0.1701502799987793, -0.6938040256500244, 1.2627859115600586, -0.5287904739379883, -0.037142038345336914, 0.4858124256134033, 0.255367636680603, 1.3129734992980957, -0.579315185546875, -0.8542194366455078, 0.37485814094543457, 1.3067511320114136, -0.8169629573822021, -1.3181209564208984, -0.46187376976013184, 0.8856953382492065, -5.781276226043701, 0.5195879936218262, -6.172327518463135, 0.4469127655029297, 0.31067514419555664, 1.836989164352417, -0.7087697982788086, -0.16672635078430176, -0.5321009159088135, -0.1288597583770752, 1.373633861541748, 0.07379150390625, 0.10985076427459717, -0.7406911849975586, -0.17225360870361328, -0.22725582122802734, -0.196730375289917, 1.6410235166549683, -0.546637773513794, -0.9243805408477783, -0.010609865188598633, -0.5502986907958984, -0.4200413227081299, -4.9641218185424805, 0.09615945816040039, 1.6848292350769043, -0.2270345687866211, -0.6147208213806152, -0.3372378349304199, -0.4258246421813965, 0.25247931480407715, -0.1701502799987793, -1.0000576972961426, 2.0855445861816406, -0.00047469139099121094, -0.7639245986938477, -0.5612225532531738, -0.36986303329467773, 0.9501504898071289, 0.18192219734191895, -5.217800140380859, 1.212099552154541, -0.637845516204834, -0.21645450592041016, -0.19029903411865234, -0.2826404571533203, 1.3914995193481445, -0.7170834541320801, -0.32788872718811035, 1.8182578086853027, 0.08683490753173828, 0.4438818693161011, 0.9484403133392334, -0.8428506851196289, -0.31955981254577637, 1.4567787647247314, 3.089381456375122, 1.4841687679290771, -1.203334093093872, 1.7213969230651855, -0.8174581527709961, -0.8739359378814697, -0.5308396816253662, -0.5608434677124023, 0.8521349430084229, 0.3001190423965454, 1.921919822692871, 0.003256082534790039, -1.050652027130127, 1.5200719833374023, -0.6352155208587646, 1.3747903108596802, -0.8359029293060303, 2.0523595809936523, -1.5067858695983887, -0.29758524894714355, 0.4881577491760254, 2.121306896209717, -0.21872687339782715, -0.5437257289886475, 1.3356819152832031, -0.47953319549560547, -0.7930071353912354, -1.4138569831848145, -0.1470174789428711, -4.628926753997803, -0.6431255340576172, 1.1066834926605225, -0.373409628868103, -2.594498634338379, 1.5252351760864258, 1.1464931964874268, 1.5252351760864258, -0.2056887149810791, -0.4625661373138428, -0.02831411361694336, -1.1078476905822754, 0.923600435256958, -0.654865026473999, 1.3658106327056885, -1.890489101409912], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 6144, "num_env_steps_trained": 19440, "num_agent_steps_sampled": 6144, "num_agent_steps_trained": 19440, "last_target_update_ts": 6144, "num_target_updates": 11}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 6144, "num_agent_steps_trained": 19440, "num_env_steps_sampled": 6144, "num_env_steps_trained": 19440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 6144, "agent_timesteps_total": 6144, "timers": {"training_iteration_time_ms": 291.561, "learn_time_ms": 60.372, "learn_throughput": 3975.322, "synch_weights_time_ms": 19.189}, "counters": {"num_env_steps_sampled": 6144, "num_env_steps_trained": 19440, "num_agent_steps_sampled": 6144, "num_agent_steps_trained": 19440, "last_target_update_ts": 6144, "num_target_updates": 11}, "done": false, "episodes_total": 16, "training_iteration": 6, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-31", "timestamp": 1655478091, "time_this_iter_s": 4.624799013137817, "time_total_s": 29.96605372428894, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 29.96605372428894, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 39.42857142857144, "ram_util_percent": 57.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.804246425628662, "min_q": -1.2206902503967285, "max_q": 7.2117743492126465, "mean_td_error": -0.46080973744392395}, "td_error": [1.7684040069580078, 1.5180352926254272, -1.9375990629196167, -0.6376512050628662, 0.03728818893432617, -1.0353140830993652, -1.0693503618240356, -0.43638718128204346, 0.062099456787109375, -6.850531578063965, 1.3684546947479248, -0.03587031364440918, 0.3338932991027832, -0.08129501342773438, 1.1017887592315674, -6.445961952209473, 0.7694382667541504, -1.5941228866577148, 0.09966492652893066, 0.28375303745269775, 0.4402804374694824, -12.105916976928711, -0.970989465713501, 0.7977828979492188, 0.6067914962768555, 1.379807472229004, 0.01059103012084961, 0.37131786346435547, 1.4335839748382568, -0.8819794654846191, 0.924299955368042, 0.3161020278930664, 0.3748568296432495, 0.19060754776000977, 0.6963844299316406, -0.9381281137466431, -0.4355783462524414, 0.26856207847595215, 0.738629937171936, -0.43638718128204346, 1.4795100688934326, 0.618972659111023, -1.0273497104644775, -1.5293018817901611, -1.1045598983764648, 0.32829153537750244, 1.6577235460281372, 0.924299955368042, 1.6124571561813354, -1.4346004724502563, 0.564051628112793, -0.803642749786377, -1.9850389957427979, -1.681166172027588, -1.7332513332366943, -0.9070478677749634, 1.3525700569152832, -0.1304488182067871, -0.9391744136810303, -0.5129836797714233, -0.6295247077941895, 1.4387006759643555, -1.0705105066299438, -1.1875712871551514, 0.5817395448684692, -0.1294083595275879, -1.5413930416107178, -0.041173696517944336, -0.46466565132141113, -1.0004053115844727, -0.6163811683654785, 0.44887232780456543, 0.6282402276992798, -0.40084028244018555, -1.0227913856506348, -0.0024902820587158203, -1.1445741653442383, -0.08353281021118164, -0.5122861862182617, -1.4057564735412598, 0.2250213623046875, 0.7237739562988281, 2.3501803874969482, 0.94891357421875, -1.0226244926452637, -1.081324577331543, -4.339877128601074, 0.9440622329711914, 0.20796942710876465, -8.228070259094238, -0.332122802734375, -0.696307897567749, -1.1749663352966309, -1.5954437255859375, -0.18263959884643555, -0.8040168285369873, 0.9820492267608643, 0.934776782989502, 2.3780722618103027, -4.754166603088379, -0.4873530864715576, -1.5371555089950562, -0.19524097442626953, -5.300636291503906, -1.3759727478027344, 0.317230224609375, 1.9874444007873535, 0.8741881251335144, 0.020668387413024902, 0.9355378150939941, -0.6182270050048828, -3.246506452560425, -0.8179726600646973, -0.01895308494567871, -0.28142499923706055, 1.8590006828308105, 1.589867353439331, -0.6243584156036377, -1.409580945968628, 1.0239381790161133, -0.9241735935211182, -0.7472410202026367, 1.078548789024353, -1.5864341259002686, -1.1693470478057861, 0.7504187822341919, 0.3674449920654297, 0.3331131041049957, -0.16471433639526367, -0.19304728507995605, 1.2218645811080933, 1.2858302593231201, 0.7770967483520508, 1.7733042240142822, 0.0725545883178711, -0.041173696517944336, 0.19060754776000977, -2.3877410888671875, 0.32829153537750244, 2.038522720336914, -0.9020838737487793, 1.1642260551452637, -0.4438025951385498, -1.010164499282837, 0.3008233308792114, -0.14945554733276367, -1.3117122650146484, -10.23579216003418, 1.1906089782714844, -1.3036130666732788, 0.5660074949264526, -1.012340784072876, 0.6756343841552734, -0.8011069297790527, 1.2857847213745117, 1.145183801651001, 0.19060754776000977, 0.5643488168716431, -1.730353832244873, -5.133297920227051, -1.0353140830993652, -0.5656390190124512, -1.0467748641967773, 0.6282402276992798, -5.372668266296387, 1.847224473953247, -1.0707132816314697, 0.5660074949264526, -1.0085809230804443, -1.1471304893493652, -0.1699509620666504, -0.6007540225982666, 0.19895243644714355, -7.041731834411621, -1.3022552728652954, 0.7882249355316162, 1.5791987180709839, -1.9243876934051514, 2.6186447143554688, -0.47806692123413086, -0.7607927322387695, -4.693779468536377, -1.190997838973999, -0.9810309410095215, -0.3050740957260132, -2.6706693172454834, 1.22306489944458, 0.020668387413024902, 1.5245957374572754, -0.0869361162185669, 0.6298167705535889, -6.404748916625977, -0.777371883392334, -1.0732386112213135, -1.7307076454162598, 1.7875843048095703, 0.18410444259643555, 1.70389986038208, 1.145183801651001, -0.8048620223999023, 0.8765325546264648, 2.3780722618103027, -1.5293018817901611, -0.4066286087036133, -0.6797688007354736, -0.2232351303100586, -0.5849936008453369, -1.8019649982452393, -0.8651000261306763, -0.4833984375, 0.27468442916870117, -0.6540725231170654, 1.5273776054382324, 1.2206823825836182, -0.7469143867492676, -1.6049669981002808, 0.13953447341918945, -1.409790277481079, 0.9827039241790771, -1.071519374847412, 0.04721570014953613, 1.3090951442718506, -4.352800369262695, 1.965428352355957, 0.19258689880371094, 1.3371083736419678, 0.061232924461364746, -6.312929630279541, -1.1264424324035645, -0.21424627304077148, 0.35901975631713867, 0.9719604253768921, 0.2611713409423828, -1.3453083038330078, -0.3454298973083496, -0.7388782501220703, 1.4162261486053467, -0.28983068466186523, -0.5608878135681152, -1.5916900634765625], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 7168, "num_env_steps_trained": 23280, "num_agent_steps_sampled": 7168, "num_agent_steps_trained": 23280, "last_target_update_ts": 7168, "num_target_updates": 13}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 7168, "num_agent_steps_trained": 23280, "num_env_steps_sampled": 7168, "num_env_steps_trained": 23280, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 7168, "agent_timesteps_total": 7168, "timers": {"training_iteration_time_ms": 326.75, "learn_time_ms": 59.475, "learn_throughput": 4035.284, "synch_weights_time_ms": 50.873}, "counters": {"num_env_steps_sampled": 7168, "num_env_steps_trained": 23280, "num_agent_steps_sampled": 7168, "num_agent_steps_trained": 23280, "last_target_update_ts": 7168, "num_target_updates": 13}, "done": false, "episodes_total": 16, "training_iteration": 7, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-36", "timestamp": 1655478096, "time_this_iter_s": 5.072657585144043, "time_total_s": 35.03871130943298, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 35.03871130943298, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.15714285714285, "ram_util_percent": 57.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.763708472251892, "min_q": -3.5472660064697266, "max_q": 8.822704315185547, "mean_td_error": -0.6024327874183655}, "td_error": [0.6002063751220703, -1.680323600769043, -0.7800352573394775, 1.2027007341384888, 0.8449946641921997, 0.7096462249755859, 0.32908082008361816, 1.9327569007873535, -0.7743735313415527, -0.018111228942871094, -1.0703201293945312, -0.23906421661376953, -2.0332367420196533, -0.6625356674194336, 1.7779335975646973, -7.326165199279785, -1.5471922159194946, 1.720719337463379, -0.32809972763061523, -8.770389556884766, 0.6648226380348206, 0.33615589141845703, -0.9961963295936584, 0.3463444709777832, -0.9909310340881348, 0.7812106609344482, -0.37814223766326904, 1.6522424221038818, 0.660942792892456, -0.4372934103012085, 1.8924870491027832, -0.43371057510375977, 0.927495002746582, -0.5868496894836426, -0.7749166488647461, 0.983423113822937, -0.1361851692199707, -0.5855749845504761, -0.071533203125, 0.7490636110305786, -0.21531248092651367, -0.5068938732147217, -1.6702662706375122, -2.715439796447754, -0.6692357063293457, -0.9393899440765381, 0.39129072427749634, -0.9556269645690918, 0.7374329566955566, -0.8631425499916077, -1.88456392288208, -0.11708825826644897, -0.18248939514160156, 0.13627910614013672, 0.46923571825027466, -0.6848719120025635, 0.42879772186279297, -1.635124921798706, 0.7374329566955566, -2.4627017974853516, -1.8092656135559082, -0.6030900478363037, 0.02250504493713379, -0.3112930655479431, -0.6498279571533203, -0.48533105850219727, 0.2445206642150879, -2.0332367420196533, -1.219811201095581, 0.11669206619262695, -1.573167324066162, 0.9529755115509033, -1.5540497303009033, 1.2521978616714478, -1.2224717140197754, 0.825164794921875, 0.834674596786499, 0.8500528335571289, -2.480417251586914, 1.8817634582519531, -1.5026278495788574, -1.0683956146240234, -1.2372620105743408, -0.2920980453491211, 0.4550829529762268, -1.0925097465515137, -0.34819793701171875, -2.562617778778076, -0.7483694553375244, 1.4969627857208252, 0.3463444709777832, 1.0195229053497314, 2.1114301681518555, 0.28974854946136475, -1.5973789691925049, -0.023190975189208984, 0.1849813461303711, 0.4713360667228699, -6.840852737426758, 0.4209280014038086, 0.1338493824005127, -1.8821909427642822, -0.9087963104248047, -0.10457265377044678, -0.3161814212799072, 0.2718132734298706, 2.102508544921875, -0.6260976791381836, -0.4678921699523926, -2.349853992462158, -10.836225509643555, -1.6628692150115967, -1.7823361158370972, -0.5219447612762451, 1.090571403503418, -0.1199941635131836, 0.05395913124084473, 0.3499135971069336, 0.022260665893554688, -0.5469505786895752, 1.462625503540039, -1.2785835266113281, -0.217820405960083, 1.7868623733520508, 1.2478358745574951, -1.4054844379425049, -12.21618938446045, -0.49632930755615234, -3.098175048828125, 0.16218280792236328, 0.22637414932250977, -0.6626467704772949, -0.02274984121322632, -0.8638818264007568, -9.761528968811035, -2.0632247924804688, 0.9970066547393799, -1.3723480701446533, 0.12779760360717773, -0.07058560848236084, 0.5401108264923096, -0.4877821207046509, 0.13518482446670532, 0.6775650978088379, 0.049423277378082275, 0.5591646432876587, -0.7101913690567017, -1.7952015399932861, 0.11669206619262695, -0.21838760375976562, -1.7340749502182007, -0.6373772621154785, 0.12918806076049805, 0.7374329566955566, -7.388652324676514, -0.11062133312225342, -1.2759513854980469, 0.07566511631011963, -1.877192735671997, 1.4275732040405273, 0.5234640836715698, -0.003000974655151367, 1.0817750692367554, -0.8352227210998535, -0.02274984121322632, 0.30104684829711914, -0.27037572860717773, 1.179488182067871, 0.32441139221191406, 0.09187531471252441, 0.929328441619873, -1.123963713645935, -1.50930655002594, -0.37814223766326904, 0.5432467460632324, -2.0851120948791504, -0.4746590554714203, 0.3286689519882202, -0.11708825826644897, -0.4113030433654785, 0.9970066547393799, -0.690180778503418, -0.6991300582885742, -0.41682136058807373, -1.32468843460083, -0.2013382911682129, 0.9062339067459106, -0.6062545776367188, -1.9300583600997925, 0.7931609153747559, -1.323782205581665, -0.7721470594406128, -2.488048553466797, 0.9020400047302246, -0.31503868103027344, -0.028258562088012695, -1.3044416904449463, -1.861720323562622, -0.48777294158935547, -1.2889823913574219, 0.5591646432876587, -0.17353606224060059, -0.7343692779541016, 1.1567881107330322, -1.4929661750793457, -8.75951099395752, -1.101658582687378, 0.0787879228591919, -1.0076472759246826, -0.6107053756713867, -0.024356365203857422, 0.010296821594238281, 1.2521978616714478, 1.179488182067871, -6.68618631362915, -0.234485924243927, 0.07445335388183594, 0.34055203199386597, -1.9615342617034912, -0.5439090728759766, -0.34112775325775146, -0.7324619293212891, -0.7332057952880859, 0.4210638999938965, -1.1407382488250732, 0.06331968307495117, -1.5138022899627686, -0.9500494003295898, -1.8050117492675781, -1.4037573337554932, -0.9241683483123779, 0.8112096786499023, -0.5901198387145996, -0.45697158575057983, -0.05050230026245117, -0.4205174446105957, -2.660614252090454, -0.1203927993774414, 0.5018146634101868, 0.20568251609802246], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 8192, "num_env_steps_trained": 27120, "num_agent_steps_sampled": 8192, "num_agent_steps_trained": 27120, "last_target_update_ts": 8192, "num_target_updates": 15}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -186.4327369555831, "episode_reward_mean": -73.2085185633041, "episode_len_mean": 257.8125, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5508545392692231, "mean_inference_ms": 22.325663125816845, "mean_action_processing_ms": 0.13413780178201762, "mean_env_wait_ms": 5.15988208732384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 8192, "num_agent_steps_trained": 27120, "num_env_steps_sampled": 8192, "num_env_steps_trained": 27120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 8192, "agent_timesteps_total": 8192, "timers": {"training_iteration_time_ms": 307.624, "learn_time_ms": 59.238, "learn_throughput": 4051.445, "synch_weights_time_ms": 19.889}, "counters": {"num_env_steps_sampled": 8192, "num_env_steps_trained": 27120, "num_agent_steps_sampled": 8192, "num_agent_steps_trained": 27120, "last_target_update_ts": 8192, "num_target_updates": 15}, "done": false, "episodes_total": 16, "training_iteration": 8, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-41", "timestamp": 1655478101, "time_this_iter_s": 4.82011342048645, "time_total_s": 39.858824729919434, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 39.858824729919434, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.58571428571428, "ram_util_percent": 57.971428571428575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.5243914127349854, "min_q": -6.520686626434326, "max_q": 9.620617866516113, "mean_td_error": -0.13001208007335663}, "td_error": [1.50677490234375, -0.8511766195297241, 0.3521122932434082, 0.4506106376647949, -1.938507318496704, 0.661212682723999, -0.04810905456542969, -0.05597519874572754, 0.25462865829467773, -1.4742928743362427, -1.578719973564148, 0.7174618244171143, 2.192917823791504, -1.7605535984039307, -0.43662452697753906, -0.6758267879486084, 0.31178855895996094, 0.22137069702148438, 0.040425777435302734, -0.18541689217090607, -0.5650356411933899, -0.5335369110107422, -0.5158504843711853, 0.6882869005203247, -0.5222434997558594, -0.3440375328063965, 0.24731361865997314, -0.6171092987060547, 0.22137069702148438, 0.22137069702148438, -0.26672935485839844, 0.38138389587402344, 0.6964125037193298, 0.30600404739379883, 1.7183971405029297, 0.4716644287109375, -0.10373210906982422, 1.6576886177062988, 1.3032596111297607, -0.43973684310913086, -0.9343063831329346, 0.2730684280395508, -1.454089879989624, -0.49565577507019043, -0.8599179983139038, 0.027937889099121094, -0.5088077783584595, 0.7195210456848145, -0.029881715774536133, -0.10182619094848633, 0.7195210456848145, 1.5981464385986328, -3.8812367916107178, -0.22742962837219238, -0.5793488025665283, 0.7905495762825012, 0.6843605041503906, 1.7932591438293457, -1.2190014123916626, 1.4678077697753906, -0.9347330927848816, 0.4542422294616699, -1.655914306640625, 2.11008358001709, 1.2110657691955566, -0.09132075309753418, 1.1384049654006958, -0.7222627401351929, -0.37240588665008545, -1.8501992225646973, -0.10729002952575684, 1.2024732828140259, 0.5779962539672852, -1.5982141494750977, -9.226635932922363, -0.7842230796813965, -0.6454929113388062, 0.32503652572631836, 1.508347511291504, 1.7307672500610352, -2.092353343963623, 1.9209258556365967, 0.5157499313354492, 1.7158799171447754, -0.7048748135566711, 1.508347511291504, 0.9960777759552002, 0.3679642677307129, 2.504157543182373, -1.548331379890442, -0.7196071743965149, -2.25948429107666, 0.06394386291503906, -0.24574041366577148, -0.26510000228881836, -0.4567892551422119, 0.7776799201965332, 1.6292378902435303, 0.6306357383728027, -0.8217747211456299, 1.0674455165863037, 1.5416531562805176, -0.19888782501220703, 0.2757798433303833, 0.7651002407073975, -1.5177713632583618, 0.7584763765335083, -2.994931936264038, 1.2441718578338623, -1.4129550457000732, 0.34485435485839844, -0.6415836811065674, 1.4568665027618408, 0.37844347953796387, 0.22137069702148438, -0.9457483291625977, -0.7668766975402832, 0.5803613662719727, 2.20297908782959, 1.8709702491760254, 0.5670905113220215, 1.1034443378448486, 0.3857555389404297, 1.3654260635375977, 0.3069620132446289, 2.761667490005493, 2.463182210922241, 0.2131500244140625, 1.437922477722168, -1.5912785530090332, -1.2091357707977295, -0.7260550856590271, -0.0966564416885376, -0.9675240516662598, 0.0908193588256836, -0.3820478916168213, -1.840744972229004, -2.962711811065674, -0.3638277053833008, 0.4729793965816498, 1.0296180248260498, -0.3021507263183594, 0.09953880310058594, -1.3257529735565186, -0.4022383689880371, 0.21070516109466553, 1.5321747064590454, 1.8440287113189697, -0.43662452697753906, 1.5641369819641113, 0.07290220260620117, -0.6429746150970459, 2.6244664192199707, -1.6008052825927734, -0.40834498405456543, -0.3590688705444336, 1.5740699768066406, -0.3022170066833496, -0.8734229207038879, -0.07690238952636719, -0.2153937816619873, -1.8501992225646973, 0.09686040878295898, 1.3238332271575928, -0.2095041275024414, 1.0345253944396973, 0.40279620885849, 1.4904794692993164, 0.4523963928222656, -2.68143630027771, -1.4355194568634033, -0.579344630241394, 0.01313924789428711, -1.4231752157211304, 0.7083785533905029, 0.09990096092224121, -2.0310535430908203, 0.4729793965816498, 0.45488929748535156, 1.6330029964447021, 1.9305394887924194, 1.3109647035598755, 0.6631565093994141, 2.538627862930298, -0.3590688705444336, 1.9305394887924194, 1.3040995597839355, 0.6922309398651123, -0.5009341239929199, -0.7620080709457397, -7.464605808258057, 0.7396214008331299, -1.131278157234192, -0.4993171691894531, 0.8741011619567871, 0.4558372497558594, 0.9971847534179688, -1.2094273567199707, -2.322983741760254, -1.4425190687179565, -3.2439870834350586, -5.4504008293151855, -9.659712791442871, 0.5011801719665527, -4.9117913246154785, -1.3856180906295776, -0.8217747211456299, 1.3040995597839355, 1.090542197227478, 1.9992246627807617, 0.665564775466919, -0.3624229431152344, 1.4154715538024902, -0.6784284114837646, -0.8031375408172607, 0.37481141090393066, 2.276700019836426, 1.9259438514709473, 0.691789984703064, -1.0368258953094482, 0.9903407096862793, -0.10525274276733398, 0.4729793965816498, -0.029493331909179688, -1.3395326137542725, -0.3524923324584961, 1.45599365234375, -1.3732936382293701, -0.01387166976928711, -4.608591556549072, -0.4782145619392395, 0.5288643836975098, 0.11163330078125, -0.5721535682678223, -0.8658251762390137, -0.21154630184173584, -10.078843116760254, -0.43662452697753906, 0.4506106376647949, 1.5014193058013916], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 9216, "num_env_steps_trained": 30960, "num_agent_steps_sampled": 9216, "num_agent_steps_trained": 30960, "last_target_update_ts": 9216, "num_target_updates": 17}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -189.74127238988876, "episode_reward_mean": -83.81423881691363, "episode_len_mean": 260.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5525854978053104, "mean_inference_ms": 22.334888695625782, "mean_action_processing_ms": 0.1338614055238732, "mean_env_wait_ms": 5.107112116598409, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -189.74127238988876, "episode_reward_mean": -83.81423881691363, "episode_len_mean": 260.0, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5525854978053104, "mean_inference_ms": 22.334888695625782, "mean_action_processing_ms": 0.1338614055238732, "mean_env_wait_ms": 5.107112116598409, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 9216, "num_agent_steps_trained": 30960, "num_env_steps_sampled": 9216, "num_env_steps_trained": 30960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 9216, "agent_timesteps_total": 9216, "timers": {"training_iteration_time_ms": 319.795, "learn_time_ms": 59.011, "learn_throughput": 4067.015, "synch_weights_time_ms": 18.8}, "counters": {"num_env_steps_sampled": 9216, "num_env_steps_trained": 30960, "num_agent_steps_sampled": 9216, "num_agent_steps_trained": 30960, "last_target_update_ts": 9216, "num_target_updates": 17}, "done": false, "episodes_total": 18, "training_iteration": 9, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-46", "timestamp": 1655478106, "time_this_iter_s": 5.174010753631592, "time_total_s": 45.032835483551025, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 45.032835483551025, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.599999999999998, "ram_util_percent": 58.08571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.3847980499267578, "min_q": -7.844139575958252, "max_q": 11.56182861328125, "mean_td_error": 0.02330910414457321}, "td_error": [2.434978485107422, 0.49346017837524414, 1.1584386825561523, -0.973691463470459, -1.2512097358703613, -1.0235435962677002, 1.6651432514190674, 1.5081171989440918, 0.9664294719696045, 0.8003935813903809, 0.7998292446136475, -0.44034671783447266, 2.1638259887695312, 0.8310004472732544, 0.7067427635192871, -6.335315227508545, -1.143813133239746, 0.8055191040039062, 0.6731767654418945, -7.685877799987793, 1.7485407590866089, -2.486912250518799, 0.09737968444824219, 1.8217716217041016, 0.5472104549407959, -0.1712038516998291, 0.007388114929199219, 1.6257390975952148, 1.1301933526992798, -0.32425451278686523, -1.3418350219726562, -0.671278715133667, 0.17609739303588867, 0.45804744958877563, 0.7719354629516602, -1.5501906871795654, 0.35445499420166016, 0.7660021781921387, -1.2390832901000977, -0.6832072734832764, -0.03227663040161133, -4.001570701599121, 1.5664877891540527, 2.694519519805908, -0.6250391006469727, 6.283365726470947, -0.1402721405029297, 0.48674726486206055, 1.6300573348999023, 0.18808913230895996, -0.39012575149536133, 1.0572831630706787, 0.803657054901123, 1.7747774124145508, 1.4759254455566406, 1.6997113227844238, 1.755580186843872, 0.7237534523010254, -0.0837869644165039, 1.7169713973999023, 0.7067427635192871, -0.08882617950439453, -0.7695010304450989, -1.8660802841186523, 0.6748471260070801, -4.261931419372559, -5.706247329711914, -1.8233404159545898, 1.0782546997070312, 1.271009922027588, 1.6654671430587769, -9.853312492370605, -0.1516742706298828, 0.03498345613479614, -5.458590507507324, -0.1472625732421875, 0.7284457683563232, -0.24825000762939453, 0.5882868766784668, -0.30841195583343506, 0.8959159851074219, 0.07820618152618408, 2.256138801574707, -1.578148603439331, 2.4103286266326904, 0.2760772705078125, 0.5594415664672852, 2.5266947746276855, 1.0985665321350098, -3.7647809982299805, 0.6590461730957031, -8.477149963378906, -1.0525789260864258, 0.9451198577880859, 0.7660021781921387, 0.4518418312072754, 0.7284457683563232, 0.10490402579307556, -0.4995620846748352, 0.27115726470947266, 0.7776656150817871, 0.7615447044372559, -0.9080687761306763, -1.3947467803955078, 0.5446081161499023, 0.5364731550216675, -1.352677345275879, 2.434978485107422, -0.3444967269897461, -0.39385366439819336, -1.3418025970458984, 0.6590461730957031, -0.11639618873596191, 1.751594066619873, 0.17274045944213867, 1.8290886878967285, 0.8404407501220703, -0.3048049211502075, 0.7183628082275391, -0.9468400478363037, 0.651731014251709, -0.705268383026123, 1.7850522994995117, 0.45369434356689453, 1.5664877891540527, 0.4560222625732422, 2.3783066272735596, 2.1254868507385254, 0.5486087799072266, 3.256681203842163, -11.115777015686035, -2.073517322540283, -0.20597028732299805, 0.5097732543945312, 0.8719916343688965, 0.17665672302246094, 0.6336140632629395, 1.8716599941253662, 1.1536564826965332, 0.8250350952148438, -0.7400803565979004, 0.44662296772003174, 0.11575603485107422, 0.7510647773742676, -7.302190780639648, 0.026782989501953125, 1.3203620910644531, 0.9053277969360352, -0.8582119941711426, 0.5220685005187988, -5.989859104156494, 0.11649560928344727, 0.1615796685218811, -0.9404464364051819, -0.31674957275390625, 0.6646696329116821, -0.5874490737915039, 1.755580186843872, 0.9693441390991211, -0.17122292518615723, 0.9860916137695312, 1.3048486709594727, 1.817793846130371, 0.21104049682617188, -0.782958984375, -1.7337311506271362, 0.17484521865844727, 1.7747774124145508, 0.0823049545288086, 1.1885271072387695, 0.9135713577270508, -0.855865478515625, 0.6366958618164062, 1.0248005390167236, 1.43870210647583, -0.2957644462585449, 0.5398969650268555, 1.9320154190063477, 0.2134108543395996, 0.17742013931274414, 1.0523929595947266, -1.6449146270751953, 1.5475435256958008, -0.8246588706970215, -0.8650350570678711, 0.5721116065979004, -0.02296733856201172, -0.074972003698349, 1.0921368598937988, -0.45458436012268066, 0.695868968963623, -0.9543323516845703, -0.33703094720840454, 1.0782546997070312, 0.017146170139312744, -0.4430384635925293, -1.4752895832061768, -0.6007192134857178, -2.073822259902954, 1.388134479522705, -0.008939981460571289, 2.5103797912597656, 0.5705126523971558, -7.361799240112305, 2.237034320831299, -0.39160311222076416, -0.08903074264526367, -1.070056676864624, -0.5698882341384888, -2.121575355529785, 2.1542463302612305, -7.755620002746582, 0.8719916343688965, -0.8166446685791016, 2.7319209575653076, 1.5657329559326172, -0.9574356079101562, 0.9467196464538574, 1.8204331398010254, 0.8335566520690918, 1.4468412399291992, 2.055173873901367, 2.6259078979492188, 1.430427074432373, 2.5411343574523926, 0.6240698099136353, -1.2228004932403564, 1.2634153366088867, -2.690981388092041, -0.6790802478790283, 2.005856990814209, -1.2153284549713135, 2.434978485107422, 2.5103507041931152, -1.5633858442306519, 1.7859396934509277, -4.04412841796875, 0.9231956005096436, 1.4269752502441406, -0.015371322631835938], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 10240, "num_env_steps_trained": 34800, "num_agent_steps_sampled": 10240, "num_agent_steps_trained": 34800, "last_target_update_ts": 10240, "num_target_updates": 19}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -393.1968399062753, "episode_reward_mean": -154.3747841667916, "episode_len_mean": 292.7142857142857, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5407927829460515, "mean_inference_ms": 22.382107446041204, "mean_action_processing_ms": 0.1332786921111537, "mean_env_wait_ms": 4.849979621216095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -393.1968399062753, "episode_reward_mean": -154.3747841667916, "episode_len_mean": 292.7142857142857, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5407927829460515, "mean_inference_ms": 22.382107446041204, "mean_action_processing_ms": 0.1332786921111537, "mean_env_wait_ms": 4.849979621216095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 10240, "num_agent_steps_trained": 34800, "num_env_steps_sampled": 10240, "num_env_steps_trained": 34800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 10240, "agent_timesteps_total": 10240, "timers": {"training_iteration_time_ms": 328.643, "learn_time_ms": 59.376, "learn_throughput": 4042.061, "synch_weights_time_ms": 20.588}, "counters": {"num_env_steps_sampled": 10240, "num_env_steps_trained": 34800, "num_agent_steps_sampled": 10240, "num_agent_steps_trained": 34800, "last_target_update_ts": 10240, "num_target_updates": 19}, "done": false, "episodes_total": 28, "training_iteration": 10, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-52", "timestamp": 1655478112, "time_this_iter_s": 5.465392589569092, "time_total_s": 50.49822807312012, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 50.49822807312012, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.925, "ram_util_percent": 58.375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.9197919368743896, "min_q": -8.55793285369873, "max_q": 13.437397956848145, "mean_td_error": 0.07210449874401093}, "td_error": [-4.460416793823242, 1.0627005100250244, -0.8051295280456543, 0.7751116752624512, 0.6442705988883972, 0.9239733219146729, 1.0173687934875488, 3.053046226501465, -1.2401752471923828, 3.303485870361328, -1.7211953401565552, -5.7566118240356445, -10.443612098693848, 2.1748507022857666, 1.8611843585968018, 1.1452263593673706, -1.271916389465332, -0.9043197631835938, 1.2636699676513672, 0.06252431869506836, 2.761378526687622, -5.813071250915527, 3.7004332542419434, 0.3294168710708618, -7.285335540771484, -0.5009145736694336, 1.4663000106811523, 0.893885612487793, 0.42887213826179504, -5.951910018920898, -0.434924840927124, -0.8648920059204102, 1.2989704608917236, 0.06476974487304688, 0.5131664276123047, 1.5435547828674316, -7.110785484313965, 1.2989704608917236, 0.7175631523132324, 0.963068962097168, 0.0016998648643493652, -0.1613330841064453, 0.9609112739562988, 2.541627883911133, 0.893885612487793, 3.361647129058838, 1.147481918334961, -0.04057943820953369, -0.7850210666656494, 0.693058967590332, -0.1403675079345703, 0.2878570556640625, 0.5397272109985352, -1.1217126846313477, 0.5184197425842285, 0.4381589889526367, 0.9485354423522949, -1.8881335258483887, -5.878252029418945, 0.6337594985961914, 0.04978513717651367, 0.21666812896728516, 0.693058967590332, -0.1574721336364746, -0.9702976942062378, 0.3272528648376465, 3.273332118988037, 1.998311996459961, -1.0691900253295898, 2.23392915725708, 0.42542266845703125, 0.27313530445098877, 1.138223648071289, 0.1190151572227478, -7.669021129608154, 0.3610248565673828, -1.2961115837097168, 0.07070934772491455, -0.3874087333679199, 0.9408183097839355, 1.0938483476638794, -0.6282711029052734, 0.8209033012390137, 3.249509811401367, 1.0923652648925781, 2.194693088531494, 0.7357382774353027, -0.21791505813598633, 1.998311996459961, 0.5931620597839355, -2.4417810440063477, 1.652886152267456, 1.44511079788208, -0.7694187164306641, -1.0592260360717773, 0.2986311912536621, 0.9147406220436096, 2.169185161590576, 0.27466630935668945, 0.35520362854003906, 0.7413558959960938, -4.867390155792236, 3.3767900466918945, 1.2213103771209717, 1.8984708786010742, -1.3199548721313477, 0.35520362854003906, 0.7841262817382812, 1.911348581314087, -0.20989170670509338, -3.234622001647949, 1.8238800764083862, 0.01506948471069336, 2.0425519943237305, -0.9856209754943848, 1.117842197418213, 1.8238800764083862, 0.03495979309082031, 1.7797966003417969, 2.5991992950439453, 1.1359186172485352, -7.392647743225098, 0.6346292495727539, 0.43271827697753906, -0.31305503845214844, 1.1619648933410645, 0.7987384796142578, -0.8776764869689941, 0.43982887268066406, 2.4056215286254883, 1.0594916343688965, -1.9845569133758545, 1.147481918334961, 0.003238201141357422, 0.893885612487793, -0.7795305252075195, -4.030779838562012, 1.3748154640197754, 0.03175997734069824, -1.301952838897705, -7.138968467712402, -0.29411935806274414, -0.3472721576690674, -0.9851529598236084, 0.7615506649017334, -0.2656736373901367, 1.2496981620788574, 0.7264847755432129, 2.08864688873291, 1.8802516460418701, -0.7399635314941406, 0.8119988441467285, -4.945586204528809, -0.13051557540893555, -0.04057943820953369, 2.7525789737701416, 1.7263305187225342, 2.169602394104004, -0.5380086898803711, 0.5142040252685547, -7.507744789123535, -4.2637434005737305, 1.0825300216674805, 1.0328361988067627, 1.9498653411865234, -0.7785758972167969, 1.724684715270996, 0.36128973960876465, 1.6256005764007568, 1.050990104675293, -1.7464516162872314, -0.06396245956420898, 0.9674835205078125, 2.90655517578125, -0.3377494812011719, 0.3295755386352539, -0.4563913345336914, -3.4176340103149414, 0.997730553150177, 1.8589839935302734, -1.1024141311645508, -0.04396200180053711, -0.11464309692382812, -0.8051295280456543, -0.8046779632568359, 2.8213047981262207, 0.10620355606079102, 0.5955538749694824, -0.14240598678588867, 2.301807165145874, 0.2772202491760254, -0.03675079345703125, 1.3153033256530762, -2.8813490867614746, 0.8108291625976562, 2.1879868507385254, 1.4250822067260742, 0.9606504440307617, 1.3412067890167236, 3.111103057861328, -1.040798306465149, 0.9186692237854004, -0.02292346954345703, 0.7870782613754272, -0.04313468933105469, 0.8246850967407227, -1.8621680736541748, 0.09553337097167969, 0.8580913543701172, -1.2716553211212158, -0.6177101135253906, 0.40184545516967773, 2.773066520690918, 2.0616703033447266, 0.1443157196044922, 0.6992111206054688, -0.11464309692382812, -0.2772250175476074, -0.3033735752105713, 0.04950761795043945, -2.0701096057891846, 0.3693580627441406, 0.6424241065979004, 0.7357382774353027, 1.6688611507415771, 1.758068561553955, 0.840773344039917, 1.3757338523864746, -0.9504175186157227, 0.7016239166259766, -1.290092945098877, -9.696770668029785, 1.0205525159835815, 0.5641260147094727, 1.8473005294799805, 1.9423222541809082, -0.26947736740112305, -0.24314165115356445, 2.0569868087768555, 2.601229667663574], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 11264, "num_env_steps_trained": 38640, "num_agent_steps_sampled": 11264, "num_agent_steps_trained": 38640, "last_target_update_ts": 11264, "num_target_updates": 21}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.63488826691173, "episode_len_mean": 304.21875, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5352657507828983, "mean_inference_ms": 22.437767340591343, "mean_action_processing_ms": 0.1348277575301585, "mean_env_wait_ms": 4.783148296157888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.63488826691173, "episode_len_mean": 304.21875, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5352657507828983, "mean_inference_ms": 22.437767340591343, "mean_action_processing_ms": 0.1348277575301585, "mean_env_wait_ms": 4.783148296157888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 11264, "num_agent_steps_trained": 38640, "num_env_steps_sampled": 11264, "num_env_steps_trained": 38640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 11264, "agent_timesteps_total": 11264, "timers": {"training_iteration_time_ms": 319.76, "learn_time_ms": 60.491, "learn_throughput": 3967.538, "synch_weights_time_ms": 19.59}, "counters": {"num_env_steps_sampled": 11264, "num_env_steps_trained": 38640, "num_agent_steps_sampled": 11264, "num_agent_steps_trained": 38640, "last_target_update_ts": 11264, "num_target_updates": 21}, "done": false, "episodes_total": 32, "training_iteration": 11, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-01-57", "timestamp": 1655478117, "time_this_iter_s": 5.2186362743377686, "time_total_s": 55.716864347457886, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 55.716864347457886, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.9625, "ram_util_percent": 58.4875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.1078484058380127, "min_q": -10.25784969329834, "max_q": 13.569300651550293, "mean_td_error": 0.298340380191803}, "td_error": [0.08868408203125, 1.0423479080200195, 2.6733663082122803, 2.5951972007751465, 0.08053350448608398, -0.0313568115234375, 2.0902767181396484, -1.7040197849273682, 1.2956724166870117, -0.12099111080169678, 0.4045705795288086, -0.606041431427002, 1.0092458724975586, -0.8754115104675293, 0.5138592720031738, 2.952162265777588, 0.3557319641113281, 1.4606809616088867, 1.5841801166534424, 0.5014047622680664, 3.127265691757202, 1.1599457263946533, 0.10810184478759766, -2.0107462406158447, 2.702633857727051, 2.660719871520996, -4.521028518676758, 0.8046948909759521, 0.2850918769836426, 0.6804075241088867, 1.7119388580322266, -2.215700149536133, -0.45851993560791016, 0.955986499786377, 0.3856196403503418, 1.7245583534240723, 1.038316249847412, -0.07267546653747559, 0.7288885116577148, 0.7989892959594727, -2.044079303741455, 0.13780784606933594, 0.11778450012207031, 1.172119140625, 1.166680097579956, -0.09541702270507812, -10.668161392211914, 0.9540252685546875, -3.138030529022217, 0.7397373914718628, 1.7324962615966797, 0.8444555401802063, -0.9047603607177734, -0.12186527252197266, 0.15282511711120605, 2.6174514293670654, 3.3604016304016113, 0.38169431686401367, 1.4492073059082031, -0.28429222106933594, 0.42327260971069336, -8.407915115356445, -0.4023728370666504, 1.766080617904663, 0.37529468536376953, -0.9463338851928711, 0.4461841583251953, -0.005964159965515137, 0.15524864196777344, -0.06697750091552734, 0.6478943824768066, 0.7581660747528076, 1.1719191074371338, -0.40173864364624023, -6.614437103271484, 2.757814407348633, -0.406154990196228, -0.7253203392028809, -4.376930236816406, 2.065739631652832, 3.984701156616211, 0.2482316493988037, 3.173552989959717, 3.641996383666992, -1.399667739868164, -1.9461803436279297, 0.4969205856323242, 0.299346923828125, -5.110401153564453, 1.809952735900879, 1.7827472686767578, 2.3740055561065674, -0.6620573997497559, 0.6491069793701172, 3.752855062484741, -6.472873687744141, 3.343992233276367, 2.7302825450897217, 0.7150249481201172, -0.6907854080200195, -0.9018938541412354, 1.8588371276855469, 0.9165153503417969, 1.0874662399291992, -0.3983297348022461, 0.5955147743225098, -0.10163545608520508, 0.4027538299560547, 0.7858388423919678, 1.2329702377319336, 1.332977294921875, 1.0641002655029297, -5.8468732833862305, -5.971075534820557, -0.4342925548553467, 0.5711185932159424, 0.1249246597290039, -0.1990489959716797, -0.9113030433654785, -0.03698873519897461, -5.065438270568848, -0.6207733154296875, -0.7092781066894531, 0.9152731895446777, -1.0004522800445557, -2.6198081970214844, 0.610565185546875, 1.6656780242919922, 1.9357779026031494, 0.9295578002929688, 0.16682720184326172, -0.8409098982810974, 1.3785123825073242, -0.05984306335449219, 0.5314927101135254, -1.517566204071045, 0.9919157028198242, 0.87255859375, 2.3180673122406006, 1.430506706237793, 3.111161470413208, 0.22233152389526367, 0.8929872512817383, 2.0027880668640137, 1.246445655822754, 1.521742820739746, 2.757814407348633, 0.004916191101074219, 1.698927879333496, 0.18201693892478943, 1.6696586608886719, 0.36142492294311523, 0.4927959442138672, -0.5877151489257812, -0.12166976928710938, 0.27696800231933594, 1.1361298561096191, 1.9594573974609375, 1.2232980728149414, -5.230849266052246, 0.5771389007568359, 2.766491413116455, -1.310743808746338, 0.5314927101135254, 1.7421412467956543, 2.2300286293029785, 1.9692211151123047, 1.1183264255523682, 3.984701156616211, 1.338017463684082, 0.34293532371520996, 0.8404049873352051, 1.4977664947509766, 5.3501386642456055, -8.565817832946777, 2.0926356315612793, 1.9320778846740723, 1.1637067794799805, 0.8488454818725586, 0.2938995361328125, 0.19745850563049316, 2.0674571990966797, 0.030507564544677734, 2.0867321491241455, 1.8136472702026367, 2.4821157455444336, 1.0092458724975586, -0.5639104843139648, 2.3190512657165527, 1.5191564559936523, -0.3597736358642578, 2.4175899028778076, -1.007568120956421, 0.3557319641113281, 1.4707562923431396, -1.7032809257507324, -0.09084510803222656, 0.845881462097168, 0.011032938957214355, -0.728208065032959, 0.6262378692626953, 1.0641002655029297, 3.866767168045044, -4.793524265289307, -3.950868844985962, -0.7266969680786133, 1.4692915678024292, -3.4711623191833496, 0.03733491897583008, 2.595590829849243, -1.352778434753418, -0.22381210327148438, 2.5298728942871094, -0.12099111080169678, 0.6521196365356445, 0.10683822631835938, 0.6395196914672852, -0.9467155933380127, 1.1111044883728027, 1.8970656394958496, 0.7963075637817383, 1.2308969497680664, 3.346414089202881, -0.05175018310546875, 1.172119140625, 0.7963075637817383, 1.1051483154296875, -1.570305347442627, -10.668161392211914, 0.1463603973388672, -0.04981964826583862, 1.4647912979125977, 0.12581348419189453, -1.822204828262329, 1.9817912578582764, 0.5964791774749756, 0.49545764923095703, 0.7703189849853516, 1.1784944534301758, -0.08199787139892578], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 12288, "num_env_steps_trained": 42480, "num_agent_steps_sampled": 12288, "num_agent_steps_trained": 42480, "last_target_update_ts": 12288, "num_target_updates": 23}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.63488826691173, "episode_len_mean": 304.21875, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5352657507828983, "mean_inference_ms": 22.437767340591343, "mean_action_processing_ms": 0.1348277575301585, "mean_env_wait_ms": 4.783148296157888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.63488826691173, "episode_len_mean": 304.21875, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5352657507828983, "mean_inference_ms": 22.437767340591343, "mean_action_processing_ms": 0.1348277575301585, "mean_env_wait_ms": 4.783148296157888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 12288, "num_agent_steps_trained": 42480, "num_env_steps_sampled": 12288, "num_env_steps_trained": 42480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 12288, "agent_timesteps_total": 12288, "timers": {"training_iteration_time_ms": 309.288, "learn_time_ms": 59.696, "learn_throughput": 4020.339, "synch_weights_time_ms": 19.594}, "counters": {"num_env_steps_sampled": 12288, "num_env_steps_trained": 42480, "num_agent_steps_sampled": 12288, "num_agent_steps_trained": 42480, "last_target_update_ts": 12288, "num_target_updates": 23}, "done": false, "episodes_total": 32, "training_iteration": 12, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-02", "timestamp": 1655478122, "time_this_iter_s": 5.049945831298828, "time_total_s": 60.766810178756714, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 60.766810178756714, "timesteps_since_restore": 0, "iterations_since_restore": 12, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.471428571428575, "ram_util_percent": 58.557142857142864}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.29429036378860474, "min_q": -13.140204429626465, "max_q": 14.959900856018066, "mean_td_error": -1.080474615097046}, "td_error": [0.3741779327392578, 1.277017593383789, -1.0967578887939453, 1.0821666717529297, -8.389450073242188, 0.5655117034912109, -1.9467964172363281, -1.615365982055664, -2.0972023010253906, -2.136594772338867, -0.9501329660415649, -0.42259693145751953, -3.4516162872314453, -0.5504550933837891, -12.209012985229492, -1.0622844696044922, 0.1802746057510376, 0.2773573398590088, -5.952487945556641, 0.259918212890625, -0.7064580917358398, -0.35633647441864014, -0.8627724647521973, -0.6881669759750366, 0.09583568572998047, -8.962020874023438, -0.11590445041656494, -0.01466822624206543, -0.9202876091003418, -1.758571743965149, -4.511080741882324, -0.48601341247558594, 0.1850452423095703, -0.9800597429275513, 0.9101247787475586, -2.181704044342041, -1.4944052696228027, -0.31265878677368164, -8.359718322753906, -5.908417701721191, 0.4849294126033783, 0.9333100318908691, 1.2812070846557617, -1.6743144989013672, -0.5494318008422852, -1.4667091369628906, -0.10257911682128906, -8.191967010498047, -9.00475788116455, -1.3462557792663574, -2.3403773307800293, 0.011724114418029785, -1.0840201377868652, -0.3064250946044922, 0.1954798698425293, -1.0954298973083496, 0.0814371109008789, -0.10882186889648438, 1.2799677848815918, 0.5583772659301758, 0.8336477279663086, -0.6724252700805664, -1.5020751953125, -0.0964193344116211, -1.5237542390823364, -0.4592704772949219, 0.4331636428833008, -0.3102703094482422, -0.3627803325653076, -1.7777009010314941, -0.20585668087005615, 0.10821247100830078, -9.354188919067383, -1.8358638286590576, 1.0156240463256836, -1.8426389694213867, -1.0483245849609375, -2.9096202850341797, -1.2866712808609009, 0.4260725975036621, -1.9369659423828125, 0.984044075012207, -8.389450073242188, -0.3248262405395508, -0.12239837646484375, 1.8381376266479492, -0.7113423347473145, -0.8337001800537109, -1.2232160568237305, 0.40596675872802734, -8.045952796936035, 0.6611270904541016, -0.00543975830078125, -1.0967578887939453, -2.5528295040130615, 0.6918895244598389, 0.20275592803955078, 0.134954571723938, -0.7260360717773438, 0.9788050651550293, -2.881878137588501, -0.01466822624206543, 2.6092844009399414, 1.2965717315673828, -3.01615047454834, 0.2623128890991211, -0.10907173156738281, -0.7064580917358398, 0.6611270904541016, -0.2117919921875, -0.652052640914917, -0.7012443542480469, -0.4037792682647705, -0.8145253658294678, -0.2552928924560547, -0.07679510116577148, -1.8007922172546387, 0.15474891662597656, -8.055727005004883, 2.339299440383911, -0.1966053545475006, -3.723951816558838, -1.2153346538543701, -0.9567375183105469, -2.446852207183838, -1.81097412109375, 1.7696781158447266, -1.3898062705993652, -0.1099843978881836, 1.0259292125701904, 1.2522398233413696, -1.887497901916504, -1.491614818572998, 0.5456857681274414, -0.9936771988868713, -1.3886475563049316, 1.0742530822753906, -0.23217999935150146, -1.0954298973083496, -0.39237117767333984, -0.7469315528869629, -0.8427925109863281, -0.20770502090454102, -1.0875680446624756, -3.559983968734741, -0.9800597429275513, -0.6881669759750366, -0.28685855865478516, 1.2411508560180664, -1.793208122253418, -6.470045566558838, -0.7213406562805176, -9.472602844238281, 0.15793991088867188, -0.39809274673461914, -1.3183021545410156, -0.03441476821899414, -0.37868547439575195, 1.9100135564804077, -8.10660171508789, 0.8028616905212402, -0.2770700454711914, -0.7454586029052734, -2.3236823081970215, -0.47277259826660156, 0.09491872787475586, -0.7642374038696289, -0.6703853607177734, 1.277017593383789, 0.18030261993408203, -1.3153960704803467, -0.6679630279541016, -0.09109210968017578, -1.5206832885742188, -3.408034324645996, -0.5066184997558594, -1.677851676940918, 6.512421607971191, -0.8655386567115784, -2.805161952972412, 1.0742530822753906, 1.0847318172454834, -0.23264825344085693, 2.329352378845215, -1.2693068981170654, 0.42362380027770996, -0.11698532104492188, -0.6281375885009766, 0.3917497396469116, -0.3972005844116211, -1.1992299556732178, -0.1408909559249878, 1.6233844757080078, -3.9819416999816895, -0.19539928436279297, 0.2555348873138428, -1.0954298973083496, -5.765905380249023, -1.6423873901367188, -0.9262244701385498, -0.6827747821807861, -2.8166403770446777, -1.4390411376953125, -1.5664119720458984, 0.2597503662109375, -1.0875680446624756, -0.0964193344116211, -2.3761730194091797, -8.574557304382324, -0.3947334289550781, 0.5137512683868408, -2.003960132598877, 1.2333099842071533, 0.5212588310241699, -5.512012004852295, 0.19921636581420898, -0.3162040710449219, -0.7572524547576904, -0.29988574981689453, 0.4260725975036621, -0.3460097312927246, 0.5459151268005371, -1.2229335308074951, 0.698661208152771, -1.037895679473877, -0.4972653388977051, -0.6969466209411621, 1.0450215339660645, -0.32511043548583984, -1.3918607234954834, -1.3450937271118164, 0.7057552337646484, -0.7538728713989258, 0.8967642784118652, -0.12239837646484375, 0.46343135833740234, -0.8549008369445801, -5.980611801147461, -1.5615053176879883, -3.104677200317383], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 13312, "num_env_steps_trained": 46320, "num_agent_steps_sampled": 13312, "num_agent_steps_trained": 46320, "last_target_update_ts": 13312, "num_target_updates": 25}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.9953938900973, "episode_len_mean": 304.6060606060606, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5358797721312527, "mean_inference_ms": 22.46727151340933, "mean_action_processing_ms": 0.1351054947834657, "mean_env_wait_ms": 4.778702614916352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.9953938900973, "episode_len_mean": 304.6060606060606, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5358797721312527, "mean_inference_ms": 22.46727151340933, "mean_action_processing_ms": 0.1351054947834657, "mean_env_wait_ms": 4.778702614916352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 13312, "num_agent_steps_trained": 46320, "num_env_steps_sampled": 13312, "num_env_steps_trained": 46320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 13312, "agent_timesteps_total": 13312, "timers": {"training_iteration_time_ms": 328.45, "learn_time_ms": 60.274, "learn_throughput": 3981.792, "synch_weights_time_ms": 20.389}, "counters": {"num_env_steps_sampled": 13312, "num_env_steps_trained": 46320, "num_agent_steps_sampled": 13312, "num_agent_steps_trained": 46320, "last_target_update_ts": 13312, "num_target_updates": 25}, "done": false, "episodes_total": 33, "training_iteration": 13, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-08", "timestamp": 1655478128, "time_this_iter_s": 5.1556713581085205, "time_total_s": 65.92248153686523, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 65.92248153686523, "timesteps_since_restore": 0, "iterations_since_restore": 13, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.875, "ram_util_percent": 58.712500000000006}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.6541407108306885, "min_q": -15.346635818481445, "max_q": 15.783989906311035, "mean_td_error": -1.0898162126541138}, "td_error": [-0.8114757537841797, -0.2563619613647461, -7.451539993286133, -6.596412181854248, -0.713326096534729, -0.9382755756378174, -1.2794246673583984, -0.18890905380249023, -0.058234572410583496, -0.033782005310058594, 0.11701583862304688, -0.29697322845458984, 0.8921451568603516, -10.087013244628906, -1.1127862930297852, -0.5819177627563477, 0.09636402130126953, -0.031670570373535156, -1.1951408386230469, -0.6642608642578125, 1.4658565521240234, 0.5950279235839844, -0.9125375747680664, -1.0756855010986328, -0.21351957321166992, -1.002375602722168, -1.0047688484191895, -0.8296578526496887, 0.5311524868011475, 0.6279773712158203, -0.0223236083984375, -1.249983787536621, -0.7997255325317383, -1.6550101041793823, -0.5916967391967773, -1.5093989372253418, 0.13576284050941467, -0.522099494934082, 0.3923063278198242, -1.0698294639587402, -0.8902063369750977, -3.764942169189453, 0.5287389755249023, -0.8648557662963867, -0.07371330261230469, -2.6181812286376953, -1.116490364074707, -8.656631469726562, 0.1594099998474121, -1.9822444915771484, -1.2650747299194336, -1.6638628244400024, -2.446709156036377, -0.5820517539978027, 0.15671539306640625, 0.5801725387573242, 0.5950279235839844, -0.8732352256774902, -0.5279455184936523, -7.738763332366943, -0.7817144393920898, 2.174785614013672, -1.029210090637207, -0.4736671447753906, 0.0030965805053710938, -0.8078174591064453, 0.4369196891784668, -0.847327709197998, 0.20567941665649414, -0.04783439636230469, -1.5079586505889893, -1.0169199705123901, 0.054943084716796875, -4.39281702041626, -11.694660186767578, -0.7037248611450195, -0.7202138900756836, -0.9691009521484375, 0.12091541290283203, -4.424738883972168, -0.43242955207824707, 0.8272743225097656, -0.7112388610839844, -3.2902421951293945, -1.5093989372253418, -0.7171027660369873, 0.8787946701049805, -1.6971421241760254, -0.48164236545562744, 0.6903600692749023, -1.3944892883300781, -0.7037248611450195, 0.04690694808959961, -0.28682518005371094, -0.6409235000610352, -1.3153718709945679, 0.7778730392456055, -1.0271142721176147, 1.8452777862548828, -2.496598720550537, -0.4637565612792969, -0.41535472869873047, -2.2823708057403564, -1.3042936325073242, -0.5689620971679688, -2.155095100402832, 1.2766590118408203, -0.5411176681518555, -1.2955284118652344, -8.527931213378906, 0.2935643196105957, 1.0888763666152954, 0.5063209533691406, 0.5950279235839844, -0.3074040412902832, -1.2436351776123047, 1.1631956100463867, -1.2592792510986328, -0.9181861877441406, -0.7839503288269043, -0.6303977966308594, -2.0639255046844482, -6.708804130554199, -1.9575729370117188, -0.37419557571411133, -0.7147927284240723, -0.06562137603759766, 1.2640976905822754, 0.5820035934448242, 0.0054111480712890625, 0.09841537475585938, -0.7540717124938965, -0.926386833190918, -6.48211145401001, -1.1906471252441406, -0.663914680480957, -1.1036386489868164, -2.381112813949585, -0.22161006927490234, -4.831049919128418, -8.861639022827148, -1.029210090637207, -0.8527607917785645, -0.21484375, -0.7147927284240723, -1.0843515396118164, 3.0529932975769043, 0.8001346588134766, -0.8113946914672852, 0.2459583282470703, -0.8477249145507812, -0.6371784210205078, -0.4627389907836914, -0.7839503288269043, -0.1640005111694336, -2.2592220306396484, -2.180469512939453, 0.5950279235839844, 1.8452777862548828, -0.08354473114013672, -0.12030792236328125, 0.2834343910217285, -0.7892208099365234, -0.5376729965209961, -0.9382755756378174, -1.1127862930297852, -2.0990657806396484, -1.1333198547363281, -0.907076358795166, -1.2506189346313477, -1.1734793186187744, 0.5129575729370117, -2.3759660720825195, 0.5053472518920898, -6.63615083694458, 0.7778730392456055, -0.3328121304512024, 0.5016489028930664, 0.06500935554504395, 0.6332225799560547, -1.1691324710845947, 0.11231517791748047, -1.848215103149414, -1.3022202253341675, -4.273639678955078, -0.17539501190185547, 0.9047708511352539, -1.9607019424438477, -2.795971155166626, -6.626734733581543, -0.8012847900390625, -0.4622917175292969, -1.2755441665649414, -1.2325443029403687, -7.540643692016602, -0.7558873891830444, 1.6428203582763672, -0.0700235366821289, -1.5801982879638672, -2.0948729515075684, -0.43452930450439453, -2.698748826980591, -3.3720219135284424, -0.6607785224914551, 0.5028324127197266, -1.5252628326416016, -6.6933159828186035, -0.19885730743408203, 0.20786285400390625, -1.6156625747680664, 1.2173137664794922, -3.857588768005371, 0.2672119140625, -1.3359708786010742, 0.3764371871948242, -1.9838132858276367, 0.2753915786743164, -2.506422519683838, -0.531226634979248, -0.04876422882080078, 1.6984331607818604, 3.18001127243042, 2.1413373947143555, -0.702333927154541, -0.26506948471069336, -0.8926811218261719, -1.1045303344726562, -8.196565628051758, -0.45238780975341797, -5.790355682373047, -0.615480899810791, -0.3327350616455078, -0.24677801132202148, -0.41644716262817383, -0.2950153350830078, -1.4208295345306396, 0.1695866584777832, -1.8122987747192383, -1.0734727382659912, 0.6383543014526367], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 14336, "num_env_steps_trained": 50160, "num_agent_steps_sampled": 14336, "num_agent_steps_trained": 50160, "last_target_update_ts": 14336, "num_target_updates": 27}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.9953938900973, "episode_len_mean": 304.6060606060606, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5358797721312527, "mean_inference_ms": 22.46727151340933, "mean_action_processing_ms": 0.1351054947834657, "mean_env_wait_ms": 4.778702614916352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -182.9953938900973, "episode_len_mean": 304.6060606060606, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5358797721312527, "mean_inference_ms": 22.46727151340933, "mean_action_processing_ms": 0.1351054947834657, "mean_env_wait_ms": 4.778702614916352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 14336, "num_agent_steps_trained": 50160, "num_env_steps_sampled": 14336, "num_env_steps_trained": 50160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 14336, "agent_timesteps_total": 14336, "timers": {"training_iteration_time_ms": 338.938, "learn_time_ms": 59.97, "learn_throughput": 4002.004, "synch_weights_time_ms": 19.989}, "counters": {"num_env_steps_sampled": 14336, "num_env_steps_trained": 50160, "num_agent_steps_sampled": 14336, "num_agent_steps_trained": 50160, "last_target_update_ts": 14336, "num_target_updates": 27}, "done": false, "episodes_total": 33, "training_iteration": 14, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-13", "timestamp": 1655478133, "time_this_iter_s": 5.290474891662598, "time_total_s": 71.21295642852783, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 71.21295642852783, "timesteps_since_restore": 0, "iterations_since_restore": 14, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.41428571428572, "ram_util_percent": 58.82857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.5278959274291992, "min_q": -16.028635025024414, "max_q": 18.018268585205078, "mean_td_error": -0.35285434126853943}, "td_error": [0.6524105072021484, 0.27374267578125, 0.36221885681152344, -0.8702435493469238, -0.010288715362548828, -4.8577165603637695, 0.742457389831543, 0.991304874420166, 1.6521625518798828, 0.03579521179199219, -0.3352489471435547, 1.5307178497314453, -1.9583067893981934, -0.6034622192382812, 1.0455923080444336, 1.6192388534545898, 0.07870924472808838, -0.1460651159286499, 0.27374267578125, 0.5882431268692017, -0.2853851318359375, -5.081445693969727, 0.5835886001586914, -0.8339525461196899, -0.09801393747329712, 0.27845287322998047, 1.2399425506591797, -1.3884859085083008, -1.9731521606445312, -0.26929378509521484, 0.5595922470092773, -1.7189490795135498, 0.8565435409545898, 0.6753506660461426, -0.2101583480834961, 0.6524105072021484, 0.9517014026641846, -1.1866503953933716, 1.6639518737792969, 0.3782806396484375, 1.6769771575927734, 1.3521767854690552, 0.47444820404052734, 0.4850492477416992, 0.22869014739990234, 0.7550907135009766, -0.4525632858276367, 2.0030250549316406, 0.49940967559814453, 0.593658447265625, 1.2261962890625, 2.090789794921875, 0.41021955013275146, 0.38484954833984375, -9.753825187683105, -0.4213237762451172, -0.7089300155639648, 0.9856767654418945, -0.9053421020507812, -0.702977180480957, 0.17977285385131836, 2.2441623210906982, 0.1673727035522461, -7.7604451179504395, 1.67439603805542, 0.2916526794433594, -2.6460652351379395, 1.2072460651397705, -1.0662651062011719, 1.6500892639160156, 1.7292224168777466, 0.4634366035461426, -0.8936481475830078, 0.2901725769042969, 0.36460113525390625, 0.42282962799072266, 0.40676403045654297, 1.9243059158325195, 1.1493806838989258, 1.869950532913208, 0.18588268756866455, -1.1773343086242676, -0.26302552223205566, 0.8051023483276367, 0.35528564453125, -0.2908363342285156, 0.9597835540771484, 0.6307096481323242, -0.006534576416015625, -0.9761650562286377, -0.839363694190979, 1.1215124130249023, 0.7835094928741455, 2.3234286308288574, 0.4850492477416992, 0.3497958183288574, 1.75732421875, 0.9430971145629883, 1.021932601928711, -0.49080848693847656, 0.5427913665771484, -1.244236946105957, 0.2699880599975586, 1.0490570068359375, 2.3005943298339844, -5.365321159362793, -0.6832723617553711, 1.190800666809082, 0.24380874633789062, 0.7817115783691406, 0.8981056213378906, 2.0523130893707275, 0.7146567106246948, 0.5610723495483398, -6.465004920959473, -0.4701509475708008, -0.9211620092391968, 0.0946969985961914, 0.1162109375, -4.278765678405762, -1.114372968673706, 0.02620553970336914, -1.2773211002349854, 0.741368293762207, -0.7130308151245117, -1.0258331298828125, 1.7821292877197266, 0.4887990951538086, -8.743003845214844, 2.002579689025879, 0.11653375625610352, 0.7617149353027344, 1.273069143295288, -1.7270088195800781, 1.8469018936157227, 0.062197208404541016, 0.6803510189056396, 0.17386817932128906, -2.6443862915039062, 0.8279037475585938, 0.47185707092285156, -0.5562996864318848, 1.1762847900390625, 0.5226078033447266, -1.1004199981689453, -0.42177581787109375, 0.1162109375, -0.9702686071395874, -5.206672668457031, -0.9341771602630615, -1.0465295314788818, 0.9856767654418945, -0.9428195953369141, -0.7556986808776855, -1.8361515998840332, 1.1686381101608276, -2.347496509552002, 0.20600080490112305, 0.8098349571228027, -0.26302552223205566, 1.017364501953125, 0.41021955013275146, -0.49651241302490234, 0.529820442199707, 0.6297817230224609, -0.8736560344696045, 0.0381770133972168, -1.1984272003173828, -0.48685240745544434, 1.7903242111206055, -0.13204526901245117, -2.181321144104004, 0.7061252593994141, -1.5915746688842773, 0.24563980102539062, -0.20281195640563965, 0.6654982566833496, 0.8238539695739746, -3.5594701766967773, -7.150557994842529, -6.399012565612793, 1.0615148544311523, 1.4132614135742188, -1.5934998989105225, -2.3509469032287598, 0.03715229034423828, 0.6524105072021484, -1.2937999963760376, -0.4629030227661133, 0.6816310882568359, 0.690098762512207, -13.862207412719727, -1.0005979537963867, -0.2792210578918457, 1.7411565780639648, -7.687500953674316, 0.2897806167602539, -1.8601531982421875, -6.960319519042969, 0.26583003997802734, 0.4850492477416992, 1.0490570068359375, -0.20000243186950684, -2.1363162994384766, -0.1460651159286499, -0.6285390853881836, -0.1802072525024414, -0.006258964538574219, 1.4032573699951172, 0.9905061721801758, 1.4631452560424805, -4.943622589111328, 0.2544708251953125, -0.1664344072341919, 1.5191179513931274, 0.7939962148666382, 0.47629499435424805, 0.24380874633789062, 1.0250561237335205, 0.2900114059448242, -0.1167898178100586, -2.542059898376465, -1.6860103607177734, 1.2881324291229248, 0.33824634552001953, 0.40607643127441406, 2.046114921569824, 1.028688907623291, -1.383232593536377, 0.26439857482910156, 0.5920352935791016, 0.8301725387573242, -10.498869895935059, 1.9692573547363281, 1.3162126541137695, 0.3501152992248535, -2.384766101837158, -9.753825187683105, 0.2410440444946289, -2.0728025436401367], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 15360, "num_env_steps_trained": 54000, "num_agent_steps_sampled": 15360, "num_agent_steps_trained": 54000, "last_target_update_ts": 15360, "num_target_updates": 29}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -200.16946001017564, "episode_len_mean": 310.8157894736842, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5340429081349372, "mean_inference_ms": 22.608514018709432, "mean_action_processing_ms": 0.1346807688435054, "mean_env_wait_ms": 4.7164705421544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -415.4468524828553, "episode_reward_mean": -200.16946001017564, "episode_len_mean": 310.8157894736842, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5340429081349372, "mean_inference_ms": 22.608514018709432, "mean_action_processing_ms": 0.1346807688435054, "mean_env_wait_ms": 4.7164705421544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 15360, "num_agent_steps_trained": 54000, "num_env_steps_sampled": 15360, "num_env_steps_trained": 54000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 15360, "agent_timesteps_total": 15360, "timers": {"training_iteration_time_ms": 356.411, "learn_time_ms": 59.957, "learn_throughput": 4002.896, "synch_weights_time_ms": 20.086}, "counters": {"num_env_steps_sampled": 15360, "num_env_steps_trained": 54000, "num_agent_steps_sampled": 15360, "num_agent_steps_trained": 54000, "last_target_update_ts": 15360, "num_target_updates": 29}, "done": false, "episodes_total": 38, "training_iteration": 15, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-19", "timestamp": 1655478139, "time_this_iter_s": 5.541417360305786, "time_total_s": 76.75437378883362, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 76.75437378883362, "timesteps_since_restore": 0, "iterations_since_restore": 15, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.837500000000002, "ram_util_percent": 58.912499999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.6709901094436646, "min_q": -18.110614776611328, "max_q": 18.929601669311523, "mean_td_error": -0.6981834173202515}, "td_error": [1.1305689811706543, 1.1746430397033691, 1.426216959953308, 0.0351099967956543, 8.990357398986816, 3.4498257637023926, 1.7290287017822266, -9.297354698181152, 1.4331226348876953, 14.466790199279785, -15.39406681060791, 2.782353401184082, -1.0241632461547852, -1.2496106624603271, -10.220854759216309, -1.7410955429077148, -0.07501220703125, -4.693123817443848, 1.0229847431182861, -0.21222496032714844, -0.18138599395751953, -5.761091232299805, 1.6039361953735352, -0.7434811592102051, -7.633288383483887, -7.397517204284668, -0.11514854431152344, -1.6786704063415527, 1.258244514465332, 2.8542473316192627, 0.6680707931518555, 2.4303624629974365, -0.3033885955810547, -7.063424587249756, 0.08807659149169922, 0.5048370361328125, -0.8454146385192871, -0.07501220703125, 0.1560649871826172, 0.19105148315429688, -8.326631546020508, -0.3897867202758789, 1.0490360260009766, -0.21108484268188477, -0.07619857788085938, 0.05161094665527344, 0.6018257141113281, 1.0170307159423828, -0.44506072998046875, -0.28943824768066406, -2.7544116973876953, 0.26210689544677734, -0.9896345138549805, -1.7971699237823486, 0.07965230941772461, -1.959043025970459, 0.697026252746582, 2.663532257080078, -0.16703391075134277, 0.5205497741699219, -8.116469383239746, -5.521234035491943, -0.6787185668945312, 2.1668524742126465, -1.806809902191162, -9.012090682983398, 0.017894744873046875, -0.24115753173828125, 0.22863483428955078, 0.6735045909881592, -0.4894876480102539, 0.7640447616577148, -1.0419034957885742, -1.9169769287109375, -0.12056732177734375, -0.6664247512817383, 0.8976058959960938, 1.2163887023925781, -6.635252952575684, 1.1813907623291016, 0.20855236053466797, 0.5739421844482422, -3.6444101333618164, -0.24617767333984375, 0.38794612884521484, 0.8414087295532227, -7.987048625946045, 14.035224914550781, 0.3377237319946289, -1.3705501556396484, -0.3899984359741211, 0.04962730407714844, -4.337530136108398, 1.0765936374664307, -2.283649444580078, -1.4523921012878418, 0.2254495620727539, -5.761091232299805, -0.02894115447998047, 0.031104087829589844, -0.09505796432495117, 1.7660694122314453, -7.295052528381348, -1.766221046447754, -0.5171089172363281, 2.350168228149414, -0.5740771293640137, 0.6018257141113281, -0.8404543399810791, 1.066701889038086, 1.8420220613479614, 2.2458276748657227, 0.6068143844604492, -6.159130096435547, 0.8340997695922852, 1.6160682439804077, -2.22683048248291, -1.0212116241455078, 1.463979721069336, 0.6177139282226562, 0.8289546966552734, -1.2954015731811523, 0.24409198760986328, -0.9048566818237305, -1.8054161071777344, 0.1421833038330078, 0.8976058959960938, 1.5773991346359253, 0.4867830276489258, 0.27405834197998047, -0.18220138549804688, 0.10368824005126953, -0.1710529327392578, -2.64064359664917, 0.7065010070800781, -0.23555994033813477, -8.741637229919434, -0.4041569232940674, 1.05525803565979, -0.012838363647460938, -0.3033885955810547, 0.14129257202148438, -1.1118431091308594, 1.5074949264526367, -0.44632434844970703, 0.517554759979248, -2.948329448699951, -0.3899984359741211, -6.740279197692871, -6.407337188720703, -0.4894876480102539, -0.05084419250488281, -0.4244418144226074, 1.3640761375427246, -1.3028888702392578, -0.23555994033813477, 1.0490360260009766, 3.555797576904297, -4.065881729125977, 0.5450844764709473, -2.339114189147949, -2.097791910171509, -2.3401894569396973, 1.4869587421417236, -0.28943824768066406, 2.6071062088012695, 1.0208191871643066, -10.385282516479492, 2.7253551483154297, -1.0084562301635742, 1.720874309539795, -0.2287912368774414, 0.6680707931518555, 0.45614147186279297, -4.159172534942627, -1.4958820343017578, 1.2724719047546387, 0.7281842231750488, -0.0891413688659668, 1.1497802734375, -8.870077133178711, 1.6689884662628174, 0.19108843803405762, -1.821639060974121, 1.7246346473693848, 0.8829095363616943, -4.336616516113281, 0.04306983947753906, 1.648848056793213, 0.5906162261962891, 2.985985040664673, -0.0437922477722168, -0.05084419250488281, -0.3936271667480469, 0.4867830276489258, 1.5434001684188843, 2.722958564758301, 0.29852867126464844, -0.20088863372802734, -0.9556771516799927, -2.3435816764831543, -0.8239331245422363, -0.2398538589477539, -3.991870641708374, 1.7288084030151367, 0.19732999801635742, 1.0458126068115234, 0.7516541481018066, -1.2020549774169922, -0.9227333068847656, -2.3007588386535645, -1.637062430381775, -1.4072442054748535, -7.08762788772583, 1.5731277465820312, -10.75772476196289, -0.4463376998901367, 0.8190032243728638, 1.87298583984375, -1.3809356689453125, -1.3409194946289062, 1.3125028610229492, 0.12424087524414062, -5.106774806976318, -9.339994430541992, -0.6492252349853516, 0.11086845397949219, -1.2503337860107422, 0.07260417938232422, -4.396014213562012, 0.22863483428955078, -1.5217018127441406, 1.3755292892456055, -2.121910572052002, 2.271124839782715, -0.039835453033447266, -0.126434326171875, -0.39354801177978516, 1.2700839042663574, 0.3978457450866699], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 16384, "num_env_steps_trained": 57840, "num_agent_steps_sampled": 16384, "num_agent_steps_trained": 57840, "last_target_update_ts": 16384, "num_target_updates": 31}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -464.6643412485719, "episode_reward_mean": -223.01949091463587, "episode_len_mean": 320.09302325581393, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5307918588041645, "mean_inference_ms": 22.705863056233145, "mean_action_processing_ms": 0.1351448509547257, "mean_env_wait_ms": 4.656482803691643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -464.6643412485719, "episode_reward_mean": -223.01949091463587, "episode_len_mean": 320.09302325581393, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5307918588041645, "mean_inference_ms": 22.705863056233145, "mean_action_processing_ms": 0.1351448509547257, "mean_env_wait_ms": 4.656482803691643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 16384, "num_agent_steps_trained": 57840, "num_env_steps_sampled": 16384, "num_env_steps_trained": 57840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 16384, "agent_timesteps_total": 16384, "timers": {"training_iteration_time_ms": 359.355, "learn_time_ms": 61.497, "learn_throughput": 3902.617, "synch_weights_time_ms": 21.19}, "counters": {"num_env_steps_sampled": 16384, "num_env_steps_trained": 57840, "num_agent_steps_sampled": 16384, "num_agent_steps_trained": 57840, "last_target_update_ts": 16384, "num_target_updates": 31}, "done": false, "episodes_total": 43, "training_iteration": 16, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-24", "timestamp": 1655478144, "time_this_iter_s": 5.458664178848267, "time_total_s": 82.21303796768188, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 82.21303796768188, "timesteps_since_restore": 0, "iterations_since_restore": 16, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.512499999999996, "ram_util_percent": 59.224999999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.9791033267974854, "min_q": -20.422847747802734, "max_q": 18.300199508666992, "mean_td_error": -0.8663684725761414}, "td_error": [-0.1275310516357422, -10.369067192077637, -12.189224243164062, 0.701749324798584, -8.562925338745117, 0.3747673034667969, -1.0046749114990234, 0.6302967071533203, 0.14676284790039062, -1.6154298782348633, -0.6942462921142578, 0.9319114685058594, -0.5843954086303711, 0.5036811828613281, 7.694892883300781, -6.4355926513671875, 0.9612729549407959, -0.6996407508850098, 1.6984285116195679, -1.0379390716552734, -2.1550464630126953, 0.5817298889160156, 1.2636065483093262, 1.4850850105285645, -0.324737548828125, 0.33979225158691406, 0.9393062591552734, 0.2110424041748047, 0.8891868591308594, 2.352108955383301, -1.2729520797729492, 0.39104652404785156, 0.09438514709472656, -4.408306121826172, -0.40714073181152344, 1.0084753036499023, -1.334085464477539, -1.1533517837524414, -1.5647697448730469, -0.13695526123046875, 0.1587982177734375, 0.29007667303085327, 0.7604942321777344, 0.22884464263916016, 1.088592529296875, -7.429112434387207, 1.43951416015625, 1.257218837738037, -0.024454116821289062, 2.5128064155578613, -9.820988655090332, 1.145301342010498, -0.966588020324707, -0.05831432342529297, -0.8673906326293945, 0.06170368194580078, -1.020395278930664, -5.337033271789551, -1.3087120056152344, 1.1964755058288574, 0.5618257522583008, 1.9769282341003418, -1.5775384902954102, 0.3006887435913086, -0.3743753433227539, -0.4239692687988281, 1.1390361785888672, 1.1024322509765625, 1.0371975898742676, -1.1638679504394531, 1.0903658866882324, 1.7357807159423828, 1.5235424041748047, -0.8338394165039062, -0.16377735137939453, -1.962681770324707, 0.4650101661682129, -3.1277666091918945, -0.2848062515258789, -3.397676944732666, 0.29453134536743164, 0.5930948257446289, -1.6170225143432617, -2.04593563079834, -1.9359288215637207, 0.6520891189575195, 1.4949073791503906, -4.337000846862793, 0.6895217895507812, -0.03213977813720703, 0.10112953186035156, 0.46698665618896484, -1.273782730102539, -4.601038932800293, 0.40564727783203125, 0.307159423828125, -0.49190056324005127, 0.6895217895507812, 1.2621650695800781, -0.6936955451965332, 0.5133895874023438, 1.0671348571777344, 0.32442617416381836, -0.7245368957519531, 0.9775657653808594, -0.7785987854003906, 0.435546875, 0.26944541931152344, -1.248805046081543, 0.5817298889160156, -7.709017753601074, -0.028789520263671875, 0.9002799987792969, 0.3636016845703125, 0.5618257522583008, -0.0041370391845703125, -0.9632968902587891, -7.585975646972656, 1.5101041793823242, -1.7562055587768555, 0.8727874755859375, 0.5568907260894775, -0.7871041297912598, -9.97493839263916, 0.37439775466918945, 0.2110424041748047, -8.605425834655762, 0.6740627288818359, -2.0058956146240234, -0.1913127899169922, -0.1229391098022461, -0.4788351058959961, 0.24248790740966797, -2.5881829261779785, 1.4643304347991943, -0.2178173065185547, -0.7345199584960938, -1.2075586318969727, -0.653294563293457, -0.6508274078369141, 0.6287021636962891, -9.285202026367188, -1.8959085941314697, 0.5163259506225586, -0.12499046325683594, -10.297459602355957, 0.5300512313842773, 1.1693506240844727, -1.5393500328063965, -4.420204162597656, -1.8087329864501953, -2.9546213150024414, 1.275162696838379, 2.541982650756836, 0.9439131021499634, -0.38431644439697266, 0.8013797402381897, -6.187126159667969, 0.23648548126220703, -1.8311907052993774, -0.08815956115722656, 1.821345329284668, -0.16131591796875, -1.1489171981811523, 1.1024322509765625, -1.5289011001586914, 1.0130534172058105, -1.8299636840820312, 2.9519002437591553, -2.543288230895996, -1.8608484268188477, -0.6851558685302734, 0.403048038482666, -1.0857534408569336, -8.562925338745117, -4.921089172363281, -3.022578239440918, -0.8083662986755371, -1.1739630699157715, 0.5251579284667969, -0.24729442596435547, 0.28968048095703125, 1.0848121643066406, -1.8220996856689453, 1.0263376235961914, 0.10071039199829102, -0.6855347156524658, 0.21398544311523438, -1.8917217254638672, 1.1489715576171875, 1.2228312492370605, -0.780848503112793, 0.17629051208496094, 0.6723537445068359, -0.6289854049682617, -9.860756874084473, -9.860756874084473, -1.044560432434082, -8.626785278320312, -0.1532888412475586, 0.030885696411132812, -0.3539915084838867, 0.8953151702880859, -4.659365653991699, 0.3744659423828125, 1.9480533599853516, -7.709017753601074, 2.2502050399780273, 0.34189319610595703, -1.4679756164550781, -0.03650784492492676, -2.70040225982666, -0.6271214485168457, -0.024454116821289062, 0.1452770233154297, -0.419003963470459, 0.4250040054321289, -0.7023048400878906, 1.814126968383789, -2.216895580291748, -0.4146137237548828, -2.8728981018066406, 0.7156196236610413, 1.43951416015625, -1.3490169048309326, 1.5750846862792969, -1.0379390716552734, 0.6713104248046875, 0.24710464477539062, -0.8881816864013672, -1.0714035034179688, 2.389667510986328, -10.417028427124023, -0.7215290069580078, -0.17165565490722656, 0.8527631759643555, -0.027513861656188965, -0.8784294128417969, -0.6191940307617188, -0.16377735137939453], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 17408, "num_env_steps_trained": 61680, "num_agent_steps_sampled": 17408, "num_agent_steps_trained": 61680, "last_target_update_ts": 17408, "num_target_updates": 33}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -551.6457608342171, "episode_reward_mean": -241.26335960927796, "episode_len_mean": 327.7659574468085, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.527506997715002, "mean_inference_ms": 22.771554844142077, "mean_action_processing_ms": 0.13508649402864228, "mean_env_wait_ms": 4.6043356320435755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -551.6457608342171, "episode_reward_mean": -241.26335960927796, "episode_len_mean": 327.7659574468085, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.527506997715002, "mean_inference_ms": 22.771554844142077, "mean_action_processing_ms": 0.13508649402864228, "mean_env_wait_ms": 4.6043356320435755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 17408, "num_agent_steps_trained": 61680, "num_env_steps_sampled": 17408, "num_env_steps_trained": 61680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 17408, "agent_timesteps_total": 17408, "timers": {"training_iteration_time_ms": 321.746, "learn_time_ms": 60.275, "learn_throughput": 3981.725, "synch_weights_time_ms": 20.089}, "counters": {"num_env_steps_sampled": 17408, "num_env_steps_trained": 61680, "num_agent_steps_sampled": 17408, "num_agent_steps_trained": 61680, "last_target_update_ts": 17408, "num_target_updates": 33}, "done": false, "episodes_total": 47, "training_iteration": 17, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-30", "timestamp": 1655478150, "time_this_iter_s": 5.282544136047363, "time_total_s": 87.49558210372925, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 87.49558210372925, "timesteps_since_restore": 0, "iterations_since_restore": 17, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.7625, "ram_util_percent": 59.225}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.3929744064807892, "min_q": -20.56171226501465, "max_q": 21.21067237854004, "mean_td_error": -1.0561310052871704}, "td_error": [0.06010913848876953, -5.014993667602539, -0.4362931251525879, -0.7884349822998047, -0.856654167175293, -0.3023693561553955, 1.5162849426269531, -0.2739219665527344, -0.17516398429870605, 0.10925102233886719, 0.7041425704956055, -1.6735917329788208, 0.05413341522216797, -1.489267349243164, 1.1489229202270508, -2.246668815612793, -0.6862173080444336, -8.30890941619873, 0.2167038917541504, 0.7415580749511719, -0.13359469175338745, -0.8682956695556641, -0.12312793731689453, -0.7326507568359375, -0.9861764907836914, 0.6282892227172852, -1.650944709777832, -1.479156494140625, -1.9277315139770508, -0.4550905227661133, -10.332747459411621, -0.4150276184082031, 0.1253976821899414, -0.6815943717956543, 0.2701606750488281, -1.3077116012573242, -0.7086248397827148, -1.472707748413086, -1.0548038482666016, -0.7850489616394043, -1.0306148529052734, -0.31137847900390625, 0.330564022064209, 0.16781210899353027, -0.8932204246520996, 0.5874910354614258, -0.040706634521484375, 0.2921180725097656, -0.4252328872680664, -1.5009287595748901, -1.889780044555664, -0.25560951232910156, -1.2489986419677734, 0.29370880126953125, -6.016925811767578, 0.9832792282104492, -0.9330053329467773, -1.489267349243164, -0.09290480613708496, 0.045142173767089844, -0.3326033353805542, -2.510767936706543, -0.911585807800293, -0.32516050338745117, -0.8044624328613281, -1.169921875, -7.434003829956055, -0.44332027435302734, -0.10140204429626465, -0.9975013732910156, -1.4670028686523438, 0.5923938751220703, -0.12430763244628906, -0.8164157867431641, 0.2889242172241211, 0.2131209373474121, 0.7360954284667969, 0.9724528789520264, -0.4821596145629883, -9.830358505249023, -0.9882678985595703, -2.4211325645446777, -0.8432760238647461, 0.5513877868652344, 1.0694513320922852, 0.28530311584472656, -0.34407997131347656, -0.007477283477783203, 0.0021905899047851562, -1.3859891891479492, 0.6048765182495117, -2.2627639770507812, -2.043564796447754, 0.2167038917541504, -0.6040582656860352, 0.3149242401123047, 0.26430320739746094, -0.3055121898651123, -0.35094261169433594, -0.6048822402954102, 0.1100625991821289, -0.9464511871337891, 0.6313447952270508, -1.8702516555786133, -1.9147891998291016, -7.613608360290527, -0.3665008544921875, 0.8605518341064453, 0.8605518341064453, -8.884449005126953, 2.2458019256591797, 1.2732677459716797, 0.06010913848876953, 0.5612850189208984, -0.493959903717041, 0.9368414878845215, -0.9200053215026855, 0.7092156410217285, 1.653160572052002, -1.9659662246704102, -0.04163360595703125, 1.173498272895813, 0.3435020446777344, 0.16781210899353027, -0.6267253160476685, -0.5887184143066406, -0.7632055282592773, -0.4352874755859375, -0.5514779090881348, -0.21497058868408203, -1.8786792755126953, -2.1373414993286133, -0.6668796539306641, 0.6035962104797363, 10.562565803527832, -5.374361991882324, -0.3665008544921875, 0.22135639190673828, -1.6111278533935547, 0.3225574493408203, -1.0872304439544678, -0.12224817276000977, 0.0970916748046875, 0.5122432708740234, 0.2853355407714844, -0.3167686462402344, -6.27862548828125, -0.6027488708496094, -11.182650566101074, -0.7450656890869141, 1.1011962890625, -0.2679305076599121, -0.32516050338745117, -0.03472137451171875, 1.9113712310791016, -0.9464511871337891, -1.2555274963378906, -2.8414926528930664, 0.8822078704833984, -10.627462387084961, 0.0970916748046875, -0.23954200744628906, -2.3284435272216797, 0.20876693725585938, 0.10561227798461914, -1.3274297714233398, 1.1728782653808594, -2.1683807373046875, -0.2729787826538086, -0.2588367462158203, 0.29668283462524414, 0.03601217269897461, -0.008731842041015625, -5.8813557624816895, 0.600245475769043, 0.2757229804992676, -3.6433377265930176, -0.8194212913513184, -6.643603324890137, -0.6286201477050781, -0.19299602508544922, -0.5405454635620117, -6.593904495239258, 0.11012840270996094, -0.7374401092529297, -0.5986485481262207, -9.460251808166504, -0.43691539764404297, -1.633401870727539, -11.475452423095703, -0.16748046875, -0.0870976448059082, -1.3617753982543945, -7.245424747467041, -10.060027122497559, 2.5100479125976562, 0.20277786254882812, 0.5559196472167969, 0.07391548156738281, -9.70733642578125, 1.318887710571289, -0.5584449768066406, 0.1423192024230957, -1.8729724884033203, 0.26483631134033203, 0.190032958984375, 0.17853021621704102, -0.6479253768920898, -0.43242549896240234, -1.3785347938537598, -3.2477684020996094, -0.976654052734375, -1.194199562072754, -3.23183536529541, 0.572296142578125, 0.05367469787597656, -0.13309669494628906, -1.9125065803527832, 0.797760009765625, -9.846918106079102, 1.5009918212890625, 0.7312536239624023, 0.9724528789520264, -1.334200382232666, -0.1860952377319336, -0.01309823989868164, -1.2715206146240234, -8.204290390014648, -0.581233024597168, 0.7825965881347656, 0.20561790466308594, 0.41358280181884766, -2.2989110946655273, -0.40854549407958984, -0.1814289093017578, -1.1104068756103516, -2.754664421081543, 0.7076120376586914, -0.1465611457824707, -2.303800582885742], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 18432, "num_env_steps_trained": 65520, "num_agent_steps_sampled": 18432, "num_agent_steps_trained": 65520, "last_target_update_ts": 18432, "num_target_updates": 35}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -250.60844471227998, "episode_len_mean": 330.3125, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5274800343621152, "mean_inference_ms": 22.793152819050988, "mean_action_processing_ms": 0.13561336498226803, "mean_env_wait_ms": 4.589393485924331, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -250.60844471227998, "episode_len_mean": 330.3125, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5274800343621152, "mean_inference_ms": 22.793152819050988, "mean_action_processing_ms": 0.13561336498226803, "mean_env_wait_ms": 4.589393485924331, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 18432, "num_agent_steps_trained": 65520, "num_env_steps_sampled": 18432, "num_env_steps_trained": 65520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 18432, "agent_timesteps_total": 18432, "timers": {"training_iteration_time_ms": 315.506, "learn_time_ms": 59.831, "learn_throughput": 4011.327, "synch_weights_time_ms": 19.688}, "counters": {"num_env_steps_sampled": 18432, "num_env_steps_trained": 65520, "num_agent_steps_sampled": 18432, "num_agent_steps_trained": 65520, "last_target_update_ts": 18432, "num_target_updates": 35}, "done": false, "episodes_total": 48, "training_iteration": 18, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-35", "timestamp": 1655478155, "time_this_iter_s": 5.000349283218384, "time_total_s": 92.49593138694763, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 92.49593138694763, "timesteps_since_restore": 0, "iterations_since_restore": 18, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.22857142857142, "ram_util_percent": 59.31428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.079527497291565, "min_q": -23.305099487304688, "max_q": 20.758657455444336, "mean_td_error": -0.8993463516235352}, "td_error": [-1.4849443435668945, 0.5060849189758301, -0.030378341674804688, -2.4068288803100586, -0.13416653871536255, 0.39841461181640625, -0.8851985931396484, 1.706695556640625, 2.4468889236450195, 0.3915858268737793, 0.23778438568115234, -1.9615209102630615, 0.3349189758300781, -2.1893749237060547, -0.022054672241210938, -1.3621788024902344, -0.07222986221313477, 0.5060849189758301, -0.0741114616394043, -2.16333270072937, 0.04564380645751953, 1.3733782768249512, 0.16600418090820312, -1.6387243270874023, -1.3312606811523438, 12.246030807495117, -0.11428642272949219, 1.400632381439209, -0.5025882720947266, 0.09247493743896484, -1.1724436283111572, 0.7129206657409668, -0.6416144371032715, -3.0134105682373047, -5.847043514251709, -0.26114654541015625, 1.7110939025878906, 0.6053133010864258, -5.287105560302734, 0.5110220909118652, -1.9487271308898926, 0.04467964172363281, -2.4453482627868652, -0.2687368392944336, 0.5593516230583191, 9.03787899017334, -0.8789267539978027, 0.37506866455078125, 0.43409252166748047, -0.5148882865905762, 0.8164405822753906, -1.6049203872680664, -3.0916409492492676, -1.763449788093567, 0.05781698226928711, -1.9510917663574219, 0.4268302917480469, 0.49059104919433594, -1.7309656143188477, -0.44207000732421875, 0.0459442138671875, 1.7911388874053955, -5.010897636413574, -0.7166118621826172, -3.171261787414551, -1.17515230178833, -6.348322868347168, -2.4167637825012207, 0.1594867706298828, -1.8898348808288574, -0.18934059143066406, -1.4129037857055664, -4.400074481964111, -1.5171833038330078, 1.0108813047409058, -3.064969062805176, -2.173346519470215, 0.46974754333496094, 1.5793704986572266, 0.19085025787353516, 2.2719459533691406, -0.2976722717285156, 1.9129524230957031, 0.1040945053100586, -0.9074318408966064, -0.03296661376953125, -0.5426206588745117, 1.3733782768249512, -8.425009727478027, 0.9844989776611328, -1.0384082794189453, -0.81756591796875, 1.203455924987793, 0.10944366455078125, -2.669161558151245, 0.5639324188232422, -1.0233640670776367, -0.17250537872314453, -1.8862905502319336, -1.5432543754577637, -0.8456897735595703, -0.9462471008300781, -1.9281244277954102, -0.12358474731445312, -1.6229910850524902, 0.5750555992126465, 0.02779388427734375, -1.9904520511627197, -1.6036548614501953, 0.721379280090332, -2.909606695175171, -1.5188164710998535, -3.0706353187561035, -1.9615209102630615, 0.7542037963867188, -2.6267640590667725, 0.14971637725830078, 0.5687103271484375, -0.6692743301391602, -2.331085205078125, -0.5829925537109375, -0.0741114616394043, 0.14333796501159668, -1.1532163619995117, -0.03686666488647461, 0.9714126586914062, -0.9061646461486816, -0.9392356872558594, 1.4888300895690918, -0.19737815856933594, -0.19741249084472656, 1.1962862014770508, -1.8017406463623047, -1.0205821990966797, -0.73114013671875, 0.3421440124511719, -0.7698535919189453, 0.9346580505371094, 3.4566774368286133, -12.204913139343262, -1.3872699737548828, -8.95985221862793, -8.950897216796875, -1.7497282028198242, -1.479447364807129, -0.8128147125244141, 0.8855633735656738, 1.3214035034179688, -0.9804754257202148, 0.7764801979064941, -1.8343029022216797, -1.675733208656311, -0.7769746780395508, -0.18934059143066406, 1.057220697402954, 0.6446533203125, 1.8132870197296143, -0.39800262451171875, -3.031947612762451, 0.17544937133789062, 1.5650835037231445, -2.347951889038086, -0.14076614379882812, -3.311161994934082, -9.598840713500977, -2.707737922668457, -0.2544994354248047, 1.3733782768249512, -1.0932693481445312, -3.1916003227233887, -0.969214916229248, -0.21837329864501953, 0.4268302917480469, 1.9129524230957031, -1.1815801858901978, -1.3427543640136719, -0.12600421905517578, -1.881643295288086, -3.82273006439209, -8.515317916870117, -1.0789971351623535, -0.5071220397949219, -3.3344926834106445, -4.675454616546631, -0.12566375732421875, -0.8025412559509277, -3.083725929260254, 0.051497459411621094, 1.1224453449249268, -1.1678028106689453, -0.6264190673828125, -1.104194164276123, -0.6841202974319458, -1.0449190139770508, 0.13846492767333984, -0.42403221130371094, -0.07707023620605469, -1.204437255859375, -0.9010423421859741, -0.4799013137817383, 0.2122516632080078, -0.6683635711669922, -0.6208820343017578, -0.6654081344604492, 0.9082164764404297, 0.3988809585571289, 0.6055817604064941, -1.1343684196472168, -5.269680023193359, -0.8456897735595703, -1.3226284980773926, -0.7505359649658203, 0.019334077835083008, 0.8087959289550781, 6.387884140014648, -0.2000732421875, -1.1791057586669922, -0.9019451141357422, -0.30918121337890625, -11.700214385986328, -0.16375732421875, -0.6974821090698242, -1.5506491661071777, -11.95854663848877, 0.46123695373535156, -1.41347336769104, -6.531713962554932, -0.6792316436767578, -0.19741249084472656, 0.5476694107055664, -1.8277173042297363, -0.22725868225097656, -2.16628360748291, -2.160250663757324, -0.8824896812438965, -2.0192246437072754, -1.310701847076416, -2.0489487648010254, -0.41266918182373047, 0.7169961929321289], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 19456, "num_env_steps_trained": 69360, "num_agent_steps_sampled": 19456, "num_agent_steps_trained": 69360, "last_target_update_ts": 19456, "num_target_updates": 37}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -247.13434658625297, "episode_len_mean": 329.0408163265306, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5273418323511709, "mean_inference_ms": 22.81134805736248, "mean_action_processing_ms": 0.13541011336314077, "mean_env_wait_ms": 4.585823396127823, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -247.13434658625297, "episode_len_mean": 329.0408163265306, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5273418323511709, "mean_inference_ms": 22.81134805736248, "mean_action_processing_ms": 0.13541011336314077, "mean_env_wait_ms": 4.585823396127823, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 19456, "num_agent_steps_trained": 69360, "num_env_steps_sampled": 19456, "num_env_steps_trained": 69360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 19456, "agent_timesteps_total": 19456, "timers": {"training_iteration_time_ms": 326.57, "learn_time_ms": 61.402, "learn_throughput": 3908.67, "synch_weights_time_ms": 20.489}, "counters": {"num_env_steps_sampled": 19456, "num_env_steps_trained": 69360, "num_agent_steps_sampled": 19456, "num_agent_steps_trained": 69360, "last_target_update_ts": 19456, "num_target_updates": 37}, "done": false, "episodes_total": 49, "training_iteration": 19, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-40", "timestamp": 1655478160, "time_this_iter_s": 5.129580974578857, "time_total_s": 97.62551236152649, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 97.62551236152649, "timesteps_since_restore": 0, "iterations_since_restore": 19, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.0125, "ram_util_percent": 59.4625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.5442596673965454, "min_q": -23.8259220123291, "max_q": 22.518749237060547, "mean_td_error": -0.7663112878799438}, "td_error": [-1.188004732131958, -1.1965694427490234, 0.8679909706115723, 0.8237619400024414, 0.5897588729858398, 0.9134376049041748, -10.037988662719727, 1.0024547576904297, -2.128838539123535, -0.9362163543701172, 1.0195484161376953, 0.9432029724121094, -1.1870765686035156, -1.5408706665039062, -0.5506876707077026, 0.8134298324584961, 0.5050530433654785, 0.2342061996459961, 1.2326183319091797, 1.5476906299591064, -1.3100602626800537, -2.5378212928771973, -2.9010634422302246, -0.37850189208984375, -1.6141552925109863, 0.5386829376220703, 0.8592327833175659, 0.7290494441986084, -1.6738343238830566, 0.3495997190475464, -0.2891077995300293, 1.0206317901611328, 0.7597560882568359, 0.4552538990974426, -1.016716718673706, 0.15037202835083008, 0.3474607467651367, -0.28176021575927734, -0.5448360443115234, 0.6540012359619141, 0.5736446380615234, 0.3337993621826172, -0.019059181213378906, -6.580234527587891, -7.830607891082764, -1.3931446075439453, 2.3093342781066895, 0.1464061737060547, 0.9218378067016602, 0.9471454620361328, 0.320098876953125, -1.7966842651367188, -1.222954273223877, -0.8512741327285767, 0.6646307110786438, -0.118377685546875, -0.5162796974182129, -0.41588878631591797, -11.103229522705078, -2.9871938228607178, -7.680968761444092, -1.754906415939331, 1.9575953483581543, 0.17480182647705078, 3.8835926055908203, 15.895753860473633, 1.191976547241211, 0.9124550819396973, -1.2146234512329102, -1.9257011413574219, 0.915973424911499, -5.405684471130371, -0.6462130546569824, -0.2344040870666504, 0.0985569953918457, -0.14716720581054688, -12.372859001159668, 0.2505149841308594, 0.9191648960113525, -0.4145803451538086, 0.04987907409667969, 1.2754268646240234, -3.123900890350342, 0.6965650916099548, 1.8573861122131348, 1.6107563972473145, 0.9124550819396973, -0.3865170478820801, -4.5652008056640625, 0.1345071792602539, 0.5606594085693359, -2.2102746963500977, -0.0002346038818359375, 0.17653465270996094, -0.8622230291366577, 1.298628807067871, 0.2527899742126465, -0.060263633728027344, -0.3547706604003906, 0.8251075744628906, 0.12416410446166992, -0.048625946044921875, -5.756215572357178, 0.9937427043914795, -8.669105529785156, 0.2105121612548828, -2.6307506561279297, -0.46489715576171875, -8.776956558227539, 0.2826271057128906, -0.08911991119384766, -0.7938175201416016, -0.22403335571289062, 0.4148998260498047, -0.9468088150024414, 2.8810160160064697, 1.868617057800293, -0.39559268951416016, -1.3286418914794922, -4.957637786865234, -1.3487882614135742, 0.18289947509765625, -0.061197757720947266, -0.09360027313232422, 0.6045427322387695, -1.1059637069702148, -0.05899333953857422, -0.09043025970458984, -0.6731414794921875, -0.2146320343017578, -0.2510089874267578, 0.35418468713760376, 0.3944816589355469, 1.9289016723632812, -0.1428821086883545, 0.2881135940551758, 0.9480490684509277, 0.04987907409667969, -1.9480972290039062, 0.21138954162597656, 0.3579134941101074, -2.697054862976074, 1.068777084350586, 0.920989990234375, -2.2755608558654785, -0.24881935119628906, -0.7230305671691895, 0.49849891662597656, -1.1329896450042725, 0.04858684539794922, 1.1551666259765625, -2.0264577865600586, -6.441476821899414, 0.08022737503051758, -0.0794057846069336, 0.05461876094341278, 0.8192646503448486, -0.5337467193603516, 0.6721267700195312, -0.9288392066955566, 1.0195484161376953, 0.19912481307983398, 1.48537015914917, -1.596374273300171, -0.12683916091918945, -0.9476585388183594, -9.764900207519531, 0.2917027473449707, -11.722795486450195, 0.2780795097351074, -0.4428443908691406, -3.8916375637054443, -0.9046773910522461, -0.5967521667480469, -0.038249969482421875, -0.6477736234664917, -0.5431423187255859, -0.3884315490722656, -7.515987396240234, 3.1639211177825928, -1.6634063720703125, -0.13482880592346191, -1.461459755897522, -0.6764035224914551, -6.023248672485352, 0.818171501159668, -0.07769012451171875, -0.2865934371948242, -0.4605879783630371, -7.723435401916504, 0.1566929817199707, 0.369964599609375, -1.1653251647949219, 0.2975034713745117, 1.7017040252685547, 1.1551666259765625, -5.070046424865723, -2.3187363147735596, -2.5418262481689453, 0.4081214368343353, 0.5699872970581055, -6.90264892578125, 0.7236475944519043, 0.5010833740234375, 0.37293243408203125, 1.1120309829711914, -0.6184616088867188, -0.026119709014892578, -0.5302531719207764, 0.41973257064819336, -0.5688095092773438, -4.562402725219727, 2.8614702224731445, 0.881263256072998, -2.180044651031494, 0.7114996910095215, 1.1063432693481445, -2.0995230674743652, -0.2306671142578125, -5.405684471130371, -1.1541662216186523, 0.04974174499511719, -9.679971694946289, 0.5219478607177734, -0.43733787536621094, 0.1063690185546875, -0.08782386779785156, -0.9708280563354492, -6.897424221038818, -0.23984360694885254, -0.14007568359375, -1.1647255420684814, 0.1340172290802002, -0.44097232818603516, -1.0098400115966797, 0.07915616035461426, -0.06226050853729248, -0.9708280563354492, 1.7556943893432617, -0.2258472442626953], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 20480, "num_env_steps_trained": 73200, "num_agent_steps_sampled": 20480, "num_agent_steps_trained": 73200, "last_target_update_ts": 20480, "num_target_updates": 39}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -245.57116331834837, "episode_len_mean": 329.0188679245283, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5271745922279292, "mean_inference_ms": 22.862709682265756, "mean_action_processing_ms": 0.13556981463154857, "mean_env_wait_ms": 4.5556000304988356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -245.57116331834837, "episode_len_mean": 329.0188679245283, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5271745922279292, "mean_inference_ms": 22.862709682265756, "mean_action_processing_ms": 0.13556981463154857, "mean_env_wait_ms": 4.5556000304988356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 20480, "num_agent_steps_trained": 73200, "num_env_steps_sampled": 20480, "num_env_steps_trained": 73200, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 20480, "agent_timesteps_total": 20480, "timers": {"training_iteration_time_ms": 336.187, "learn_time_ms": 60.008, "learn_throughput": 3999.481, "synch_weights_time_ms": 19.901}, "counters": {"num_env_steps_sampled": 20480, "num_env_steps_trained": 73200, "num_agent_steps_sampled": 20480, "num_agent_steps_trained": 73200, "last_target_update_ts": 20480, "num_target_updates": 39}, "done": false, "episodes_total": 53, "training_iteration": 20, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-46", "timestamp": 1655478166, "time_this_iter_s": 5.3284571170806885, "time_total_s": 102.95396947860718, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 102.95396947860718, "timesteps_since_restore": 0, "iterations_since_restore": 20, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.72857142857143, "ram_util_percent": 59.614285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.0101056098937988, "min_q": -23.670955657958984, "max_q": 23.116117477416992, "mean_td_error": -0.993435800075531}, "td_error": [-0.7245903015136719, 1.437347412109375, -1.0633535385131836, -8.582115173339844, 0.7473373413085938, 0.48898887634277344, 4.228046894073486, 1.528158187866211, -2.6786317825317383, -0.7327642440795898, -4.166970729827881, 0.8073806762695312, 1.3531641960144043, -6.50139045715332, -0.012654304504394531, 0.12432098388671875, 0.1953880786895752, 0.14630126953125, -1.407315731048584, -3.369800090789795, -1.279228925704956, -0.47055482864379883, 0.4951000213623047, 0.7823810577392578, -2.42047119140625, -0.20524215698242188, -1.2646465301513672, 0.3444383144378662, -1.9385666847229004, -1.913824439048767, 0.5966653823852539, 0.927560567855835, -1.1276278495788574, -1.8024320602416992, 1.8541285991668701, -1.7916374206542969, 0.046292781829833984, 0.6880995035171509, -0.7042083740234375, -0.6973615884780884, 0.30870532989501953, 0.40523815155029297, -0.8615912199020386, -0.6846842765808105, 0.7334260940551758, -1.2176003456115723, -1.510793685913086, -0.9624898433685303, -0.7735633850097656, 0.2958390712738037, 0.007732868194580078, -1.9018380641937256, 0.059856414794921875, -0.1780686378479004, -0.31467485427856445, -0.6800791025161743, -0.1820240020751953, 1.672811508178711, -3.159543991088867, -5.205799102783203, -1.3925666809082031, -0.8168115615844727, -1.5739641189575195, -1.12200927734375, -0.7831306457519531, 0.5215435028076172, 0.01263427734375, 1.521265983581543, -0.5945076942443848, -1.6406726837158203, -2.121224880218506, -0.8115501403808594, -1.7347159385681152, -0.7992568016052246, -1.4953298568725586, -0.5094108581542969, -1.3329418897628784, -5.876005172729492, 1.7809629440307617, -1.2383692264556885, -0.12504863739013672, -0.1780686378479004, -1.29754638671875, -2.4119911193847656, -0.8809995651245117, -0.26096534729003906, -0.5761427879333496, -1.4029226303100586, -0.12635421752929688, -0.4680900573730469, -1.7748565673828125, -1.5228309631347656, -2.5197486877441406, 0.3461925983428955, -0.5603294372558594, 0.7854108810424805, -1.1292723417282104, -2.516228675842285, 0.41890859603881836, -13.406842231750488, 0.007706642150878906, 0.07486534118652344, 2.05557918548584, -0.47658538818359375, -1.4846725463867188, -0.4474372863769531, -0.6135330200195312, -0.7974238395690918, -0.668461799621582, 0.6843868494033813, 0.19767260551452637, 0.04113626480102539, -0.5882759094238281, -0.40678977966308594, -1.686601161956787, -1.3965449333190918, 1.6168060302734375, -0.6012449264526367, 1.1222352981567383, -2.0503711700439453, -0.7479152679443359, -4.829008102416992, 0.5755500793457031, 1.0479631423950195, -0.7210149765014648, -1.3504691123962402, 1.272273063659668, 0.15905332565307617, 1.233330249786377, -0.3769969940185547, 0.3719463348388672, -0.4567089080810547, -1.4541401863098145, -1.7911944389343262, -7.145142555236816, -0.7907848358154297, -2.0760974884033203, -0.925089955329895, -0.35677194595336914, 0.7206499576568604, 1.3300800323486328, -0.37793731689453125, 0.7378463745117188, -0.3414936065673828, 0.06409645080566406, -0.31841397285461426, 0.6204347610473633, -0.9485890865325928, -0.8989629745483398, -3.2310097217559814, 2.298953056335449, -1.0229053497314453, -0.7619171142578125, -7.262165546417236, -0.4093971252441406, 0.7291989326477051, 0.4222846031188965, -0.2148294448852539, 0.11616659164428711, -0.26096534729003906, -9.99370288848877, 1.2762813568115234, -1.2896089553833008, -0.18910789489746094, -1.0523357391357422, -1.1150178909301758, 1.3439922332763672, -2.764073371887207, -8.002798080444336, -3.2797045707702637, -1.7187590599060059, -1.0086941719055176, 0.4111499786376953, -1.4130430221557617, -2.3409905433654785, -8.990886688232422, -1.8172450065612793, -0.360903263092041, -0.7443809509277344, -0.2073993682861328, -2.150514602661133, 0.6660280227661133, -0.2730836868286133, 1.6783380508422852, -1.8172450065612793, -1.6113691329956055, -0.8664798736572266, -1.2675762176513672, -0.20524215698242188, 1.1770811080932617, -1.2268319129943848, -6.477665901184082, 0.4800649881362915, -1.076416015625, -1.3931245803833008, -1.3683013916015625, -1.686601161956787, -2.9589858055114746, -2.9772329330444336, 0.5215435028076172, -0.7177915573120117, 1.402377963066101, -1.6720294952392578, 0.2466716766357422, -0.3579428791999817, -1.3973274230957031, -1.8516783714294434, 0.2133312225341797, 4.405026435852051, -1.1655478477478027, -1.272132396697998, 0.09509086608886719, 0.6834297180175781, -1.423257827758789, 0.10987997055053711, 0.15870380401611328, -3.7760887145996094, 0.5003871917724609, -0.31841397285461426, -2.5848493576049805, -7.282417297363281, -2.249927043914795, 1.9356942176818848, -1.5724539756774902, -1.3016271591186523, 0.4848966598510742, 0.5172567367553711, -1.5228309631347656, -2.365316390991211, -1.3154444694519043, 1.2009387016296387, 0.15222644805908203, -3.372178554534912, -1.4197282791137695, -9.177203178405762, 0.671952486038208, -0.9153798818588257, -9.589644432067871, -1.4936480522155762, -0.3818931579589844], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 21504, "num_env_steps_trained": 77040, "num_agent_steps_sampled": 21504, "num_agent_steps_trained": 77040, "last_target_update_ts": 21504, "num_target_updates": 41}, "sampler_results": {"episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -248.6335237150819, "episode_len_mean": 329.7068965517241, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5253564354983369, "mean_inference_ms": 22.9417603033139, "mean_action_processing_ms": 0.13542677469695302, "mean_env_wait_ms": 4.522619543925385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 0.5063197687268257, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -248.6335237150819, "episode_len_mean": 329.7068965517241, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5253564354983369, "mean_inference_ms": 22.9417603033139, "mean_action_processing_ms": 0.13542677469695302, "mean_env_wait_ms": 4.522619543925385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 21504, "num_agent_steps_trained": 77040, "num_env_steps_sampled": 21504, "num_env_steps_trained": 77040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 21504, "agent_timesteps_total": 21504, "timers": {"training_iteration_time_ms": 362.423, "learn_time_ms": 61.995, "learn_throughput": 3871.309, "synch_weights_time_ms": 19.988}, "counters": {"num_env_steps_sampled": 21504, "num_env_steps_trained": 77040, "num_agent_steps_sampled": 21504, "num_agent_steps_trained": 77040, "last_target_update_ts": 21504, "num_target_updates": 41}, "done": false, "episodes_total": 58, "training_iteration": 21, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-52", "timestamp": 1655478172, "time_this_iter_s": 5.595177412033081, "time_total_s": 108.54914689064026, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 108.54914689064026, "timesteps_since_restore": 0, "iterations_since_restore": 21, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.95555555555555, "ram_util_percent": 59.81111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.4718756079673767, "min_q": -23.637990951538086, "max_q": 23.794340133666992, "mean_td_error": -0.7302992343902588}, "td_error": [0.4123692512512207, 3.258193016052246, 0.5015676021575928, 0.2820332646369934, 0.8541866540908813, 0.3842630386352539, -7.64299201965332, -10.636964797973633, -0.6275296211242676, 0.2245655059814453, 0.38187432289123535, -0.2629241943359375, -0.3593144416809082, -0.6273288726806641, -4.033580780029297, 0.7842369079589844, 0.08953571319580078, 0.5126247406005859, -0.3692569136619568, -2.2535505294799805, 0.44371795654296875, -0.07413482666015625, -0.5456763505935669, 0.7963838577270508, -1.1523361206054688, -0.37856292724609375, -0.5064477920532227, -6.846761703491211, 0.5768423080444336, -2.200671672821045, 0.4847080707550049, -0.5310764312744141, -0.8388557434082031, -0.07166838645935059, 0.4691038131713867, -0.06782913208007812, 0.26633453369140625, -0.9235248565673828, -6.856695175170898, 1.71112060546875, -0.2140960693359375, -1.3204364776611328, -0.44458723068237305, -6.670456409454346, -0.4948997497558594, 0.4118824005126953, -0.6367950439453125, -7.543179512023926, 0.6586260795593262, 0.10945749282836914, -0.461822509765625, -1.3156518936157227, -0.7751684188842773, -0.472137451171875, -0.9711666107177734, -0.10902023315429688, -0.16580772399902344, -0.5972011089324951, -1.016037940979004, -0.7294012308120728, 0.790675163269043, -1.3703479766845703, -9.443187713623047, -2.134617805480957, 0.16151809692382812, -1.5195331573486328, 1.6419777870178223, -0.1485576629638672, -0.3354191780090332, 0.6993657350540161, -0.403533935546875, -1.3864784240722656, 1.772775650024414, 0.7836408615112305, 0.8817625045776367, -0.4242582321166992, -2.3612213134765625, 0.7716569900512695, 0.7041826248168945, -0.3175315856933594, 0.8863359689712524, -8.997701644897461, 1.1545140743255615, -0.9230537414550781, -0.03843498229980469, 1.0771312713623047, 0.02271413803100586, 0.08597137033939362, -0.8411769866943359, -1.0183000564575195, -1.423471450805664, 0.04024505615234375, -0.27475738525390625, -0.3758525848388672, -1.475369930267334, -0.13341522216796875, 0.7613792419433594, -0.5873260498046875, 0.6658825874328613, 0.1527848243713379, 0.18160009384155273, 0.49250340461730957, -0.19624614715576172, 0.4266258478164673, -0.8628897666931152, 0.4691038131713867, 0.2840399742126465, 0.4944796562194824, -1.418539047241211, -0.2618551254272461, -1.4950143098831177, 1.2247810363769531, -0.16232872009277344, -0.8725299835205078, -0.06238079071044922, -2.029989719390869, -1.9266166687011719, -0.3295440673828125, 0.396862268447876, -0.11680984497070312, -0.17307758331298828, -1.3156518936157227, -0.6860342025756836, 0.14856141805648804, -1.2831697463989258, -7.5473809242248535, -0.21056175231933594, -1.5700454711914062, 1.0103631019592285, -0.22066092491149902, -1.5400333404541016, -5.2496843338012695, 0.7097058296203613, 0.1175224781036377, -1.5711431503295898, -1.3269100189208984, -1.0646343231201172, -0.5239009857177734, -1.786494255065918, -2.4231271743774414, -6.998613357543945, -1.3905105590820312, 2.857027530670166, 0.27028846740722656, -0.15125203132629395, 0.5703103542327881, 0.5871148705482483, 1.1561765670776367, 0.7998237609863281, -0.6184227466583252, -1.232903003692627, 0.44579577445983887, -0.2563595771789551, 0.23627281188964844, -1.381807804107666, -0.5609755516052246, -7.0836615562438965, 10.000783920288086, -0.03433990478515625, -0.09630346298217773, -0.5559244155883789, 0.7291450500488281, -0.8725299835205078, 0.8921003341674805, -1.206533432006836, -0.043813467025756836, -0.12145328521728516, -3.815429210662842, -0.3295440673828125, 0.4209871292114258, -7.545001983642578, -0.009714126586914062, -0.8824911117553711, -1.3513221740722656, -0.3082723617553711, 1.9419498443603516, -0.4023313522338867, -0.22991657257080078, 0.42000770568847656, -0.07887744903564453, 0.16354060173034668, -1.1883821487426758, -1.603445053100586, -0.7457427978515625, -0.022775650024414062, 2.1815900802612305, 1.2433855533599854, 0.0964202880859375, -0.46990346908569336, -0.7294607162475586, -7.00765323638916, -0.3205070495605469, -0.6673374176025391, 0.2320244014263153, -9.71998405456543, 0.7593469619750977, -7.5473809242248535, 0.568260669708252, -1.347696304321289, 0.6250381469726562, 0.18174076080322266, 0.24195194244384766, 1.742682695388794, -1.6901719570159912, 1.3669414520263672, -0.4242582321166992, -0.11680984497070312, 0.14299941062927246, 0.16337966918945312, -0.6816005706787109, 0.7597074508666992, 0.42000770568847656, -0.35367393493652344, -1.9879493713378906, 0.039122581481933594, 0.03639030456542969, 0.9613676071166992, 0.19118213653564453, 0.706059455871582, -0.46167755126953125, -6.278129577636719, -7.546789169311523, -0.6672196388244629, -0.5209598541259766, 0.4425983428955078, -1.7556371688842773, -0.054012298583984375, 0.4847080707550049, 0.6864203214645386, 0.15546298027038574, 0.7931138277053833, -1.7362546920776367, -0.6328303813934326, -0.2140960693359375, -0.08426260948181152, -0.14251327514648438, 0.6250438690185547, 0.6432018280029297, -0.8181228637695312, -4.875682830810547], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 22528, "num_env_steps_trained": 80880, "num_agent_steps_sampled": 22528, "num_agent_steps_trained": 80880, "last_target_update_ts": 22528, "num_target_updates": 43}, "sampler_results": {"episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -249.08431527538906, "episode_len_mean": 329.6031746031746, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5241185833318747, "mean_inference_ms": 23.05460797344638, "mean_action_processing_ms": 0.13591590951389226, "mean_env_wait_ms": 4.489268391161313, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -249.08431527538906, "episode_len_mean": 329.6031746031746, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5241185833318747, "mean_inference_ms": 23.05460797344638, "mean_action_processing_ms": 0.13591590951389226, "mean_env_wait_ms": 4.489268391161313, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 22528, "num_agent_steps_trained": 80880, "num_env_steps_sampled": 22528, "num_env_steps_trained": 80880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 22528, "agent_timesteps_total": 22528, "timers": {"training_iteration_time_ms": 328.448, "learn_time_ms": 61.674, "learn_throughput": 3891.401, "synch_weights_time_ms": 20.09}, "counters": {"num_env_steps_sampled": 22528, "num_env_steps_trained": 80880, "num_agent_steps_sampled": 22528, "num_agent_steps_trained": 80880, "last_target_update_ts": 22528, "num_target_updates": 43}, "done": false, "episodes_total": 63, "training_iteration": 22, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-02-57", "timestamp": 1655478177, "time_this_iter_s": 5.296518802642822, "time_total_s": 113.84566569328308, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 113.84566569328308, "timesteps_since_restore": 0, "iterations_since_restore": 22, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 37.74285714285715, "ram_util_percent": 60.10000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.533931851387024, "min_q": -25.528614044189453, "max_q": 24.863733291625977, "mean_td_error": -0.052730560302734375}, "td_error": [-0.6005871295928955, -1.3446712493896484, 2.3873956203460693, 0.5081729888916016, -1.1850783824920654, 1.0458860397338867, 0.5249350070953369, -0.5279502868652344, 0.275409460067749, 0.6758270263671875, 0.8644771575927734, 0.032924652099609375, 0.4119834899902344, -4.230354309082031, -0.6902694702148438, -0.6218290328979492, 2.0661916732788086, -0.5231941938400269, 1.2567920684814453, -1.48410964012146, 2.647653579711914, -7.4563093185424805, 2.083110809326172, 1.0741996765136719, 1.3472626209259033, 0.9135751724243164, -6.331991195678711, -0.1836996078491211, -2.066030502319336, 0.7785854339599609, 1.5315876007080078, -0.5635442733764648, -5.269770622253418, 0.5174198150634766, -0.3372211456298828, 1.4073288440704346, -0.4352324306964874, 0.8916425704956055, -0.21386146545410156, -1.3348965644836426, 0.3345060348510742, 0.19884872436523438, 0.6235673427581787, 0.36471986770629883, 0.47941017150878906, -0.9392905235290527, 0.33019256591796875, 0.8416233062744141, 0.1758584976196289, 0.5699176788330078, 1.1880264282226562, -6.831000328063965, 0.33501434326171875, 0.09930801391601562, -0.30870580673217773, 0.42296648025512695, 0.30594539642333984, 0.2724483013153076, 0.9100704193115234, 0.4137839078903198, -0.8113174438476562, 0.5946378707885742, 0.5445528030395508, -0.137969970703125, -0.01035606861114502, 0.1175304651260376, -0.8767185211181641, 0.3440532684326172, -0.23311614990234375, -0.15033209323883057, 0.09183359146118164, -0.6848897933959961, -0.9457664489746094, 1.9957504272460938, 0.6846132278442383, 2.039785861968994, -1.1740303039550781, 0.6309418678283691, -3.630293846130371, 0.21306610107421875, 0.07939863204956055, 0.36397552490234375, -4.16513204574585, 1.1250896453857422, 0.6229610443115234, 0.2619657516479492, -0.1403512954711914, 0.46527957916259766, -1.0181665420532227, 1.0837244987487793, 0.3509935140609741, -0.3448368310928345, 0.19357681274414062, -6.732661247253418, 2.4384469985961914, 0.05730319023132324, 0.5579566955566406, 0.8452491760253906, 1.8530454635620117, 1.5110211372375488, 0.19357562065124512, 0.530827522277832, -7.5152997970581055, -1.2013535499572754, 0.9247002601623535, -1.014908790588379, -1.0284433364868164, -0.13040685653686523, -0.8444569110870361, 1.3073062896728516, -1.4648656845092773, -0.5636968612670898, 0.5081729888916016, 0.5630998611450195, -1.1908659934997559, -0.057773590087890625, -0.6302928924560547, 0.09930801391601562, 0.07157516479492188, 1.2357110977172852, -9.689654350280762, 1.2919120788574219, 0.48947715759277344, 0.3345060348510742, -1.1394538879394531, 2.1280202865600586, 0.21173977851867676, 1.2438983917236328, -0.2207050323486328, 1.4316775798797607, 1.2819366455078125, -0.06322526931762695, -0.012982845306396484, 0.4799213409423828, -0.2835121154785156, -0.4834575653076172, 0.7547388076782227, -0.49830174446105957, 0.7371597290039062, 2.3646798133850098, 0.9651899337768555, 1.2112083435058594, -0.21553850173950195, -1.5088768005371094, 0.9018077850341797, 1.410918951034546, -0.5997772216796875, 1.3667049407958984, 0.11825752258300781, 1.381730556488037, -1.1276206970214844, 0.9604206085205078, 0.24315452575683594, -6.989561080932617, 2.473761558532715, -1.7335524559020996, 1.0568580627441406, -0.15186119079589844, 1.2920799255371094, 0.15085315704345703, 0.5664100646972656, 0.9716219902038574, -0.024289608001708984, 1.7833642959594727, 0.7791337966918945, 0.6310129165649414, -7.256527900695801, -0.7987747192382812, 0.32134580612182617, -0.6133086681365967, 0.16898393630981445, -0.6136407852172852, -0.003838062286376953, 0.3308744430541992, -10.532596588134766, -7.637386322021484, 1.1265945434570312, 0.9693756103515625, 1.941765546798706, 14.573542594909668, 0.6071547269821167, 1.2097816467285156, 0.08652496337890625, 0.1851329803466797, -0.9814929962158203, 1.0929994583129883, -1.3587427139282227, 0.4178485870361328, 1.626373052597046, 1.4940471649169922, -0.22861862182617188, -0.6133086681365967, 0.591160774230957, 3.0608978271484375, 1.7209360599517822, 0.3055429458618164, 0.9333114624023438, -1.699793815612793, -0.3868139386177063, -0.06662559509277344, 0.03711652755737305, 0.85772705078125, 2.2160282135009766, 0.8721747398376465, 1.5921258926391602, 0.7490668296813965, 0.9301167726516724, 0.8577737808227539, -1.7344403266906738, -0.08691167831420898, -6.708309650421143, 0.08510065078735352, 1.7812070846557617, 0.1688232421875, 0.534968376159668, 0.021509170532226562, 0.5963821411132812, -0.08299732208251953, -1.5995750427246094, -0.11658382415771484, 0.6749820709228516, -0.7923316955566406, 1.6752920150756836, 0.5197240114212036, 0.2575082778930664, -5.396624565124512, 1.4910693168640137, 1.7327542304992676, 0.3531486988067627, -0.003148794174194336, 0.9200839996337891, 0.28752851486206055, -1.4682941436767578, 0.051070213317871094, -1.0552005767822266, 0.35741329193115234, 1.635400652885437, 2.2029476165771484, 0.4558391571044922, 0.7979907989501953], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 23552, "num_env_steps_trained": 84720, "num_agent_steps_sampled": 23552, "num_agent_steps_trained": 84720, "last_target_update_ts": 23552, "num_target_updates": 45}, "sampler_results": {"episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -253.16164818708785, "episode_len_mean": 330.484375, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5236161634096845, "mean_inference_ms": 23.074460175105536, "mean_action_processing_ms": 0.1357960628960948, "mean_env_wait_ms": 4.483374971961916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -253.16164818708785, "episode_len_mean": 330.484375, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5236161634096845, "mean_inference_ms": 23.074460175105536, "mean_action_processing_ms": 0.1357960628960948, "mean_env_wait_ms": 4.483374971961916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 23552, "num_agent_steps_trained": 84720, "num_env_steps_sampled": 23552, "num_env_steps_trained": 84720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 23552, "agent_timesteps_total": 23552, "timers": {"training_iteration_time_ms": 330.172, "learn_time_ms": 61.204, "learn_throughput": 3921.289, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 23552, "num_env_steps_trained": 84720, "num_agent_steps_sampled": 23552, "num_agent_steps_trained": 84720, "last_target_update_ts": 23552, "num_target_updates": 45}, "done": false, "episodes_total": 64, "training_iteration": 23, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-02", "timestamp": 1655478182, "time_this_iter_s": 5.169828414916992, "time_total_s": 119.01549410820007, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 119.01549410820007, "timesteps_since_restore": 0, "iterations_since_restore": 23, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.7, "ram_util_percent": 60.1375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.7256360054016113, "min_q": -26.89230728149414, "max_q": 26.27326202392578, "mean_td_error": -0.6482715606689453}, "td_error": [0.4961662292480469, 0.8071160316467285, -8.975847244262695, 0.7880616188049316, -2.265545129776001, -0.8522491455078125, -0.6136136054992676, 1.1579344272613525, -0.8250737190246582, 0.9271583557128906, -0.2735252380371094, -1.2607669830322266, -0.2060413360595703, -0.6876413822174072, 0.5032749176025391, -2.1276285648345947, 2.261845588684082, 1.9738216400146484, -0.6692905426025391, 1.8733501434326172, -0.6028213500976562, 0.722346305847168, 0.40362977981567383, 0.012202262878417969, -0.29096508026123047, -0.7744979858398438, 0.18537163734436035, -1.859584093093872, -2.1259875297546387, -0.44588422775268555, -0.5468578338623047, 0.24268633127212524, -0.9124747514724731, 0.046733736991882324, -0.6382870674133301, -2.8824656009674072, 0.4926881790161133, 1.1260366439819336, -0.9978408813476562, -7.684679985046387, -7.710667133331299, 1.7058582305908203, 0.3518095016479492, 0.185028076171875, 0.3096647262573242, -0.04922056198120117, -1.6658782958984375, -0.09319543838500977, 0.17278480529785156, 0.41113781929016113, 1.5600813627243042, -2.822972536087036, 0.5825891494750977, 0.3168373107910156, 0.7679047584533691, -0.950859546661377, 0.3065528869628906, 0.298386812210083, -3.1232032775878906, 1.1256961822509766, -1.0342540740966797, 0.19170761108398438, 0.3822002410888672, 0.10289919376373291, -1.5522971153259277, 0.2212543487548828, -0.7841434478759766, -1.1166160106658936, -0.5915498733520508, 1.3453874588012695, 2.3695602416992188, -0.32620906829833984, -0.6692659854888916, -0.567014217376709, -0.13854694366455078, -0.7769041061401367, 0.6427497863769531, 0.1460428237915039, 0.1642819046974182, 1.1523122787475586, -1.4382230043411255, -2.1266026496887207, 1.304931640625, -1.9875526428222656, -0.15820884704589844, -0.15738320350646973, -0.5908622741699219, -0.48134317994117737, 0.3172469139099121, -0.028385639190673828, 0.7195034027099609, -0.9508705139160156, -0.12878966331481934, -0.09237051010131836, -0.772221565246582, 0.10377848148345947, -0.03258049488067627, 0.13134002685546875, -1.6212096214294434, -0.10338973999023438, 0.5725469589233398, 0.8724346160888672, 0.9025058746337891, 0.298386812210083, 0.5393176078796387, -0.93109130859375, 0.6924595832824707, -0.2434900999069214, -5.682530403137207, -8.23335075378418, -1.5699338912963867, 1.2872514724731445, -1.3995559215545654, 0.3400897979736328, 0.4837055206298828, -0.04977816343307495, -1.1243312358856201, -1.3107118606567383, 0.6640777587890625, -0.6229381561279297, 17.138086318969727, 0.022541522979736328, 2.005823850631714, -2.8398609161376953, 0.5045223236083984, 1.1235361099243164, 0.3534066677093506, -6.452760219573975, 0.15609169006347656, -1.0187139511108398, -7.575605392456055, -2.6733193397521973, -0.26859474182128906, -0.582763671875, -1.5744342803955078, 0.1636556088924408, -0.5814971923828125, -1.6527109146118164, 0.6857662200927734, -0.4202219247817993, 0.29143428802490234, -7.03165340423584, 0.03612709045410156, -0.1787099838256836, -2.0620338916778564, -1.537210464477539, 0.2418212890625, -0.5469863414764404, -0.08510804176330566, 0.10086393356323242, -0.4309043884277344, 0.13057899475097656, -1.3316912651062012, -7.77401065826416, -0.9933981895446777, -0.029961109161376953, -0.7493009567260742, -0.940711498260498, -0.21637916564941406, 0.17527198791503906, 0.009551286697387695, -0.4936332702636719, 0.21477127075195312, 0.17544174194335938, -0.8701281547546387, -0.5688762664794922, -1.184701919555664, -7.744603157043457, 1.8973007202148438, -0.6704339981079102, -1.6481373310089111, 1.1438099145889282, -1.1371915340423584, 0.14476871490478516, 0.0907745361328125, -7.252884864807129, 0.09544944763183594, -0.13854694366455078, 0.4818248748779297, 0.5683541297912598, -2.0115318298339844, -0.04677581787109375, -0.8986731171607971, -0.31346702575683594, 1.2515010833740234, 1.5910043716430664, -0.8585637807846069, -7.4818949699401855, 0.6517477035522461, -0.02125149965286255, -4.645965099334717, 0.06415367126464844, -0.35924673080444336, -0.2952136993408203, -0.15515613555908203, 0.16452407836914062, -0.48204994201660156, -0.07018470764160156, -2.1072158813476562, 1.4688196182250977, 0.02242898941040039, -0.27994537353515625, 0.8603763580322266, -0.1227257251739502, 0.5458288192749023, -1.7605385780334473, -10.893978118896484, -0.22950062155723572, -0.35686683654785156, -7.229265213012695, -0.7493009567260742, -8.220229148864746, -0.7726068496704102, -1.6516485214233398, -0.03076028823852539, -0.12250006198883057, -1.2187862396240234, 0.23082923889160156, -0.41964149475097656, -0.2238931655883789, -0.8789329528808594, -1.167614459991455, -0.9325428605079651, 0.5273923873901367, 0.7677059173583984, 0.8516247272491455, -0.8015626668930054, -0.091522216796875, 0.6620802879333496, -0.9949207305908203, 0.20598411560058594, -0.6151080131530762, -0.8212261199951172, -0.703650951385498, -0.6499160528182983, -0.8860607147216797, -0.588134765625, -1.761821985244751, 0.0656125545501709, -1.0209507942199707], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 24576, "num_env_steps_trained": 88560, "num_agent_steps_sampled": 24576, "num_agent_steps_trained": 88560, "last_target_update_ts": 24576, "num_target_updates": 47}, "sampler_results": {"episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -247.28094898581958, "episode_len_mean": 328.6212121212121, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5237309134777778, "mean_inference_ms": 23.103893444664138, "mean_action_processing_ms": 0.13577014599337459, "mean_env_wait_ms": 4.476128515818682, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -247.28094898581958, "episode_len_mean": 328.6212121212121, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5237309134777778, "mean_inference_ms": 23.103893444664138, "mean_action_processing_ms": 0.13577014599337459, "mean_env_wait_ms": 4.476128515818682, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 24576, "num_agent_steps_trained": 88560, "num_env_steps_sampled": 24576, "num_env_steps_trained": 88560, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 24576, "agent_timesteps_total": 24576, "timers": {"training_iteration_time_ms": 347.775, "learn_time_ms": 61.413, "learn_throughput": 3907.97, "synch_weights_time_ms": 19.79}, "counters": {"num_env_steps_sampled": 24576, "num_env_steps_trained": 88560, "num_agent_steps_sampled": 24576, "num_agent_steps_trained": 88560, "last_target_update_ts": 24576, "num_target_updates": 47}, "done": false, "episodes_total": 66, "training_iteration": 24, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-08", "timestamp": 1655478188, "time_this_iter_s": 5.438063144683838, "time_total_s": 124.45355725288391, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 124.45355725288391, "timesteps_since_restore": 0, "iterations_since_restore": 24, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.387499999999996, "ram_util_percent": 60.2625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.809772491455078, "min_q": -26.531314849853516, "max_q": 26.3415470123291, "mean_td_error": -0.30398064851760864}, "td_error": [-0.28196239471435547, 1.2048749923706055, -0.3383476734161377, 0.6382613182067871, -1.302286148071289, 1.5070905685424805, 0.42615795135498047, -3.760542392730713, 0.8376710414886475, 0.4169120788574219, 1.0380620956420898, -4.668893814086914, 1.458120346069336, -0.43323421478271484, -0.9386529922485352, -0.1934967041015625, 2.8996400833129883, -4.72431755065918, 0.23284649848937988, 0.6082558631896973, -1.4205141067504883, 1.5253734588623047, 0.9808101654052734, 0.4827556610107422, 0.9338779449462891, 0.0487821102142334, -1.2967948913574219, -0.2324666976928711, -2.1619668006896973, -0.4445505142211914, 0.2064352035522461, -0.46573638916015625, 0.40493202209472656, -0.2518043518066406, -0.6042652130126953, 0.6114237308502197, 1.4883356094360352, 1.0449695587158203, 0.20290803909301758, 1.2048749923706055, 3.3083038330078125, 0.6704349517822266, -1.0436391830444336, 1.6889113187789917, -1.3194949626922607, 0.4672532081604004, 1.2149527072906494, -5.082256317138672, -1.6781291961669922, 0.4931182861328125, -7.515039920806885, -6.860675811767578, 0.04515838623046875, -9.240974426269531, 0.019193172454833984, -1.3872690200805664, 0.5708816051483154, 1.5232009887695312, 0.7390275001525879, -4.0912628173828125, 0.6524724960327148, 0.11736583709716797, 1.1792446374893188, 0.530970573425293, 0.9523382186889648, -0.015482664108276367, -0.42349910736083984, -0.22367000579833984, -5.722912311553955, 0.42067575454711914, 0.6804013252258301, 0.273134708404541, -7.108360290527344, 0.8873157501220703, -0.4772930145263672, 0.2866659164428711, 0.9198513031005859, 0.33284807205200195, 10.117372512817383, 0.06841182708740234, 0.2101573944091797, -0.931786298751831, 0.6462044715881348, -5.7030110359191895, -11.687477111816406, -6.824699401855469, -8.191977500915527, -3.843860626220703, 1.335646629333496, 1.3143420219421387, -0.4631919860839844, 0.5793609619140625, 0.5664806365966797, 0.7777061462402344, 0.9656529426574707, 0.020969390869140625, -0.40680408477783203, 0.5519833564758301, 0.76446533203125, 0.024326324462890625, -2.1710920333862305, 0.6048026084899902, 1.1339623928070068, 0.7668113708496094, 0.2696744203567505, 1.4648675918579102, -1.5339250564575195, -1.159341812133789, -0.7714411020278931, 0.5521335601806641, 1.5198725461959839, 0.48103904724121094, 1.1111106872558594, -2.2346057891845703, 1.4417524337768555, -0.4127804934978485, 0.09987831115722656, -0.8768545389175415, -0.296600341796875, 0.8685240745544434, 0.4431215524673462, 0.8825068473815918, -0.550438404083252, -0.4904975891113281, 0.9703454971313477, -1.4060802459716797, -5.906179428100586, -1.1156574487686157, 1.2773523330688477, 0.17690467834472656, 1.128934621810913, 0.4104623794555664, 0.7127957344055176, 0.9845929145812988, -0.8660717010498047, -0.5135211944580078, 0.6023876667022705, 1.6019001007080078, -0.13497543334960938, -0.5882217884063721, 0.9346542358398438, -10.463364601135254, 0.9570839405059814, -0.7270386219024658, -0.24604034423828125, 1.9429645538330078, -4.976487636566162, -0.8915257453918457, -0.6445706486701965, 2.9111204147338867, 1.4167871475219727, 1.0027518272399902, 2.726116180419922, 0.37249064445495605, 1.2290210723876953, 0.2063455581665039, 0.01523900032043457, -0.3102893829345703, 1.855036735534668, -0.315407395362854, 0.4143247604370117, -1.6228173971176147, 0.530970573425293, 0.6150150299072266, 1.4052600860595703, 0.21438312530517578, 0.6001739501953125, 0.31780242919921875, -8.812593460083008, -0.8221168518066406, -1.2989482879638672, 0.01523900032043457, -1.2927703857421875, 0.8612790107727051, -0.2760601043701172, -0.6144368648529053, 0.6090602874755859, -7.675658226013184, 0.7955570220947266, 0.7305526733398438, -1.866197109222412, 0.8085689544677734, 1.255502700805664, -0.7102766036987305, 1.2747340202331543, 0.54229736328125, 0.5932369232177734, 1.1052403450012207, 1.2097773551940918, 1.7931246757507324, 0.9365459680557251, -0.1698455810546875, -8.902738571166992, 1.1345901489257812, 0.6747541427612305, 1.3157272338867188, 0.11064624786376953, 1.8090829849243164, 1.254746437072754, 1.0449695587158203, -7.617443561553955, 1.1304233074188232, 0.6010265350341797, -1.5295472145080566, 0.5469619035720825, 1.113835334777832, 0.21493160724639893, 0.6077594757080078, -7.09361457824707, 1.2548699378967285, 1.077096939086914, 0.3152637481689453, 0.6435374021530151, -0.5721893310546875, 1.1664113998413086, 0.9053783416748047, -2.2326154708862305, 0.5995330810546875, 1.2989693880081177, 1.5642955303192139, 0.5174083709716797, -0.2683321237564087, 0.9651050567626953, -0.5154662132263184, 2.1686344146728516, -0.06866931915283203, 0.745686411857605, 0.8054819107055664, 1.3301949501037598, -0.4247169494628906, -0.9359264373779297, -1.9156546592712402, 1.3769702911376953, 0.2976107597351074, -0.3245372772216797, 0.6010265350341797, -0.16639137268066406, -0.12334060668945312, 1.146702766418457, -0.10063552856445312], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 25600, "num_env_steps_trained": 92400, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 92400, "last_target_update_ts": 25600, "num_target_updates": 49}, "sampler_results": {"episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -243.73243897642408, "episode_len_mean": 327.4142857142857, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5239223559067884, "mean_inference_ms": 23.14990555366226, "mean_action_processing_ms": 0.1356905597779663, "mean_env_wait_ms": 4.464231765062982, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -243.73243897642408, "episode_len_mean": 327.4142857142857, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5239223559067884, "mean_inference_ms": 23.14990555366226, "mean_action_processing_ms": 0.1356905597779663, "mean_env_wait_ms": 4.464231765062982, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 92400, "num_env_steps_sampled": 25600, "num_env_steps_trained": 92400, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 25600, "agent_timesteps_total": 25600, "timers": {"training_iteration_time_ms": 338.097, "learn_time_ms": 61.153, "learn_throughput": 3924.594, "synch_weights_time_ms": 20.071}, "counters": {"num_env_steps_sampled": 25600, "num_env_steps_trained": 92400, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 92400, "last_target_update_ts": 25600, "num_target_updates": 49}, "done": false, "episodes_total": 70, "training_iteration": 25, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-13", "timestamp": 1655478193, "time_this_iter_s": 5.414998769760132, "time_total_s": 129.86855602264404, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 129.86855602264404, "timesteps_since_restore": 0, "iterations_since_restore": 25, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 37.4625, "ram_util_percent": 60.3625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.2551608085632324, "min_q": -26.441587448120117, "max_q": 27.195636749267578, "mean_td_error": -0.5642207860946655}, "td_error": [1.1852054595947266, 0.6388709545135498, -2.01800537109375, 0.01916980743408203, 0.12965917587280273, 0.9090675115585327, -0.6378145217895508, -0.42245960235595703, -2.5197157859802246, -0.07118988037109375, 0.32619786262512207, 1.1191139221191406, -1.037369728088379, 0.20163917541503906, -0.9736270904541016, -0.07543659210205078, 0.38899850845336914, -1.8280048370361328, -1.3307760953903198, 0.4734344482421875, 0.5991306304931641, 1.1283283233642578, 0.35854244232177734, -4.41960334777832, 0.17451000213623047, -0.6667413711547852, -0.6223983764648438, -0.18274784088134766, -1.5169973373413086, -0.1609264612197876, -1.1792869567871094, -0.9920711517333984, 0.12229537963867188, 0.008664131164550781, -1.198882818222046, 5.6117963790893555, -1.031397819519043, -1.0427148342132568, 0.22956609725952148, -0.9769449234008789, 0.29670166969299316, 0.7967061996459961, 1.362142562866211, 0.9379448890686035, 1.9021492004394531, 0.036795616149902344, -10.60012149810791, 0.2051374912261963, 0.11153316497802734, -1.7390937805175781, -0.33138275146484375, -1.8931617736816406, -1.0983667373657227, -0.05001115798950195, -0.24153900146484375, -8.11669921875, -0.1138467788696289, -1.5741653442382812, 0.1458892822265625, -0.29313087463378906, -6.084812164306641, -0.976813793182373, -5.316404342651367, 0.1357320249080658, 0.14212238788604736, 0.9042949676513672, -0.14884662628173828, -0.4658083915710449, -0.8721994161605835, 0.37706661224365234, -1.0389347076416016, -0.33357906341552734, -5.677642822265625, -0.10915744304656982, -0.41875743865966797, -0.9774971008300781, -0.5825932025909424, -1.248849868774414, -1.2438621520996094, -0.3666343688964844, -0.25311279296875, 2.3237686157226562, -0.6962285041809082, -1.1883306503295898, 0.4819190502166748, -0.5862572193145752, -0.3328704833984375, 0.061614036560058594, -1.1644468307495117, -1.4196901321411133, 0.4673271179199219, 0.6578254699707031, 0.9024791717529297, -1.113468885421753, -0.9220857620239258, -1.4780311584472656, 0.2052764892578125, -2.5451412200927734, -0.8614873290061951, -0.5357146263122559, -0.10381317138671875, -0.9213985204696655, -0.2105693817138672, 0.29621362686157227, 0.9535772800445557, -5.016523361206055, -0.81591796875, -0.12233924865722656, 0.25186777114868164, -1.2483453750610352, -0.6705513000488281, -1.0867948532104492, -0.7711267471313477, -1.025322437286377, 0.9430694580078125, -0.7101898193359375, 1.0267915725708008, -0.2890472412109375, -1.1310558319091797, 0.5999164581298828, -0.7106447219848633, -0.8900947570800781, -1.015932559967041, 1.4106063842773438, -0.5843796133995056, -0.31185150146484375, 0.6334095001220703, 2.5421886444091797, 1.053880214691162, 1.735741138458252, 1.6248321533203125, -0.30718231201171875, -0.5866478681564331, 1.095067024230957, -1.4028984308242798, -0.5970363616943359, -1.6986751556396484, 1.1542727947235107, 0.1382460594177246, 1.1881847381591797, -1.6479759216308594, 0.45008325576782227, 0.271514892578125, -7.830234527587891, -0.2511892318725586, -0.8958134651184082, -0.3392910957336426, -0.2763996124267578, -0.694404125213623, 1.3385543823242188, -1.904581069946289, -2.085603713989258, -1.1861915588378906, -0.8022346496582031, -1.0801467895507812, 0.01916980743408203, 0.1458892822265625, -1.4277000427246094, -0.9904489517211914, 2.385021209716797, 0.02863597869873047, 1.2470436096191406, 0.9236602783203125, 0.5905017852783203, -1.211801528930664, -0.4651244878768921, 0.4575587809085846, -0.3604731559753418, 6.647269248962402, 0.7470226287841797, 1.3068971633911133, 0.08658656477928162, 0.34982967376708984, 0.3953824043273926, 2.0475168228149414, -0.03634071350097656, 0.2059307098388672, -0.796104907989502, -6.168357849121094, -0.6602020263671875, -0.17345428466796875, -0.24940872192382812, -1.8669624328613281, -0.058718204498291016, -2.176569938659668, 0.7080869674682617, 0.7889151573181152, -0.15476250648498535, -6.538928031921387, -0.3666343688964844, 1.4856843948364258, 1.0267915725708008, 0.01628732681274414, -2.011458396911621, 0.09064674377441406, 1.0665807723999023, -7.434087753295898, -1.2594280242919922, 0.2856121063232422, 0.4834282398223877, 0.25434303283691406, 0.9181003570556641, -1.3164653778076172, -12.928606986999512, 0.9790439605712891, 1.918783187866211, -0.5979468822479248, -0.058718204498291016, -0.14539170265197754, 0.6381444931030273, -0.9842395782470703, -10.238755226135254, -0.06836414337158203, -1.1870908737182617, 4.966416358947754, 0.4341087341308594, -10.265780448913574, 0.2117481231689453, -1.537438988685608, 0.2321479320526123, -0.47530364990234375, -1.156224012374878, 0.3319072723388672, -0.26380395889282227, -0.36930084228515625, -0.9929008483886719, -0.7047610282897949, -0.3331441879272461, -0.16750335693359375, -0.6780204772949219, 0.07709741592407227, 0.5905017852783203, 0.25933194160461426, -0.9805631637573242, 0.8400592803955078, -0.13007354736328125, 0.05769157409667969, -6.266356945037842, -0.6521447896957397, 1.5991744995117188], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 26624, "num_env_steps_trained": 96240, "num_agent_steps_sampled": 26624, "num_agent_steps_trained": 96240, "last_target_update_ts": 26624, "num_target_updates": 51}, "sampler_results": {"episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -240.10566499620677, "episode_len_mean": 325.7866666666667, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5241320646021063, "mean_inference_ms": 23.218627930743683, "mean_action_processing_ms": 0.1361775845742844, "mean_env_wait_ms": 4.4427453999164905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -240.10566499620677, "episode_len_mean": 325.7866666666667, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5241320646021063, "mean_inference_ms": 23.218627930743683, "mean_action_processing_ms": 0.1361775845742844, "mean_env_wait_ms": 4.4427453999164905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 26624, "num_agent_steps_trained": 96240, "num_env_steps_sampled": 26624, "num_env_steps_trained": 96240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 26624, "agent_timesteps_total": 26624, "timers": {"training_iteration_time_ms": 348.788, "learn_time_ms": 62.074, "learn_throughput": 3866.37, "synch_weights_time_ms": 20.443}, "counters": {"num_env_steps_sampled": 26624, "num_env_steps_trained": 96240, "num_agent_steps_sampled": 26624, "num_agent_steps_trained": 96240, "last_target_update_ts": 26624, "num_target_updates": 51}, "done": false, "episodes_total": 75, "training_iteration": 26, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-19", "timestamp": 1655478199, "time_this_iter_s": 5.378978252410889, "time_total_s": 135.24753427505493, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 135.24753427505493, "timesteps_since_restore": 0, "iterations_since_restore": 26, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.74285714285714, "ram_util_percent": 60.48571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.411297082901001, "min_q": -27.31722640991211, "max_q": 27.861724853515625, "mean_td_error": -1.3887041807174683}, "td_error": [-0.8673057556152344, -1.301192283630371, -2.882326126098633, -3.6358914375305176, -0.744391679763794, -1.0833330154418945, 0.5240880250930786, 0.9589977264404297, -0.7706394195556641, -0.23787879943847656, -0.8307285308837891, -2.002129554748535, -1.576167106628418, 0.5076613426208496, 1.5646724700927734, -1.0630378723144531, -0.9731881618499756, 1.0792007446289062, -0.4489784240722656, -0.9808893203735352, -2.905986785888672, -0.9896302223205566, -0.8115253448486328, -8.14914321899414, -3.2825145721435547, -0.07487010955810547, -1.6262054443359375, -0.4392433166503906, -4.003751754760742, -0.08781576156616211, -1.345052719116211, -11.38095474243164, -1.3154051303863525, -8.427372932434082, 0.1673755645751953, -0.5785808563232422, -1.5734808444976807, -1.0132231712341309, 3.132204532623291, 0.2769889831542969, -0.5129661560058594, 0.49941444396972656, -3.8452186584472656, -1.8323578834533691, -2.481156349182129, -0.10854768753051758, -0.3546104431152344, -0.3065834045410156, 0.9510335922241211, -3.5105628967285156, 0.7132377624511719, -1.6421329975128174, -0.9302678108215332, 1.399465560913086, -2.373213291168213, -1.7808666229248047, -8.391478538513184, -2.337911605834961, 0.497422456741333, -7.694738388061523, -0.7679653167724609, -0.7424345016479492, -2.0843143463134766, -0.7213740348815918, -0.6004917025566101, -3.663872718811035, -6.076900482177734, -1.427567481994629, -1.1851310729980469, 0.3751182556152344, -2.0220651626586914, -1.7401814460754395, -1.4154548645019531, -1.8273677825927734, -9.678275108337402, -1.3598053455352783, -0.8454694747924805, 4.806634902954102, -0.1682720184326172, -0.00347900390625, -0.5203127861022949, -1.9892041683197021, -0.6809600591659546, 0.11262214183807373, 0.10415816307067871, -0.5648350715637207, -0.26592302322387695, -2.6159238815307617, -1.9622457027435303, -2.1148977279663086, -0.868537425994873, 0.4945564270019531, -0.6656311750411987, -1.5040345191955566, -0.5785808563232422, -0.7886486053466797, -0.870796799659729, -2.6687965393066406, -0.30902671813964844, -0.8728275299072266, -6.902346611022949, -2.5134048461914062, -1.3059816360473633, -0.7650413513183594, -0.648314356803894, -0.3387622833251953, -4.587911605834961, -1.679616928100586, -0.5697822570800781, 1.3455345630645752, 0.2675962448120117, -2.555102825164795, -0.9479808807373047, -0.88730788230896, -0.9936141967773438, 0.10323169827461243, -1.4766120910644531, -1.0707135200500488, -1.7283287048339844, -0.24906468391418457, -2.2512731552124023, 0.5773143768310547, -0.2712364196777344, -1.0490093231201172, -5.379749298095703, -0.22632217407226562, -0.7618942260742188, -1.6898555755615234, -8.701065063476562, -0.41053128242492676, 0.24497032165527344, -0.7617874145507812, -2.1684083938598633, -1.3257033824920654, -1.017176628112793, -1.6331803798675537, -1.588651418685913, 0.5931299328804016, -0.8486847877502441, -1.49322509765625, -0.8488736152648926, -1.7916193008422852, 1.131378173828125, -1.909749984741211, -0.4444859027862549, -0.7441778182983398, -1.1367464065551758, -6.55926513671875, 0.45153331756591797, 0.1855297088623047, -8.352195739746094, 0.40490150451660156, -0.844252347946167, -2.5252904891967773, -0.19956231117248535, -2.890631675720215, -1.7948904037475586, -0.3836698532104492, 0.31960582733154297, -2.2693047523498535, -1.3889498710632324, -0.14487075805664062, -1.269216537475586, -1.8164081573486328, -1.4793510437011719, -0.9166030883789062, -0.04019784927368164, -6.972787857055664, -0.11066055297851562, 0.4354972839355469, -0.903910756111145, -0.32582521438598633, -2.2254018783569336, -1.2186269760131836, -0.7360677719116211, -0.7332866191864014, -0.496553897857666, -1.0493698120117188, -1.7730116844177246, -1.3089418411254883, 0.9475831985473633, -2.461665630340576, -0.297149658203125, 0.1946430206298828, 0.1946430206298828, -7.19317626953125, -1.2023283243179321, -0.44159889221191406, -0.9830713272094727, -0.7416706085205078, -8.543621063232422, -2.5224175453186035, -0.3945646286010742, -2.030697822570801, -1.4233219623565674, -3.8390049934387207, -2.1472482681274414, -0.8841705322265625, -8.635287284851074, -2.423581600189209, -4.128549575805664, -2.5780553817749023, -0.5466722846031189, 0.5773143768310547, -0.8270998001098633, -7.006311416625977, -1.4468954801559448, -0.03593254089355469, -0.2885866165161133, 0.3897705078125, -8.14914321899414, -1.9977760314941406, -0.9932346343994141, -0.4246492385864258, -1.8298425674438477, -2.6400232315063477, -1.7595272064208984, -0.2992362976074219, -1.0774526596069336, -2.5175228118896484, -2.0408401489257812, -0.8540511131286621, -1.6623797416687012, -1.694601058959961, -0.3439826965332031, -0.11459541320800781, -1.0855051279067993, -1.0863733291625977, 0.36572742462158203, -1.2771058082580566, -0.8487486839294434, 0.30564332008361816, -0.5341141819953918, -0.14639854431152344, 0.49037647247314453, -1.4595565795898438, -2.245523452758789, -0.48800742626190186, 19.780941009521484, -0.08840751647949219], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 27648, "num_env_steps_trained": 100080, "num_agent_steps_sampled": 27648, "num_agent_steps_trained": 100080, "last_target_update_ts": 27648, "num_target_updates": 53}, "sampler_results": {"episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -237.78060284713283, "episode_len_mean": 324.625, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5227069467369043, "mean_inference_ms": 23.29496424789449, "mean_action_processing_ms": 0.1360487791220779, "mean_env_wait_ms": 4.425006925921954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 2.4343045204877853, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -237.78060284713283, "episode_len_mean": 324.625, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5227069467369043, "mean_inference_ms": 23.29496424789449, "mean_action_processing_ms": 0.1360487791220779, "mean_env_wait_ms": 4.425006925921954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 27648, "num_agent_steps_trained": 100080, "num_env_steps_sampled": 27648, "num_env_steps_trained": 100080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 27648, "agent_timesteps_total": 27648, "timers": {"training_iteration_time_ms": 308.549, "learn_time_ms": 61.371, "learn_throughput": 3910.667, "synch_weights_time_ms": 20.088}, "counters": {"num_env_steps_sampled": 27648, "num_env_steps_trained": 100080, "num_agent_steps_sampled": 27648, "num_agent_steps_trained": 100080, "last_target_update_ts": 27648, "num_target_updates": 53}, "done": false, "episodes_total": 80, "training_iteration": 27, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-24", "timestamp": 1655478204, "time_this_iter_s": 5.064544916152954, "time_total_s": 140.31207919120789, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 140.31207919120789, "timesteps_since_restore": 0, "iterations_since_restore": 27, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.2125, "ram_util_percent": 60.6875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 4.2940497398376465, "min_q": -27.205854415893555, "max_q": 30.435224533081055, "mean_td_error": 0.06834020465612411}, "td_error": [0.6145974397659302, 0.1025543212890625, 0.8576770424842834, -0.8417868614196777, 0.9402618408203125, 0.27606451511383057, 2.7954578399658203, 1.3776576519012451, -0.634709358215332, 1.2614059448242188, 0.30945920944213867, -0.7151327133178711, 0.3003387451171875, -0.12361335754394531, 0.4356897473335266, -0.35736083984375, -0.9439058303833008, 0.33132266998291016, 1.346426010131836, -1.2713127136230469, 0.45894432067871094, -0.45812320709228516, 0.46796226501464844, 0.9227476119995117, 0.9576320648193359, 1.9904594421386719, -1.3634757995605469, 2.3172848224639893, 1.679948329925537, 0.32822513580322266, -0.7380580902099609, 0.4040050506591797, 0.370147705078125, -1.9891090393066406, 0.2754650115966797, 0.882965087890625, 0.7321300506591797, -0.8257765769958496, 2.2281084060668945, -0.7918300628662109, -1.0119028091430664, 0.7555103302001953, 1.2290940284729004, 0.48244309425354004, 1.1122856140136719, 0.48565673828125, -0.465739905834198, -1.1105480194091797, 3.1623706817626953, 1.7034530639648438, 0.4049186706542969, 0.708348274230957, 0.004199981689453125, 0.17215633392333984, 14.504706382751465, 0.6046047210693359, -6.003525733947754, 2.5734667778015137, -0.28530120849609375, -0.7313404083251953, 0.6029109954833984, 1.1210556030273438, -0.8351478576660156, 2.325960159301758, 1.1111888885498047, 1.592453956604004, 2.029046058654785, -0.35736083984375, -8.204082489013672, 0.5393452644348145, 1.217733383178711, 1.4834825992584229, -2.411468505859375, 1.0059747695922852, -6.8810882568359375, 0.3970400094985962, -0.3262338638305664, -1.2413558959960938, 0.30277442932128906, 0.33216285705566406, 0.6060581207275391, 0.8944869041442871, -0.73616623878479, 0.661712646484375, 0.10609245300292969, 0.12237262725830078, -5.967972755432129, 0.525477409362793, 0.0016694068908691406, -4.007203102111816, -0.3096780776977539, 0.9658169746398926, 0.5473155975341797, 0.004199981689453125, 0.5673942565917969, -1.4682788848876953, -1.937486171722412, 0.33402419090270996, -0.5541114807128906, -3.634500503540039, -1.1963138580322266, -1.2516613006591797, 2.1229114532470703, 0.8269133567810059, 0.7597446441650391, -6.964570999145508, -0.10951995849609375, 0.2869119644165039, 0.7317459583282471, -0.07099151611328125, 1.7959403991699219, -0.4171485900878906, -5.2218017578125, 1.2559921741485596, 0.23602652549743652, -0.07443046569824219, -0.5802230834960938, -0.08025550842285156, 1.4424934387207031, 1.3780183792114258, 0.43407130241394043, 0.7597494125366211, 0.229644775390625, -4.111104965209961, 0.5871000289916992, -1.4742958545684814, -0.7534198760986328, 2.0877513885498047, 0.06163465976715088, -1.057091474533081, 0.9238814115524292, 1.2027521133422852, -0.9562788009643555, 0.8326358795166016, 0.30449867248535156, 1.4935563802719116, 0.5975322723388672, 0.9422774314880371, 3.8631837368011475, 0.06126213073730469, 0.7597494125366211, -0.7157402038574219, -0.2527647018432617, 0.8381538391113281, -0.15726089477539062, 0.24155807495117188, 1.4014739990234375, 0.5257177352905273, 1.2374629974365234, 0.05882763862609863, -0.25145673751831055, -0.6292247772216797, 0.9706230163574219, -1.7858448028564453, 1.8379125595092773, 0.33705615997314453, -2.9356672763824463, 0.16362333297729492, 1.9123916625976562, 0.19712257385253906, 0.7739772796630859, 1.7405147552490234, -0.6839935779571533, -6.097085952758789, -0.8351478576660156, -0.0836944580078125, -0.3868074417114258, 1.4270380735397339, -5.887407302856445, 0.689842700958252, 1.4356913566589355, -1.7079782485961914, 0.794677734375, 0.34359073638916016, -1.3732943534851074, 0.8137493133544922, -0.6913890838623047, 0.8574389815330505, -1.2040808200836182, 1.2296841144561768, -0.8852746486663818, 1.254429817199707, 2.2343263626098633, 0.5688066482543945, 0.2876472473144531, 0.3944544196128845, -0.06787109375, 1.6767010688781738, 1.7879638671875, 2.3611812591552734, -0.6568374633789062, 0.7516279816627502, 2.2761688232421875, -0.19077777862548828, -9.723978042602539, -0.8792476654052734, -0.7936809062957764, -0.6168382167816162, -0.1515369415283203, 0.004941225051879883, 2.9885807037353516, 1.0498676300048828, 3.454901695251465, 0.8179354667663574, 0.3204154968261719, 1.531076431274414, 0.0015454292297363281, 0.24082183837890625, -2.108043670654297, 0.24082183837890625, -0.2729988098144531, 0.6655216217041016, -0.11233901977539062, -0.2283022403717041, 0.7590188980102539, 0.03522777557373047, 0.1273670196533203, 2.2479019165039062, 0.2261309027671814, 1.9187312126159668, -0.1603412628173828, 1.27583909034729, 2.578740119934082, -0.8490209579467773, -0.32572460174560547, -2.289954662322998, -1.1591911315917969, 1.4478607177734375, 0.3908505439758301, 0.3132801055908203, -0.024221420288085938, -1.6606740951538086, -4.892200469970703, -2.827042579650879, -1.4193425178527832, 0.16540145874023438, 0.5499534606933594, 1.9079608917236328, 0.8168689012527466, 0.4868435859680176], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 28672, "num_env_steps_trained": 103920, "num_agent_steps_sampled": 28672, "num_agent_steps_trained": 103920, "last_target_update_ts": 28672, "num_target_updates": 55}, "sampler_results": {"episode_reward_max": 21.81153803318739, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -234.57576160169677, "episode_len_mean": 323.24691358024694, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5231084174620011, "mean_inference_ms": 23.30446285772361, "mean_action_processing_ms": 0.13600714172021852, "mean_env_wait_ms": 4.423893316182666, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 21.81153803318739, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -234.57576160169677, "episode_len_mean": 323.24691358024694, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5231084174620011, "mean_inference_ms": 23.30446285772361, "mean_action_processing_ms": 0.13600714172021852, "mean_env_wait_ms": 4.423893316182666, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 28672, "num_agent_steps_trained": 103920, "num_env_steps_sampled": 28672, "num_env_steps_trained": 103920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 28672, "agent_timesteps_total": 28672, "timers": {"training_iteration_time_ms": 320.267, "learn_time_ms": 61.693, "learn_throughput": 3890.246, "synch_weights_time_ms": 20.388}, "counters": {"num_env_steps_sampled": 28672, "num_env_steps_trained": 103920, "num_agent_steps_sampled": 28672, "num_agent_steps_trained": 103920, "last_target_update_ts": 28672, "num_target_updates": 55}, "done": false, "episodes_total": 81, "training_iteration": 28, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-30", "timestamp": 1655478210, "time_this_iter_s": 5.056786775588989, "time_total_s": 145.36886596679688, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 145.36886596679688, "timesteps_since_restore": 0, "iterations_since_restore": 28, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.15714285714286, "ram_util_percent": 60.82857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 6.690282344818115, "min_q": -25.033226013183594, "max_q": 32.670772552490234, "mean_td_error": -0.5852058529853821}, "td_error": [-1.4305548667907715, -6.5035223960876465, 1.3618640899658203, -0.014345645904541016, -0.42812347412109375, -0.6436824798583984, 0.43772125244140625, 0.25475502014160156, -6.625279426574707, -0.2221851348876953, 0.3521132469177246, 0.47177886962890625, 0.6651268005371094, 0.13659095764160156, -1.4220471382141113, -1.8940563201904297, 1.0140037536621094, 1.6120672225952148, -0.2211933135986328, 0.11474609375, 0.6367778778076172, -0.10445761680603027, -0.8456344604492188, -1.2516974210739136, -1.9580049514770508, -1.311859130859375, -1.2236690521240234, -0.40885448455810547, 0.9874866008758545, -0.6148409843444824, -0.8728618621826172, -0.5433864593505859, 1.0476183891296387, -0.5904026031494141, 2.2577269077301025, 0.13129901885986328, 0.47848057746887207, -1.3535537719726562, 0.7617874145507812, 1.5801944732666016, 0.41343021392822266, 0.5334587097167969, 0.7488203048706055, 1.6018224954605103, 0.9166641235351562, 0.7915596961975098, 1.6846122741699219, 0.10364341735839844, -1.0709114074707031, 0.17990577220916748, 2.078690528869629, -1.131439208984375, -0.5451483726501465, 0.41343021392822266, -0.5750112533569336, 0.4779219627380371, -1.2501378059387207, -0.46088552474975586, -13.487326622009277, -0.7880496978759766, -0.15495270490646362, 0.1395263671875, 1.719808578491211, -0.2876625061035156, 0.0322260856628418, -0.3119087219238281, -0.31749486923217773, 0.47437572479248047, -0.40784549713134766, 1.9843554496765137, 0.23358440399169922, -6.680869102478027, 0.1331215500831604, 0.8530921936035156, 0.9488735198974609, 0.41343021392822266, -6.339689254760742, 0.16476869583129883, -0.2554035186767578, -1.652608871459961, 0.38822174072265625, -0.9790420532226562, 1.0116863250732422, -0.9489431381225586, -0.32579994201660156, 0.018143653869628906, 1.2588586807250977, 1.843729019165039, -7.251964569091797, 0.1271495819091797, -0.1573314666748047, 1.6037168502807617, 1.8270320892333984, 0.11474609375, -1.2986352443695068, 0.4823477268218994, -6.262302398681641, 1.3457107543945312, -3.338498830795288, -1.7541356086730957, 0.7845268249511719, 0.5693173408508301, 0.42984580993652344, 0.16427993774414062, -0.992926836013794, 0.09962892532348633, -0.3985886573791504, -0.052384376525878906, -0.6156656742095947, -0.10605812072753906, -0.36138343811035156, 0.06731319427490234, -0.2827320098876953, -0.25175952911376953, -0.33837890625, -0.2913398742675781, -29.496475219726562, -2.124868154525757, -3.16786527633667, -5.650469779968262, -0.1704082489013672, -7.692633628845215, -0.4242222309112549, 0.6681623458862305, -8.008707046508789, -1.6753616333007812, -5.17733907699585, -0.12438774108886719, 0.26572155952453613, -8.47339916229248, 0.3647890090942383, 1.8089826107025146, 0.10280227661132812, 1.425333023071289, 1.1535091400146484, 1.4404220581054688, 0.34462928771972656, -0.4351768493652344, -7.585245609283447, 0.6935157775878906, 0.23072242736816406, -0.10605812072753906, -1.2986352443695068, 0.2516822814941406, 0.6813027858734131, 0.5661163330078125, 0.8612313270568848, -2.0240492820739746, -0.05345630645751953, -5.9894561767578125, 0.3487510681152344, -3.537504196166992, 6.49465274810791, 9.547306060791016, -1.3684911727905273, 0.4490843415260315, 1.139976978302002, 0.43012237548828125, -1.3603620529174805, 0.5735397338867188, 0.6519513130187988, -0.7353782653808594, -10.03574275970459, -0.6615009307861328, -0.4221753776073456, -0.6450929641723633, -0.5500483512878418, 0.9123902320861816, -1.325657844543457, -0.5719127655029297, -0.4219086170196533, 0.38744163513183594, -1.2182884216308594, 0.055889129638671875, 0.6851701736450195, 0.498992919921875, -0.38608360290527344, 0.011348724365234375, 0.6412830352783203, 0.46307373046875, 1.6907825469970703, 2.2258167266845703, 0.9593963623046875, -0.7409744262695312, -1.6044576168060303, 1.251147747039795, -0.7390341758728027, -0.8369655609130859, -4.275289058685303, 0.6144084930419922, 0.06731319427490234, -0.2960633635520935, 1.749934196472168, -0.11471116542816162, -11.384634017944336, 0.6577425003051758, -10.249567031860352, 0.7192373275756836, 0.1331215500831604, -1.5910282135009766, 1.1713619232177734, 0.18103837966918945, -0.13005447387695312, -1.8644943237304688, 1.2863922119140625, 0.17167282104492188, -0.1945662498474121, 0.5976324081420898, -0.42068448662757874, 0.9750027656555176, 0.6367778778076172, 0.6784720420837402, -1.1310844421386719, -1.217081069946289, 0.5061826705932617, 1.3891878128051758, 1.9707508087158203, -0.3249835968017578, 0.6662960052490234, 0.6319742202758789, 0.24257469177246094, -0.014429092407226562, -1.7237067222595215, -1.026963233947754, 0.5347433090209961, 2.432985305786133, 2.9409923553466797, 0.29972851276397705, -1.0650568008422852, -0.2783851623535156, 10.229315757751465, -0.2623615264892578, 0.052524566650390625, 1.307246208190918, -1.6073007583618164, -9.153761863708496, 0.9017853736877441, -0.5358133316040039, -0.0472407341003418, 0.006124734878540039], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 29696, "num_env_steps_trained": 107760, "num_agent_steps_sampled": 29696, "num_agent_steps_trained": 107760, "last_target_update_ts": 29696, "num_target_updates": 57}, "sampler_results": {"episode_reward_max": 21.81153803318739, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -234.42234011182944, "episode_len_mean": 323.2048192771084, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5229739457188395, "mean_inference_ms": 23.327068261023623, "mean_action_processing_ms": 0.1359463657509579, "mean_env_wait_ms": 4.419268474585179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 21.81153803318739, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -234.42234011182944, "episode_len_mean": 323.2048192771084, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5229739457188395, "mean_inference_ms": 23.327068261023623, "mean_action_processing_ms": 0.1359463657509579, "mean_env_wait_ms": 4.419268474585179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 29696, "num_agent_steps_trained": 107760, "num_env_steps_sampled": 29696, "num_env_steps_trained": 107760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 29696, "agent_timesteps_total": 29696, "timers": {"training_iteration_time_ms": 329.447, "learn_time_ms": 61.575, "learn_throughput": 3897.663, "synch_weights_time_ms": 20.688}, "counters": {"num_env_steps_sampled": 29696, "num_env_steps_trained": 107760, "num_agent_steps_sampled": 29696, "num_agent_steps_trained": 107760, "last_target_update_ts": 29696, "num_target_updates": 57}, "done": false, "episodes_total": 83, "training_iteration": 29, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-35", "timestamp": 1655478215, "time_this_iter_s": 5.138777494430542, "time_total_s": 150.50764346122742, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 150.50764346122742, "timesteps_since_restore": 0, "iterations_since_restore": 29, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.137499999999996, "ram_util_percent": 60.975}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 5.7889790534973145, "min_q": -28.351903915405273, "max_q": 31.673370361328125, "mean_td_error": -0.7642596960067749}, "td_error": [-0.5875564813613892, -1.3038597106933594, -1.4755802154541016, -0.4273252487182617, -6.141324996948242, 2.118927001953125, 0.7562007904052734, 1.6138381958007812, 1.552381992340088, -6.980876922607422, -0.795499324798584, 1.2510786056518555, 0.7940325736999512, -5.460509300231934, 0.14046859741210938, -0.08553314208984375, 0.18885040283203125, 0.1015157699584961, 0.22760581970214844, 0.765716552734375, -1.1122474670410156, -0.3241415023803711, -0.9470925331115723, -0.8567070960998535, 0.49386024475097656, -0.6453614234924316, -0.7781696319580078, 0.051133036613464355, -4.25083065032959, 0.06251192092895508, -11.419351577758789, -0.4295182228088379, -0.26461029052734375, 0.9711397886276245, 1.7062549591064453, -1.397918701171875, -1.1345844268798828, -0.18932533264160156, -0.20193910598754883, -1.2442388534545898, -1.4535150527954102, -1.0431797504425049, -0.28858423233032227, 0.5507698059082031, 0.21833813190460205, -0.8078824877738953, -1.8931398391723633, -1.0592684745788574, -0.2683589458465576, -2.127884864807129, -5.3381757736206055, -1.4597139358520508, -0.8379058837890625, -0.4365253448486328, -0.42804718017578125, -0.43877530097961426, 0.01197957992553711, -0.19313454627990723, -1.16961669921875, 0.19196128845214844, -0.4384140968322754, -0.2852973937988281, -0.34442996978759766, 1.4760189056396484, -0.2591969966888428, -1.2563114166259766, -0.019641876220703125, 0.5943503379821777, 0.03745269775390625, 1.4332389831542969, 0.17711007595062256, -0.8650474548339844, -0.1860518455505371, 0.3090912103652954, -0.17974889278411865, 0.3346366882324219, 1.1157031059265137, -0.06307744979858398, -6.398340225219727, -2.240436553955078, 0.5707826614379883, -0.8677043914794922, -1.0866756439208984, 0.8921680450439453, -2.114849090576172, -0.6326961517333984, -5.016847133636475, -0.35926055908203125, -1.2249774932861328, -0.17974889278411865, -1.7499656677246094, -5.345417022705078, -9.742776870727539, -0.24636459350585938, -0.5580568313598633, -0.229522705078125, -0.6675295829772949, 0.4149136543273926, -0.4326467514038086, -0.3757528066635132, -0.22545242309570312, 0.6679172515869141, 1.7457469701766968, 0.24728822708129883, 0.31946372985839844, -0.19202089309692383, -2.08111572265625, -0.15220701694488525, -2.4394123554229736, -0.2035360336303711, 0.5540657043457031, -2.410442352294922, 1.1086406707763672, -1.161672592163086, -0.48859596252441406, 0.8017749786376953, -0.0644845962524414, 0.007295727729797363, -1.3038597106933594, 0.7562007904052734, -0.1250591278076172, -0.43938159942626953, -0.5634098052978516, 0.11654472351074219, -0.5232634544372559, -0.31115448474884033, -0.1593790054321289, -0.8632526397705078, -0.6530556678771973, 0.47323036193847656, 0.3789377212524414, -0.16031169891357422, -1.3452410697937012, -0.696789026260376, -1.157064437866211, -7.190666198730469, 0.40631961822509766, -1.3499441146850586, 0.06991767883300781, -0.3438229560852051, 0.3633594512939453, 1.2596702575683594, -0.00824737548828125, -1.5962810516357422, 0.2417302131652832, 0.036917686462402344, -1.7490119934082031, -0.1718120574951172, 0.2789726257324219, 0.24408721923828125, 0.14603233337402344, 1.161123275756836, 0.338134765625, 0.5807924270629883, -0.8311367034912109, 2.038372039794922, 0.5591220855712891, -7.102708339691162, -7.279775142669678, -6.019929885864258, 0.05305290222167969, -1.2103424072265625, 0.4292168617248535, -0.1971922516822815, -0.25161170959472656, -1.7532498836517334, -0.8351898193359375, -7.15907096862793, 1.5954368114471436, -0.6601467132568359, 0.906460165977478, 0.9100961685180664, 0.3000335693359375, -0.5046567916870117, 0.9361057281494141, -0.3979969024658203, -1.286971092224121, 0.271487832069397, -1.584744930267334, -0.3597252368927002, -0.9872360229492188, -3.5035247802734375, 0.21515846252441406, -3.231576442718506, -6.408124923706055, -1.6620383262634277, -1.9431571960449219, -0.24117794632911682, -0.8595428466796875, -2.2257533073425293, -5.409536361694336, 0.7668018341064453, -1.4386672973632812, -1.4707915782928467, -4.1852312088012695, -0.749474048614502, -1.9301247596740723, 0.038982391357421875, -0.8585205078125, -1.4656858444213867, -0.13867568969726562, -0.10054588317871094, 0.4548221230506897, -0.1313648223876953, -1.2052720785140991, -0.7071266174316406, -1.945755958557129, -1.2349348068237305, -0.5125026702880859, 0.40843963623046875, -1.5343341827392578, -0.3240938186645508, 0.7498159408569336, 0.0453033447265625, -0.7762807011604309, 0.7332763671875, -1.096090316772461, -0.10032892227172852, -0.3164215087890625, -1.102132797241211, 0.03233909606933594, 1.0567095279693604, -1.509650707244873, 0.5775718688964844, 0.3714594841003418, 0.8872935771942139, -0.526802659034729, 0.5588312149047852, -1.0383925437927246, 0.527130126953125, -0.19313454627990723, -0.7888209819793701, 0.10283580422401428, -0.19678306579589844, 2.052107334136963, 0.5362071990966797, -0.4780282974243164, -1.1539907455444336, -0.7724800109863281, 0.11809349060058594], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 30720, "num_env_steps_trained": 111600, "num_agent_steps_sampled": 30720, "num_agent_steps_trained": 111600, "last_target_update_ts": 30720, "num_target_updates": 59}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -221.88143734142676, "episode_len_mean": 318.3296703296703, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5229349855601256, "mean_inference_ms": 23.426523544898114, "mean_action_processing_ms": 0.13601344536156346, "mean_env_wait_ms": 4.401688086668348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -221.88143734142676, "episode_len_mean": 318.3296703296703, "episodes_this_iter": 8, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5229349855601256, "mean_inference_ms": 23.426523544898114, "mean_action_processing_ms": 0.13601344536156346, "mean_env_wait_ms": 4.401688086668348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 30720, "num_agent_steps_trained": 111600, "num_env_steps_sampled": 30720, "num_env_steps_trained": 111600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 30720, "agent_timesteps_total": 30720, "timers": {"training_iteration_time_ms": 347.418, "learn_time_ms": 62.155, "learn_throughput": 3861.324, "synch_weights_time_ms": 20.29}, "counters": {"num_env_steps_sampled": 30720, "num_env_steps_trained": 111600, "num_agent_steps_sampled": 30720, "num_agent_steps_trained": 111600, "last_target_update_ts": 30720, "num_target_updates": 59}, "done": false, "episodes_total": 91, "training_iteration": 30, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-40", "timestamp": 1655478220, "time_this_iter_s": 5.461235761642456, "time_total_s": 155.96887922286987, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 155.96887922286987, "timesteps_since_restore": 0, "iterations_since_restore": 30, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.775000000000006, "ram_util_percent": 61.0375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 5.553033351898193, "min_q": -30.396751403808594, "max_q": 34.19978713989258, "mean_td_error": -1.2511100769042969}, "td_error": [-1.3914334774017334, -1.4896793365478516, -1.656240463256836, -1.1766571998596191, -1.5723152160644531, -0.10790467262268066, -3.046565055847168, -0.6541786193847656, -0.18587732315063477, -1.5320277214050293, -2.374696731567383, -6.770969390869141, 0.5334296226501465, -1.4714832305908203, -0.3276996612548828, 0.3775634765625, 0.5274486541748047, -0.7882494926452637, -0.7736878395080566, 1.1689229011535645, -1.0747766494750977, -1.6722917556762695, -10.989157676696777, -0.3760261535644531, 0.11400437355041504, -2.060487747192383, -0.7406549453735352, -2.183438301086426, -0.8618292808532715, -2.4418230056762695, -2.4055135250091553, -2.511922836303711, -0.5579986572265625, 0.5247516632080078, -3.4256696701049805, -0.16496038436889648, -0.9744129180908203, -1.8441877365112305, 1.2741912603378296, -0.258514404296875, -2.6262474060058594, 0.3365144729614258, -2.2534942626953125, 1.6682395935058594, -0.719658613204956, 0.5724306106567383, 0.8145313262939453, -1.3857612609863281, -1.2651805877685547, -0.897797703742981, -1.7837276458740234, -4.2175798416137695, -1.3565559387207031, -1.8478374481201172, -14.474359512329102, -3.3957290649414062, -6.592042446136475, -1.296881079673767, -1.815138339996338, -6.670108795166016, -1.2810001373291016, 1.475316047668457, -1.8441715240478516, -1.072957992553711, 0.8423118591308594, -0.3515129089355469, -0.9410066604614258, -0.5741496682167053, -0.0695958137512207, -8.06437873840332, -2.507756233215332, -6.173208236694336, 7.27200174331665, -0.5618586540222168, 1.1022582054138184, 0.009737014770507812, 0.231536865234375, -0.5913128852844238, -1.7694263458251953, -1.3924808502197266, -1.0661859512329102, -0.6145806312561035, -2.224506378173828, -2.3333053588867188, -0.9035525321960449, -1.9330615997314453, -1.780019760131836, -1.0299224853515625, -1.3062009811401367, -0.8626646995544434, -3.323151111602783, -0.3242473602294922, -1.3539314270019531, 0.0187225341796875, -0.5821801424026489, -0.06675577163696289, -0.08030128479003906, -0.45749855041503906, -0.4218158721923828, 0.04181098937988281, -12.793681144714355, -0.3907299041748047, -0.3242473602294922, -7.686589241027832, -2.1541335582733154, -0.6898384094238281, -0.699293851852417, -8.720276832580566, 1.571310043334961, 1.1851806640625, -2.2690839767456055, 1.1631193161010742, -0.3946819305419922, -1.883406162261963, 0.2237548828125, -0.5744562149047852, -1.0140113830566406, -2.737154960632324, 1.0912060737609863, -0.35177040100097656, -1.970329761505127, -0.9911861419677734, -1.9045295715332031, -11.085848808288574, -1.753957748413086, -1.780740737915039, 0.15991735458374023, -2.6211681365966797, -1.6415925025939941, -1.1168479919433594, 0.8247718811035156, -0.47013092041015625, -2.2936882972717285, -0.5604057312011719, -0.18786048889160156, 3.0640525817871094, -0.6267006397247314, -4.514468193054199, 0.6601862907409668, -1.4508819580078125, 0.07940483093261719, 0.7807598114013672, -0.1364307403564453, -2.9176506996154785, 14.414048194885254, 17.787904739379883, -0.41639649868011475, 2.750459671020508, -0.10910606384277344, 0.04375457763671875, -0.3412618637084961, 0.2614259719848633, -0.08923721313476562, -0.8822879791259766, -3.0888099670410156, 0.23802947998046875, -0.10552406311035156, -4.426888465881348, -1.4442377090454102, -0.44380712509155273, -1.2918996810913086, -0.6043796539306641, 1.4923715591430664, -0.7134819030761719, -0.40906333923339844, 0.0875544548034668, -5.018729209899902, 0.6142176389694214, -6.5548248291015625, 1.167464256286621, -6.2186994552612305, -2.0246667861938477, 3.2778539657592773, 0.2577478885650635, 0.35773277282714844, -0.41040802001953125, -1.7229139804840088, -1.7570972442626953, 0.23173904418945312, 0.3045501708984375, -0.7837734222412109, -1.6769036054611206, -3.5566916465759277, -2.3277714252471924, -0.39747095108032227, -0.6007890701293945, -0.6518011093139648, -1.5066652297973633, -0.9379129409790039, -26.8089599609375, 0.8010187149047852, -1.279386043548584, -3.2990918159484863, -0.6364059448242188, -0.9916055202484131, -1.9370794296264648, -0.25075531005859375, -0.5028934478759766, 0.6601862907409668, -0.5649290084838867, -3.2456912994384766, -1.299072027206421, 7.631277561187744, 0.016439318656921387, -1.686417579650879, -0.20568227767944336, -2.5304908752441406, -0.78594970703125, 0.2074432373046875, -1.0238404273986816, -1.9388313293457031, -0.5023394823074341, -6.834096908569336, -0.0103607177734375, 0.23920679092407227, -0.20198297500610352, -1.4389519691467285, 0.8466202020645142, -7.4478278160095215, -1.036362648010254, -0.7123966217041016, -1.4439976215362549, -1.9472980499267578, -2.3416709899902344, 1.0360240936279297, -11.868427276611328, -1.3947153091430664, 0.27336251735687256, -2.019092559814453, 1.0967960357666016, -0.6896686553955078, 0.8354127407073975, -1.8422095775604248, -2.8456058502197266, 0.49123692512512207, -6.861507415771484, 5.444403648376465, -2.02459716796875, 0.513545036315918, 0.6359376907348633], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 31744, "num_env_steps_trained": 115440, "num_agent_steps_sampled": 31744, "num_agent_steps_trained": 115440, "last_target_update_ts": 31744, "num_target_updates": 61}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -218.2251430672217, "episode_len_mean": 316.8936170212766, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5226537104952486, "mean_inference_ms": 23.457198383964794, "mean_action_processing_ms": 0.13626340377632926, "mean_env_wait_ms": 4.392321138466769, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -218.2251430672217, "episode_len_mean": 316.8936170212766, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5226537104952486, "mean_inference_ms": 23.457198383964794, "mean_action_processing_ms": 0.13626340377632926, "mean_env_wait_ms": 4.392321138466769, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 31744, "num_agent_steps_trained": 115440, "num_env_steps_sampled": 31744, "num_env_steps_trained": 115440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 31744, "agent_timesteps_total": 31744, "timers": {"training_iteration_time_ms": 322.611, "learn_time_ms": 62.057, "learn_throughput": 3867.439, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 31744, "num_env_steps_trained": 115440, "num_agent_steps_sampled": 31744, "num_agent_steps_trained": 115440, "last_target_update_ts": 31744, "num_target_updates": 61}, "done": false, "episodes_total": 94, "training_iteration": 31, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-46", "timestamp": 1655478226, "time_this_iter_s": 5.1895551681518555, "time_total_s": 161.15843439102173, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 161.15843439102173, "timesteps_since_restore": 0, "iterations_since_restore": 31, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.04285714285714, "ram_util_percent": 61.18571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 6.2433319091796875, "min_q": -31.211366653442383, "max_q": 34.68705368041992, "mean_td_error": -0.8472893834114075}, "td_error": [-2.6372830867767334, -0.7388484477996826, -0.7628765106201172, 0.10499763488769531, 0.5312964916229248, 0.3705768585205078, -0.24589157104492188, -0.6185379028320312, -2.697772979736328, -1.5596461296081543, 0.05501437187194824, -2.0511505603790283, 1.285233974456787, -1.6219291687011719, -0.40865325927734375, -2.148061752319336, -0.6627599000930786, 2.450352907180786, 0.18950271606445312, -0.9349539279937744, -0.5852470397949219, -1.0603718757629395, -1.0404366254806519, -3.276012420654297, -1.6263028383255005, -0.13595008850097656, 1.3787431716918945, -0.8849911689758301, -1.9594612121582031, 4.315945625305176, -0.8741849660873413, 0.3484840393066406, -0.8486366271972656, -0.8421154022216797, -1.8151955604553223, -0.956512451171875, -0.06719207763671875, -1.4576282501220703, -0.9873809814453125, -1.2069511413574219, 1.2728667259216309, -1.5319790840148926, -1.6403241157531738, -1.3296384811401367, -0.2665104866027832, -0.4702930450439453, -1.9057655334472656, -0.24573087692260742, -0.25301551818847656, -2.1154985427856445, -1.1778415441513062, -2.104241371154785, 0.4769284725189209, -7.038068771362305, 0.024055838584899902, -2.9333746433258057, -0.3090496063232422, 0.5222291946411133, -0.2604236602783203, -1.256723403930664, -2.377225875854492, -1.4305419921875, 0.11988258361816406, -1.281881332397461, -0.9591622352600098, -0.049274444580078125, -7.121181964874268, -0.07085800170898438, 0.0607452392578125, -0.15740394592285156, -1.487614631652832, -2.3286852836608887, -2.2711381912231445, -1.8141260147094727, -1.190084457397461, -1.4093985557556152, -1.6219291687011719, -0.3178896903991699, 0.016689777374267578, -1.1532154083251953, 0.47536468505859375, -1.4970474243164062, 0.9623966217041016, -1.1570172309875488, 0.8031063079833984, 0.5035867691040039, 0.4524402618408203, -2.5722169876098633, -0.06858158111572266, -2.1356430053710938, -0.5891790390014648, -1.5076708793640137, 0.6439800262451172, -0.13157224655151367, -0.28307342529296875, -2.298600673675537, -0.5520162582397461, -0.060760498046875, -1.1671886444091797, -1.8476753234863281, 0.3894767761230469, -0.47541868686676025, 0.5339794158935547, 1.2570018768310547, -0.026227951049804688, -1.783484697341919, -0.5147494673728943, -0.46341657638549805, -2.089718818664551, -1.419236183166504, -0.06249427795410156, -0.8956508636474609, -1.4182453155517578, -0.8081040382385254, -1.731785774230957, 0.7861297130584717, -0.749929666519165, -2.6142735481262207, -1.223738670349121, -1.5212888717651367, -0.43787193298339844, 0.060985565185546875, -0.07387161254882812, -11.177560806274414, 0.5328083038330078, -1.7756352424621582, 0.27158665657043457, 0.2428455352783203, -3.26700496673584, -0.44492340087890625, 0.12688446044921875, -0.17720603942871094, -2.573293685913086, -0.5090276598930359, -0.3552114963531494, 1.805063247680664, 0.7915830612182617, 0.5936012268066406, -0.30965375900268555, -1.0789332389831543, 0.6057267189025879, -1.415934443473816, -0.8184795379638672, -0.7758042812347412, -2.4474520683288574, -0.4823017120361328, -0.5684356689453125, 0.5349960327148438, -6.890931129455566, -0.3939552307128906, -0.3078312873840332, 0.7047634124755859, 0.03771209716796875, -0.19433355331420898, 1.490041732788086, 0.9147310256958008, 0.08038902282714844, -8.417980194091797, -0.28859519958496094, 1.205209732055664, -0.4645671844482422, 0.79632568359375, -8.220436096191406, -4.811079025268555, -0.9075384140014648, -6.059347152709961, -0.8760396242141724, -0.07890510559082031, -1.0538139343261719, 1.5468263626098633, -4.244137763977051, -0.5891306400299072, 7.872016906738281, 0.9724769592285156, -3.0656521320343018, -0.2813529968261719, -1.5051779747009277, -0.47162532806396484, -5.721244812011719, -0.3509817123413086, -0.22277355194091797, -0.5436220169067383, -1.1645774841308594, 0.5021038055419922, -1.6038570404052734, -0.8961590528488159, -0.1217041015625, -2.9521031379699707, -0.4786567687988281, -1.1414813995361328, -1.3048133850097656, 0.7191200256347656, -4.599689483642578, -2.3951752185821533, -1.7322770357131958, -1.244309902191162, 1.1488170623779297, -4.984952926635742, -0.28003501892089844, -0.25475502014160156, -1.7866058349609375, -1.285867691040039, 0.3018779754638672, 0.9019145965576172, -1.9595167636871338, 0.9098777770996094, -0.8025579452514648, 0.6132717132568359, -0.03293609619140625, 0.4381439685821533, 0.5992281436920166, -0.6319494247436523, -0.5448908805847168, -0.9650802612304688, -1.317300796508789, -1.4199934005737305, -0.3099632263183594, -0.8234124183654785, 0.24010896682739258, 0.9764919281005859, -2.2381229400634766, -0.6173410415649414, -0.8013534545898438, -0.18377971649169922, 0.4079704284667969, 1.0602083206176758, 4.073480606079102, 0.1852273941040039, -0.1664562225341797, -0.8447704315185547, -1.2552590370178223, -0.48731231689453125, -3.549833297729492, -0.9823551177978516, -1.3933610916137695, 1.625070571899414, -1.1224250793457031, 0.15815448760986328, -1.436319351196289, -0.7061080932617188], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 32768, "num_env_steps_trained": 119280, "num_agent_steps_sampled": 32768, "num_agent_steps_trained": 119280, "last_target_update_ts": 32768, "num_target_updates": 63}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -221.0260804737966, "episode_len_mean": 317.4329896907216, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5226621074193885, "mean_inference_ms": 23.473263516659323, "mean_action_processing_ms": 0.13613252472715426, "mean_env_wait_ms": 4.386349744626887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -221.0260804737966, "episode_len_mean": 317.4329896907216, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5226621074193885, "mean_inference_ms": 23.473263516659323, "mean_action_processing_ms": 0.13613252472715426, "mean_env_wait_ms": 4.386349744626887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 32768, "num_agent_steps_trained": 119280, "num_env_steps_sampled": 32768, "num_env_steps_trained": 119280, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 32768, "agent_timesteps_total": 32768, "timers": {"training_iteration_time_ms": 333.995, "learn_time_ms": 62.259, "learn_throughput": 3854.851, "synch_weights_time_ms": 20.788}, "counters": {"num_env_steps_sampled": 32768, "num_env_steps_trained": 119280, "num_agent_steps_sampled": 32768, "num_agent_steps_trained": 119280, "last_target_update_ts": 32768, "num_target_updates": 63}, "done": false, "episodes_total": 97, "training_iteration": 32, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-51", "timestamp": 1655478231, "time_this_iter_s": 5.220057964324951, "time_total_s": 166.37849235534668, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 166.37849235534668, "timesteps_since_restore": 0, "iterations_since_restore": 32, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.5125, "ram_util_percent": 61.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 8.959222793579102, "min_q": -29.97863006591797, "max_q": 35.07706832885742, "mean_td_error": -0.42924049496650696}, "td_error": [0.7874259948730469, -2.0966835021972656, -0.3717985153198242, 0.3474910259246826, -0.7247843742370605, -0.9557180404663086, -0.5378017425537109, 1.3937101364135742, 0.07307624816894531, -0.7072181701660156, 1.3169441223144531, -0.848564624786377, 0.5505790710449219, -9.835132598876953, -0.5492935180664062, 1.1719417572021484, 0.6624698638916016, -0.6922931671142578, -7.702794551849365, -0.2816638946533203, -9.712050437927246, -0.8094778060913086, -7.399648666381836, 15.327268600463867, 1.4853324890136719, -1.2122526168823242, 1.058786392211914, -0.634676456451416, -0.345703125, 0.9357023239135742, -0.6789350509643555, 1.0245399475097656, -0.4459800720214844, -2.4613564014434814, -5.020195960998535, 1.0499235391616821, -7.560708999633789, -0.4438807964324951, -0.555288553237915, -1.8853273391723633, -0.5607185363769531, 0.15372276306152344, 2.469388961791992, -0.6560602188110352, 1.5686988830566406, -0.9316952228546143, -0.3459348678588867, -8.21829891204834, -1.3104757070541382, 0.4319324493408203, -1.7186155319213867, 0.5362286567687988, -0.21287155151367188, 0.18213462829589844, 0.0024034976959228516, 0.5447998046875, -6.198524475097656, 1.1537418365478516, 0.9565038681030273, 0.9562292098999023, -8.666844367980957, 1.3965024948120117, -0.3810081481933594, -0.6252098083496094, 0.39606380462646484, -5.142750263214111, -0.1947464942932129, -0.21663427352905273, -2.097958564758301, -0.5276060104370117, 0.5052585601806641, -1.647876501083374, -0.10411602258682251, 0.8881320953369141, 0.35057592391967773, 0.6094455718994141, 1.3042659759521484, -0.25833630561828613, 0.8087921142578125, -0.026533126831054688, 0.27794647216796875, 1.2250652313232422, -0.1660609245300293, 1.5246028900146484, -1.565929889678955, -0.39685702323913574, 0.488739013671875, 0.5387506484985352, -1.2049789428710938, -0.10203170776367188, 1.0207767486572266, 0.9551868438720703, 0.4481697082519531, -0.6655445098876953, 1.0417442321777344, 0.10869741439819336, 2.153989791870117, 0.012667655944824219, 0.24631404876708984, -0.6003189086914062, -0.6282558441162109, 0.9356184005737305, 1.2139301300048828, -9.725191116333008, -0.12004470825195312, 20.726686477661133, 1.412062168121338, 0.5326895713806152, -6.5488433837890625, -1.805200219154358, 0.9439554214477539, -0.6789350509643555, 0.5792980194091797, 0.7268228530883789, -0.8272762298583984, 0.6361312866210938, -0.9969339370727539, 0.626350998878479, 1.5839099884033203, -1.7087368965148926, -0.2221508026123047, -0.5159759521484375, -2.250861167907715, -0.866246223449707, 1.1930876970291138, 0.37310028076171875, -5.247239589691162, 1.2250652313232422, 0.15262699127197266, 0.5447998046875, 1.1762847900390625, -0.7837362289428711, 1.0028133392333984, -1.307861328125, -3.2080230712890625, 1.4082975387573242, -3.4958362579345703, 0.04456198215484619, -1.6747875213623047, 0.24241065979003906, 0.5362286567687988, -0.22203636169433594, -0.6615619659423828, 1.1791000366210938, 0.3294548988342285, 1.264052391052246, -0.8989381790161133, -1.3631000518798828, -0.9415779113769531, -5.546875953674316, -6.198524475097656, -0.7430334091186523, 0.5173139572143555, 0.9002623558044434, -0.17712152004241943, 0.8167257308959961, -0.709801197052002, -2.1302361488342285, 1.4787054061889648, 0.19438982009887695, 0.8034763336181641, 0.012667655944824219, 1.1858692169189453, -2.191267967224121, 0.709228515625, 0.22469520568847656, 0.2828207015991211, 1.643244743347168, -1.3443031311035156, -0.4401988983154297, 0.7226276397705078, 0.888704776763916, 1.0037040710449219, -1.5818719863891602, -1.3813292980194092, 0.5562248229980469, 0.012130498886108398, 0.2397003173828125, 1.1099457740783691, -0.8720245361328125, -1.840867042541504, 0.4152488708496094, -10.135814666748047, 0.9530029296875, 1.530735969543457, -2.0318360328674316, -2.252894401550293, -1.3010673522949219, 0.7048516273498535, -0.39915740489959717, -0.7868556976318359, 2.168354034423828, 0.8201808929443359, 0.7865104675292969, 1.0755958557128906, -0.5417611598968506, 0.6575660705566406, 0.4228806495666504, 1.0446529388427734, -0.23418211936950684, 1.016901969909668, -0.8698663711547852, 0.2608966827392578, -0.7686386108398438, 1.299346923828125, 1.2552356719970703, -1.7963218688964844, -1.0561575889587402, -8.725167274475098, -0.829803466796875, 0.2079620361328125, -0.4217643737792969, 0.8378698825836182, -0.44588375091552734, -5.546875953674316, 1.2197990417480469, 1.4853324890136719, 0.26036596298217773, -0.15929126739501953, 1.5043773651123047, 0.9224281311035156, -2.0318360328674316, -1.0211200714111328, -0.46599364280700684, -0.6659469604492188, -0.30769824981689453, -5.640143871307373, 0.5514402389526367, -6.85101318359375, 0.2964153289794922, -0.5807771682739258, 1.26165771484375, 2.3102540969848633, -0.17748451232910156, 0.20858383178710938, 0.7937192916870117, -0.6862585544586182, 0.7226276397705078, -0.14238643646240234, 1.5976104736328125], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 33792, "num_env_steps_trained": 123120, "num_agent_steps_sampled": 33792, "num_agent_steps_trained": 123120, "last_target_update_ts": 33792, "num_target_updates": 65}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -218.31733741942378, "episode_len_mean": 316.1212121212121, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5225400537713398, "mean_inference_ms": 23.490816392939873, "mean_action_processing_ms": 0.13603425013867787, "mean_env_wait_ms": 4.38403908366648, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -218.31733741942378, "episode_len_mean": 316.1212121212121, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-22.337031990289688, -52.47303342074156, -72.09597000479698, 0.5063197687268257, -36.709118694067, -39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489], "episode_lengths": [233, 252, 253, 218, 238, 243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5225400537713398, "mean_inference_ms": 23.490816392939873, "mean_action_processing_ms": 0.13603425013867787, "mean_env_wait_ms": 4.38403908366648, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 33792, "num_agent_steps_trained": 123120, "num_env_steps_sampled": 33792, "num_env_steps_trained": 123120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 33792, "agent_timesteps_total": 33792, "timers": {"training_iteration_time_ms": 328.297, "learn_time_ms": 62.803, "learn_throughput": 3821.457, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 33792, "num_env_steps_trained": 123120, "num_agent_steps_sampled": 33792, "num_agent_steps_trained": 123120, "last_target_update_ts": 33792, "num_target_updates": 65}, "done": false, "episodes_total": 99, "training_iteration": 33, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-03-57", "timestamp": 1655478237, "time_this_iter_s": 5.26747989654541, "time_total_s": 171.6459722518921, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 171.6459722518921, "timesteps_since_restore": 0, "iterations_since_restore": 33, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.449999999999996, "ram_util_percent": 61.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 5.4989142417907715, "min_q": -30.690906524658203, "max_q": 33.95050811767578, "mean_td_error": -0.17939621210098267}, "td_error": [0.09154224395751953, 0.4480109214782715, 0.271054744720459, 0.6798450946807861, 0.8773455619812012, 0.9661521911621094, 0.5480306148529053, 0.722559928894043, -1.016289472579956, 0.3517913818359375, 0.6224422454833984, -0.4014780521392822, 0.16067981719970703, -5.278311729431152, 0.15667247772216797, -0.5151505470275879, 1.0516376495361328, -0.8184680938720703, -2.635875701904297, 0.6254711151123047, -0.9015436172485352, -0.4951043128967285, 1.0773937702178955, 0.00415802001953125, -1.746945858001709, -0.4350395202636719, 0.41638755798339844, -0.34026241302490234, 0.03951835632324219, 0.8339881896972656, 0.9007186889648438, 0.28305625915527344, -6.145148277282715, -0.06640338897705078, 0.8198761940002441, 0.42524707317352295, -0.2714409828186035, -0.9769268035888672, -0.5489902496337891, 0.8795328140258789, 1.4847660064697266, -1.4084033966064453, 1.0927085876464844, 0.1402263641357422, -0.07486820220947266, 0.6146087646484375, 0.3485727310180664, 1.021127700805664, -2.4827375411987305, 0.01987755298614502, -1.4939510822296143, 1.884836196899414, 0.7604351043701172, -0.8805398941040039, -0.44982051849365234, -0.2467951774597168, 1.0850811004638672, 1.9893856048583984, -1.4675464630126953, 0.10853719711303711, -2.4827375411987305, -0.22167205810546875, 0.3189011812210083, 0.09900307655334473, 0.8743457794189453, 0.5564661026000977, 0.3529987335205078, 0.9661521911621094, -0.4905242919921875, -3.7195568084716797, 0.406982421875, 1.156206488609314, -0.08960437774658203, 0.45586585998535156, -1.979488730430603, -0.4657630920410156, 1.0396804809570312, 1.7383310794830322, 0.30482006072998047, -0.8090362548828125, 0.9602663516998291, -9.432926177978516, 1.130461573600769, 0.7924820780754089, -0.3556089401245117, -1.7375659942626953, -0.5453791618347168, 1.9886481761932373, 0.29667580127716064, 1.355013370513916, 1.364750862121582, 0.46979618072509766, 5.033039093017578, 9.181215286254883, 1.9886481761932373, 0.4119453430175781, 0.695530891418457, -3.896799087524414, -0.940410852432251, 0.5269041061401367, -0.5726089477539062, -3.959178924560547, -1.1240720748901367, -0.4350395202636719, -0.4884834289550781, -0.27663707733154297, -0.18077898025512695, 1.0356006622314453, -2.7311744689941406, 1.0651664733886719, 0.6736059188842773, 0.6668252944946289, 1.8852519989013672, -9.914085388183594, 1.1369006633758545, -0.17564868927001953, 3.853555679321289, 0.5025801658630371, -0.6445999145507812, 1.6381235122680664, 0.6661758422851562, -0.07748222351074219, -0.07337379455566406, 0.2414073944091797, 0.8136503100395203, -1.5281829833984375, 0.6139302253723145, 2.26975154876709, -3.6137285232543945, 0.10600090026855469, 1.9877573251724243, 0.7567863464355469, 0.5962038040161133, -0.17564868927001953, -3.829029083251953, -0.09470558166503906, -0.09470558166503906, 0.09773588180541992, -0.8628520965576172, -0.8414831161499023, -0.11025714874267578, -0.02713918685913086, -0.22328567504882812, 1.2414960861206055, 0.3710594177246094, 1.4177894592285156, -0.4219837188720703, -0.10934066772460938, 2.1149730682373047, 0.026012897491455078, 0.8497307896614075, -0.35141706466674805, -2.1264419555664062, 0.38466691970825195, -0.6620187759399414, 1.1666431427001953, 2.4350426197052, -0.3672046661376953, 0.19515013694763184, -0.17597198486328125, 0.6919317245483398, 0.7986056804656982, 0.22537755966186523, -5.803792953491211, 0.5275330543518066, -0.10435843467712402, -0.47138339281082153, 1.6246471405029297, 0.22167587280273438, 0.9968657493591309, -0.3609600067138672, 0.46802663803100586, 0.02321004867553711, 0.06924223899841309, 0.39291852712631226, -0.026047229766845703, -0.03824043273925781, -1.1877620220184326, 2.436370849609375, 0.08171844482421875, -0.19541573524475098, 0.00276947021484375, -1.0064024925231934, -4.177103042602539, 1.4939289093017578, 0.2772378921508789, 1.9470939636230469, 1.8275337219238281, 0.3529205322265625, -2.354827404022217, -1.5624510049819946, 0.25508642196655273, 0.05217289924621582, 0.46802663803100586, -0.4303436279296875, -0.113128662109375, -0.48096656799316406, 0.38466691970825195, 0.9985055923461914, -4.225673675537109, -12.912667274475098, 0.45256853103637695, 0.11257457733154297, -0.5658769607543945, 0.23958730697631836, 0.6243553161621094, 0.7412643432617188, 0.2188739776611328, -0.5203495025634766, -0.2354140281677246, 0.20867586135864258, 0.5507068634033203, 0.046849727630615234, -0.5910539627075195, -0.8495235443115234, 1.629740834236145, 0.23130035400390625, 0.5335350036621094, 0.7604351043701172, -1.7722015380859375, 0.32262468338012695, -0.7257680892944336, -7.571910858154297, -4.638020992279053, 0.011795997619628906, 2.381619691848755, 0.8819751739501953, 0.007783412933349609, -1.8111740350723267, -0.36632466316223145, -0.20026779174804688, -0.7783318758010864, -0.13805723190307617, 0.6956908106803894, 0.37534046173095703, 0.22537755966186523, -0.08715927600860596, -6.6700615882873535, -1.003169298171997, -1.4939510822296143], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 34816, "num_env_steps_trained": 126960, "num_agent_steps_sampled": 34816, "num_agent_steps_trained": 126960, "last_target_update_ts": 34816, "num_target_updates": 67}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -217.2668502099067, "episode_len_mean": 315.6, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564], "episode_lengths": [243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5206600033174145, "mean_inference_ms": 23.59773783376362, "mean_action_processing_ms": 0.13652822090436276, "mean_env_wait_ms": 4.317800761527588, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -217.2668502099067, "episode_len_mean": 315.6, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.00460398197174, -61.113994769752026, -114.00690034776926, -49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564], "episode_lengths": [243, 246, 278, 258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5206600033174145, "mean_inference_ms": 23.59773783376362, "mean_action_processing_ms": 0.13652822090436276, "mean_env_wait_ms": 4.317800761527588, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 34816, "num_agent_steps_trained": 126960, "num_env_steps_sampled": 34816, "num_env_steps_trained": 126960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 34816, "agent_timesteps_total": 34816, "timers": {"training_iteration_time_ms": 342.801, "learn_time_ms": 62.535, "learn_throughput": 3837.879, "synch_weights_time_ms": 20.388}, "counters": {"num_env_steps_sampled": 34816, "num_env_steps_trained": 126960, "num_agent_steps_sampled": 34816, "num_agent_steps_trained": 126960, "last_target_update_ts": 34816, "num_target_updates": 67}, "done": false, "episodes_total": 105, "training_iteration": 34, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-02", "timestamp": 1655478242, "time_this_iter_s": 5.403119802474976, "time_total_s": 177.04909205436707, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 177.04909205436707, "timesteps_since_restore": 0, "iterations_since_restore": 34, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.25714285714286, "ram_util_percent": 61.57142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 8.024491310119629, "min_q": -29.474102020263672, "max_q": 36.5837516784668, "mean_td_error": -0.43063271045684814}, "td_error": [0.15056419372558594, 0.8984326124191284, -0.4887847900390625, 0.3104124069213867, -0.5610218048095703, 1.0645103454589844, -1.4932278394699097, -0.7280664443969727, 0.7478122711181641, -0.08056259155273438, -0.5359125137329102, -0.0876321792602539, -0.04437112808227539, -0.6821174621582031, -5.420860290527344, -0.20442581176757812, -2.397174835205078, 0.6143092513084412, -0.03870677947998047, 0.598052978515625, 0.5947649478912354, -0.6337776184082031, 0.3602914810180664, 1.725092887878418, -0.3062267303466797, 1.0495100021362305, -0.11281013488769531, 4.813895225524902, 0.5360317230224609, 0.24103832244873047, 0.012081742286682129, 0.6772947311401367, 0.3535184860229492, 0.14466428756713867, -0.18369674682617188, 0.1286182403564453, -0.10339927673339844, -7.949196815490723, 0.3533935546875, -0.11814594268798828, -0.8975620269775391, -0.4409904479980469, 1.0496821403503418, -2.753925323486328, -1.3541998863220215, 0.8468103408813477, 0.4708728790283203, 0.31026458740234375, -0.8049685955047607, -0.17395734786987305, -0.2795839309692383, 0.7717432975769043, -0.5051801204681396, -0.3577289581298828, -3.4721145629882812, 0.872807502746582, -0.4017486572265625, -0.6391935348510742, -1.2327404022216797, 0.1669750213623047, 0.047310590744018555, 0.7885441780090332, 0.10907554626464844, -0.726111888885498, 8.849824905395508, 0.10248041152954102, 1.8908271789550781, -0.5936222076416016, 1.4375591278076172, 0.8873558044433594, -5.2643914222717285, -0.5423784255981445, 1.611910343170166, -0.9342193603515625, -0.6919221878051758, -0.008637428283691406, 0.4708728790283203, -0.1434621810913086, -0.4903198480606079, -0.08068084716796875, -8.92408561706543, -8.688100814819336, -0.12522411346435547, 0.7445735931396484, -0.06945037841796875, -0.41431760787963867, 0.6443473100662231, -0.89935302734375, 0.5117025375366211, -0.6543351411819458, -0.2567824125289917, -6.118602752685547, 0.5558013916015625, -10.260952949523926, 0.020696163177490234, 0.23932790756225586, 1.6177501678466797, -0.17335033416748047, -6.675487518310547, -8.962115287780762, 0.8075950145721436, -9.055803298950195, -0.10786384344100952, 1.1691913604736328, 1.3937010765075684, 0.7887581586837769, 0.585207462310791, 1.069685935974121, -0.7496776580810547, -0.5798277854919434, -0.39972352981567383, 0.3098011016845703, -1.3208465576171875, 1.3628597259521484, -7.834428787231445, -4.817874908447266, 0.518336296081543, -1.2165429592132568, -0.7442607879638672, 0.039459228515625, 0.5426101684570312, -0.6124515533447266, -0.8350334167480469, -1.6300934553146362, 0.9978876113891602, 1.065413475036621, -1.638880729675293, 0.23250865936279297, 0.3428936004638672, 2.017939567565918, 0.08336734771728516, -0.6049668788909912, 0.6962776184082031, -5.964288711547852, 0.181915283203125, -0.4360719919204712, -0.04655170440673828, -0.11568498611450195, -0.5249967575073242, 0.1480388641357422, -0.05423164367675781, -6.453001022338867, 1.4949188232421875, 1.461623191833496, 0.2560713291168213, 0.2600212097167969, 0.11330032348632812, -0.02044677734375, 0.9794807434082031, 0.09857320785522461, 1.0430517196655273, 0.25999248027801514, 3.7668914794921875, -0.16739416122436523, -0.45279598236083984, -0.4768657684326172, -8.061986923217773, -6.004794120788574, 0.9992997646331787, -0.5793042182922363, 1.0323152542114258, 1.1467437744140625, 0.019599437713623047, 0.19836020469665527, -0.0027294158935546875, -0.36174583435058594, 0.04343223571777344, -12.636500358581543, 1.7356376647949219, -0.45279598236083984, -0.04992866516113281, -0.3508453369140625, -0.6398906707763672, -0.8409347534179688, -0.5961160659790039, 0.45562076568603516, -0.4395408630371094, 0.008594512939453125, -0.43718719482421875, 0.4054131805896759, 0.012671947479248047, -1.2364368438720703, -0.4466361999511719, 0.28256821632385254, 2.31192684173584, -0.3370037078857422, -9.949810028076172, -0.777468204498291, -0.6829872131347656, 0.3881874084472656, 0.10965991020202637, -0.06913614273071289, -0.6280426979064941, -0.28765714168548584, 1.7909717559814453, -0.3339834213256836, -1.1066207885742188, 9.617027282714844, -0.2744007110595703, 0.3434419631958008, -0.21221923828125, -2.9992504119873047, -0.39893293380737305, -0.8405425548553467, 2.370814085006714, 0.030933380126953125, -0.06723785400390625, 0.9729552268981934, -8.535462379455566, -0.35424041748046875, -0.1274094581604004, -0.4590640068054199, 0.6456508636474609, -1.9040374755859375, -0.15328454971313477, -0.03795433044433594, 15.141958236694336, 0.09556770324707031, -0.5274175405502319, 0.8173823356628418, 2.146724224090576, -1.3378734588623047, 0.8840765953063965, -0.3722400665283203, 0.6503181457519531, -1.1898460388183594, -0.2594623565673828, -0.1114969253540039, -0.2133164405822754, 0.4876365661621094, 1.4550890922546387, -5.7415900230407715, -0.2914552688598633, 2.047321319580078, 1.4550890922546387, -0.19675254821777344, -0.05678367614746094, 0.09402179718017578, 0.1159372329711914, -0.13070297241210938], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 35840, "num_env_steps_trained": 130800, "num_agent_steps_sampled": 35840, "num_agent_steps_trained": 130800, "last_target_update_ts": 35840, "num_target_updates": 69}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -217.50422266103328, "episode_len_mean": 316.15, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502], "episode_lengths": [258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5194617491065892, "mean_inference_ms": 23.669464586880537, "mean_action_processing_ms": 0.13633402299743524, "mean_env_wait_ms": 4.284745325168268, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -217.50422266103328, "episode_len_mean": 316.15, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-49.59112238883972, -125.28160909563303, -80.90338322520256, -89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502], "episode_lengths": [258, 270, 260, 272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5194617491065892, "mean_inference_ms": 23.669464586880537, "mean_action_processing_ms": 0.13633402299743524, "mean_env_wait_ms": 4.284745325168268, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 35840, "num_agent_steps_trained": 130800, "num_env_steps_sampled": 35840, "num_env_steps_trained": 130800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 35840, "agent_timesteps_total": 35840, "timers": {"training_iteration_time_ms": 326.502, "learn_time_ms": 62.328, "learn_throughput": 3850.58, "synch_weights_time_ms": 20.286}, "counters": {"num_env_steps_sampled": 35840, "num_env_steps_trained": 130800, "num_agent_steps_sampled": 35840, "num_agent_steps_trained": 130800, "last_target_update_ts": 35840, "num_target_updates": 69}, "done": false, "episodes_total": 108, "training_iteration": 35, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-08", "timestamp": 1655478248, "time_this_iter_s": 5.389012575149536, "time_total_s": 182.4381046295166, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 182.4381046295166, "timesteps_since_restore": 0, "iterations_since_restore": 35, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.050000000000004, "ram_util_percent": 61.6875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 8.862161636352539, "min_q": -30.913127899169922, "max_q": 34.74958419799805, "mean_td_error": -0.3109343349933624}, "td_error": [-1.6510114669799805, -4.020127296447754, -0.3425025939941406, 0.48145103454589844, -0.765629768371582, 1.44775390625, -1.5566425323486328, 0.8229541778564453, -9.568277359008789, -0.8090553283691406, -1.0332794189453125, -1.2362422943115234, 0.07761335372924805, -0.9292511940002441, 1.0035667419433594, 0.20407795906066895, -0.22247982025146484, -1.5549392700195312, 1.0372450351715088, -0.22626066207885742, -2.4871468544006348, -0.47748154401779175, 0.2799496650695801, -0.6541938781738281, -0.27556753158569336, -0.13326263427734375, -2.9632186889648438, 0.020769596099853516, -0.9971714019775391, -0.5598258972167969, 1.4800529479980469, -1.4788265228271484, 3.043346405029297, -1.3183307647705078, 0.621429443359375, 0.22483253479003906, -0.436673641204834, 0.05060291290283203, -0.4732327461242676, 0.788630485534668, 1.7956385612487793, -1.2200126647949219, -3.4423017501831055, 0.44690513610839844, 0.07603073120117188, -1.329117774963379, -1.0705509185791016, -0.3983592987060547, 0.26969146728515625, 1.0460205078125, -1.3580684661865234, 0.20407795906066895, -0.23902606964111328, 0.3309140205383301, 0.08684444427490234, 1.4104881286621094, -0.28045177459716797, 1.173257827758789, -1.414107322692871, -2.7714388370513916, -0.0276947021484375, -7.647550582885742, 0.049579620361328125, -4.66218376159668, -0.7213630676269531, 2.1495752334594727, -0.1831035614013672, 0.8194370269775391, 0.5402007699012756, -4.337308883666992, 0.49745750427246094, 0.015691757202148438, -0.4155158996582031, 0.44778919219970703, -0.3280143737792969, 0.5903205871582031, 4.750862121582031, 1.6465396881103516, 0.6202459335327148, -4.599844932556152, 1.149953842163086, -0.7006330490112305, -0.8389072418212891, 1.0933527946472168, -1.6359214782714844, -0.25244903564453125, 1.4735276699066162, 0.621429443359375, 0.13770437240600586, 1.4772887229919434, 0.08427810668945312, 0.558286190032959, -0.3957090377807617, 1.2314491271972656, 0.6851534843444824, 0.845848560333252, -1.0919246673583984, 3.1819915771484375, 0.19278907775878906, -1.1934661865234375, 0.3692131042480469, -0.5190567970275879, -1.064125657081604, -0.39325714111328125, -0.155242919921875, -0.3685469627380371, -0.8815402984619141, -1.4192392826080322, 0.40241193771362305, -1.1857690811157227, -0.07992172241210938, -0.07374715805053711, -0.3889636993408203, 0.18224334716796875, 0.5020503997802734, 0.1688694953918457, -1.2232246398925781, -0.17278385162353516, 0.7708091735839844, -0.4518585205078125, -0.38239526748657227, -0.3202226161956787, 0.10703372955322266, 0.8099241256713867, 1.8574562072753906, 0.6703627109527588, -0.4518585205078125, 1.1389703750610352, 0.5673465728759766, -1.0314226150512695, -0.6752147674560547, 0.9351367950439453, -0.10266542434692383, -0.6138401031494141, 3.804645538330078, -0.7811336517333984, 1.7947406768798828, -0.4471883773803711, -0.0421600341796875, -0.3606376647949219, -7.133408546447754, 0.36749267578125, -0.02326202392578125, -0.8350439071655273, -0.08647727966308594, 1.8527822494506836, -0.3280143737792969, -0.45975303649902344, 0.5555181503295898, 1.1804141998291016, 0.21183061599731445, -6.869930267333984, -0.7639656066894531, -0.037647247314453125, 0.039891958236694336, -0.6420059204101562, -0.21986377239227295, -0.21987056732177734, -0.0941162109375, -6.00624942779541, 0.11032485961914062, -0.38248443603515625, -0.9516711235046387, 0.0055201128125190735, -1.8474903106689453, -0.9508472084999084, -1.2975106239318848, 0.035633087158203125, 0.5979757308959961, -3.114595413208008, 0.09625840187072754, 0.322263240814209, -1.5990362167358398, 0.1828266978263855, -1.0002350807189941, 0.6784214973449707, 0.057046592235565186, 3.1793136596679688, -1.5875015258789062, 1.327596664428711, 2.321183919906616, 0.6793241500854492, 1.4735276699066162, 1.4933724403381348, 1.2922039031982422, 1.3258862495422363, 0.26961517333984375, 2.200550079345703, -0.18279647827148438, -0.7099647521972656, 0.27984094619750977, -4.729652404785156, 3.1643171310424805, -0.7264389991760254, 0.7567462921142578, -9.644622802734375, 0.03136253356933594, -0.5101423263549805, -1.4584550857543945, -0.2708902359008789, 0.7442960739135742, -1.5638532638549805, 1.554492473602295, 0.848297119140625, 0.050403594970703125, -0.0721588134765625, 0.027138233184814453, -6.547357559204102, 0.06787776947021484, 0.479925274848938, -0.9077415466308594, 0.634058952331543, 0.5979757308959961, 0.7990989685058594, -0.12048983573913574, 0.05130720138549805, -1.2619106769561768, -4.659404754638672, 0.3174610137939453, -0.6684576272964478, 1.9974513053894043, 0.38094139099121094, -0.5016975402832031, 0.5712490081787109, -0.4518585205078125, -0.3305215835571289, 0.12611567974090576, -1.0484046936035156, 0.5678539276123047, 0.8707790374755859, -0.15108585357666016, 0.5960006713867188, -0.2069845199584961, -0.5954303741455078, 0.18244552612304688, -5.707254409790039, 0.46059757471084595, -0.6901407241821289, 0.7262053489685059, 1.7490055561065674], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 36864, "num_env_steps_trained": 134640, "num_agent_steps_sampled": 36864, "num_agent_steps_trained": 134640, "last_target_update_ts": 36864, "num_target_updates": 71}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -223.24251647345721, "episode_len_mean": 317.92, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296], "episode_lengths": [272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5192468590953837, "mean_inference_ms": 23.716339700211567, "mean_action_processing_ms": 0.1363805586384029, "mean_env_wait_ms": 4.2581863022008575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -223.24251647345721, "episode_len_mean": 317.92, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-89.44518464058638, -186.4327369555831, -85.8381531611085, -82.93167883902788, -73.67809526622295, -189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296], "episode_lengths": [272, 305, 274, 267, 258, 297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5192468590953837, "mean_inference_ms": 23.716339700211567, "mean_action_processing_ms": 0.1363805586384029, "mean_env_wait_ms": 4.2581863022008575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 36864, "num_agent_steps_trained": 134640, "num_env_steps_sampled": 36864, "num_env_steps_trained": 134640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 36864, "agent_timesteps_total": 36864, "timers": {"training_iteration_time_ms": 333.847, "learn_time_ms": 63.077, "learn_throughput": 3804.882, "synch_weights_time_ms": 19.989}, "counters": {"num_env_steps_sampled": 36864, "num_env_steps_trained": 134640, "num_agent_steps_sampled": 36864, "num_agent_steps_trained": 134640, "last_target_update_ts": 36864, "num_target_updates": 71}, "done": false, "episodes_total": 111, "training_iteration": 36, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-13", "timestamp": 1655478253, "time_this_iter_s": 5.3625078201293945, "time_total_s": 187.800612449646, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 187.800612449646, "timesteps_since_restore": 0, "iterations_since_restore": 36, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.675, "ram_util_percent": 61.8125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 8.638948440551758, "min_q": -30.49159812927246, "max_q": 38.12080764770508, "mean_td_error": -0.7442491054534912}, "td_error": [0.30693626403808594, 1.0520849227905273, 0.2723202705383301, -1.6049671173095703, -0.008296012878417969, 1.0389080047607422, 0.1196298599243164, 1.3525691032409668, 0.31398487091064453, 0.16380727291107178, -1.0711450576782227, 13.325448036193848, -0.1523761749267578, -7.813020706176758, -0.8215436935424805, -1.4943723678588867, 0.7386386394500732, -1.0679359436035156, 0.7349624633789062, -0.9837741851806641, -0.05097198486328125, -0.31518733501434326, 0.46893608570098877, 2.111603260040283, -1.3917045593261719, 0.7868165969848633, -0.32388806343078613, 1.2338101863861084, 0.17959856986999512, 3.098292350769043, -0.11820793151855469, -7.349682807922363, -2.048656463623047, -0.7613094449043274, 0.27982521057128906, -0.02108001708984375, -0.21521949768066406, -1.7671089172363281, -0.31815779209136963, -0.7728023529052734, -0.21940135955810547, -1.3066840171813965, -0.08463096618652344, -4.3966264724731445, 0.48353099822998047, 0.2548675537109375, 0.8198351860046387, -0.7096462249755859, 1.811044692993164, -0.1795673370361328, -0.031106948852539062, -4.294079780578613, 0.020293235778808594, -4.341997146606445, -1.9054069519042969, -3.589176654815674, -0.6313180923461914, 1.3891620635986328, -0.6756744384765625, -0.8512406349182129, 0.708465576171875, -0.7880086898803711, 0.8101730346679688, 0.9332809448242188, -0.10896015167236328, -1.8409080505371094, -0.45746445655822754, 0.7044410705566406, -0.4848346710205078, -0.3607621192932129, -1.4895689487457275, 0.3124551773071289, -0.13106346130371094, -1.5803894996643066, 1.004103660583496, 0.1475508213043213, -1.167600393295288, 0.5106830596923828, 1.0155029296875, -1.6456184387207031, -4.961490631103516, -0.47501182556152344, -2.625856399536133, 0.8152379989624023, -0.0464019775390625, 0.6748442649841309, -1.5682369470596313, -2.546978712081909, -2.644430160522461, 0.3827476501464844, -0.5840826034545898, -0.6051244735717773, -1.955667495727539, -0.029050827026367188, 0.6644210815429688, -0.5624771118164062, -2.8512229919433594, -6.097731590270996, -0.33133840560913086, 1.7233715057373047, 0.2976875305175781, 0.9723773002624512, -0.3513317108154297, -1.2757701873779297, 0.9577789306640625, -0.43214893341064453, -6.167381286621094, -0.067138671875, 0.12633323669433594, 0.29433584213256836, -0.595745325088501, -1.1370458602905273, 0.8148555755615234, -3.416733741760254, 0.06836986541748047, -0.7122592926025391, -0.6090497970581055, -0.8231159448623657, -0.16036415100097656, -1.9721713066101074, 0.04258298873901367, -0.7748508453369141, -0.12343120574951172, -0.5375022888183594, -2.505446434020996, -5.3692827224731445, -0.5056781768798828, -0.9062889814376831, -1.1017494201660156, -1.5963964462280273, 0.4392127990722656, -1.1530017852783203, 0.8421726226806641, -0.44779014587402344, 0.9323444366455078, -0.85666823387146, 1.4872455596923828, -1.3066048622131348, -1.8506313562393188, -0.2098526954650879, 1.5959038734436035, -0.25550270080566406, -0.5551900863647461, 0.21367120742797852, -1.6909503936767578, 1.7632378339767456, -0.5777311325073242, -8.910215377807617, -5.222034454345703, -0.43991518020629883, -9.790422439575195, -10.576318740844727, 2.3701672554016113, -1.2077312469482422, -0.3095989227294922, 1.8082208633422852, -1.1882057189941406, 0.9309859275817871, -0.42803144454956055, -2.0619144439697266, -0.35192954540252686, 0.05602264404296875, -1.3037900924682617, -0.8439797163009644, -0.05412006378173828, -0.00630497932434082, 0.05514717102050781, -5.356504440307617, -0.6305255889892578, -2.7090988159179688, 0.6065177917480469, -0.2507803440093994, 0.08794116973876953, 4.384884834289551, -13.4088716506958, 1.7320232391357422, 2.1333751678466797, -0.21011829376220703, -0.30772531032562256, 0.32947254180908203, 1.1139605045318604, 0.114501953125, -1.2050514221191406, 0.023469924926757812, -0.6107692718505859, 0.42519569396972656, -0.5599997043609619, -0.027284622192382812, -0.9973173141479492, 0.34072113037109375, 0.7765693664550781, -1.4036998748779297, -1.5457406044006348, -0.9597063064575195, -0.7031631469726562, -0.30923986434936523, -1.4799325466156006, -2.1180825233459473, -4.532594680786133, 0.2944488525390625, -8.799625396728516, -1.9086418151855469, 0.6318769454956055, 0.023469924926757812, -1.2160385847091675, 1.0381441116333008, -1.1789865493774414, -2.33815336227417, 0.8076915740966797, 0.6693038940429688, 0.019922256469726562, 1.6657466888427734, -0.29199695587158203, -7.302587509155273, 0.09173583984375, 0.5440711975097656, -0.3182210922241211, 0.7099952697753906, -6.952470302581787, 0.9272947907447815, -2.213873863220215, -0.7017054557800293, 0.17578506469726562, -0.807316780090332, -0.16164779663085938, 0.4210805892944336, 7.693098068237305, -0.8374977111816406, -0.7873731255531311, 1.4113349914550781, -0.07307672500610352, -1.6666011810302734, -0.9653205871582031, 0.2647514343261719, -2.483743667602539, -1.2770004272460938, -2.268024444580078, -7.491291046142578, -0.4040250778198242, -0.7720088958740234], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 37888, "num_env_steps_trained": 138480, "num_agent_steps_sampled": 37888, "num_agent_steps_trained": 138480, "last_target_update_ts": 37888, "num_target_updates": 73}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -221.77014969199897, "episode_len_mean": 316.84, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948], "episode_lengths": [297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5183521619818527, "mean_inference_ms": 23.85226979463865, "mean_action_processing_ms": 0.1364335568648096, "mean_env_wait_ms": 4.235853384115432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -221.77014969199897, "episode_len_mean": 316.84, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-189.74127238988876, -147.57872930169106, -326.34175731241703, -393.1968399062753, -254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948], "episode_lengths": [297, 258, 368, 366, 338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5183521619818527, "mean_inference_ms": 23.85226979463865, "mean_action_processing_ms": 0.1364335568648096, "mean_env_wait_ms": 4.235853384115432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 37888, "num_agent_steps_trained": 138480, "num_env_steps_sampled": 37888, "num_env_steps_trained": 138480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 37888, "agent_timesteps_total": 37888, "timers": {"training_iteration_time_ms": 346.857, "learn_time_ms": 63.693, "learn_throughput": 3768.103, "synch_weights_time_ms": 20.388}, "counters": {"num_env_steps_sampled": 37888, "num_env_steps_trained": 138480, "num_agent_steps_sampled": 37888, "num_agent_steps_trained": 138480, "last_target_update_ts": 37888, "num_target_updates": 73}, "done": false, "episodes_total": 116, "training_iteration": 37, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-20", "timestamp": 1655478260, "time_this_iter_s": 5.979254961013794, "time_total_s": 193.7798674106598, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 193.7798674106598, "timesteps_since_restore": 0, "iterations_since_restore": 37, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.26666666666667, "ram_util_percent": 61.96666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 9.945977210998535, "min_q": -33.86554718017578, "max_q": 38.86204147338867, "mean_td_error": -0.5599353313446045}, "td_error": [1.6130595207214355, -1.308248519897461, 0.47281455993652344, 1.384089469909668, 11.396622657775879, -0.41391468048095703, -0.49279022216796875, 0.24999012053012848, 1.9971933364868164, -7.273725509643555, -1.231271743774414, -1.6420841217041016, 1.9399337768554688, -2.85858154296875, -3.3298778533935547, 0.2698020935058594, 0.8813457489013672, 1.072354793548584, -4.529259204864502, -0.9504423141479492, -0.4054579734802246, -5.1176300048828125, 0.41575050354003906, 0.27747997641563416, -0.18695354461669922, 18.653196334838867, -0.8123226165771484, -0.26937198638916016, -1.155837059020996, -0.271636962890625, -1.4806995391845703, -0.5385360717773438, -1.8633365631103516, -1.3352527618408203, 1.2609376907348633, 3.4718055725097656, 0.1579434871673584, -0.7698898315429688, 0.9808311462402344, 0.2389688491821289, 1.837693691253662, -0.2168264389038086, 0.529749870300293, -1.433791160583496, -1.4104156494140625, -0.9975795745849609, 0.8939247131347656, -1.0893630981445312, -0.5520782470703125, -2.088449478149414, 1.5280399322509766, -1.0205268859863281, -0.6087261438369751, 5.371192932128906, 1.9122419357299805, -2.306661605834961, -0.5769424438476562, -1.5153064727783203, 1.1945152282714844, -6.344007968902588, -1.080535888671875, -1.277672290802002, -1.607522964477539, 0.2903609275817871, -0.12964463233947754, -2.3544883728027344, 1.711167335510254, 0.48801910877227783, 0.23145198822021484, -2.049917221069336, -0.0246734619140625, -1.2811775207519531, -0.7686100006103516, 1.903676986694336, 2.048646926879883, 0.7705922722816467, -3.1410837173461914, -9.832235336303711, -0.5784206390380859, -0.8209142684936523, 2.2549867630004883, -0.5867824554443359, 0.05745744705200195, -0.8440642356872559, -2.6580278873443604, -0.3004136085510254, -0.5548534393310547, 1.8380088806152344, -0.40844154357910156, 2.0099716186523438, 0.21686363220214844, -2.4456708431243896, -2.558431625366211, -0.31606483459472656, 0.4618663787841797, 1.094905138015747, -5.25623893737793, -0.7539138197898865, -0.08248710632324219, -0.8553303480148315, -0.9823741912841797, -0.9818515777587891, 0.4628028869628906, -0.0533905029296875, -0.3587982654571533, 0.11584591865539551, 0.1901111602783203, -0.5547637939453125, -0.6787261962890625, -1.6284904479980469, 1.665144920349121, -0.3076305389404297, -1.7034664154052734, 0.1901111602783203, -1.8191413879394531, -0.052974700927734375, 0.6458606719970703, 0.03639793395996094, -8.516889572143555, -1.542426586151123, -1.1617794036865234, -0.3621782064437866, 1.295804500579834, -0.7494373321533203, 9.930399894714355, -2.0036697387695312, -0.8991556167602539, -1.4798660278320312, -7.199674606323242, 0.46450233459472656, 1.0475821495056152, -5.043292999267578, -1.433791160583496, 1.442631721496582, 1.496870994567871, -1.4229774475097656, 0.9317522048950195, -7.729455947875977, -1.3858680725097656, -0.4401988983154297, -0.7433280944824219, -0.9072647094726562, -1.4648199081420898, 1.0880346298217773, -0.9964599609375, 1.3023077249526978, -0.5495185852050781, 1.4459519386291504, -1.3920536041259766, 1.2864723205566406, -0.21379470825195312, -0.6136093139648438, -1.091719627380371, -0.07385063171386719, -0.5784206390380859, -1.253015398979187, -7.770071029663086, -1.7172794342041016, -1.0662803649902344, -0.042514801025390625, -0.9962520599365234, -0.3748455047607422, -1.4071979522705078, 0.15046310424804688, -0.9716567993164062, -1.558743953704834, 0.2429027557373047, 0.5458230972290039, -0.34017008543014526, -1.9157581329345703, -7.239995002746582, -1.334686279296875, 0.0145721435546875, -1.4767570495605469, -3.293707847595215, -2.029691696166992, -17.47149658203125, -1.2922172546386719, -1.121225357055664, -0.479736328125, -4.567626953125, 1.326158046722412, 0.9533882141113281, 0.3743553161621094, -1.529989242553711, 0.08545494079589844, -0.4483509063720703, -2.214588165283203, 0.1126260757446289, -0.9402523040771484, -1.6828985214233398, 2.1919918060302734, -3.494609832763672, 0.5680813789367676, -2.3123035430908203, 0.2715029716491699, 2.621918201446533, 3.028928756713867, -0.5385360717773438, 1.3771276473999023, -0.6844272613525391, -0.1877002716064453, -0.5395535230636597, -9.966692924499512, 1.6400775909423828, -0.6344165802001953, 0.8258354663848877, -0.6790151596069336, -3.365018844604492, 7.253568649291992, -0.4321746826171875, 1.5265140533447266, 0.5377645492553711, -0.3780078887939453, 1.4611396789550781, -1.5366778373718262, 0.14363479614257812, -0.4915323257446289, -1.3869104385375977, -0.07950353622436523, -1.4908437728881836, -1.5230255126953125, 1.326158046722412, 0.2407054901123047, -1.0757317543029785, 0.05194282531738281, 1.3751206398010254, -0.030714750289916992, -0.5977935791015625, -5.7532501220703125, 0.8601522445678711, -1.1624860763549805, -1.3858680725097656, 2.357553005218506, 0.1332998275756836, -1.06024169921875, -1.750758171081543, 0.11794471740722656, -0.04341602325439453, 0.6815223693847656], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 38912, "num_env_steps_trained": 142320, "num_agent_steps_sampled": 38912, "num_agent_steps_trained": 142320, "last_target_update_ts": 38912, "num_target_updates": 75}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -215.71398251600564, "episode_len_mean": 314.78, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689], "episode_lengths": [338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5181512926212427, "mean_inference_ms": 23.92015873504844, "mean_action_processing_ms": 0.13648736376312878, "mean_env_wait_ms": 4.220973730029051, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -215.71398251600564, "episode_len_mean": 314.78, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-254.61224640905857, -303.57033114880323, -279.91651432961226, -274.59529020637274, -236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689], "episode_lengths": [338, 356, 349, 346, 336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5181512926212427, "mean_inference_ms": 23.92015873504844, "mean_action_processing_ms": 0.13648736376312878, "mean_env_wait_ms": 4.220973730029051, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 38912, "num_agent_steps_trained": 142320, "num_env_steps_sampled": 38912, "num_env_steps_trained": 142320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 38912, "agent_timesteps_total": 38912, "timers": {"training_iteration_time_ms": 331.48, "learn_time_ms": 62.716, "learn_throughput": 3826.8, "synch_weights_time_ms": 19.989}, "counters": {"num_env_steps_sampled": 38912, "num_env_steps_trained": 142320, "num_agent_steps_sampled": 38912, "num_agent_steps_trained": 142320, "last_target_update_ts": 38912, "num_target_updates": 75}, "done": false, "episodes_total": 120, "training_iteration": 38, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-25", "timestamp": 1655478265, "time_this_iter_s": 5.293113946914673, "time_total_s": 199.07298135757446, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 199.07298135757446, "timesteps_since_restore": 0, "iterations_since_restore": 38, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.17142857142858, "ram_util_percent": 62.028571428571425}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 11.688111305236816, "min_q": -32.601070404052734, "max_q": 42.202423095703125, "mean_td_error": 0.3249070942401886}, "td_error": [-0.300811767578125, 2.200195789337158, -0.33191871643066406, 0.9785480499267578, -0.2242565155029297, 1.1105756759643555, 0.5805332660675049, -0.07223320007324219, 1.1088199615478516, -0.03530693054199219, -1.5487957000732422, 1.5272216796875, 0.5410346984863281, 1.1528658866882324, 2.020143508911133, 0.770233154296875, 2.6542134284973145, -0.047176361083984375, -0.04439520835876465, -0.29760169982910156, 0.9572620391845703, 2.2648868560791016, 0.0537567138671875, 1.3707084655761719, 0.5352954864501953, -6.808488845825195, 0.1916217803955078, 1.4663105010986328, 0.3870270252227783, 0.5505008697509766, 1.5468764305114746, 0.07253646850585938, 1.0180225372314453, 2.577486515045166, 1.060190200805664, -0.5120453834533691, 0.6496315002441406, 1.8069753646850586, -2.3188514709472656, 1.1528658866882324, 0.023798346519470215, 0.09816551208496094, 0.16459274291992188, 1.1530265808105469, 0.036258697509765625, 1.566823959350586, 2.8877944946289062, 0.9785480499267578, 0.8672695159912109, 0.5462818145751953, 0.6450365781784058, 0.8531618118286133, -0.6294403076171875, -0.8525733947753906, 0.26201343536376953, -0.661865234375, -0.3398609161376953, 0.8672695159912109, -5.6359710693359375, -0.3153400421142578, -6.397586822509766, -0.3074071407318115, 1.9243927001953125, 0.174774169921875, 0.14350366592407227, 2.583711624145508, 2.3870880603790283, -0.1505870819091797, 0.4513988494873047, -0.2852986454963684, 0.930999755859375, -0.3173999786376953, -0.5720467567443848, 0.007338523864746094, -0.06612873077392578, 0.2207660675048828, 0.7132244110107422, -11.04760456085205, -0.23723149299621582, -1.5390281677246094, -5.2207794189453125, 0.46685791015625, -0.03214073181152344, -1.723740577697754, 17.551259994506836, 0.5405044555664062, 0.971867561340332, 0.670626163482666, -0.3906135559082031, 0.3064957857131958, 2.8805007934570312, -1.8866195678710938, -3.9776577949523926, 1.6597051620483398, 0.8355202674865723, 0.1612529754638672, 1.1577668190002441, 0.5313401222229004, -0.29012298583984375, 1.2111787796020508, 1.1140165328979492, -0.20759296417236328, 0.3491877317428589, 4.482966899871826, 0.9576549530029297, 0.27361392974853516, 0.09709024429321289, -0.36999034881591797, 2.0054502487182617, 0.18902063369750977, 0.5519075393676758, 0.5048885345458984, 0.021735191345214844, 2.1466617584228516, -0.15338754653930664, -1.8664789199829102, -1.3260362148284912, 0.651641845703125, 0.5167140960693359, 0.3851041793823242, 0.3575897216796875, -1.2903804779052734, 7.4315972328186035, 1.3586444854736328, 0.2900848388671875, -0.9211835861206055, -0.04585742950439453, -1.5473785400390625, 0.5403356552124023, -7.201568603515625, -0.4660501480102539, -4.779623031616211, -0.23679351806640625, 0.23629474639892578, -9.241992950439453, 3.6804862022399902, 3.5420966148376465, 0.5338611602783203, 0.6300182342529297, 1.0559768676757812, 0.7571773529052734, 0.1957848072052002, -8.72226333618164, 1.4044113159179688, 7.2352166175842285, -0.28509521484375, -0.03335380554199219, -1.6421642303466797, 8.390119552612305, 1.3084068298339844, -1.7180531024932861, -3.88909912109375, -0.19962692260742188, 1.3707084655761719, -1.6162834167480469, -0.8418500423431396, -0.16196918487548828, 3.5420966148376465, -6.657041549682617, 0.9381570816040039, 0.39084434509277344, -1.5871696472167969, 0.8309097290039062, -3.884079933166504, 0.6993503570556641, 0.6513945460319519, 1.0221748352050781, -2.747833013534546, -5.726693153381348, 0.27353668212890625, 0.5679244995117188, 0.07224559783935547, -0.7088356018066406, 0.7574291229248047, 0.927492618560791, 1.2884387969970703, 0.10742568969726562, 0.10884618759155273, -7.45842170715332, 0.005313873291015625, -5.587685585021973, -1.2406902313232422, 1.231663703918457, 0.7374062538146973, 0.6378931403160095, 0.8451347351074219, 1.231663703918457, 0.19407939910888672, 0.4794578552246094, 0.016344547271728516, 0.5001926422119141, 0.07297134399414062, 2.520371437072754, 1.7590062618255615, 0.5983619689941406, -1.0309138298034668, 1.51324462890625, -0.4370574951171875, -0.48254966735839844, 0.6232833862304688, 1.0540695190429688, 1.0208473205566406, 0.3494281768798828, -0.2880585193634033, 0.18720793724060059, -9.060991287231445, 1.231663703918457, 1.3538703918457031, 2.010761022567749, 0.1642169952392578, 0.14350366592407227, 0.45365047454833984, 0.5682106018066406, 1.7170252799987793, 0.6450365781784058, 2.5678906440734863, 0.2700767517089844, 0.7737197875976562, 1.51324462890625, 1.6661205291748047, 1.942483901977539, 15.961663246154785, 1.3146581649780273, -0.40342044830322266, 0.06087160110473633, 2.411024570465088, 0.5603141784667969, 1.294851303100586, -0.5573387145996094, 2.5516223907470703, 5.291330337524414, 1.551483154296875, -1.5397109985351562, 7.63834285736084, 12.277750968933105, 1.8057365417480469, -0.19838714599609375, 0.8082551956176758, -1.40341055393219, -1.44952392578125], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 39936, "num_env_steps_trained": 146160, "num_agent_steps_sampled": 39936, "num_agent_steps_trained": 146160, "last_target_update_ts": 39936, "num_target_updates": 77}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -209.33597829185427, "episode_len_mean": 311.4, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083], "episode_lengths": [336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5179810719292904, "mean_inference_ms": 24.007541153008706, "mean_action_processing_ms": 0.13673903449000915, "mean_env_wait_ms": 4.214813216783097, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -209.33597829185427, "episode_len_mean": 311.4, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-236.82846321165562, -241.90552121400833, -269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083], "episode_lengths": [336, 353, 358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5179810719292904, "mean_inference_ms": 24.007541153008706, "mean_action_processing_ms": 0.13673903449000915, "mean_env_wait_ms": 4.214813216783097, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 39936, "num_agent_steps_trained": 146160, "num_env_steps_sampled": 39936, "num_env_steps_trained": 146160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 39936, "agent_timesteps_total": 39936, "timers": {"training_iteration_time_ms": 329.243, "learn_time_ms": 64.07, "learn_throughput": 3745.893, "synch_weights_time_ms": 20.488}, "counters": {"num_env_steps_sampled": 39936, "num_env_steps_trained": 146160, "num_agent_steps_sampled": 39936, "num_agent_steps_trained": 146160, "last_target_update_ts": 39936, "num_target_updates": 77}, "done": false, "episodes_total": 124, "training_iteration": 39, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-30", "timestamp": 1655478270, "time_this_iter_s": 5.320545434951782, "time_total_s": 204.39352679252625, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 204.39352679252625, "timesteps_since_restore": 0, "iterations_since_restore": 39, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 30.7875, "ram_util_percent": 62.175000000000004}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 9.833972930908203, "min_q": -32.357261657714844, "max_q": 37.530757904052734, "mean_td_error": -0.14200732111930847}, "td_error": [0.5808162689208984, 2.4678592681884766, -0.09877395629882812, 0.5699954032897949, -0.23538589477539062, -0.7055644989013672, -0.6284828186035156, -0.16265869140625, -1.1690540313720703, 0.5205059051513672, 1.3439464569091797, 0.13789516687393188, -0.06316757202148438, -1.9406628608703613, -9.16724967956543, 0.8401697874069214, 1.2496294975280762, 2.1390647888183594, -0.22788429260253906, -0.5089378356933594, -0.6091842651367188, 1.4359318017959595, -0.6282806396484375, 0.21189308166503906, 0.5798063278198242, 0.12739276885986328, -7.14887809753418, -10.637744903564453, 0.6251316070556641, -0.3727588653564453, -0.9316093921661377, 0.10736465454101562, -2.059957504272461, 1.0081157684326172, -1.9570846557617188, 0.8739004135131836, -7.350210189819336, 1.7437191009521484, 0.06132698059082031, -0.16180729866027832, 0.1184229850769043, 0.8091754913330078, -0.9499969482421875, 0.3563035726547241, -0.5249261856079102, 3.8322267532348633, 2.4930121898651123, -0.13409423828125, 0.5762279033660889, 0.027738571166992188, 0.48009681701660156, 0.8752975463867188, 1.256917953491211, 1.8617010116577148, -1.3045989274978638, -1.1670169830322266, -5.119304656982422, -0.8128957748413086, 1.6067628860473633, -6.52657413482666, -0.2987174987792969, -0.19260597229003906, 0.6293601989746094, -0.10375213623046875, 1.3149700164794922, -0.1223294734954834, -0.06118583679199219, 1.3306465148925781, 1.3838176727294922, -1.55548095703125, 0.30469799041748047, -0.8673162460327148, -0.7627735137939453, 0.2881813049316406, 0.6089968681335449, 0.5539069175720215, -2.3939924240112305, 1.4852466583251953, 0.6282739639282227, -0.9109044075012207, 1.0581235885620117, 1.6021003723144531, 0.2196979522705078, -0.6508755683898926, -0.06902217864990234, 2.5612545013427734, 1.0792274475097656, -2.212599515914917, -0.9185714721679688, 0.8506050109863281, 8.449909210205078, 1.256204605102539, -0.7936515808105469, -1.9175033569335938, 1.6022491455078125, -1.2986135482788086, -0.2908344268798828, 1.500563144683838, 0.607856273651123, -2.1733646392822266, 4.407893657684326, 0.7857422828674316, 0.7329397201538086, -4.362908363342285, 0.9378814697265625, -1.0764679908752441, -11.588508605957031, -2.3466129302978516, -1.9175033569335938, 1.7164688110351562, -0.4648571014404297, -5.04698371887207, -0.09877395629882812, -0.24285316467285156, -1.1063282489776611, -0.26393985748291016, 0.35100436210632324, -0.3382444381713867, 0.1314539909362793, 0.19990158081054688, -1.1346211433410645, 1.5190271139144897, 0.23633384704589844, 0.4410896301269531, 0.3033561706542969, 1.487407922744751, -4.352489471435547, 1.1935629844665527, -0.884282112121582, 0.20529842376708984, -0.4064769744873047, 1.5582942962646484, 1.6248970031738281, -0.04461479187011719, -1.1509456634521484, 0.7685413360595703, -0.6562900543212891, -6.213545799255371, 1.3290653228759766, 0.9753398895263672, 0.9229164123535156, -0.9340343475341797, -1.1778669357299805, -1.2811965942382812, -0.6692981719970703, 3.1180057525634766, -1.0569963455200195, 0.07680320739746094, -0.1607494354248047, 0.4934401512145996, -1.3038043975830078, 2.5346975326538086, 0.42745018005371094, 0.2704153060913086, -2.573719024658203, 12.923346519470215, -0.20583438873291016, 1.4669315814971924, 0.6282249689102173, 0.40825939178466797, -0.06821680068969727, -0.674468994140625, -0.8795967102050781, -0.111785888671875, 0.02487945556640625, 0.43849849700927734, 9.964643478393555, -0.5065460205078125, 0.8474273681640625, 1.4852466583251953, -0.0689544677734375, 0.09401893615722656, 0.42928504943847656, -1.0242748260498047, 0.5152273178100586, 0.32365894317626953, -0.8318710327148438, -0.07087421417236328, -0.7347526550292969, -6.849456787109375, 0.3053913116455078, -0.6697883605957031, -1.320943832397461, 0.3866105079650879, 0.5823841094970703, 0.30286693572998047, -0.13179874420166016, -7.190080642700195, -1.0213594436645508, 0.8163490295410156, -0.331878662109375, -0.7337408065795898, 1.8858566284179688, 0.5909585952758789, 1.1372718811035156, 0.8948497772216797, 0.03093576431274414, -0.3095541000366211, -7.487372875213623, 0.4947471618652344, -0.8710153102874756, -0.06440353393554688, -10.594205856323242, 1.6158742904663086, 2.330353260040283, 1.1715507507324219, 1.3690557479858398, -5.159963607788086, -0.12127494812011719, -7.385913848876953, 2.1395859718322754, -0.08401870727539062, -5.600053787231445, -5.039615631103516, -0.6424016952514648, 0.1478719711303711, -0.2025165557861328, -0.5904707908630371, 0.8243122100830078, 0.09183120727539062, 17.536352157592773, 0.5842323303222656, -0.6842136383056641, 0.7435693740844727, 0.34654784202575684, 4.383360385894775, 0.12457847595214844, 0.46149253845214844, 3.9808502197265625, 1.615365982055664, 0.2315230369567871, 1.2788429260253906, -1.9136419296264648, 2.4136996269226074, -0.3586158752441406, 0.15610980987548828, -0.33641624450683594, 0.4703395366668701, 1.2450008392333984, -0.6797428131103516], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 40960, "num_env_steps_trained": 150000, "num_agent_steps_sampled": 40960, "num_agent_steps_trained": 150000, "last_target_update_ts": 40960, "num_target_updates": 79}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -209.70559501945974, "episode_len_mean": 310.58, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344], "episode_lengths": [358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.517728687111751, "mean_inference_ms": 24.036365665949692, "mean_action_processing_ms": 0.1366837795859396, "mean_env_wait_ms": 4.208062933531184, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -209.70559501945974, "episode_len_mean": 310.58, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-269.8638171777129, -233.00687704980373, -396.0639368072152, -299.74056724458933, -410.57111133635044, -415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344], "episode_lengths": [358, 346, 393, 379, 391, 376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.517728687111751, "mean_inference_ms": 24.036365665949692, "mean_action_processing_ms": 0.1366837795859396, "mean_env_wait_ms": 4.208062933531184, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 40960, "num_agent_steps_trained": 150000, "num_env_steps_sampled": 40960, "num_env_steps_trained": 150000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 40960, "agent_timesteps_total": 40960, "timers": {"training_iteration_time_ms": 318.908, "learn_time_ms": 64.031, "learn_throughput": 3748.213, "synch_weights_time_ms": 20.089}, "counters": {"num_env_steps_sampled": 40960, "num_env_steps_trained": 150000, "num_agent_steps_sampled": 40960, "num_agent_steps_trained": 150000, "last_target_update_ts": 40960, "num_target_updates": 79}, "done": false, "episodes_total": 126, "training_iteration": 40, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-36", "timestamp": 1655478276, "time_this_iter_s": 5.114804744720459, "time_total_s": 209.5083315372467, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 209.5083315372467, "timesteps_since_restore": 0, "iterations_since_restore": 40, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.924999999999997, "ram_util_percent": 62.2}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 11.264741897583008, "min_q": -32.699188232421875, "max_q": 41.35752868652344, "mean_td_error": -0.528640627861023}, "td_error": [0.116912841796875, 0.2597827911376953, -0.4160327911376953, 0.3832359313964844, 0.9635524749755859, -5.640976905822754, -0.6028923988342285, -0.22457504272460938, -1.1494731903076172, 0.4270796775817871, -0.870244026184082, -1.2573661804199219, 0.9609823226928711, -0.05782604217529297, 0.4180409908294678, 2.128480911254883, 0.16296648979187012, 1.662348747253418, -0.03009510040283203, -0.41457653045654297, -0.05365180969238281, 0.011621475219726562, -0.1614089012145996, -0.09137916564941406, -0.08820343017578125, -0.4127979278564453, 0.0001506805419921875, -0.7975273132324219, -0.2694578170776367, -0.8935384750366211, -7.417886734008789, -0.10951614379882812, 0.18474864959716797, 0.2099144458770752, -0.9562978744506836, 0.25988245010375977, -0.3486292362213135, -0.45748138427734375, 1.944502830505371, -0.8725252151489258, -0.16796875, -0.6060905456542969, -0.2134532928466797, -0.4404029846191406, -9.975837707519531, -0.5904655456542969, -0.7541542053222656, 0.036669254302978516, -0.4340524673461914, -0.19331884384155273, -0.14998245239257812, -0.29981136322021484, -0.42794346809387207, 0.2614593505859375, -1.9047813415527344, 1.210775375366211, 9.904516220092773, 0.5358619689941406, 0.05617690086364746, -0.9801750183105469, 0.8274335861206055, -1.63267183303833, -0.06086921691894531, -5.2380523681640625, -0.18256163597106934, -2.0646138191223145, 1.1197075843811035, 0.3089733123779297, -0.5626335144042969, -1.003387451171875, -0.7829341888427734, 1.4760894775390625, 1.4880056381225586, -4.063986778259277, 1.4492557048797607, -1.2597084045410156, -4.712238311767578, 0.31424832344055176, -0.6177401542663574, 0.6139965057373047, -0.4331626892089844, -0.4316082000732422, -0.7231521606445312, 0.1165924072265625, -0.5574831962585449, 0.48950958251953125, -1.1842937469482422, -0.5274391174316406, -4.7597808837890625, 0.6718559265136719, -2.2050905227661133, 0.8750238418579102, 3.2104811668395996, 0.720738410949707, 0.36113834381103516, 12.460192680358887, -0.4738006591796875, -6.3050713539123535, -0.5969047546386719, 1.2019004821777344, -7.739768981933594, -0.11041636765003204, -2.1228866577148438, 0.17187881469726562, -6.093055725097656, 0.3848743438720703, -0.02813243865966797, -0.22022247314453125, -1.1747798919677734, -0.24081802368164062, 0.7413330078125, -9.568744659423828, -1.290024757385254, 1.9769783020019531, 1.4483842849731445, -1.2679176330566406, 0.11684036254882812, 0.368091344833374, -1.7649650573730469, -5.521663665771484, 1.9329833984375, -10.506143569946289, 1.7484188079833984, -0.28828907012939453, -0.6558933258056641, 0.2015361785888672, -3.472177505493164, -0.04217338562011719, -7.248569488525391, -0.7328557968139648, 0.6101970672607422, 3.857515811920166, -0.8612594604492188, 0.7413330078125, -0.49769020080566406, -0.11184120178222656, 0.49273681640625, 4.672105312347412, -0.22337913513183594, -0.32826805114746094, -1.513418197631836, -0.5299282073974609, -0.2313823699951172, -0.9283447265625, 0.7226428985595703, -0.0810699462890625, 2.705629348754883, 0.09309101104736328, 1.1437406539916992, -2.651468276977539, 2.308137893676758, -1.3812751770019531, 0.6764564514160156, -0.6636962890625, -0.4805259704589844, -0.3054962158203125, -0.6408748626708984, -0.4721240997314453, -0.4659996032714844, 1.0023212432861328, -1.4484367370605469, -1.3732213973999023, 0.3121366500854492, -0.5205869674682617, -0.5878009796142578, 0.09189486503601074, -0.7681999206542969, -0.5023918151855469, 1.2328681945800781, -5.599864959716797, -0.9734694957733154, 0.16833877563476562, 1.9562759399414062, 0.11684036254882812, -0.08752059936523438, -0.4430713653564453, -0.614100456237793, -0.8243789672851562, 0.7862920761108398, -0.1790180206298828, 0.6942214965820312, 0.4145498275756836, -0.2802391052246094, 0.9628019332885742, 1.0394325256347656, -0.7795333862304688, -0.9884967803955078, 0.5376930236816406, -0.39086341857910156, -2.3223323822021484, -0.13877391815185547, 1.3773374557495117, 0.7433509826660156, -1.1035308837890625, 0.7413330078125, 1.1778603792190552, 0.7844791412353516, 0.6942214965820312, -0.4764995574951172, -1.9274053573608398, -2.1757140159606934, 0.694373607635498, -0.24259281158447266, 5.311443328857422, -1.357015609741211, -0.03753089904785156, -0.3486292362213135, -3.088505268096924, -1.1441974639892578, -5.970946788787842, -0.2174091339111328, -1.1747798919677734, -2.0197086334228516, -6.997220039367676, 0.05483126640319824, -1.0692977905273438, -2.100679636001587, -1.2204933166503906, -0.5867443084716797, -0.17574310302734375, 0.34121227264404297, -1.4537477493286133, 0.48127174377441406, 0.09781646728515625, -0.6789798736572266, -3.0149312019348145, -0.11387002468109131, 1.6454038619995117, -6.689064025878906, -1.422403335571289, -0.756009578704834, 0.9192781448364258, -0.1375560760498047, 0.477017879486084, 1.0113954544067383, -6.088720321655273, 1.3165297508239746, -0.5930118560791016, 1.2089405059814453, -5.412471771240234], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 41984, "num_env_steps_trained": 153840, "num_agent_steps_sampled": 41984, "num_agent_steps_trained": 153840, "last_target_update_ts": 41984, "num_target_updates": 81}, "sampler_results": {"episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -194.7186038786918, "episode_len_mean": 303.57, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145], "episode_lengths": [376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5188127021875611, "mean_inference_ms": 24.144055684760787, "mean_action_processing_ms": 0.13650027091675407, "mean_env_wait_ms": 4.206982921635105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 29.211538091301918, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -194.7186038786918, "episode_len_mean": 303.57, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-415.4468524828553, -194.53157383203506, -360.80521090328693, -243.96122986078262, -224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145], "episode_lengths": [376, 317, 362, 326, 335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5188127021875611, "mean_inference_ms": 24.144055684760787, "mean_action_processing_ms": 0.13650027091675407, "mean_env_wait_ms": 4.206982921635105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 41984, "num_agent_steps_trained": 153840, "num_env_steps_sampled": 41984, "num_env_steps_trained": 153840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 41984, "agent_timesteps_total": 41984, "timers": {"training_iteration_time_ms": 330.251, "learn_time_ms": 63.18, "learn_throughput": 3798.675, "synch_weights_time_ms": 20.382}, "counters": {"num_env_steps_sampled": 41984, "num_env_steps_trained": 153840, "num_agent_steps_sampled": 41984, "num_agent_steps_trained": 153840, "last_target_update_ts": 41984, "num_target_updates": 81}, "done": false, "episodes_total": 131, "training_iteration": 41, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-41", "timestamp": 1655478281, "time_this_iter_s": 5.383586168289185, "time_total_s": 214.8919177055359, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 214.8919177055359, "timesteps_since_restore": 0, "iterations_since_restore": 41, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.174999999999997, "ram_util_percent": 62.3}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 13.064350128173828, "min_q": -31.222320556640625, "max_q": 38.3875732421875, "mean_td_error": -0.42457109689712524}, "td_error": [-4.729957580566406, -0.2306842803955078, -0.07655906677246094, -4.4547882080078125, 0.8683309555053711, -1.5905265808105469, -8.306337356567383, -6.546868324279785, 1.3339675664901733, 0.06164884567260742, 1.3921985626220703, -7.922939300537109, 2.2477073669433594, -0.4317808151245117, -0.5900230407714844, 0.3801274299621582, 1.2483000755310059, -0.2478179931640625, 0.3465576171875, -31.29436492919922, -1.3387813568115234, 0.019296646118164062, 0.7775354385375977, -1.7909660339355469, 0.9852485656738281, -0.4639606475830078, 0.18488216400146484, -0.03474617004394531, -0.18085479736328125, 0.03804969787597656, 0.29801082611083984, -0.8113746643066406, -5.851583480834961, -2.779083251953125, 0.10879898071289062, 0.04399394989013672, 0.15707838535308838, -5.585975646972656, -1.8143329620361328, -0.36761474609375, -0.5448474884033203, 0.5322728157043457, 1.0847368240356445, 0.5807170867919922, 1.0784211158752441, -1.0710725784301758, -0.19681358337402344, 0.5849685668945312, -5.5240020751953125, 0.940791130065918, 0.3697795867919922, 1.4491653442382812, 1.6348206996917725, 0.9235095977783203, 0.9684152603149414, 0.05559825897216797, -1.2807273864746094, -3.1543235778808594, 0.1465625762939453, 1.393692970275879, 1.5727710723876953, -0.20046770572662354, 1.257009506225586, 0.7050046920776367, 1.6751095056533813, -0.21789932250976562, -0.5453281402587891, -0.04511737823486328, -0.6522483825683594, -0.8431205749511719, -0.9500312805175781, -0.0396728515625, 1.4860572814941406, 0.47273826599121094, -4.082128524780273, -0.437225341796875, 2.414839267730713, -0.10894012451171875, -0.013521194458007812, 0.1988086700439453, -4.772911071777344, -0.16069412231445312, 0.04005622863769531, 1.1557121276855469, -1.5485420227050781, 0.9357280731201172, -0.44654417037963867, 2.2212324142456055, 0.2041945457458496, -0.49277400970458984, 1.3301182985305786, 1.09055757522583, 0.029571533203125, -1.281052827835083, 0.4610252380371094, 0.22222566604614258, -0.17240619659423828, -6.614805221557617, 0.6871099472045898, -1.5394353866577148, 0.13524436950683594, 1.368185043334961, -1.324716567993164, -0.5777015686035156, -0.4297924041748047, 1.2530632019042969, 2.1054584980010986, -1.3724708557128906, 2.7657785415649414, -0.29787588119506836, 1.5785846710205078, 0.8212451934814453, 0.35202598571777344, -0.5716390609741211, 0.17698001861572266, 0.6846542358398438, 1.260274887084961, -0.2134532928466797, 0.2368694543838501, 0.16592931747436523, 1.639291763305664, 1.845428466796875, 2.533790111541748, -6.556332588195801, 0.3297309875488281, -0.9506778717041016, 0.5916123390197754, 0.6847591400146484, -0.16479206085205078, -0.6648712158203125, -0.5319633483886719, -0.6152210235595703, -1.1468420028686523, -1.7584228515625, 0.9257535934448242, -1.1014039516448975, -0.07733345031738281, 0.7369191646575928, 1.9247016906738281, 1.759246826171875, -6.801630020141602, 1.509078025817871, -0.06039619445800781, -7.230062484741211, 1.8914098739624023, 0.09675025939941406, 0.29486846923828125, -4.765933990478516, 0.06340885162353516, 1.7584342956542969, 0.7408759593963623, 0.9450969696044922, 0.4750404357910156, 1.361280918121338, -0.07832479476928711, -1.3700218200683594, -7.338366508483887, 2.8089447021484375, 0.9729156494140625, 1.7777156829833984, -6.246092796325684, 0.2636070251464844, 2.59348726272583, 1.2530632019042969, 1.421804428100586, 0.2569618225097656, 1.9335033893585205, 2.6471800804138184, 0.0922861099243164, -0.2540922164916992, -0.37061309814453125, -6.656885147094727, -0.028291702270507812, -1.58544921875, 0.3628382682800293, -1.9491291046142578, 1.899484634399414, -0.5085506439208984, -0.7731304168701172, 0.7604217529296875, -0.6223287582397461, -5.624794960021973, -1.0667076110839844, -0.16069412231445312, 2.4049415588378906, 0.4622335433959961, 1.6472091674804688, -0.36505699157714844, 1.9688539505004883, 1.1464719772338867, -1.348592758178711, 1.2038097381591797, 0.7642478942871094, -1.0809745788574219, 1.1771736145019531, 2.353930711746216, 0.3420295715332031, -6.319100379943848, 1.5659828186035156, -0.5700664520263672, -4.417111396789551, -4.734447479248047, 0.6420936584472656, -1.1434288024902344, 0.3064765930175781, 0.2283611297607422, 0.04040348529815674, 0.8020787239074707, 0.3900127410888672, 2.4488391876220703, -1.8940246105194092, 1.759246826171875, 0.40940332412719727, -1.8725013732910156, -0.21983623504638672, 0.1451115608215332, 0.504673957824707, 1.772634506225586, 0.05468177795410156, 1.0397462844848633, 0.9416885375976562, 1.361280918121338, 1.314523696899414, 0.8435115814208984, 0.19594764709472656, -0.7208423614501953, -9.391735076904297, -0.8703112602233887, 0.6852922439575195, 2.068063735961914, 0.7235279083251953, 0.44766807556152344, 0.22143888473510742, 0.9076213836669922, -0.4868659973144531, -0.2240619659423828, -0.6585693359375, -0.5170106887817383, 0.8893728256225586, 0.5314235687255859], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 43008, "num_env_steps_trained": 157680, "num_agent_steps_sampled": 43008, "num_agent_steps_trained": 157680, "last_target_update_ts": 43008, "num_target_updates": 83}, "sampler_results": {"episode_reward_max": 31.712017722427845, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -182.40183464877308, "episode_len_mean": 298.21, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987], "episode_lengths": [335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5192317278458769, "mean_inference_ms": 24.19541948276161, "mean_action_processing_ms": 0.13625222856698477, "mean_env_wait_ms": 4.204152285011992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 31.712017722427845, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -182.40183464877308, "episode_len_mean": 298.21, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-224.43402007222176, -378.8419892936945, -359.54903188347816, -277.37607838213444, -436.4729839116335, -362.73964773863554, -464.6643412485719, -442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987], "episode_lengths": [335, 367, 369, 352, 397, 387, 409, 408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5192317278458769, "mean_inference_ms": 24.19541948276161, "mean_action_processing_ms": 0.13625222856698477, "mean_env_wait_ms": 4.204152285011992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 43008, "num_agent_steps_trained": 157680, "num_env_steps_sampled": 43008, "num_env_steps_trained": 157680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 43008, "agent_timesteps_total": 43008, "timers": {"training_iteration_time_ms": 344.136, "learn_time_ms": 64.57, "learn_throughput": 3716.913, "synch_weights_time_ms": 20.088}, "counters": {"num_env_steps_sampled": 43008, "num_env_steps_trained": 157680, "num_agent_steps_sampled": 43008, "num_agent_steps_trained": 157680, "last_target_update_ts": 43008, "num_target_updates": 83}, "done": false, "episodes_total": 135, "training_iteration": 42, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-47", "timestamp": 1655478287, "time_this_iter_s": 5.345556974411011, "time_total_s": 220.2374746799469, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 220.2374746799469, "timesteps_since_restore": 0, "iterations_since_restore": 42, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 30.385714285714283, "ram_util_percent": 62.44285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 12.264636039733887, "min_q": -30.82651138305664, "max_q": 40.85038375854492, "mean_td_error": -0.29535940289497375}, "td_error": [-3.150296211242676, -1.6066322326660156, 0.05474853515625, 1.3348870277404785, 0.9735603332519531, -0.1732940673828125, -0.7009992599487305, 1.5597591400146484, 1.5094127655029297, 0.17804622650146484, -2.2133476734161377, -0.5857386589050293, 0.35174560546875, -0.2957344055175781, 0.4267442226409912, -0.0910654067993164, 0.6048984527587891, 0.07711362838745117, -0.11742782592773438, 0.5366942882537842, 0.41323232650756836, -4.60515022277832, -1.6338844299316406, -0.10647439956665039, -5.910357475280762, 10.786191940307617, 1.9533615112304688, 1.0406570434570312, 0.857177734375, -0.10306906700134277, 0.36464619636535645, -0.36383330821990967, 0.3722200393676758, 0.39332008361816406, -1.361532211303711, -6.942970275878906, 2.6334991455078125, -2.1096572875976562, 0.01901984214782715, -1.0588159561157227, -0.3321237564086914, 0.6151288151741028, -1.3268184661865234, -1.4657716751098633, -0.360459566116333, -1.1014633178710938, 0.48197174072265625, -5.298394203186035, -0.4999847412109375, -0.7687520980834961, 0.5754522085189819, 1.1488571166992188, -4.052029609680176, -0.41644859313964844, 0.7642545700073242, -2.8704276084899902, 2.035572052001953, -0.460662841796875, 0.8375301361083984, -1.1014633178710938, -7.04071044921875, -0.6565532684326172, 0.32720184326171875, 0.12376785278320312, 0.29961395263671875, -0.0017948150634765625, -0.5377392768859863, -0.92690110206604, 0.19857871532440186, 0.11560344696044922, -0.9802627563476562, 0.31487083435058594, -0.7899932861328125, -0.8370170593261719, -1.430673599243164, 0.5964603424072266, -1.1315040588378906, -0.4609794616699219, -0.03506278991699219, -1.2762870788574219, -0.8808317184448242, 1.2994804382324219, -0.712244987487793, 0.1428985595703125, 0.4601249694824219, 0.9270811080932617, -0.4801816940307617, -0.2470407485961914, -0.8189083337783813, 0.31800365447998047, -1.4662609100341797, -1.639388084411621, -0.179840087890625, -1.1309471130371094, -1.8910105228424072, -0.5569396018981934, -1.8101942539215088, -0.4933748245239258, 1.9212760925292969, -0.5299692153930664, 0.2720375061035156, -0.11138725280761719, -6.799684524536133, 1.3774185180664062, 1.1505584716796875, 0.5994799137115479, -1.1885108947753906, 0.9555492401123047, 0.9133138656616211, 0.16727828979492188, 0.32753753662109375, -1.2341985702514648, -7.601314544677734, 0.8871841430664062, 1.4150962829589844, 1.1914358139038086, 0.3679656982421875, -4.91826057434082, -0.3627885580062866, -0.7134647369384766, -7.425725936889648, 1.1937837600708008, -0.3180570602416992, 0.45389461517333984, -0.48808860778808594, -4.800678253173828, 10.786191940307617, 0.619555652141571, -1.2762870788574219, 0.3073768615722656, 1.2545909881591797, -0.6270866394042969, 0.26239967346191406, -0.46353965997695923, 0.16122746467590332, -1.9536595344543457, -0.2782402038574219, 0.96087646484375, 0.45349884033203125, 0.2519569396972656, 1.4327147006988525, -6.646245956420898, 1.1833477020263672, -0.2413015365600586, 2.243316650390625, -7.0300469398498535, 1.570948600769043, 5.678014755249023, -0.21105551719665527, 0.4137411117553711, -1.943131923675537, 1.1317138671875, -0.6095199584960938, 0.26091575622558594, -5.643872261047363, 0.5214939117431641, -0.09964752197265625, 2.1169776916503906, 0.020928621292114258, -6.060899257659912, -0.017495155334472656, -1.1989331245422363, -0.5383181571960449, 0.28888893127441406, -0.5819911956787109, -0.8333613872528076, 0.5509815216064453, 1.007150650024414, -1.107675552368164, 1.6012763977050781, -1.0125188827514648, 1.3940753936767578, -0.30797481536865234, -0.24890422821044922, -0.8559074401855469, 0.169769287109375, -1.2654590606689453, -2.157075881958008, -0.16608023643493652, 1.1327877044677734, -1.8190069198608398, 0.078125, 0.4310896396636963, -0.81817626953125, -5.005751609802246, 2.57183837890625, 2.8199424743652344, -0.38176441192626953, 5.678014755249023, 23.83665657043457, -9.62564468383789, -1.211540699005127, 0.5547313690185547, -0.23050308227539062, -0.6095199584960938, 1.4874401092529297, -1.2776732444763184, 0.4977731704711914, -0.667335033416748, -2.3127951622009277, 0.6870479583740234, 0.5067481994628906, 0.05699729919433594, 0.020928621292114258, -0.10603713989257812, 0.49988555908203125, -1.1750783920288086, 1.399911880493164, -0.019649505615234375, 1.350677490234375, 0.25931358337402344, 0.8730831146240234, -5.615621566772461, 1.3260936737060547, -2.181241989135742, -0.6525096893310547, 1.0153322219848633, -6.320129871368408, -1.0979514122009277, -0.7366625070571899, -1.2932095527648926, 1.4230327606201172, -0.2709493637084961, -0.8225746154785156, 0.0466461181640625, -1.355903148651123, -5.124500751495361, -1.2549858093261719, 0.4306201934814453, 0.14202332496643066, 0.21260297298431396, -0.6257619857788086, 3.3077917098999023, -1.6903467178344727, 0.3815269470214844, 1.799489974975586, 1.3371734619140625, -0.30889368057250977, 0.4391632080078125, 0.7259311676025391], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 44032, "num_env_steps_trained": 161520, "num_agent_steps_sampled": 44032, "num_agent_steps_trained": 161520, "last_target_update_ts": 44032, "num_target_updates": 85}, "sampler_results": {"episode_reward_max": 31.712017722427845, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -170.33470237717032, "episode_len_mean": 292.26, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125], "episode_lengths": [408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5200163948092295, "mean_inference_ms": 24.26378384157067, "mean_action_processing_ms": 0.13651045938845469, "mean_env_wait_ms": 4.200607932822836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 31.712017722427845, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -170.33470237717032, "episode_len_mean": 292.26, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-442.1455776616931, -330.4618988856673, -551.6457608342171, -425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125], "episode_lengths": [408, 373, 429, 416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5200163948092295, "mean_inference_ms": 24.26378384157067, "mean_action_processing_ms": 0.13651045938845469, "mean_env_wait_ms": 4.200607932822836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 44032, "num_agent_steps_trained": 161520, "num_env_steps_sampled": 44032, "num_env_steps_trained": 161520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 44032, "agent_timesteps_total": 44032, "timers": {"training_iteration_time_ms": 332.765, "learn_time_ms": 64.693, "learn_throughput": 3709.802, "synch_weights_time_ms": 21.289}, "counters": {"num_env_steps_sampled": 44032, "num_env_steps_trained": 161520, "num_agent_steps_sampled": 44032, "num_agent_steps_trained": 161520, "last_target_update_ts": 44032, "num_target_updates": 85}, "done": false, "episodes_total": 142, "training_iteration": 43, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-52", "timestamp": 1655478292, "time_this_iter_s": 5.463632583618164, "time_total_s": 225.70110726356506, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 225.70110726356506, "timesteps_since_restore": 0, "iterations_since_restore": 43, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 30.375, "ram_util_percent": 62.5125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.612232208251953, "min_q": -31.526596069335938, "max_q": 44.59451675415039, "mean_td_error": -0.24329419434070587}, "td_error": [-8.86395263671875, 0.2799825668334961, 0.6351890563964844, 0.57781982421875, 2.1409072875976562, 0.6623468399047852, 0.6377277374267578, -1.8875951766967773, 0.6118888854980469, 2.1583824157714844, 0.36463356018066406, 0.42141056060791016, 1.3971772193908691, -0.1698169708251953, -1.3324837684631348, 0.21527862548828125, 3.476926803588867, 1.4621734619140625, -0.8933610916137695, 0.45038604736328125, -7.349471092224121, 0.2168407440185547, -0.335052490234375, 1.184164047241211, 0.4014014005661011, 0.21595382690429688, -0.04254150390625, -0.3329887390136719, 1.7585601806640625, 0.9480080604553223, 0.1781158447265625, 0.5832531452178955, -1.8637886047363281, -0.45436954498291016, -0.4020271301269531, 0.9283514022827148, 0.09888076782226562, -0.36357688903808594, 1.5591049194335938, 0.21369552612304688, -0.674799919128418, 0.8113727569580078, -1.7857208251953125, -0.34061527252197266, -0.18494606018066406, -5.887432098388672, 0.5115756988525391, 0.4395294189453125, -1.0594711303710938, 1.0853824615478516, -2.7732887268066406, 0.19974517822265625, -0.18174171447753906, -0.7120733261108398, -0.26905250549316406, -0.3196749687194824, 2.4603519439697266, -0.4014854431152344, 0.3451118469238281, 1.0276603698730469, 0.21595382690429688, 1.1392159461975098, 0.1707448959350586, 0.15780258178710938, -0.7263202667236328, -1.1546850204467773, 0.9339733123779297, 2.2838973999023438, 0.46094799041748047, -4.814725875854492, -29.31511116027832, -0.02176189422607422, 1.487039566040039, 0.42374610900878906, -0.6684989929199219, -1.0817718505859375, 0.5341529846191406, -0.44712066650390625, 0.4526653289794922, -0.9008585214614868, 0.3145599365234375, -5.587135314941406, -11.277013778686523, 0.7146215438842773, -0.3601207733154297, 0.44530677795410156, 0.000152587890625, -0.08460617065429688, -5.10938835144043, 1.1392159461975098, -0.968010425567627, 1.4587631225585938, 0.2052469253540039, -0.859832763671875, 1.2890205383300781, -0.12630653381347656, -0.3610038757324219, 1.3701519966125488, 0.4174976348876953, 0.16470909118652344, -0.17342376708984375, -0.3888511657714844, -1.0448951721191406, -3.0657100677490234, -0.5876703262329102, 31.641080856323242, 0.6938934326171875, 9.128654479980469, -0.7734794616699219, 0.061163902282714844, -1.8949613571166992, 0.26746368408203125, 0.33719444274902344, 0.4784965515136719, 0.062201499938964844, 1.2923431396484375, 1.7539558410644531, 0.636244535446167, -1.4580268859863281, 0.26184844970703125, 0.7744169235229492, 0.3522777557373047, -0.7434568405151367, 0.6467084884643555, -0.12193107604980469, 0.13095331192016602, 0.48300743103027344, 0.18070030212402344, 1.029648780822754, -0.33181190490722656, 0.685645341873169, -0.9828920364379883, -1.4919509887695312, -1.0263748168945312, -0.05354499816894531, 2.1592044830322266, -1.2838947772979736, 0.9234247207641602, 2.1869475841522217, 0.8407163619995117, 0.6392860412597656, -0.18671584129333496, 0.30155372619628906, -1.081502914428711, 0.9390380382537842, -2.4887514114379883, 0.7734012603759766, -0.13642191886901855, 0.31139564514160156, 0.28533387184143066, 1.222513198852539, -0.36547183990478516, -0.2725515365600586, -0.5123195648193359, -2.0687904357910156, -0.45290541648864746, 1.2520771026611328, -0.8095550537109375, 0.8844375610351562, 2.0674972534179688, -0.14688682556152344, -0.441619873046875, -0.40358924865722656, -8.62185287475586, -7.4779205322265625, 0.3783721923828125, 0.2171640396118164, 0.018082261085510254, 1.8354344367980957, 1.450605869293213, -0.7026700973510742, 1.1453180313110352, -0.13858604431152344, -0.5618267059326172, -3.132054328918457, 0.8375740051269531, -2.2420034408569336, -0.22964096069335938, 0.46566200256347656, 0.5098857879638672, 0.5804271697998047, 0.050719261169433594, -0.06498527526855469, -1.1235198974609375, 0.018082261085510254, 0.16874265670776367, -0.9141063690185547, 0.2096271514892578, 0.9988412857055664, 0.42167091369628906, -0.17844676971435547, -6.49781608581543, 0.8133049011230469, 0.38967132568359375, 0.3142242431640625, 0.05712127685546875, 0.5562810897827148, 0.4890861511230469, 0.8787498474121094, 1.8629097938537598, 1.1208086013793945, 1.5183391571044922, 0.2317028045654297, 1.8450055122375488, 0.5915756225585938, 0.9219908714294434, -0.4689359664916992, -0.3672027587890625, -0.1549816131591797, -0.14457130432128906, 0.6092166900634766, -0.5318927764892578, 0.8945045471191406, 1.1942329406738281, 0.5676641464233398, 1.886031150817871, 0.00396728515625, 0.41317176818847656, 0.7795524597167969, 0.8421077728271484, -12.313247680664062, -19.82290267944336, 0.8556156158447266, -0.5619850158691406, -0.25675392150878906, 0.9691133499145508, -6.718606948852539, 2.0116989612579346, 0.5842781066894531, -0.22446823120117188, 1.8103179931640625, -1.1221504211425781, 0.060703277587890625, -0.2747631072998047, -0.06465911865234375, -0.8909587860107422, -2.128445625305176, 0.0772562026977539, -0.3309793472290039, 0.8280735015869141], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 45056, "num_env_steps_trained": 165360, "num_agent_steps_sampled": 45056, "num_agent_steps_trained": 165360, "last_target_update_ts": 45056, "num_target_updates": 87}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -156.32400873295964, "episode_len_mean": 286.13, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452], "episode_lengths": [416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5207810596270971, "mean_inference_ms": 24.28711638805187, "mean_action_processing_ms": 0.13619501487191304, "mean_env_wait_ms": 4.206150752732787, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -689.8274445533752, "episode_reward_mean": -156.32400873295964, "episode_len_mean": 286.13, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-425.07802380621433, -442.3541087806225, -689.8274445533752, -80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452], "episode_lengths": [416, 423, 450, 268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5207810596270971, "mean_inference_ms": 24.28711638805187, "mean_action_processing_ms": 0.13619501487191304, "mean_env_wait_ms": 4.206150752732787, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 45056, "num_agent_steps_trained": 165360, "num_env_steps_sampled": 45056, "num_env_steps_trained": 165360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 45056, "agent_timesteps_total": 45056, "timers": {"training_iteration_time_ms": 317.965, "learn_time_ms": 63.773, "learn_throughput": 3763.342, "synch_weights_time_ms": 20.005}, "counters": {"num_env_steps_sampled": 45056, "num_env_steps_trained": 165360, "num_agent_steps_sampled": 45056, "num_agent_steps_trained": 165360, "last_target_update_ts": 45056, "num_target_updates": 87}, "done": false, "episodes_total": 145, "training_iteration": 44, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-04-58", "timestamp": 1655478298, "time_this_iter_s": 5.0786426067352295, "time_total_s": 230.7797498703003, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 230.7797498703003, "timesteps_since_restore": 0, "iterations_since_restore": 44, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 29.675, "ram_util_percent": 62.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.434114456176758, "min_q": -31.704036712646484, "max_q": 42.81523895263672, "mean_td_error": 0.2948431670665741}, "td_error": [0.6376762390136719, 0.27931880950927734, 1.6625862121582031, 0.4867258071899414, 0.18854427337646484, 1.117828369140625, 0.9102926254272461, -0.28367042541503906, 1.117635726928711, 1.402968406677246, 1.2286949157714844, 0.1230463981628418, 0.20970773696899414, 1.2270393371582031, 2.037032127380371, 2.7840538024902344, -0.18205928802490234, -0.33458805084228516, 1.8532238006591797, 1.0811958312988281, 0.22817230224609375, 0.7940788269042969, -1.670152187347412, 0.8957099914550781, 0.8606510162353516, 1.5739078521728516, -0.8391590118408203, -0.25426673889160156, -1.9017775058746338, 0.9961738586425781, 0.4136772155761719, 1.4129996299743652, 1.1461906433105469, -0.7093391418457031, 3.0140933990478516, -0.47672462463378906, -0.8155994415283203, -6.617855072021484, 0.22725868225097656, -0.03732943534851074, 0.8480243682861328, -0.2590970993041992, -0.15191078186035156, 0.08628082275390625, 0.7188689708709717, -0.4441204071044922, -0.39769935607910156, 12.501726150512695, -0.7449159622192383, 0.8606510162353516, 1.4528312683105469, 1.413787841796875, -0.4720144271850586, 1.7928285598754883, 1.5696735382080078, 2.7836227416992188, 0.7260570526123047, 3.3580455780029297, 0.4993705749511719, 0.5779495239257812, -6.443449974060059, 0.3524971008300781, 1.0775871276855469, -0.8889923095703125, 0.2551441192626953, 8.151930809020996, 0.30095863342285156, -0.7678127288818359, -1.3206148147583008, -6.241111755371094, -0.373380184173584, 0.7617502212524414, -0.7187986373901367, -0.8372173309326172, 1.2400531768798828, 0.42247772216796875, -0.7322206497192383, -8.752883911132812, -1.0184803009033203, -0.8627743721008301, 0.48158979415893555, 0.8748079538345337, -7.359723091125488, 0.3408699035644531, -0.31357574462890625, -2.7822799682617188, 4.891883850097656, -0.7645788192749023, 0.6028447151184082, -0.011165618896484375, 0.38329601287841797, 2.5998616218566895, 0.10041618347167969, 0.30074405670166016, 1.1006221771240234, 0.5103130340576172, 0.09126853942871094, 0.5175777673721313, -0.2897205352783203, -0.46997737884521484, 0.3998093605041504, 1.0625934600830078, 0.6301603317260742, 1.1027107238769531, -1.3529415130615234, -0.21736526489257812, 0.3499774932861328, 0.14482975006103516, -0.1927098035812378, -0.8789892196655273, 2.449887752532959, 0.861520528793335, -0.22811222076416016, 0.48706722259521484, 0.2745380401611328, 2.0307798385620117, -0.27703857421875, -0.7317237854003906, -6.794760704040527, 0.03575897216796875, -1.365687370300293, 0.048954010009765625, -0.04836273193359375, 1.9447593688964844, -5.386680603027344, -6.4448041915893555, 2.341777801513672, 2.948465347290039, -0.5298957824707031, 0.5501315593719482, -6.326019287109375, 1.0510749816894531, 2.4293737411499023, 0.12602901458740234, 0.4100303649902344, 1.6208724975585938, 0.03477668762207031, -0.5206851959228516, 0.7529106140136719, -0.010618209838867188, -4.307886123657227, -8.18185806274414, -0.27503013610839844, -2.071392059326172, 0.7188689708709717, 1.8848533630371094, 1.3020572662353516, 0.7052583694458008, -0.196075439453125, 0.9246501922607422, 0.7590274810791016, 0.9283905029296875, 1.2664337158203125, 1.7362632751464844, 2.356382369995117, 0.8705809116363525, 2.425534248352051, 0.9533500671386719, -11.023260116577148, 0.4473590850830078, -5.021481990814209, 0.9506664276123047, 0.15076112747192383, 0.16165614128112793, 1.0448169708251953, -0.8417491912841797, 0.2223672866821289, 1.472921371459961, -0.7775745391845703, 0.4023122787475586, 1.3634471893310547, 1.8534832000732422, 1.3026766777038574, -1.1905174255371094, 0.7402687072753906, 1.3636913299560547, 0.9077854156494141, 3.820659875869751, 0.18854427337646484, 0.9704399108886719, 1.009134292602539, 2.9198923110961914, 0.40478515625, 0.16842079162597656, 1.7909603118896484, 0.9228324890136719, 2.8205814361572266, -0.6453342437744141, -0.3394012451171875, 0.7280845642089844, 0.7808569073677063, 0.10372543334960938, 0.8405933380126953, 0.038269996643066406, -0.4074568748474121, -0.263916015625, 1.1329593658447266, 0.08873367309570312, 0.17937803268432617, 0.7113533020019531, 1.3314294815063477, -8.335195541381836, -1.5601177215576172, 0.20107746124267578, 0.7568225860595703, 1.0837273597717285, 26.6419734954834, 0.15294265747070312, -5.1187896728515625, 1.4289627075195312, 0.6762895584106445, -0.3919200897216797, 1.1668291091918945, 1.0811567306518555, 1.2286949157714844, 0.10067176818847656, 1.2867298126220703, 1.6616783142089844, 0.578460693359375, 1.134368896484375, 0.42441368103027344, 1.89794921875, -0.00360107421875, -1.5178298950195312, 0.7402553558349609, 1.2481765747070312, 2.3526363372802734, 0.9077854156494141, 1.1788135766983032, 0.3520064353942871, 0.9058537483215332, 0.7929801940917969, 0.41943359375, 0.3490581512451172, -0.12116527557373047, 2.0628957748413086, -0.04942512512207031, 0.8508186340332031, 0.011923789978027344, -0.13960152864456177], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 46080, "num_env_steps_trained": 169200, "num_agent_steps_sampled": 46080, "num_agent_steps_trained": 169200, "last_target_update_ts": 46080, "num_target_updates": 89}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -143.3208332902193, "episode_len_mean": 280.98, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237], "episode_lengths": [268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5220103712634017, "mean_inference_ms": 24.32671039773093, "mean_action_processing_ms": 0.13610806467104003, "mean_env_wait_ms": 4.218380308678509, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -143.3208332902193, "episode_len_mean": 280.98, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-80.37763653695583, -377.5831349045038, -338.35437013953924, -145.38038479536772, -44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237], "episode_lengths": [268, 392, 358, 302, 263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5220103712634017, "mean_inference_ms": 24.32671039773093, "mean_action_processing_ms": 0.13610806467104003, "mean_env_wait_ms": 4.218380308678509, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 46080, "num_agent_steps_trained": 169200, "num_env_steps_sampled": 46080, "num_env_steps_trained": 169200, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 46080, "agent_timesteps_total": 46080, "timers": {"training_iteration_time_ms": 338.938, "learn_time_ms": 65.869, "learn_throughput": 3643.613, "synch_weights_time_ms": 20.984}, "counters": {"num_env_steps_sampled": 46080, "num_env_steps_trained": 169200, "num_agent_steps_sampled": 46080, "num_agent_steps_trained": 169200, "last_target_update_ts": 46080, "num_target_updates": 89}, "done": false, "episodes_total": 148, "training_iteration": 45, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-03", "timestamp": 1655478303, "time_this_iter_s": 5.439502239227295, "time_total_s": 236.2192521095276, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 236.2192521095276, "timesteps_since_restore": 0, "iterations_since_restore": 45, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 38.25, "ram_util_percent": 62.95}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.180780410766602, "min_q": -31.279052734375, "max_q": 41.02391815185547, "mean_td_error": 0.1702224314212799}, "td_error": [-0.32962608337402344, 0.8087177276611328, 1.7259225845336914, 0.6288013458251953, 1.0960218906402588, 1.750253677368164, -9.484646797180176, 0.6236748695373535, 0.3123893737792969, 7.3524169921875, -6.95008659362793, 1.666031837463379, -7.191071510314941, 0.11434268951416016, -0.442840576171875, -1.2193284034729004, 0.8211336135864258, -0.41794395446777344, -0.04174923896789551, -0.3526296615600586, -0.6506152153015137, 0.8211336135864258, 3.2869768142700195, 2.743896484375, 2.574172258377075, 2.154447555541992, 0.9464387893676758, 3.137747287750244, 1.933215618133545, -11.684456825256348, -1.4394168853759766, 1.7096071243286133, 3.9288575649261475, -0.16409921646118164, 1.8824968338012695, 0.26781731843948364, -0.1609210968017578, -0.7079343795776367, 0.16900634765625, -9.713024139404297, -0.7579784393310547, 0.18530845642089844, 0.1268763542175293, 0.5308151245117188, 0.19583892822265625, 0.03960990905761719, -0.3606548309326172, 1.606612205505371, -3.8594837188720703, -0.8945941925048828, 0.9794807434082031, 1.3567602634429932, 0.8290290832519531, -0.7261905670166016, -0.2095658779144287, 0.24466466903686523, -1.500143051147461, -0.20052719116210938, 1.0704526901245117, 1.1837987899780273, 0.7917976379394531, 1.1299018859863281, 0.7868633270263672, 1.557424545288086, -1.3549842834472656, 0.6382980346679688, -0.959099292755127, 0.6585178375244141, -0.4782381057739258, -0.5058708190917969, 2.6729798316955566, -0.28493499755859375, 7.204678535461426, 2.172534942626953, 1.6238956451416016, 4.003007888793945, 0.19453811645507812, -0.11280035972595215, 0.4512290954589844, 0.6658267974853516, -3.9845752716064453, -5.416340351104736, -2.6931424140930176, -0.888035774230957, 1.0572829246520996, 0.9073143005371094, -1.6957712173461914, 1.1299018859863281, 1.306107521057129, -8.6641263961792, -0.3745899200439453, 1.6620888710021973, 1.0609389543533325, 0.2541685104370117, 1.1787939071655273, -0.2592334747314453, -4.655853271484375, 0.540553092956543, -1.0341663360595703, 0.7872829437255859, 1.4876933097839355, -5.493522644042969, 0.8238582611083984, 1.0810468196868896, -0.08372807502746582, 2.459244728088379, 0.3114185333251953, 2.5419862270355225, 0.6949710845947266, 0.31862640380859375, 0.7360076904296875, 0.7737922668457031, -0.30857276916503906, -0.09211921691894531, 0.3156852722167969, -0.976597785949707, 3.245807647705078, 1.3483686447143555, 0.6431560516357422, 1.933215618133545, -0.4480900764465332, 0.4277477264404297, -0.10458755493164062, -0.1671733856201172, -1.0775136947631836, -1.3117561340332031, 0.8268260955810547, -0.5262336730957031, -0.055226802825927734, 0.5274486541748047, 1.4741783142089844, 1.180572509765625, 2.4417991638183594, -0.7193069458007812, 1.9836584329605103, -0.93280029296875, -1.088437795639038, 1.4538936614990234, -2.454254150390625, -3.3288021087646484, 0.19009017944335938, -0.3914046287536621, 0.4535999298095703, -0.4108848571777344, 0.7088327407836914, 0.21781349182128906, -0.2580986022949219, 1.1760258674621582, -0.5179266929626465, -0.15224838256835938, 0.20455074310302734, 0.23769569396972656, 0.5791301727294922, 0.8533611297607422, 0.9720077514648438, 0.2617969512939453, -0.2447509765625, 2.4821043014526367, 1.347238540649414, 1.440511703491211, 0.3697071075439453, -1.8418102264404297, -0.47891807556152344, 4.683291435241699, 0.6197929382324219, 1.0994739532470703, 0.29978036880493164, 1.552091121673584, 1.4105033874511719, 0.9935417175292969, -0.9508914947509766, 1.0541648864746094, 0.6894989013671875, 1.330225944519043, -0.048862457275390625, 0.817378044128418, -0.761326789855957, 0.8981336951255798, 1.0684428215026855, 0.5403594970703125, -0.243499755859375, 0.8956813812255859, 0.7557430267333984, 0.1167449951171875, -0.10228347778320312, -9.145023345947266, 0.21689414978027344, 0.9402008056640625, 5.458492279052734, -0.42021942138671875, -0.6284451484680176, 1.844484567642212, -0.6193723678588867, -2.2417678833007812, 1.2501411437988281, 0.16900634765625, -0.7892646789550781, -1.9294792413711548, 1.0252552032470703, 1.8975257873535156, -0.10053825378417969, -0.006256103515625, 1.156050205230713, -1.2137680053710938, -8.774343490600586, 0.9632501602172852, 0.9412204027175903, 0.5429668426513672, 1.734161376953125, -0.10309410095214844, 0.8245468139648438, 1.5837430953979492, 1.2245445251464844, -0.29425048828125, -2.101015090942383, 1.0925464630126953, 14.280831336975098, 1.1264171600341797, 1.3298215866088867, 0.10528564453125, -0.5805654525756836, 0.7954273223876953, -0.6231003403663635, -4.430694580078125, 0.4388542175292969, -0.13936805725097656, 0.6100997924804688, 0.6249160766601562, -2.179487466812134, 0.19031333923339844, 0.988037109375, 2.2005820274353027, 0.9571771621704102, 0.3975677490234375, 0.03964424133300781, 1.634786605834961, 0.3975677490234375, 0.39936113357543945, 0.697252631187439, 0.8963699340820312], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 47104, "num_env_steps_trained": 173040, "num_agent_steps_sampled": 47104, "num_agent_steps_trained": 173040, "last_target_update_ts": 47104, "num_target_updates": 91}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -133.57276264451446, "episode_len_mean": 276.5, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196], "episode_lengths": [263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5222128016943248, "mean_inference_ms": 24.374790261454642, "mean_action_processing_ms": 0.13634362713128223, "mean_env_wait_ms": 4.219582148352708, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -133.57276264451446, "episode_len_mean": 276.5, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-44.37078330665827, -431.4433360695839, -351.590890198946, -307.2340023070574, -208.35756296664476, -106.84692806005478, -302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196], "episode_lengths": [263, 379, 372, 341, 315, 278, 351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5222128016943248, "mean_inference_ms": 24.374790261454642, "mean_action_processing_ms": 0.13634362713128223, "mean_env_wait_ms": 4.219582148352708, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 47104, "num_agent_steps_trained": 173040, "num_env_steps_sampled": 47104, "num_env_steps_trained": 173040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 47104, "agent_timesteps_total": 47104, "timers": {"training_iteration_time_ms": 352.232, "learn_time_ms": 64.17, "learn_throughput": 3740.049, "synch_weights_time_ms": 21.289}, "counters": {"num_env_steps_sampled": 47104, "num_env_steps_trained": 173040, "num_agent_steps_sampled": 47104, "num_agent_steps_trained": 173040, "last_target_update_ts": 47104, "num_target_updates": 91}, "done": false, "episodes_total": 152, "training_iteration": 46, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-09", "timestamp": 1655478309, "time_this_iter_s": 5.4653918743133545, "time_total_s": 241.68464398384094, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 241.68464398384094, "timesteps_since_restore": 0, "iterations_since_restore": 46, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 38.6875, "ram_util_percent": 62.9875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 13.269231796264648, "min_q": -28.752222061157227, "max_q": 36.74455261230469, "mean_td_error": -0.4396582245826721}, "td_error": [0.4094966650009155, 0.10347938537597656, -0.51214599609375, 0.45712852478027344, -6.148959159851074, 0.27271270751953125, -0.6377925872802734, 0.7107334136962891, 1.5428352355957031, -0.18343544006347656, -4.256372451782227, -0.3636817932128906, 0.37992286682128906, -2.7194385528564453, 0.46590232849121094, -1.0125975608825684, -0.7634273767471313, -0.9871768951416016, -0.407224178314209, -0.4533557891845703, -0.1665668487548828, -0.2829723358154297, -0.772303581237793, -6.794246673583984, -0.7423324584960938, -1.1386785507202148, 0.39032745361328125, 1.7259759902954102, -0.36639928817749023, 1.467818260192871, 0.20633697509765625, -4.409239768981934, -0.3694648742675781, -0.34200572967529297, -0.11540603637695312, 0.3393564224243164, -2.28214168548584, -0.14397048950195312, -1.5655174255371094, 0.15137672424316406, 0.7027567625045776, 1.0141887664794922, 2.682466506958008, -2.8158369064331055, -0.07456684112548828, -0.1226959228515625, 0.2357311248779297, -0.44612979888916016, -0.49285221099853516, -0.6628456115722656, 0.28348445892333984, -0.22085189819335938, -0.43971824645996094, 1.259352684020996, 0.4437580108642578, -0.8185529708862305, -0.9035587310791016, -0.8803844451904297, -0.7711124420166016, 0.13126373291015625, 0.11595726013183594, 2.264009714126587, 1.975898265838623, -0.3662240505218506, -2.438831329345703, -0.026220321655273438, -0.6958815455436707, -1.6956291198730469, -2.804457664489746, 1.908590316772461, -10.469001770019531, -0.19830560684204102, 2.081270217895508, -0.6958815455436707, -0.09763574600219727, 1.3641128540039062, 1.8636994361877441, 0.027896881103515625, -1.0468025207519531, 1.2954349517822266, -1.1162800788879395, -0.8812942504882812, -0.6337699890136719, -0.8443584442138672, -0.2353343963623047, -1.4022026062011719, -1.4658031463623047, -6.949954986572266, -1.19573974609375, -0.2215709686279297, -0.45685386657714844, -0.7431545257568359, -6.783658981323242, -1.1709480285644531, -0.6625099182128906, 0.09963387250900269, -0.22671127319335938, -0.5939931869506836, -0.40097570419311523, -2.1978511810302734, -1.3586435317993164, 0.28931665420532227, 0.7540817260742188, -0.7470493316650391, -8.576217651367188, -0.46178674697875977, -0.508636474609375, -2.472620964050293, -0.2845888137817383, -0.8352041244506836, 0.6193017959594727, 2.4132235050201416, -0.45487213134765625, -1.2223663330078125, -6.142091751098633, 0.28644371032714844, -0.03360128402709961, 0.4920363426208496, -0.42075061798095703, -0.16754209995269775, -2.6943111419677734, 0.0937952995300293, -0.4584484100341797, -0.16220951080322266, 0.4527597427368164, 0.21151041984558105, -0.8128013610839844, -0.9017667770385742, 0.2482452392578125, 0.07529449462890625, -0.5067472457885742, -0.9811420440673828, 0.7851963043212891, -0.7511711120605469, -0.6795616149902344, -1.5944827795028687, -0.4560413360595703, -0.0660867691040039, -0.5747900009155273, 0.6595979332923889, 0.6009550094604492, -0.015292167663574219, -0.1685199737548828, 0.5033187866210938, -0.3003349304199219, -0.050086021423339844, 0.45483875274658203, -0.3777122497558594, -0.3992128372192383, 25.09964942932129, -0.6701865196228027, -1.0071415901184082, 0.7018623352050781, 1.6934032440185547, -0.6332647800445557, -1.1482009887695312, -0.2365267127752304, -6.183356285095215, 0.3908610939979553, 1.5704494714736938, -0.563201904296875, -0.10199832916259766, 0.013697408139705658, -3.379535675048828, 0.8457775115966797, -0.40610313415527344, -1.5573921203613281, 0.21104049682617188, 1.3510346412658691, -9.412263870239258, -0.1437835693359375, -1.4194660186767578, 0.2449805736541748, 1.1099777221679688, -0.4779224395751953, -0.7885208129882812, 0.974425733089447, 0.6779975891113281, -0.6818351745605469, -0.429351806640625, -0.39104461669921875, -1.1521635055541992, 0.2303018569946289, 0.11597347259521484, -0.5580406188964844, 2.7114076614379883, 0.2091512680053711, -1.44073486328125, 0.7917032241821289, -0.3561439514160156, -1.2142820358276367, -1.6340632438659668, 0.2470231056213379, -0.7082805633544922, 0.2551565170288086, 0.3677835464477539, -0.575108528137207, -1.099639892578125, 0.8786077499389648, -1.5977096557617188, 1.5417289733886719, -8.416085243225098, -0.36010169982910156, -0.8440074920654297, -0.03806781768798828, -0.31350135803222656, 0.5083942413330078, 0.02204132080078125, -1.1097898483276367, -0.3890266418457031, 0.34409332275390625, -0.5392951965332031, -1.320343017578125, -4.103271484375, 7.9474196434021, -0.003612518310546875, -0.3295440673828125, 0.18388843536376953, -0.35732364654541016, 1.5595073699951172, 1.420029640197754, 11.558602333068848, -2.2799739837646484, -1.053466796875, -1.0295319557189941, 1.0843772888183594, -1.8702092170715332, -5.261913299560547, -2.0162391662597656, 0.019184112548828125, -1.032679557800293, 0.13909530639648438, 0.36118125915527344, -1.992325782775879, -0.20548248291015625, -0.6701865196228027, -1.2216720581054688, 1.065119743347168, -1.6639004945755005, -1.94842529296875], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 48128, "num_env_steps_trained": 176880, "num_agent_steps_sampled": 48128, "num_agent_steps_trained": 176880, "last_target_update_ts": 48128, "num_target_updates": 93}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -125.39185421474278, "episode_len_mean": 272.72, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827], "episode_lengths": [351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5237857396448685, "mean_inference_ms": 24.4277796227885, "mean_action_processing_ms": 0.13606220352697307, "mean_env_wait_ms": 4.227084676940151, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -125.39185421474278, "episode_len_mean": 272.72, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-302.53549482673407, -328.49774257838726, -418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827], "episode_lengths": [351, 354, 369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5237857396448685, "mean_inference_ms": 24.4277796227885, "mean_action_processing_ms": 0.13606220352697307, "mean_env_wait_ms": 4.227084676940151, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 48128, "num_agent_steps_trained": 176880, "num_env_steps_sampled": 48128, "num_env_steps_trained": 176880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 48128, "agent_timesteps_total": 48128, "timers": {"training_iteration_time_ms": 351.51, "learn_time_ms": 63.536, "learn_throughput": 3777.373, "synch_weights_time_ms": 20.599}, "counters": {"num_env_steps_sampled": 48128, "num_env_steps_trained": 176880, "num_agent_steps_sampled": 48128, "num_agent_steps_trained": 176880, "last_target_update_ts": 48128, "num_target_updates": 93}, "done": false, "episodes_total": 158, "training_iteration": 47, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-15", "timestamp": 1655478315, "time_this_iter_s": 5.562318801879883, "time_total_s": 247.24696278572083, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 247.24696278572083, "timesteps_since_restore": 0, "iterations_since_restore": 47, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.5, "ram_util_percent": 63.087500000000006}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.379941940307617, "min_q": -34.7537956237793, "max_q": 46.82003402709961, "mean_td_error": -0.534075140953064}, "td_error": [0.4697074890136719, -6.581717491149902, -0.7532882690429688, 2.2789554595947266, 1.1313400268554688, -1.4511451721191406, 1.2335395812988281, 11.414828300476074, 0.133941650390625, -0.14791655540466309, -1.5459957122802734, 0.020370125770568848, 0.12384414672851562, 0.8723230361938477, -1.688368320465088, -2.8351211547851562, 1.8308849334716797, 1.002213478088379, 1.6207599639892578, -3.898164749145508, 0.2897467613220215, 1.2479362487792969, 0.48690032958984375, -2.075786590576172, -2.774099349975586, 0.10578536987304688, -0.6703834533691406, -2.105008125305176, -0.9089469909667969, -2.940204620361328, -2.2614612579345703, 0.9812321662902832, 0.38182830810546875, 2.331510543823242, -2.2562482357025146, 0.07417678833007812, 1.6772089004516602, -1.8430681228637695, -1.3662991523742676, 0.4679412841796875, -2.06915283203125, -1.273639440536499, 10.150269508361816, 0.36431217193603516, -0.11959266662597656, 0.1057281494140625, 1.9600071907043457, 0.6747016906738281, -1.6830530166625977, 0.09118413925170898, -0.5552520751953125, -1.347452163696289, -0.5912766456604004, -1.1447830200195312, -2.5767669677734375, -0.1581592559814453, 1.0866050720214844, 0.10958480834960938, -0.6514930725097656, 0.30062103271484375, -2.125711441040039, -1.2948718070983887, -0.1378936767578125, -0.25559234619140625, 0.1814720630645752, -2.8664379119873047, -0.7394447326660156, 0.48431396484375, -1.6238975524902344, -1.9303812980651855, 3.2800755500793457, -2.506204605102539, -1.3273272514343262, 0.8914666175842285, 0.023112773895263672, 0.7584648132324219, -1.7443981170654297, 1.6866378784179688, -3.578784942626953, 4.527971267700195, 0.9132317304611206, -0.15587139129638672, -9.808624267578125, 0.3886260986328125, 1.0955543518066406, 0.025712966918945312, 13.1964111328125, 0.29061365127563477, 2.885300636291504, -1.2511062622070312, -5.268017768859863, -0.28182125091552734, -0.18148231506347656, -0.2112865447998047, 0.153167724609375, 0.9353523254394531, -2.3129730224609375, 0.45312023162841797, 0.41230297088623047, 0.747711181640625, -0.2820930480957031, -1.9783077239990234, 1.4669609069824219, 0.17773056030273438, -1.5404472351074219, -1.309417724609375, -0.6055755615234375, 0.2534751892089844, 0.02454376220703125, -0.37206268310546875, -1.3816699981689453, -1.6020240783691406, 2.4285097122192383, -0.8177003860473633, -1.3831100463867188, -1.9537935256958008, -1.3010835647583008, -1.5828208923339844, 0.16886496543884277, 0.04554939270019531, -0.5375194549560547, 0.4915657043457031, 0.17120933532714844, -5.390354156494141, -0.9059457778930664, -0.9398201704025269, -0.3144817352294922, 0.19659996032714844, -1.9708232879638672, 1.6335124969482422, 0.25168800354003906, 0.3665504455566406, -0.7122955322265625, -2.1668319702148438, -6.776508331298828, -3.8856208324432373, 0.3351011276245117, -0.4035377502441406, -0.6544380187988281, 0.8860816955566406, -11.448763847351074, -1.2447385787963867, -2.082636833190918, -0.6322040557861328, -1.1209335327148438, 4.655965805053711, 1.0606403350830078, -7.60763692855835, 0.20335769653320312, -0.18763160705566406, 1.5360603332519531, -0.5875759124755859, -0.6147689819335938, 0.06434822082519531, -0.023736953735351562, -5.301448822021484, 0.4567298889160156, -0.7615985870361328, -1.5945624113082886, -0.07578468322753906, 0.19291114807128906, -0.7165451049804688, -0.9788923263549805, -1.9097633361816406, -1.4389969110488892, -2.2351207733154297, 0.025423049926757812, -0.46149444580078125, 0.2096099853515625, -2.3119964599609375, -1.7466511726379395, 17.544086456298828, 0.45253562927246094, -9.384668350219727, -2.203948974609375, -1.044137954711914, -9.532790184020996, -1.0005149841308594, 0.7052164077758789, 0.1822490692138672, 0.17152023315429688, -0.4254751205444336, 0.2146390676498413, -0.006771087646484375, 0.6814193725585938, -12.004913330078125, -0.7820196151733398, -0.35800933837890625, 1.7355499267578125, 0.30979347229003906, -1.3568134307861328, 0.8838634490966797, -2.0082530975341797, 0.8429737091064453, -0.34288787841796875, -1.7158241271972656, 0.6026859283447266, 0.7636623382568359, 1.2425618171691895, -8.682487487792969, -0.0033416748046875, -1.2196998596191406, 1.0336151123046875, 1.6040802001953125, -1.7326240539550781, -0.1694812774658203, 1.013082504272461, -0.5282516479492188, -0.09283447265625, -0.43706846237182617, 0.6256165504455566, -0.6199979782104492, 0.032733917236328125, -0.35690879821777344, -1.7266082763671875, 0.39173316955566406, 3.127368927001953, -3.1904945373535156, 0.322235107421875, -0.5912766456604004, 18.492643356323242, -0.29839324951171875, -0.014499902725219727, 0.148406982421875, 0.07608890533447266, -0.6431703567504883, 4.2204484939575195, -0.5719442367553711, 1.4624767303466797, 0.5254068374633789, -10.645703315734863, 0.4290165901184082, -3.1720495223999023, 0.4290165901184082, -1.286665439605713, -26.587696075439453, -0.6044807434082031, -0.3428354263305664, -2.597796678543091, -0.08729171752929688], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 49152, "num_env_steps_trained": 180720, "num_agent_steps_sampled": 49152, "num_agent_steps_trained": 180720, "last_target_update_ts": 49152, "num_target_updates": 95}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -120.92058168180287, "episode_len_mean": 271.31, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285], "episode_lengths": [369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5243665301161109, "mean_inference_ms": 24.433830982071253, "mean_action_processing_ms": 0.1360135931928976, "mean_env_wait_ms": 4.229536162904685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -510.03362162411213, "episode_reward_mean": -120.92058168180287, "episode_len_mean": 271.31, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-418.7762817069888, 2.4343045204877853, -224.19227228313684, -510.03362162411213, -23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285], "episode_lengths": [369, 249, 319, 386, 261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5243665301161109, "mean_inference_ms": 24.433830982071253, "mean_action_processing_ms": 0.1360135931928976, "mean_env_wait_ms": 4.229536162904685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 49152, "num_agent_steps_trained": 180720, "num_env_steps_sampled": 49152, "num_env_steps_trained": 180720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 49152, "agent_timesteps_total": 49152, "timers": {"training_iteration_time_ms": 324.19, "learn_time_ms": 64.891, "learn_throughput": 3698.535, "synch_weights_time_ms": 20.514}, "counters": {"num_env_steps_sampled": 49152, "num_env_steps_trained": 180720, "num_agent_steps_sampled": 49152, "num_agent_steps_trained": 180720, "last_target_update_ts": 49152, "num_target_updates": 95}, "done": false, "episodes_total": 160, "training_iteration": 48, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-20", "timestamp": 1655478320, "time_this_iter_s": 5.141999006271362, "time_total_s": 252.3889617919922, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 252.3889617919922, "timesteps_since_restore": 0, "iterations_since_restore": 48, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.05714285714286, "ram_util_percent": 63.214285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.05997085571289, "min_q": -36.54829788208008, "max_q": 42.42312240600586, "mean_td_error": -0.22044380009174347}, "td_error": [0.05012321472167969, 0.7808213233947754, -0.31163597106933594, 0.19368553161621094, -6.785367965698242, -0.98272705078125, -0.48830223083496094, -6.968688011169434, 0.6864700317382812, 0.1020355224609375, 0.10811233520507812, -1.3726615905761719, 0.7262554168701172, -1.029409408569336, -1.3409134149551392, 0.2541332244873047, 0.3226776123046875, 0.5591220855712891, 0.028825044631958008, -1.1791744232177734, 0.01595449447631836, 1.3803062438964844, -0.843719482421875, 0.4614410400390625, -0.14755797386169434, 1.0161867141723633, -8.434807777404785, -0.1734333038330078, -2.831787586212158, 1.019113540649414, -1.7285957336425781, 0.12409400939941406, -0.5078258514404297, 0.08376121520996094, 0.06653976440429688, -2.907830238342285, -1.3612022399902344, -1.1568870544433594, 0.3983893394470215, -0.08184814453125, -1.4505081176757812, -1.8688135147094727, -0.8919329643249512, -1.1464989185333252, -0.21390914916992188, -0.3211231231689453, 1.1154565811157227, 1.226111888885498, 1.8002586364746094, -5.360691070556641, 0.018550872802734375, 0.6803321838378906, 0.2952079772949219, 0.16637611389160156, -0.6080341339111328, -0.0582122802734375, 0.4907264709472656, -0.9124355316162109, 0.1679248809814453, -0.2145366668701172, -1.355630874633789, 0.6533699035644531, 6.079619407653809, -0.6063919067382812, 0.03553009033203125, -1.3032007217407227, -0.13205432891845703, -0.3628377914428711, -0.5526378154754639, -3.181893825531006, 26.234222412109375, 1.0511999130249023, -0.9987154006958008, 0.8533496856689453, 0.5295562744140625, -0.10065793991088867, -0.40950965881347656, -0.7047476768493652, -1.2049150466918945, 1.1965465545654297, 0.9892911911010742, 0.10259532928466797, 0.9954071044921875, -1.1918072700500488, 1.8985595703125, 0.38837432861328125, -0.38397979736328125, 0.9033751487731934, 0.7672996520996094, -1.7574739456176758, 0.6335029602050781, -0.3872261047363281, -1.2467594146728516, 0.28791046142578125, -0.4570331573486328, -5.6789703369140625, -0.3769564628601074, -0.7248344421386719, 0.4755744934082031, -1.3139246702194214, -0.3282790184020996, 0.028825044631958008, -0.06870746612548828, -1.8688135147094727, -1.5308952331542969, -1.1284732818603516, -1.3319683074951172, -0.5047721862792969, 0.05234813690185547, 1.126810073852539, 2.0002193450927734, 0.17702531814575195, 1.6498584747314453, 0.6722202301025391, -1.4589207172393799, -1.188645362854004, 0.23244094848632812, -1.7601823806762695, -1.6995315551757812, -0.8344078063964844, 2.0821337699890137, -0.8376522064208984, -1.0696086883544922, 0.09715127944946289, -0.9046907424926758, 0.5058298110961914, 0.32303333282470703, 0.3338603973388672, -1.3156375885009766, -0.3759040832519531, -0.27200818061828613, -0.29990530014038086, 0.8910236358642578, -0.9011926651000977, 0.11089324951171875, 1.3060493469238281, 0.10841941833496094, 0.04191398620605469, -0.46825408935546875, -1.3880157470703125, -1.6368029117584229, -0.05657386779785156, 0.04068470001220703, -10.56782341003418, -0.22193050384521484, 3.9024810791015625, -1.8407566547393799, -0.8928318023681641, -0.2143383026123047, -0.5986087322235107, 0.3101797103881836, -5.3476948738098145, -0.7369322776794434, 1.2325286865234375, 0.9791278839111328, 0.3849581480026245, -2.8407318592071533, -0.5383048057556152, -0.7415180206298828, -0.05960273742675781, -0.9112701416015625, 1.5810928344726562, 12.608759880065918, 0.5485200881958008, -0.5102081298828125, -0.2290973663330078, -1.2535877227783203, 3.2388267517089844, -0.5176868438720703, -8.48779296875, 0.007989883422851562, -0.44429588317871094, 0.07417583465576172, -0.8227729797363281, -0.015655517578125, -0.8124237060546875, 1.5702018737792969, 1.3012933731079102, -7.080754280090332, -0.9919052124023438, -0.11182403564453125, -0.7722597122192383, 0.9301357269287109, 0.5207767486572266, -0.5849189758300781, -0.6845455169677734, 0.9005928039550781, 0.521355152130127, -0.4366874694824219, 2.0128517150878906, -1.8727362155914307, -1.0219783782958984, 0.8409743309020996, 0.20658302307128906, -0.5600242614746094, -5.530576705932617, 0.028825044631958008, 0.24721527099609375, -0.3600959777832031, 0.08075237274169922, 0.5015769004821777, -1.648843765258789, 0.8855476379394531, 0.8206977844238281, -0.6617603302001953, 0.3825263977050781, 1.3060493469238281, 1.0600700378417969, 0.36081933975219727, 1.8985595703125, -0.013399124145507812, -1.4501495361328125, 0.028825044631958008, 0.3546180725097656, 2.710603713989258, -1.0085029602050781, 0.03774881362915039, 0.5957984924316406, -1.3936386108398438, -0.3929786682128906, -0.5514240264892578, -1.0274620056152344, 0.9975852966308594, 1.1502323150634766, -1.7681236267089844, -1.7140436172485352, 0.03780555725097656, 1.4705710411071777, -0.48276424407958984, 0.22034931182861328, 0.09715127944946289, -7.562596321105957, 0.4901237487792969, 4.794525146484375, -0.794189453125, 6.974374771118164, -0.3941535949707031, 0.14723682403564453, -3.2341976165771484, -0.3996562957763672], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 50176, "num_env_steps_trained": 184560, "num_agent_steps_sampled": 50176, "num_agent_steps_trained": 184560, "last_target_update_ts": 50176, "num_target_updates": 97}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -112.48703556656838, "episode_len_mean": 267.79, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603], "episode_lengths": [261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5254248955371166, "mean_inference_ms": 24.439124599071896, "mean_action_processing_ms": 0.1358299520572057, "mean_env_wait_ms": 4.238769914742381, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -112.48703556656838, "episode_len_mean": 267.79, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-23.46258684247732, -94.73456224799156, -258.3222741484642, -134.1521977186203, -201.1068858280778, -147.14673759043217, -30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603], "episode_lengths": [261, 277, 330, 291, 314, 295, 261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5254248955371166, "mean_inference_ms": 24.439124599071896, "mean_action_processing_ms": 0.1358299520572057, "mean_env_wait_ms": 4.238769914742381, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 50176, "num_agent_steps_trained": 184560, "num_env_steps_sampled": 50176, "num_env_steps_trained": 184560, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 50176, "agent_timesteps_total": 50176, "timers": {"training_iteration_time_ms": 335.533, "learn_time_ms": 64.887, "learn_throughput": 3698.75, "synch_weights_time_ms": 20.168}, "counters": {"num_env_steps_sampled": 50176, "num_env_steps_trained": 184560, "num_agent_steps_sampled": 50176, "num_agent_steps_trained": 184560, "last_target_update_ts": 50176, "num_target_updates": 97}, "done": false, "episodes_total": 164, "training_iteration": 49, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-26", "timestamp": 1655478326, "time_this_iter_s": 5.418351411819458, "time_total_s": 257.80731320381165, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 257.80731320381165, "timesteps_since_restore": 0, "iterations_since_restore": 49, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.7, "ram_util_percent": 63.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 13.957789421081543, "min_q": -28.350034713745117, "max_q": 39.36845397949219, "mean_td_error": -0.6725034713745117}, "td_error": [0.29280853271484375, 0.5392189025878906, 1.190286636352539, -1.0200939178466797, -0.2872486114501953, -0.017560958862304688, 0.47882938385009766, 0.035907745361328125, 0.0029697418212890625, 0.13999223709106445, -1.1774793863296509, 0.19103431701660156, 0.8770861625671387, -5.73216438293457, -10.33737564086914, -4.246360778808594, -1.260183334350586, -0.7284603118896484, 0.5428142547607422, 0.44451141357421875, -7.48284912109375, -0.030120849609375, 0.10689163208007812, -0.41423797607421875, -6.162492752075195, 0.971308708190918, -0.6912899017333984, 0.4715232849121094, 0.025991439819335938, 0.20268630981445312, -0.7044773101806641, -0.9056987762451172, -1.0778837203979492, 1.250762939453125, -0.1196746826171875, -0.2633552551269531, -0.4946659207344055, 2.616058349609375, 0.46312522888183594, -3.9880828857421875, -2.6622657775878906, 1.0311603546142578, -0.8952679634094238, -1.0088310241699219, 0.7372770309448242, -1.8391799926757812, 0.08716392517089844, 0.9599313735961914, -0.7760906219482422, -0.004512786865234375, -2.234691619873047, -1.0949134826660156, -0.8428173065185547, -0.01268768310546875, -0.5988984107971191, -1.0667572021484375, 0.01656627655029297, -2.6449241638183594, -0.5890464782714844, -1.9478626251220703, -0.30063438415527344, 2.1315736770629883, 1.4931716918945312, 0.008270263671875, -0.20910263061523438, -0.06753396987915039, 2.2150611877441406, 0.19914627075195312, 1.6509780883789062, 0.04780006408691406, -0.5841331481933594, -0.9680032730102539, 4.574419021606445, -0.2689990997314453, 1.3845348358154297, -15.609933853149414, 0.878911018371582, 0.08745956420898438, 2.0490779876708984, 0.7798728942871094, 0.1671161651611328, 0.7497764825820923, -0.24369430541992188, 3.1209073066711426, -0.40300464630126953, 1.1238288879394531, 0.3938627243041992, -3.4152817726135254, 0.3170452117919922, -0.8418903350830078, -0.26092529296875, -1.1822738647460938, -1.394045352935791, 0.3902101516723633, -9.905184745788574, 0.06626272201538086, 2.161479949951172, -0.7066583633422852, -0.35553503036499023, -7.9608612060546875, -0.0043544769287109375, 0.7546787261962891, -0.5968027114868164, -0.4974679946899414, -0.9517421722412109, 0.2742176055908203, -0.658972978591919, 1.3294544219970703, -3.301539659500122, 3.115062713623047, 0.388946533203125, 0.5772171020507812, 0.3241739273071289, -1.0732555389404297, -0.5626707077026367, -3.301539659500122, 0.08599090576171875, 0.42386817932128906, 19.627721786499023, -3.1069350242614746, -1.566114902496338, 0.5189914703369141, 0.13063812255859375, -0.13251161575317383, 0.10935258865356445, 0.44558966159820557, 0.16695213317871094, -5.86082649230957, -1.6813735961914062, -1.7749443054199219, 1.0937213897705078, 0.3537750244140625, 0.16745567321777344, 0.09405803680419922, -6.567028045654297, -0.01268768310546875, -0.5103702545166016, 0.17889022827148438, -0.8976821899414062, 0.36679935455322266, -0.8204784393310547, 0.8639774322509766, -7.851598739624023, -1.960970401763916, -0.6278953552246094, -0.41115379333496094, -0.4181346893310547, -1.5862550735473633, -1.2033580541610718, -0.07005119323730469, -4.733589172363281, 0.2553424835205078, -7.039620399475098, 2.490830421447754, -3.4710874557495117, 0.08883285522460938, -0.06736564636230469, 0.8325901031494141, 0.0075855255126953125, 0.24155044555664062, -3.1935997009277344, 0.5158510208129883, -0.1727581024169922, -0.20207500457763672, -0.34377098083496094, -1.363194465637207, -0.5191965103149414, 0.11696434020996094, 1.6642894744873047, -0.5323600769042969, 1.0660648345947266, 0.3582801818847656, 0.009634017944335938, -7.451738357543945, -0.4624161720275879, -0.0675048828125, -0.9435634613037109, -7.2691826820373535, -0.15371322631835938, 0.3260784149169922, -1.8936691284179688, 0.4948711395263672, 0.9063777923583984, 0.5797271728515625, -13.622026443481445, -0.4299640655517578, 0.019936561584472656, 0.27705955505371094, -0.07581472396850586, 0.11224365234375, 1.521230697631836, -1.6484453678131104, -0.79791259765625, -0.0921173095703125, 0.7114105224609375, -0.4733760356903076, -3.36240291595459, 0.038360595703125, -1.7381114959716797, -0.3669109344482422, -0.4400177001953125, -2.1924235820770264, -2.33524227142334, 0.024358749389648438, -10.33737564086914, -0.1773691177368164, 0.5231475830078125, -0.13404083251953125, -2.925149917602539, -2.9791908264160156, 1.625711441040039, 0.1457500457763672, -0.3328101634979248, -0.21819734573364258, -0.014635086059570312, -0.091217041015625, 0.5122413635253906, -2.1924235820770264, -1.0978374481201172, -1.9149713516235352, -0.33092784881591797, 0.11211872100830078, 0.1603555679321289, 0.25242042541503906, 1.3284430503845215, -1.1327390670776367, 0.18370062112808228, -0.8003852963447571, 0.7859635353088379, -0.8880710601806641, -0.7591915130615234, 2.837932586669922, 0.6426162719726562, -0.3054847717285156, 1.6434249877929688, -0.7443933486938477, -1.6362628936767578, -3.5497493743896484, 0.6322731971740723, 1.5599002838134766], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 51200, "num_env_steps_trained": 188400, "num_agent_steps_sampled": 51200, "num_agent_steps_trained": 188400, "last_target_update_ts": 51200, "num_target_updates": 99}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -106.14995808102191, "episode_len_mean": 264.01, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353], "episode_lengths": [261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5259571101303342, "mean_inference_ms": 24.497859362774506, "mean_action_processing_ms": 0.13574352242324353, "mean_env_wait_ms": 4.244586263937248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -106.14995808102191, "episode_len_mean": 264.01, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-30.0790383964777, -208.08470659703016, -89.36412081867456, -235.56153660267591, -383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353], "episode_lengths": [261, 305, 262, 318, 369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5259571101303342, "mean_inference_ms": 24.497859362774506, "mean_action_processing_ms": 0.13574352242324353, "mean_env_wait_ms": 4.244586263937248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 51200, "num_agent_steps_trained": 188400, "num_env_steps_sampled": 51200, "num_env_steps_trained": 188400, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 51200, "agent_timesteps_total": 51200, "timers": {"training_iteration_time_ms": 336.231, "learn_time_ms": 65.461, "learn_throughput": 3666.286, "synch_weights_time_ms": 21.189}, "counters": {"num_env_steps_sampled": 51200, "num_env_steps_trained": 188400, "num_agent_steps_sampled": 51200, "num_agent_steps_trained": 188400, "last_target_update_ts": 51200, "num_target_updates": 99}, "done": false, "episodes_total": 170, "training_iteration": 50, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-31", "timestamp": 1655478331, "time_this_iter_s": 5.402901887893677, "time_total_s": 263.2102150917053, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 263.2102150917053, "timesteps_since_restore": 0, "iterations_since_restore": 50, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.537499999999994, "ram_util_percent": 63.5125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.45718765258789, "min_q": -34.79671096801758, "max_q": 38.717987060546875, "mean_td_error": -0.12063038349151611}, "td_error": [1.8333721160888672, 0.004543304443359375, 0.5229988098144531, -0.5058107376098633, 0.3942594528198242, 1.1564569473266602, 1.216024398803711, -0.8319063186645508, 1.4870624542236328, -0.4947690963745117, 12.939870834350586, -6.119874000549316, -0.6060123443603516, -0.17340087890625, 0.8450651168823242, 0.5506410598754883, -1.8141298294067383, 0.8834228515625, -0.8842000961303711, -0.8306293487548828, 1.4724788665771484, -0.2912750244140625, 0.45557594299316406, 1.8298206329345703, 0.006406307220458984, 0.8908944129943848, 2.0952160358428955, 1.349402666091919, 0.4176445007324219, 0.7622365951538086, 0.22831153869628906, 0.11191987991333008, -0.14013290405273438, 0.965519905090332, 0.8797931671142578, -0.22093582153320312, 0.6052207946777344, -0.6788082122802734, -0.5826072692871094, 0.47517967224121094, -3.317646026611328, -3.4669418334960938, 1.8759651184082031, -0.29531097412109375, 0.9858779907226562, -9.480208396911621, 0.4198007583618164, -1.129232406616211, 0.1346588134765625, -0.04972076416015625, -0.5564918518066406, 0.8146724700927734, 0.5139942169189453, 0.12944412231445312, -0.05957221984863281, 0.0763387680053711, -0.19814300537109375, 0.9071750640869141, -0.08021068572998047, -0.011407852172851562, -9.865280151367188, -4.326253890991211, 0.8460907936096191, -0.2851581573486328, 0.16440963745117188, 0.6222496032714844, -1.024796962738037, -1.159566879272461, 0.1788158416748047, -0.11215782165527344, 0.8979988098144531, 0.6205885410308838, 0.7364101409912109, -1.2205276489257812, -0.6335287094116211, 0.5696830749511719, -0.23696327209472656, -7.672168731689453, 0.08807754516601562, -0.3677558898925781, -0.32818603515625, -1.2472295761108398, 0.5302619934082031, -0.9788599014282227, 0.3516044616699219, 0.4238739013671875, 0.6375541687011719, -0.7741250991821289, -5.503562927246094, -0.37468814849853516, 1.4617586135864258, 0.5139942169189453, -0.6368570327758789, 0.7413115501403809, 0.05602836608886719, 0.6404159069061279, -0.04033660888671875, 0.5540046691894531, 0.37188148498535156, -0.7083377838134766, -8.66822624206543, -3.1394195556640625, 0.09591102600097656, 1.0248489379882812, 1.2170181274414062, 0.410036563873291, -0.20458984375, 0.314971923828125, -1.0467796325683594, -2.417111396789551, 0.20005226135253906, 0.4075326919555664, 0.6706008911132812, 0.27470970153808594, -1.0763959884643555, 0.054022789001464844, 0.6616725921630859, 0.6621837615966797, 0.3272075653076172, 0.43375682830810547, -5.041964530944824, -0.2380352020263672, -5.438905715942383, -0.2336101531982422, 0.9393672943115234, -0.39642333984375, -2.885669708251953, 0.06995296478271484, 0.3764381408691406, -0.07230377197265625, 0.9671056270599365, 0.2800140380859375, -0.052290916442871094, 1.1914453506469727, -0.3199458122253418, -2.093766212463379, -0.6777229309082031, 0.6298542022705078, -0.049755096435546875, -0.5114459991455078, 10.229779243469238, -0.16815567016601562, 0.2116680145263672, 0.1789875030517578, -2.390902519226074, 0.4834756851196289, -0.21067428588867188, 0.8984413146972656, 1.1894655227661133, -0.6313915252685547, 0.21858787536621094, 1.5552968978881836, -0.012467384338378906, -1.1730613708496094, -1.6795892715454102, -0.8417854309082031, 0.5913581848144531, -8.679929733276367, -0.5381021499633789, 0.64166259765625, 8.827662467956543, -0.1878528594970703, 0.6565995216369629, -0.2555561065673828, -0.43201637268066406, -0.6846942901611328, -0.030063390731811523, 0.5466146469116211, -0.14281368255615234, -0.4978923797607422, 0.6013565063476562, 0.4494619369506836, 1.321765422821045, 1.3175630569458008, 0.1731433868408203, 0.5790395736694336, -0.4876546859741211, 0.7183914184570312, 0.3047447204589844, 1.32781982421875, -0.29207420349121094, 14.555994033813477, 1.3351833820343018, 0.5466146469116211, -0.3349189758300781, 1.816817283630371, 1.314803123474121, 0.6675608158111572, 1.7893133163452148, -15.275629043579102, 1.6008143424987793, 0.4024391174316406, 0.29759836196899414, -6.328988075256348, 3.289297103881836, 0.9902939796447754, 0.9200029373168945, 0.3516044616699219, 0.3892850875854492, -0.18723297119140625, -7.430349349975586, 0.22132301330566406, -0.1166219711303711, 0.21925926208496094, -0.012624740600585938, -2.1762003898620605, -0.5459623336791992, 0.011789023876190186, 1.1685371398925781, -0.23566818237304688, 0.20354843139648438, -0.1588287353515625, 0.208404541015625, 0.3644866943359375, -0.24039649963378906, 0.43894004821777344, -1.1059112548828125, 0.1112518310546875, 3.6449146270751953, 0.53179931640625, -0.19620704650878906, 0.7944622039794922, -1.1394500732421875, 1.1550183296203613, 1.2371444702148438, -0.08673381805419922, 1.0408897399902344, 0.4831695556640625, -7.249685287475586, 0.5074806213378906, 1.1445350646972656, 0.4612541198730469, -1.0973834991455078, -1.798654556274414, 0.6430530548095703, 0.7966691255569458, 0.7374172210693359, -0.3407554626464844, -0.20579838752746582, -0.3393669128417969], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 52224, "num_env_steps_trained": 192240, "num_agent_steps_sampled": 52224, "num_agent_steps_trained": 192240, "last_target_update_ts": 52224, "num_target_updates": 101}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -103.21614418007434, "episode_len_mean": 262.64, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556], "episode_lengths": [369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.526094104271166, "mean_inference_ms": 24.504854050359313, "mean_action_processing_ms": 0.13550170490386312, "mean_env_wait_ms": 4.24631315750139, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -103.21614418007434, "episode_len_mean": 262.64, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-383.564743950963, -52.885391779243946, -229.36554308980703, -267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556], "episode_lengths": [369, 248, 321, 334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.526094104271166, "mean_inference_ms": 24.504854050359313, "mean_action_processing_ms": 0.13550170490386312, "mean_env_wait_ms": 4.24631315750139, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 52224, "num_agent_steps_trained": 192240, "num_env_steps_sampled": 52224, "num_env_steps_trained": 192240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 52224, "agent_timesteps_total": 52224, "timers": {"training_iteration_time_ms": 343.147, "learn_time_ms": 66.28, "learn_throughput": 3620.981, "synch_weights_time_ms": 20.984}, "counters": {"num_env_steps_sampled": 52224, "num_env_steps_trained": 192240, "num_agent_steps_sampled": 52224, "num_agent_steps_trained": 192240, "last_target_update_ts": 52224, "num_target_updates": 101}, "done": false, "episodes_total": 174, "training_iteration": 51, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-37", "timestamp": 1655478337, "time_this_iter_s": 5.3665452003479, "time_total_s": 268.5767602920532, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 268.5767602920532, "timesteps_since_restore": 0, "iterations_since_restore": 51, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 38.525, "ram_util_percent": 63.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.425155639648438, "min_q": -36.17873764038086, "max_q": 40.51091766357422, "mean_td_error": -0.020056121051311493}, "td_error": [-0.3009967803955078, 0.24711322784423828, -0.019237518310546875, -0.24330902099609375, -0.5159378051757812, 0.6415119171142578, 0.19866561889648438, -0.5147686004638672, -0.0955204963684082, -6.260806083679199, 0.5257682800292969, 0.7510643005371094, -0.32148170471191406, -6.888827323913574, 5.443508148193359, 0.11190986633300781, 0.24718666076660156, 0.06801986694335938, 0.6492900848388672, 1.4043540954589844, 0.1952066421508789, -0.3033933639526367, 1.3240413665771484, 1.4121675491333008, 0.9806976318359375, 0.5294599533081055, -0.8549222946166992, 1.1274471282958984, 4.89155387878418, 0.01645660400390625, 1.0586833953857422, -2.4868106842041016, 0.7451896667480469, 0.5096874237060547, 0.047016143798828125, 1.3271801471710205, 0.7932806015014648, 0.7311191558837891, -0.9490127563476562, 0.31607818603515625, -1.151327133178711, 2.2652881145477295, 1.2176151275634766, -1.7928333282470703, -0.5102677345275879, 1.9667301177978516, -0.8380031585693359, -1.5441694259643555, 0.44809579849243164, -0.0955204963684082, -0.09727096557617188, -0.8146746158599854, -1.4204273223876953, -1.3485374450683594, -0.23274946212768555, -0.1239461898803711, 0.5673446655273438, 0.1908893585205078, -1.0039749145507812, -0.5567493438720703, 0.6359348297119141, 0.35067081451416016, -0.8439521789550781, 1.0592803955078125, -0.032166481018066406, -0.398967981338501, -0.024682998657226562, 0.10973358154296875, 0.6010122299194336, 1.8950152397155762, 4.576711654663086, 0.2882728576660156, -3.5991973876953125, -0.7030029296875, -1.066751480102539, 0.33271217346191406, 0.5899906158447266, 1.4349474906921387, -0.3994426727294922, 1.357752799987793, -5.110297203063965, -0.17693710327148438, -1.476226806640625, -1.3397388458251953, -1.764974594116211, 0.6780896186828613, -0.6764316558837891, -1.3445701599121094, -0.6550769805908203, -0.3348960876464844, 1.2274837493896484, -0.22750186920166016, -1.3268871307373047, 0.22834396362304688, 0.10105133056640625, -0.4980030059814453, -0.09527134895324707, 0.10846376419067383, 1.4516258239746094, 0.5562725067138672, 0.259857177734375, 0.01837921142578125, 0.3403482437133789, 0.151153564453125, -0.26018285751342773, 0.21897125244140625, -0.13524436950683594, -1.2432689666748047, 0.4454517364501953, 0.28261375427246094, 0.3792300224304199, -0.08140182495117188, 0.5431299209594727, 0.24940872192382812, 0.046874046325683594, -0.030631542205810547, 1.3543987274169922, 0.41330528259277344, -1.0269532203674316, -12.38389778137207, 0.3685321807861328, 0.3648338317871094, 0.2097034454345703, -2.1796226501464844, 1.0510139465332031, -7.665261745452881, 0.3914775848388672, -0.46632957458496094, 0.08405113220214844, 0.5682373046875, 1.3083534240722656, -0.6114282608032227, -5.041910171508789, 1.0510139465332031, -8.05717945098877, 0.19608116149902344, 0.6359348297119141, -0.2859992980957031, 6.404343605041504, 0.4551839828491211, 0.8108158111572266, -1.5925483703613281, 1.7534680366516113, 1.5815277099609375, 2.5532150268554688, 4.317763328552246, 0.7872810363769531, -0.09136009216308594, -0.7347841262817383, 0.23998641967773438, 0.36808204650878906, 0.7370662689208984, 1.2969512939453125, 0.16196441650390625, -0.47206878662109375, 0.6262226104736328, 1.6481170654296875, 1.0236263275146484, 1.388448715209961, -2.850738048553467, 0.5098857879638672, -0.4235515594482422, 1.7893199920654297, 0.2105731964111328, 0.35887908935546875, 0.6547374725341797, 1.8548593521118164, -0.5256633758544922, -1.33866548538208, -0.3173713684082031, 0.3163490295410156, -2.955249786376953, 1.4968204498291016, -6.790359020233154, 0.043491363525390625, -0.07019329071044922, 1.8298263549804688, 22.235149383544922, 0.5664005279541016, -5.041664123535156, 0.9042472839355469, -1.501729965209961, 0.03280448913574219, -1.1838550567626953, 0.010259628295898438, -0.36060142517089844, 0.635991096496582, -1.7173595428466797, 0.8324079513549805, 1.0510139465332031, -0.42244386672973633, 1.180445671081543, -0.5768618583679199, -0.5858612060546875, 0.44235801696777344, 1.1319799423217773, 0.8980312347412109, 0.5054845809936523, 0.00628662109375, 2.1090316772460938, 0.24542999267578125, 1.0818901062011719, -0.16784286499023438, 0.5140438079833984, 1.2886905670166016, 0.3438749313354492, -9.698543548583984, -2.281465530395508, 0.10425567626953125, -5.596042633056641, 0.2741985321044922, 1.4988384246826172, 1.7087445259094238, -0.7223930358886719, -0.035175323486328125, -0.30846405029296875, 0.01627349853515625, -5.000827789306641, 0.9171934127807617, 0.6121773719787598, 0.35684967041015625, -0.09439277648925781, 0.8726768493652344, 0.12443733215332031, -1.6687307357788086, 0.5607671737670898, -1.0999412536621094, 0.6022071838378906, 0.1152496337890625, -0.33289527893066406, 0.6547374725341797, -0.5038366317749023, 0.21897125244140625, 1.185685157775879, 0.7370662689208984, 0.9832210540771484, -0.4332904815673828, -1.1857585906982422, 0.5853424072265625, 1.8899660110473633], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 53248, "num_env_steps_trained": 196080, "num_agent_steps_sampled": 53248, "num_agent_steps_trained": 196080, "last_target_update_ts": 53248, "num_target_updates": 103}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -96.55468857742846, "episode_len_mean": 260.1, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807], "episode_lengths": [334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5273482534673898, "mean_inference_ms": 24.508722523919047, "mean_action_processing_ms": 0.13537178711603734, "mean_env_wait_ms": 4.255080808184513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -464.14498011022806, "episode_reward_mean": -96.55468857742846, "episode_len_mean": 260.1, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-267.7338121458888, -135.08448902517557, -329.45411701500416, 21.81153803318739, -286.91532427817583, -169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807], "episode_lengths": [334, 287, 346, 213, 342, 301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5273482534673898, "mean_inference_ms": 24.508722523919047, "mean_action_processing_ms": 0.13537178711603734, "mean_env_wait_ms": 4.255080808184513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 53248, "num_agent_steps_trained": 196080, "num_env_steps_sampled": 53248, "num_env_steps_trained": 196080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 53248, "agent_timesteps_total": 53248, "timers": {"training_iteration_time_ms": 333.524, "learn_time_ms": 65.243, "learn_throughput": 3678.546, "synch_weights_time_ms": 20.492}, "counters": {"num_env_steps_sampled": 53248, "num_env_steps_trained": 196080, "num_agent_steps_sampled": 53248, "num_agent_steps_trained": 196080, "last_target_update_ts": 53248, "num_target_updates": 103}, "done": false, "episodes_total": 177, "training_iteration": 52, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-42", "timestamp": 1655478342, "time_this_iter_s": 5.350276708602905, "time_total_s": 273.9270370006561, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 273.9270370006561, "timesteps_since_restore": 0, "iterations_since_restore": 52, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.45, "ram_util_percent": 63.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.938260078430176, "min_q": -34.12869644165039, "max_q": 38.931663513183594, "mean_td_error": 0.004378533456474543}, "td_error": [0.9525012969970703, 2.146073341369629, -0.7672214508056641, -1.0179271697998047, 0.0884847640991211, 0.40404510498046875, -0.010126590728759766, 1.1385197639465332, 0.5348234176635742, 1.2738628387451172, -0.05745124816894531, 0.5222492218017578, -9.247488021850586, 1.6459884643554688, -0.349761962890625, -0.14462852478027344, -0.3386974334716797, 2.0464649200439453, 0.7113423347473145, 0.8105373382568359, 0.8156166076660156, 0.4705791473388672, 0.5308551788330078, -0.009367704391479492, 0.47355127334594727, 1.9414539337158203, -4.767419815063477, -5.625981330871582, -6.065168380737305, 0.6739788055419922, 0.0884847640991211, 1.0525283813476562, -2.0287246704101562, -0.2106761932373047, 0.04749107360839844, 0.17427635192871094, 0.43959999084472656, -2.7629318237304688, -7.836297988891602, -0.43758583068847656, -0.08442306518554688, 0.6720013618469238, 2.0891761779785156, -6.0223388671875, -5.502222061157227, 0.252349853515625, 0.5106563568115234, 0.5608582496643066, 0.3236351013183594, -0.0010738372802734375, 1.4683799743652344, 1.6999025344848633, -0.12291908264160156, 1.0419445037841797, 2.2488861083984375, 0.4042205810546875, -0.28643205761909485, 0.7560644149780273, 1.0959911346435547, -0.05390167236328125, 0.6451559066772461, -0.9907035827636719, -4.003740310668945, 0.3877716064453125, 0.5949134826660156, -0.18776273727416992, 0.5117340087890625, 0.35779285430908203, 0.012607574462890625, -0.3362560272216797, -4.5766754150390625, 0.48732662200927734, -0.5513229370117188, 0.11281585693359375, 0.8033409118652344, 1.6354684829711914, 0.5377750396728516, 0.08105182647705078, -0.39279937744140625, 0.8318939208984375, 1.524972915649414, 0.5859909057617188, 0.3678932189941406, -0.4463348388671875, 1.7961139678955078, 0.6672158241271973, 0.7985877990722656, 4.3330535888671875, -0.24456024169921875, -0.2758808135986328, 0.6792962551116943, -1.9648628234863281, -0.17730712890625, 0.45882415771484375, 0.7001997232437134, 1.372147560119629, -0.8766441345214844, -1.47698974609375, 0.723297119140625, -0.4288349151611328, 2.555927276611328, 0.29747676849365234, -1.9055366516113281, 0.05433082580566406, -0.18695831298828125, 0.2711677551269531, 1.295910358428955, -0.3199119567871094, 0.24834728240966797, -0.1473236083984375, 1.2025604248046875, 9.32456111907959, 0.8195991516113281, -2.412792682647705, -2.3845901489257812, 3.6818580627441406, -0.19764995574951172, 0.9038496017456055, 0.0625, 0.25838589668273926, -0.1835232973098755, 0.35859107971191406, 0.3102531433105469, 1.6982240676879883, 1.0453128814697266, 1.218897819519043, -0.39644908905029297, 0.5568981170654297, -0.21771240234375, -0.7438430786132812, 0.30193138122558594, -0.3303251266479492, 0.33677005767822266, 0.10422515869140625, -0.2788276672363281, 0.9253466129302979, -1.0468754768371582, 0.1485729217529297, -0.5329160690307617, -1.7035799026489258, -0.15425682067871094, -0.003955841064453125, 1.2284460067749023, 0.538299560546875, 0.3410663604736328, 0.20047569274902344, -0.02752685546875, 0.39101314544677734, 0.142303466796875, 0.13927841186523438, 0.18501853942871094, -1.742171287536621, 0.206878662109375, -0.1434478759765625, -0.2533388137817383, -0.7002525329589844, 1.2575020790100098, 0.11512374877929688, 1.4243316650390625, -0.40831995010375977, 0.12170219421386719, 0.4482078552246094, -5.547197341918945, 0.5488777160644531, 4.070862770080566, -1.2366113662719727, 0.5461912155151367, 2.392425537109375, -0.09991264343261719, -3.800088882446289, 0.10512363910675049, 0.7068862915039062, 0.8703269958496094, 0.4705791473388672, -0.12022590637207031, 0.8061470985412598, 3.606435775756836, -0.5486812591552734, 0.4696502685546875, -0.01588153839111328, 0.676882266998291, -0.29224586486816406, 0.23207855224609375, 0.12386512756347656, -0.12022590637207031, 0.5679769515991211, -0.3919525146484375, -8.99786376953125, -2.2630157470703125, -0.5407466888427734, 0.20055007934570312, -0.4253568649291992, 0.19873476028442383, -0.0424346923828125, 1.9591445922851562, -0.8977260589599609, 0.2878913879394531, -9.340319633483887, -1.2464561462402344, 0.5552783012390137, 2.455686569213867, -0.15357398986816406, 0.6734714508056641, -0.0818939208984375, 0.1837749481201172, -0.5340671539306641, -0.5616979598999023, 1.9491233825683594, 0.6372604370117188, 0.5894713401794434, 0.28592491149902344, 0.38275146484375, -0.35552120208740234, 0.8050813674926758, 0.27150917053222656, 0.639556884765625, 1.9559879302978516, -0.7881298065185547, 0.5665035247802734, -0.35552120208740234, -0.13721370697021484, 1.6385841369628906, 0.5115737915039062, 0.2677001953125, -0.6819286346435547, 0.6212348937988281, 1.2296123504638672, 1.0773048400878906, 0.8942031860351562, 0.36749267578125, -0.3229961395263672, -0.5879182815551758, 0.8575191497802734, 0.2140827178955078, 0.383880615234375, 0.8336076736450195, 1.624643325805664, -1.1980304718017578, -0.15497207641601562, 0.8455753326416016], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 54272, "num_env_steps_trained": 199920, "num_agent_steps_sampled": 54272, "num_agent_steps_trained": 199920, "last_target_update_ts": 54272, "num_target_updates": 105}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -94.87241297461092, "episode_len_mean": 258.26, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466], "episode_lengths": [301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5285033482605563, "mean_inference_ms": 24.529713613300125, "mean_action_processing_ms": 0.1352831240286493, "mean_env_wait_ms": 4.260004295539115, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -94.87241297461092, "episode_len_mean": 258.26, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-169.50221526622772, -45.06412099301815, 29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466], "episode_lengths": [301, 245, 224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5285033482605563, "mean_inference_ms": 24.529713613300125, "mean_action_processing_ms": 0.1352831240286493, "mean_env_wait_ms": 4.260004295539115, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 54272, "num_agent_steps_trained": 199920, "num_env_steps_sampled": 54272, "num_env_steps_trained": 199920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 54272, "agent_timesteps_total": 54272, "timers": {"training_iteration_time_ms": 343.619, "learn_time_ms": 67.048, "learn_throughput": 3579.54, "synch_weights_time_ms": 20.591}, "counters": {"num_env_steps_sampled": 54272, "num_env_steps_trained": 199920, "num_agent_steps_sampled": 54272, "num_agent_steps_trained": 199920, "last_target_update_ts": 54272, "num_target_updates": 105}, "done": false, "episodes_total": 182, "training_iteration": 53, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-48", "timestamp": 1655478348, "time_this_iter_s": 5.59015965461731, "time_total_s": 279.51719665527344, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 279.51719665527344, "timesteps_since_restore": 0, "iterations_since_restore": 53, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 38.2, "ram_util_percent": 63.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 12.737839698791504, "min_q": -34.16033935546875, "max_q": 39.26639175415039, "mean_td_error": 0.18506008386611938}, "td_error": [18.05462646484375, 0.23032188415527344, -6.197700500488281, 0.0371551513671875, -0.5226602554321289, 0.9901409149169922, 0.6042556762695312, -0.15816688537597656, -0.5034942626953125, -0.36577272415161133, 0.3112649917602539, 0.29698753356933594, -8.657760620117188, -0.31574058532714844, -1.326395034790039, 0.13797760009765625, -0.12879467010498047, 0.3950538635253906, -1.507394790649414, 1.4402503967285156, -1.4448528289794922, -0.285614013671875, -1.3280916213989258, -0.6299924850463867, -0.35591602325439453, -0.5493049621582031, -0.8346061706542969, -0.35718345642089844, 1.2090835571289062, 0.8100652694702148, 4.8240556716918945, 0.9487342834472656, -1.0780620574951172, 3.7865848541259766, 23.739608764648438, 21.673664093017578, -0.45038414001464844, -0.3326911926269531, -5.622428894042969, -0.24424266815185547, -0.5273709297180176, -0.00151824951171875, 16.007450103759766, 0.2210102081298828, -0.8115785121917725, -0.8062744140625, -0.2395496368408203, -0.4187793731689453, 0.9772090911865234, 0.343719482421875, -0.15469837188720703, -5.414926528930664, 0.9254770278930664, -0.6477174758911133, -0.5518722534179688, -0.050716400146484375, 0.21275568008422852, 1.1918020248413086, 2.48530912399292, -0.5164999961853027, 10.574684143066406, 0.5672507286071777, 1.1222267150878906, 1.669321060180664, -0.22680282592773438, -1.4456253051757812, 2.4321441650390625, -0.6748416423797607, -0.298736572265625, 0.24704456329345703, 0.12436652183532715, 2.6995959281921387, -4.451816558837891, -2.0329504013061523, 0.2745532989501953, -0.08809971809387207, -0.7305717468261719, 1.4489879608154297, 0.6005420684814453, 2.5797128677368164, -0.038611412048339844, -3.102436065673828, -0.7124185562133789, -0.4272499084472656, 1.343893051147461, 2.6188278198242188, 0.19876480102539062, -2.1599979400634766, -4.5328688621521, -0.1808624267578125, 3.553077220916748, 0.49338579177856445, -6.376476764678955, 0.22549915313720703, -2.1235885620117188, 2.5797128677368164, -2.0322704315185547, -0.3838768005371094, -0.6162815093994141, 4.508525371551514, -1.672159194946289, 11.867718696594238, 1.0476421117782593, 0.5061588287353516, 0.374753475189209, -0.7084312438964844, -0.6101398468017578, 1.7538268566131592, 10.573360443115234, 0.9889459609985352, 0.5870434045791626, -5.786308288574219, -0.6011457443237305, -0.1569366455078125, 1.0413990020751953, -0.5632476806640625, -0.88897705078125, -0.9971408843994141, 0.7317008972167969, 0.6304244995117188, 0.396209716796875, 0.6292057037353516, 0.9167966842651367, 0.8239593505859375, -0.3817329406738281, 0.11283349990844727, -0.9202003479003906, 2.848306179046631, -2.052358627319336, -0.3978700637817383, -0.9626274108886719, 0.4223051071166992, -0.558837890625, -0.46167755126953125, 0.09182357788085938, -6.597558975219727, 1.8909721374511719, 1.249119758605957, 1.6861295700073242, 1.2407512664794922, -1.2767581939697266, -0.7063446044921875, -0.35114097595214844, -1.16943359375, 1.3885726928710938, 0.2520941495895386, 0.5632991790771484, -6.011354446411133, 0.3324136734008789, 0.17334461212158203, 0.9028968811035156, -1.1085739135742188, 0.22237014770507812, 1.6794013977050781, -1.0417098999023438, 3.2899837493896484, -1.8529396057128906, 1.440556526184082, -0.34639739990234375, -0.35037660598754883, -0.1418132781982422, 0.043625593185424805, 1.0682058334350586, -0.05890941619873047, -0.3780860900878906, -0.9866542816162109, -6.872348785400391, -3.298778533935547, 0.892460823059082, -8.023109436035156, -1.2084903717041016, 1.1745243072509766, 1.4734687805175781, 1.145212173461914, 1.263082504272461, -1.2519187927246094, 0.21769332885742188, -0.3085823059082031, 0.35196971893310547, 0.17317581176757812, -0.5226602554321289, 0.8941650390625, -0.7442741394042969, -0.3965587615966797, -0.5405654907226562, 2.1514930725097656, 0.8872623443603516, -1.2695064544677734, -1.1058745384216309, -1.4352636337280273, 0.6059131622314453, -0.22803020477294922, -1.8195648193359375, -0.35718345642089844, -0.053630828857421875, -0.30266809463500977, 0.1266002655029297, -0.6994180679321289, -0.6471710205078125, 1.2830209732055664, -1.1058788299560547, 2.4532947540283203, 1.734222412109375, -0.08134269714355469, -0.28845787048339844, 0.4791126251220703, -0.34937286376953125, -7.865301609039307, 0.033061981201171875, -0.4802207946777344, -1.8430099487304688, -0.5040035247802734, -0.7564182281494141, 0.8821637630462646, 0.6325187683105469, -0.18793106079101562, -0.7372961044311523, 0.6860141754150391, 0.04172372817993164, -0.27574777603149414, 0.18283843994140625, -0.6018943786621094, 1.5306243896484375, 2.3783388137817383, -0.8648902177810669, 1.1402015686035156, 1.2830810546875, -10.258028030395508, 0.12158203125, 1.3038978576660156, -1.5338306427001953, 0.8309154510498047, -2.4053211212158203, -0.03412055969238281, 0.5177230834960938, -0.8685522079467773, -0.17910099029541016, 0.13684940338134766, -1.8106064796447754, 0.11128425598144531], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 55296, "num_env_steps_trained": 203760, "num_agent_steps_sampled": 55296, "num_agent_steps_trained": 203760, "last_target_update_ts": 55296, "num_target_updates": 107}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -93.73556286506354, "episode_len_mean": 257.96, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573], "episode_lengths": [224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5289312608292338, "mean_inference_ms": 24.544265695856684, "mean_action_processing_ms": 0.13519594420542913, "mean_env_wait_ms": 4.263527470078667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -93.73556286506354, "episode_len_mean": 257.96, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [29.211538091301918, -14.285391442477703, -89.76792103797197, -276.9171037301421, -129.26122342050076, -49.535807117819786, -158.53653913736343, -162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573], "episode_lengths": [224, 245, 254, 339, 282, 251, 302, 266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5289312608292338, "mean_inference_ms": 24.544265695856684, "mean_action_processing_ms": 0.13519594420542913, "mean_env_wait_ms": 4.263527470078667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 55296, "num_agent_steps_trained": 203760, "num_env_steps_sampled": 55296, "num_env_steps_trained": 203760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 55296, "agent_timesteps_total": 55296, "timers": {"training_iteration_time_ms": 330.949, "learn_time_ms": 66.179, "learn_throughput": 3626.51, "synch_weights_time_ms": 20.289}, "counters": {"num_env_steps_sampled": 55296, "num_env_steps_trained": 203760, "num_agent_steps_sampled": 55296, "num_agent_steps_trained": 203760, "last_target_update_ts": 55296, "num_target_updates": 107}, "done": false, "episodes_total": 184, "training_iteration": 54, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-54", "timestamp": 1655478354, "time_this_iter_s": 5.341458559036255, "time_total_s": 284.8586552143097, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 284.8586552143097, "timesteps_since_restore": 0, "iterations_since_restore": 54, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.6, "ram_util_percent": 63.712500000000006}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.586333274841309, "min_q": -30.503456115722656, "max_q": 44.60379409790039, "mean_td_error": 0.161206915974617}, "td_error": [3.4449539184570312, -0.5535373687744141, -1.9892239570617676, 0.7637920379638672, 0.7388439178466797, 0.8435525894165039, 4.30430793762207, -0.3660602569580078, -1.0131816864013672, 0.35547447204589844, 0.1594982147216797, 0.010501861572265625, -0.45015716552734375, 0.10530853271484375, 0.44464683532714844, 0.43331432342529297, 0.9393062591552734, 0.7024765014648438, -7.852290630340576, 13.933650970458984, -0.11999130249023438, -1.3568344116210938, -0.623748779296875, 0.5196590423583984, -0.7745733261108398, 0.60906982421875, 1.4044532775878906, 1.1593947410583496, 0.5253200531005859, -8.906139373779297, 2.101808547973633, -0.00038909912109375, 1.01444673538208, -4.821634292602539, 1.6509904861450195, 0.5583629608154297, 0.3987464904785156, 0.5129222869873047, 0.5967178344726562, 0.26729869842529297, 1.275245189666748, 0.0649261474609375, 1.1795806884765625, 0.7639837265014648, 0.1450366973876953, -6.005080223083496, 0.40585827827453613, 0.11435127258300781, 0.4973945617675781, 0.07059860229492188, 0.11756134033203125, 0.33931541442871094, 0.20824241638183594, -0.12696075439453125, 0.2841968536376953, 0.5231800079345703, 2.1332836151123047, 15.935556411743164, -0.16109561920166016, 0.8435525894165039, -0.4303760528564453, -0.026653289794921875, 0.010501861572265625, -8.403963088989258, 0.20894145965576172, 0.7791423797607422, 1.2024402618408203, -3.174161911010742, -0.07282507419586182, 2.03472900390625, -0.2088460922241211, 1.9079780578613281, 0.6461887359619141, 0.44200706481933594, 0.871403694152832, 0.3517875671386719, 0.7024765014648438, 0.41407012939453125, 0.16855621337890625, -0.09643363952636719, 0.28951072692871094, -0.01873302459716797, -0.4167156219482422, 0.6811141967773438, -1.0811691284179688, 0.33248043060302734, 1.2505264282226562, -0.582916259765625, -0.4269981384277344, 0.6405253410339355, 0.3602924346923828, 0.16163969039916992, -6.891923904418945, 1.1202077865600586, 0.45751953125, 0.9308910369873047, 0.9450893402099609, 0.5772380828857422, -0.9939417839050293, 1.0325736999511719, 0.08304214477539062, 0.23048782348632812, 1.0768909454345703, -0.0400390625, 0.5153617858886719, -1.4870529174804688, -0.3068075180053711, 2.2934656143188477, -1.9616565704345703, -0.5207653045654297, 0.3150463104248047, 0.6068267822265625, 0.8950042724609375, 0.4217205047607422, 0.15988731384277344, -4.825992584228516, -0.8327560424804688, 1.2644758224487305, 0.5699863433837891, -0.5399084091186523, 0.33931541442871094, 0.4554471969604492, 0.6261539459228516, 0.7362861633300781, 2.093982696533203, -1.2347412109375, 0.9353141784667969, 0.5570945739746094, -0.6317577362060547, -4.478878021240234, -7.586084365844727, -6.1335248947143555, 0.8595657348632812, 0.26394176483154297, 0.4044666290283203, 0.9372749328613281, 2.2133779525756836, -0.04630470275878906, 1.0965118408203125, 0.2964458465576172, 0.20766639709472656, 0.6676263809204102, -0.07198524475097656, 1.6657772064208984, 0.09701919555664062, -0.15748214721679688, 1.5775623321533203, -0.061672210693359375, 1.2397689819335938, 0.8965225219726562, 0.15193748474121094, 20.155481338500977, 0.3936882019042969, 0.08759498596191406, -0.05026054382324219, -1.5418968200683594, 1.7892045974731445, 0.39575767517089844, 0.1951904296875, 0.6013393402099609, -1.5999336242675781, -0.8854923248291016, -0.3431549072265625, -0.587559700012207, 0.4055595397949219, 0.2958254814147949, 0.4405231475830078, 0.6248111724853516, -0.07153701782226562, 0.28718090057373047, -6.857601165771484, 1.1071510314941406, 0.34235191345214844, 1.904520034790039, 1.0654287338256836, 1.4184138774871826, 0.2949810028076172, 0.33194923400878906, 1.4064288139343262, -6.954216003417969, 9.61031436920166, 0.7367410659790039, 0.05571174621582031, 0.2626762390136719, -0.6416473388671875, 0.722808837890625, 1.110001564025879, 0.6320285797119141, -3.0151495933532715, -0.4050302505493164, 0.1781330108642578, 1.8443527221679688, -0.5929641723632812, 0.9980039596557617, -0.14858055114746094, 1.1984329223632812, -0.2307443618774414, -0.026763916015625, 0.5160770416259766, 0.3036632537841797, 2.101808547973633, -4.938118934631348, 0.07855033874511719, 0.36193084716796875, -1.5092620849609375, 0.5473363399505615, 0.3594207763671875, -0.6535301208496094, 2.614116668701172, 0.861114501953125, 2.8244457244873047, -0.4014759063720703, 0.47016143798828125, -3.4358978271484375, 0.1678333282470703, -8.861427307128906, -0.5207653045654297, 0.3558082580566406, 0.1722269058227539, 0.5780258178710938, 0.12703990936279297, -0.0655364990234375, -0.7193117141723633, 2.0480690002441406, 0.45372581481933594, -7.852290630340576, 0.7553863525390625, 0.8664913177490234, 0.7078580856323242, -0.5955581665039062, 0.7984952926635742, 1.9473133087158203, 0.6485252380371094, 1.4025039672851562, 0.8648614883422852, -9.686698913574219, 1.4227123260498047, 7.309260845184326, 0.11713218688964844, -0.6002254486083984], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 56320, "num_env_steps_trained": 207600, "num_agent_steps_sampled": 56320, "num_agent_steps_trained": 207600, "last_target_update_ts": 56320, "num_target_updates": 109}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -88.1333936239779, "episode_len_mean": 255.05, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863], "episode_lengths": [266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5304618865477246, "mean_inference_ms": 24.5474140159123, "mean_action_processing_ms": 0.13505973289368411, "mean_env_wait_ms": 4.271846928542794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -88.1333936239779, "episode_len_mean": 255.05, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-162.1278616860509, -56.330931819975376, -103.4938567429781, -43.978382766246796, -453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863], "episode_lengths": [266, 265, 289, 257, 367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5304618865477246, "mean_inference_ms": 24.5474140159123, "mean_action_processing_ms": 0.13505973289368411, "mean_env_wait_ms": 4.271846928542794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 56320, "num_agent_steps_trained": 207600, "num_env_steps_sampled": 56320, "num_env_steps_trained": 207600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 56320, "agent_timesteps_total": 56320, "timers": {"training_iteration_time_ms": 343.766, "learn_time_ms": 65.1, "learn_throughput": 3686.632, "synch_weights_time_ms": 20.788}, "counters": {"num_env_steps_sampled": 56320, "num_env_steps_trained": 207600, "num_agent_steps_sampled": 56320, "num_agent_steps_trained": 207600, "last_target_update_ts": 56320, "num_target_updates": 109}, "done": false, "episodes_total": 191, "training_iteration": 55, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-05-59", "timestamp": 1655478359, "time_this_iter_s": 5.467050790786743, "time_total_s": 290.32570600509644, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 290.32570600509644, "timesteps_since_restore": 0, "iterations_since_restore": 55, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.8125, "ram_util_percent": 63.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 12.777138710021973, "min_q": -35.09165573120117, "max_q": 40.47481918334961, "mean_td_error": 0.05178755521774292}, "td_error": [1.1172609329223633, 1.724843978881836, -0.5150279998779297, 0.8617343902587891, 0.14998912811279297, 0.6660346984863281, 10.247551918029785, -6.422972679138184, 0.06871223449707031, -0.3939189910888672, 1.184117317199707, 0.9767124652862549, 0.011363983154296875, 0.7761907577514648, -0.314605712890625, 0.10810470581054688, 1.0316524505615234, -0.6377487182617188, 1.0881757736206055, -0.4258589744567871, -0.2560310363769531, -2.704416275024414, 0.20702743530273438, -0.3377113342285156, 0.7887115478515625, -0.0287017822265625, 0.13013744354248047, 1.8878593444824219, -0.2641735076904297, 0.9824981689453125, -0.7996540069580078, -0.07535934448242188, -1.2412109375, 0.1774616241455078, 0.03257942199707031, 0.20881271362304688, -6.952522277832031, -0.8079776763916016, 0.9295539855957031, 0.7446026802062988, -5.9915008544921875, 0.2728004455566406, 0.3061637878417969, -0.4089336395263672, 0.21959233283996582, 0.24120712280273438, 0.34476661682128906, -3.3916778564453125, -9.781949043273926, 1.0254902839660645, 1.5220260620117188, 2.613524913787842, -0.4040975570678711, -0.34807538986206055, -1.9565763473510742, 1.5068721771240234, -0.11232566833496094, 0.3980827331542969, -6.665622711181641, 0.05164813995361328, -5.12535285949707, 0.3726578950881958, 0.8552513122558594, -0.2088160514831543, -0.5972394943237305, 1.4330368041992188, 0.24174737930297852, -5.035968780517578, 2.001354217529297, 1.6693954467773438, 1.2410755157470703, -0.6733036041259766, -5.570444107055664, 2.209684371948242, 1.491537094116211, 1.045633316040039, -1.2016429901123047, 0.4211235046386719, 1.4085683822631836, 1.7030754089355469, -0.08251190185546875, -0.08004236221313477, 0.41936469078063965, 1.3879127502441406, 1.9360160827636719, -1.0493264198303223, 0.5751438140869141, -6.458362579345703, -0.24733352661132812, -0.19160842895507812, -3.730710983276367, -0.13915348052978516, -1.8648521900177002, 0.8900032043457031, 1.001011848449707, 0.10810470581054688, 0.6431617736816406, 1.3753718137741089, 0.9102954864501953, -0.9760618209838867, -0.43857383728027344, 1.7584190368652344, 1.5875192880630493, 0.9619312286376953, -0.532038688659668, -0.3625009059906006, -0.2517566680908203, -0.000278472900390625, 1.075881004333496, 12.080078125, 0.11493873596191406, 0.1998271942138672, -0.7987403869628906, -1.2453880310058594, 2.3845772743225098, -9.439128875732422, 1.776233196258545, 1.1640377044677734, -2.0321083068847656, 0.5304374694824219, 2.3508782386779785, 0.5313167572021484, 0.703099250793457, -0.4040975570678711, 0.407257080078125, -5.963278770446777, 0.3011789321899414, 0.3648090362548828, 0.9937591552734375, 2.759855270385742, 0.3503389358520508, -0.23471641540527344, -0.8228626251220703, 0.5487942695617676, -0.08640098571777344, 1.1937828063964844, -5.248315811157227, 1.5147724151611328, 0.7237720489501953, 0.3310203552246094, -1.4365556240081787, -0.9138450622558594, 1.1118431091308594, 1.4595308303833008, -0.19377708435058594, 0.450314998626709, 0.4848189353942871, -0.6605796813964844, -0.24634158611297607, 0.2803688049316406, 3.1275198459625244, 0.5742607116699219, -6.306785583496094, 0.3180980682373047, 1.3597569465637207, 0.3254365921020508, -0.38529014587402344, 0.49739551544189453, 1.326019287109375, 1.366199016571045, 0.11399459838867188, 1.279989242553711, 0.47472381591796875, 0.5376491546630859, -0.45931434631347656, 1.4522819519042969, 2.2827539443969727, -0.037201881408691406, 0.9346847534179688, -0.2803363800048828, -1.249612808227539, 0.46620941162109375, -3.1118907928466797, 2.6123270988464355, -0.6630516052246094, 1.0881757736206055, -0.6123600006103516, 0.0017681121826171875, 1.4554176330566406, 1.4881610870361328, -0.21259689331054688, 3.635683059692383, -0.7982139587402344, 1.2291889190673828, -8.053760528564453, 0.4989738464355469, 1.195981502532959, -0.20044994354248047, 0.5108757019042969, 0.7587580680847168, 0.10718727111816406, 0.9702167510986328, -0.3213386535644531, -0.023378372192382812, -5.071365833282471, -0.7310562133789062, 0.061608314514160156, 0.8576290607452393, 0.510493278503418, 0.09287834167480469, -0.07947349548339844, 1.724843978881836, 1.3990917205810547, -0.30660247802734375, -0.17189693450927734, 1.208364486694336, -0.11591720581054688, -0.015209197998046875, 1.3005688190460205, -0.87255859375, -0.23142623901367188, 1.3855094909667969, -0.27214622497558594, 1.2288084030151367, 0.335418701171875, -2.1692371368408203, -0.5517444610595703, -4.133872985839844, -3.482250213623047, -0.7997913360595703, -5.996477127075195, -0.23749065399169922, 39.062679290771484, 0.04259777069091797, -0.025156021118164062, 1.7728328704833984, 1.4143047332763672, -0.8277711868286133, 4.085597038269043, -5.200532913208008, 2.1019725799560547, 0.20041656494140625, -0.38315773010253906, -0.24936485290527344, -6.134604454040527, -1.5770530700683594, -0.8729133605957031, -0.5511722564697266, 1.3825664520263672, -0.6101438999176025], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 57344, "num_env_steps_trained": 211440, "num_agent_steps_sampled": 57344, "num_agent_steps_trained": 211440, "last_target_update_ts": 57344, "num_target_updates": 111}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -85.79050382047892, "episode_len_mean": 253.88, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782], "episode_lengths": [367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5313146932579044, "mean_inference_ms": 24.569337695764833, "mean_action_processing_ms": 0.13505495150775826, "mean_env_wait_ms": 4.2755625756408815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -85.79050382047892, "episode_len_mean": 253.88, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-453.2575632482767, -429.13041162490845, -183.11004626005888, 9.223447695374489, -143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782], "episode_lengths": [367, 379, 283, 222, 262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5313146932579044, "mean_inference_ms": 24.569337695764833, "mean_action_processing_ms": 0.13505495150775826, "mean_env_wait_ms": 4.2755625756408815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 57344, "num_agent_steps_trained": 211440, "num_env_steps_sampled": 57344, "num_env_steps_trained": 211440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 57344, "agent_timesteps_total": 57344, "timers": {"training_iteration_time_ms": 343.759, "learn_time_ms": 65.693, "learn_throughput": 3653.351, "synch_weights_time_ms": 20.389}, "counters": {"num_env_steps_sampled": 57344, "num_env_steps_trained": 211440, "num_agent_steps_sampled": 57344, "num_agent_steps_trained": 211440, "last_target_update_ts": 57344, "num_target_updates": 111}, "done": false, "episodes_total": 195, "training_iteration": 56, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-05", "timestamp": 1655478365, "time_this_iter_s": 5.367669582366943, "time_total_s": 295.6933755874634, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 295.6933755874634, "timesteps_since_restore": 0, "iterations_since_restore": 56, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.4, "ram_util_percent": 63.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 12.816289901733398, "min_q": -22.085229873657227, "max_q": 37.7725830078125, "mean_td_error": -0.08726808428764343}, "td_error": [-6.340244293212891, -1.6983757019042969, -3.693887710571289, -4.807668685913086, 0.15562009811401367, 1.8436155319213867, -2.4320621490478516, 0.41031360626220703, 0.42561912536621094, -0.3549518585205078, 0.6735963821411133, 0.3384580612182617, 1.1104278564453125, 0.7791652679443359, -0.9774990081787109, 0.24149131774902344, -0.9343647956848145, 0.04807579517364502, -0.5424213409423828, 0.8932771682739258, -0.10189437866210938, 0.617701530456543, 0.9587745666503906, 0.8004341125488281, 0.9888029098510742, -0.4163646697998047, 0.4558601379394531, 0.7038650512695312, -7.545917510986328, 1.0702943801879883, 2.2656922340393066, 0.5197811126708984, 0.1279888153076172, 0.4429655075073242, -0.07535827159881592, 0.30288219451904297, 0.39743614196777344, 0.7959303855895996, 0.04582405090332031, -0.8364038467407227, -0.6264047622680664, -0.2902851104736328, 0.3723106384277344, -0.9589419364929199, 0.5248451232910156, 0.5427455902099609, 0.3672175407409668, 0.06400489807128906, 0.6735963821411133, -0.4696197509765625, -0.3928813934326172, -1.4211721420288086, 0.6750631332397461, 0.10875892639160156, 0.5859928131103516, 1.4442291259765625, 0.7879209518432617, 0.5585651397705078, -0.6797771453857422, -0.0975189208984375, -0.34316253662109375, 0.3730945587158203, 0.012664794921875, 1.577016830444336, -0.3545788526535034, 1.026707649230957, -0.81219482421875, -0.17020225524902344, -0.05186271667480469, 3.0971527099609375, 0.9790263175964355, -9.613483428955078, 0.4604083299636841, -0.0953826904296875, -1.6109180450439453, 0.3496532440185547, 0.3031806945800781, -2.1019179821014404, 1.1431875228881836, 0.7713642120361328, 0.9973206520080566, 0.837430477142334, 0.02838897705078125, 0.08775311708450317, 0.20644664764404297, -2.6325149536132812, -0.5368995666503906, -0.5307326316833496, 5.63724422454834, 0.7207813262939453, -0.8530368804931641, 0.8443527221679688, 0.06706881523132324, 0.25139808654785156, 0.9587745666503906, 0.21659469604492188, 0.4593672752380371, -1.0386314392089844, 1.6277918815612793, -1.642136573791504, -0.5760746002197266, 0.5767803192138672, 1.2942605018615723, 0.8218002319335938, 0.4593672752380371, 1.9570512771606445, -1.9994125366210938, 1.265533447265625, 0.29454803466796875, -8.549093246459961, 0.6136913299560547, 0.7287697792053223, -0.10454559326171875, -1.1207022666931152, 1.8350963592529297, -0.03490638732910156, 0.7583999633789062, -0.08225154876708984, -1.5359601974487305, 0.05906867980957031, 0.6760096549987793, 0.6031551361083984, 0.7176189422607422, 22.648656845092773, 0.06823921203613281, -7.29301643371582, -0.4875650405883789, -0.04489898681640625, -0.5632190704345703, -0.19083404541015625, 0.6653264760971069, 0.25238800048828125, -11.021129608154297, -0.32381629943847656, -6.205467700958252, 0.35661792755126953, -0.7592563629150391, 1.848581314086914, 0.6639270782470703, 0.3682079315185547, -0.6932878494262695, -0.06796836853027344, 1.094963550567627, 0.04473447799682617, -7.126552581787109, -0.2109394073486328, 1.5061321258544922, 0.010058403015136719, -0.043074846267700195, 0.8686599731445312, 1.7552025318145752, 0.8261308670043945, -0.8574657440185547, -0.42005157470703125, 0.5520534515380859, 0.19112205505371094, 0.2225513458251953, -0.1795177459716797, 0.7946767807006836, 0.10123157501220703, 2.1134376525878906, 0.13646697998046875, 0.21692276000976562, -0.06989097595214844, -0.08420753479003906, 0.1663188934326172, -0.14381790161132812, 1.1838407516479492, 0.2292032241821289, 0.10817813873291016, 0.1546233892440796, -0.2998771667480469, 0.6030540466308594, -0.0769968032836914, 0.08015060424804688, 1.5061321258544922, 0.3031158447265625, -0.18437957763671875, -0.3602619171142578, -0.5320587158203125, 0.04182243347167969, 0.7287697792053223, -0.28467559814453125, -0.5280055999755859, 1.5383014678955078, -0.19211769104003906, 0.4080371856689453, -1.6548895835876465, -0.3376293182373047, 1.1005878448486328, 0.0296630859375, 0.44515132904052734, 0.17385292053222656, 2.809314727783203, 0.9512519836425781, 0.2038736343383789, 0.5745067596435547, 2.182450294494629, 0.4761085510253906, -0.39571094512939453, -5.590516090393066, -0.35415077209472656, -1.6468219757080078, -0.23287200927734375, 0.5868206024169922, 0.8347692489624023, -0.3261435031890869, -0.3316478729248047, -0.44082164764404297, 0.49832916259765625, -1.1771869659423828, -0.08446407318115234, -0.22426414489746094, 0.1634674072265625, 0.9888029098510742, 0.5774459838867188, 0.4244823455810547, -0.057974815368652344, 0.08008480072021484, 0.221893310546875, 0.7512636184692383, -0.6637172698974609, -0.6073722839355469, 0.24643707275390625, 0.03856658935546875, 0.31601667404174805, -6.222658157348633, -0.3361663818359375, 0.4429655075073242, -1.804443359375, -0.1195526123046875, -5.780178070068359, -0.3387908935546875, 0.7207069396972656, 0.044010162353515625, 0.36226654052734375, -0.2868766784667969, -0.08794212341308594, -0.3096580505371094, -0.6203155517578125], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 58368, "num_env_steps_trained": 215280, "num_agent_steps_sampled": 58368, "num_agent_steps_trained": 215280, "last_target_update_ts": 58368, "num_target_updates": 113}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -81.56459072872997, "episode_len_mean": 252.32, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806], "episode_lengths": [262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5324290356210503, "mean_inference_ms": 24.601518309313423, "mean_action_processing_ms": 0.1350404433898883, "mean_env_wait_ms": 4.283252240242469, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -81.56459072872997, "episode_len_mean": 252.32, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-143.8761438652873, -32.8671308234334, -12.907385729253292, -51.64833015203476, 16.48566033691168, -71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806], "episode_lengths": [262, 223, 238, 247, 219, 269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5324290356210503, "mean_inference_ms": 24.601518309313423, "mean_action_processing_ms": 0.1350404433898883, "mean_env_wait_ms": 4.283252240242469, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 58368, "num_agent_steps_trained": 215280, "num_env_steps_sampled": 58368, "num_env_steps_trained": 215280, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 58368, "agent_timesteps_total": 58368, "timers": {"training_iteration_time_ms": 335.34, "learn_time_ms": 66.167, "learn_throughput": 3627.165, "synch_weights_time_ms": 20.49}, "counters": {"num_env_steps_sampled": 58368, "num_env_steps_trained": 215280, "num_agent_steps_sampled": 58368, "num_agent_steps_trained": 215280, "last_target_update_ts": 58368, "num_target_updates": 113}, "done": false, "episodes_total": 199, "training_iteration": 57, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-10", "timestamp": 1655478370, "time_this_iter_s": 5.422641277313232, "time_total_s": 301.1160168647766, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 301.1160168647766, "timesteps_since_restore": 0, "iterations_since_restore": 57, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.028571428571425, "ram_util_percent": 63.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 10.512921333312988, "min_q": -34.383209228515625, "max_q": 38.61025619506836, "mean_td_error": -0.43189918994903564}, "td_error": [-0.1673121452331543, -0.8891258239746094, -2.7321739196777344, -1.2471895217895508, -7.696939468383789, -0.6000857353210449, -0.038651466369628906, -0.7103481292724609, 1.2443084716796875, -0.007030487060546875, -0.012955665588378906, 0.5386085510253906, -2.9168739318847656, 1.4036121368408203, 1.2026538848876953, -0.9551706314086914, -0.3146963119506836, -0.05560111999511719, 0.5645899772644043, 0.7210404872894287, -0.3445770740509033, -0.00180816650390625, -0.061896324157714844, 0.5850000381469727, -4.59796142578125, 0.2687520980834961, -0.8462629318237305, -1.0650100708007812, 0.0004096031188964844, 1.9237499237060547, 2.6639862060546875, 1.6333599090576172, 0.2748889923095703, -6.997097015380859, -0.34094810485839844, -8.27490234375, -1.7050237655639648, -0.1946420669555664, -1.0132365226745605, -1.0031147003173828, -0.6412267684936523, 0.8247947692871094, 0.3845353126525879, 0.7110261917114258, -0.08182525634765625, -3.037578582763672, 0.8838472366333008, -1.5827980041503906, -1.622118353843689, -0.6134967803955078, -0.7231769561767578, -0.04599499702453613, -5.796293258666992, -1.0040531158447266, -2.861248016357422, 0.5902862548828125, -0.10113525390625, 15.580696105957031, -1.4091663360595703, -0.33339500427246094, 0.800389289855957, 0.04869651794433594, -0.8173036575317383, -0.272149920463562, 1.1931519508361816, 0.06453895568847656, -1.2599823474884033, 1.0819664001464844, -0.34369850158691406, -1.067251205444336, -0.1731891632080078, -0.7496852874755859, -1.528956413269043, -1.6181068420410156, 0.009346961975097656, -0.5177574157714844, -0.27911120653152466, -1.1571464538574219, -0.19110107421875, -3.8589000701904297, -0.7990589141845703, 1.3958687782287598, -0.9340004920959473, -0.4492936134338379, -1.243936538696289, 0.49363136291503906, 19.16556739807129, -1.7550544738769531, -0.9370613098144531, -0.9178657531738281, 0.40702342987060547, -0.9953327178955078, -0.06938552856445312, -2.147167205810547, -0.12920570373535156, -1.3984746932983398, -0.6621379852294922, 0.2625732421875, -0.49341392517089844, -0.38268566131591797, -4.22172737121582, -2.0432796478271484, -2.06329345703125, -0.2930259704589844, 18.62362289428711, -1.691831111907959, 0.7797379493713379, -1.3740711212158203, -1.6334495544433594, -5.498665809631348, -0.9561443328857422, -1.0146770477294922, -1.163309097290039, -0.411865234375, -0.9447991847991943, -5.701469421386719, -0.6490020751953125, 0.2670001983642578, -0.619070291519165, 1.3826408386230469, 0.72418212890625, -6.984195709228516, -0.3277759552001953, -1.2530221939086914, -1.1010007858276367, -0.5179100036621094, 1.0869722366333008, -0.9974422454833984, -0.49214744567871094, -6.58445930480957, -1.2443180084228516, 2.0415821075439453, -0.7317824363708496, -0.02260589599609375, -1.3343582153320312, -0.12570858001708984, -0.4353179931640625, -0.18425369262695312, 0.942448616027832, -0.7374372482299805, -0.1595630645751953, -1.0374836921691895, -6.937191009521484, -0.8000450134277344, 0.6334571838378906, -0.23992252349853516, -0.43952369689941406, -2.1337051391601562, 0.2748870849609375, -1.1580324172973633, -1.0074725151062012, -0.4635143280029297, 0.7921371459960938, -1.0861129760742188, 1.0984611511230469, -0.6245574951171875, -0.2995758056640625, 2.3440990447998047, 1.235182285308838, 0.4473695755004883, -6.944659233093262, 0.12357711791992188, 0.08943557739257812, 1.060983657836914, -0.5572967529296875, 0.1800689697265625, -0.16574668884277344, -0.19133567810058594, 0.009346961975097656, -0.1662311553955078, 17.005674362182617, 0.4031705856323242, -0.2920494079589844, 1.2248597145080566, 0.13198423385620117, -0.9335517883300781, 0.6385149955749512, -0.6503562927246094, -11.972434997558594, -2.416078567504883, 1.3129329681396484, 1.0400047302246094, -1.2519779205322266, -1.3281526565551758, -0.7620868682861328, -6.277655601501465, 5.726705551147461, -1.5088372230529785, -0.8945639133453369, -0.4542694091796875, 0.5517234802246094, -10.234176635742188, -0.9031710624694824, -6.866395950317383, -2.47528076171875, -0.6621379852294922, 1.1076464653015137, -1.2765769958496094, -1.3839645385742188, -0.058925628662109375, 0.7876100540161133, 1.0819664001464844, -0.3842277526855469, -0.47683238983154297, 0.31746768951416016, 0.16678786277770996, -1.0253009796142578, -0.6545600891113281, -0.6239309310913086, 0.8000822067260742, -1.5326039791107178, -1.1842327117919922, -1.622118353843689, -7.131043434143066, 0.25264453887939453, 17.465538024902344, 0.5072879791259766, -1.5312180519104004, 0.6068639755249023, -0.8408069610595703, 1.383535385131836, -0.5072565078735352, -1.274099349975586, -6.679300308227539, -2.995424270629883, -1.2108516693115234, -1.362412452697754, -0.3904151916503906, 1.932168960571289, 9.262653350830078, -0.2104015350341797, -0.7290353775024414, 0.6214714050292969, -1.8478546142578125, -0.42149925231933594, 0.47437000274658203, 0.42681026458740234, -0.8471012115478516, -1.3408222198486328, -0.9624404907226562], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 59392, "num_env_steps_trained": 219120, "num_agent_steps_sampled": 59392, "num_agent_steps_trained": 219120, "last_target_update_ts": 59392, "num_target_updates": 115}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -79.80293833181263, "episode_len_mean": 251.8, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477], "episode_lengths": [269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5330170244503479, "mean_inference_ms": 24.581452345460033, "mean_action_processing_ms": 0.13472515379802144, "mean_env_wait_ms": 4.286033504846283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -79.80293833181263, "episode_len_mean": 251.8, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-71.56412057578564, -101.44959555566311, -120.32444869726896, -16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477], "episode_lengths": [269, 261, 302, 259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5330170244503479, "mean_inference_ms": 24.581452345460033, "mean_action_processing_ms": 0.13472515379802144, "mean_env_wait_ms": 4.286033504846283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 59392, "num_agent_steps_trained": 219120, "num_env_steps_sampled": 59392, "num_env_steps_trained": 219120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 59392, "agent_timesteps_total": 59392, "timers": {"training_iteration_time_ms": 353.227, "learn_time_ms": 66.261, "learn_throughput": 3622.022, "synch_weights_time_ms": 20.288}, "counters": {"num_env_steps_sampled": 59392, "num_env_steps_trained": 219120, "num_agent_steps_sampled": 59392, "num_agent_steps_trained": 219120, "last_target_update_ts": 59392, "num_target_updates": 115}, "done": false, "episodes_total": 204, "training_iteration": 58, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-16", "timestamp": 1655478376, "time_this_iter_s": 5.462409973144531, "time_total_s": 306.57842683792114, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 306.57842683792114, "timesteps_since_restore": 0, "iterations_since_restore": 58, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.675, "ram_util_percent": 63.5125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 13.173029899597168, "min_q": -20.466777801513672, "max_q": 34.296024322509766, "mean_td_error": -0.20331448316574097}, "td_error": [-0.3596172332763672, -0.025650501251220703, 0.13939189910888672, 1.7218647003173828, 0.2825803756713867, -0.1923666000366211, 1.836836338043213, -0.7854347229003906, 0.6935365200042725, 2.3054962158203125, 0.041174888610839844, 0.9940032958984375, -1.3370602130889893, -0.04532909393310547, 0.3126106262207031, -0.16918563842773438, -1.0385990142822266, -0.9667701721191406, -10.5153226852417, 1.3338088989257812, 0.5703010559082031, 0.2899026870727539, -2.2121152877807617, -4.873882293701172, 0.1619243621826172, 0.0517277717590332, -0.22960758209228516, 0.032874107360839844, 0.2871885299682617, -0.28649139404296875, -1.0800819396972656, 0.7121745347976685, -0.09218811988830566, 0.6089715957641602, -1.1548843383789062, -9.730791091918945, -0.4937725067138672, -1.0358190536499023, -0.9746977090835571, 0.025575637817382812, 0.1928424835205078, -0.6779842376708984, 0.4206371307373047, 0.14457321166992188, -10.595081329345703, -0.7745342254638672, -1.2027168273925781, 0.5272163152694702, -9.611650466918945, 0.20967864990234375, -0.06319427490234375, -0.8456211090087891, 2.207872152328491, -1.1515522003173828, 2.346616268157959, -0.8630714416503906, -1.069838523864746, 2.805286407470703, 0.18724441528320312, -0.7640652656555176, 0.7374687194824219, -0.2350330352783203, 1.2642879486083984, -1.0080108642578125, -0.9364681243896484, 2.3054962158203125, -0.5402002334594727, -5.652713775634766, -0.189422607421875, -1.1336078643798828, -7.996739387512207, -0.9900894165039062, 0.01740264892578125, -0.7312145233154297, 0.3635902404785156, -0.05014801025390625, -0.017242431640625, -0.20580291748046875, -1.2876777648925781, 1.181722640991211, -0.4014139175415039, -6.1078948974609375, -0.1824493408203125, -1.8168516159057617, -0.9954013824462891, 2.3425827026367188, 0.8019571304321289, 0.5390839576721191, 0.8625569343566895, -6.002828598022461, -1.6103534698486328, 0.38085460662841797, 2.1426734924316406, 0.0014743804931640625, -0.46317338943481445, -0.39263153076171875, 0.8616828918457031, 0.7321186065673828, 2.0964317321777344, -5.39111328125, -0.15007781982421875, 0.30075645446777344, -5.040018081665039, -0.1505889892578125, 3.098278045654297, 2.7821133136749268, 0.4971122741699219, -0.7147021293640137, 0.08179092407226562, 1.5402274131774902, 13.471616744995117, 1.1761798858642578, 0.8033313751220703, -0.15428829193115234, -0.6589860916137695, -6.759732246398926, -2.1355667114257812, -7.671934127807617, -1.8428020477294922, -0.9029998779296875, 0.42624759674072266, -0.29340028762817383, 0.43307971954345703, 0.005532264709472656, 2.8050336837768555, -1.9118165969848633, -0.5179271697998047, 1.281773567199707, -0.5552463531494141, 1.6240625381469727, -1.7231225967407227, 0.4459266662597656, 2.5707130432128906, -0.6713733673095703, -0.5506134033203125, 3.347074508666992, 0.1630878448486328, 1.6319808959960938, 0.6372127532958984, 2.124176025390625, 19.55686378479004, -0.8345279693603516, 0.7319374084472656, 0.32698822021484375, 3.118445873260498, 2.346616268157959, 0.5770187377929688, 0.23974609375, 1.4405107498168945, -0.4829425811767578, 0.49751853942871094, -0.06438589096069336, 0.2952461242675781, 0.33034420013427734, 0.09733200073242188, -1.0847187042236328, -0.7029075622558594, -0.5537519454956055, -3.9605302810668945, -2.6045589447021484, 1.4409465789794922, 0.053363800048828125, 0.3281383514404297, 0.4454174041748047, 1.3823938369750977, -1.037276268005371, 0.8297344446182251, -0.33586978912353516, -1.4920005798339844, -0.5449413061141968, 0.2105579376220703, 0.8625569343566895, -0.8793716430664062, 1.4985289573669434, -0.15766382217407227, -2.1658315658569336, 0.21274948120117188, -0.2206554412841797, -3.6210479736328125, -0.7303361892700195, 2.6425490379333496, -1.2451305389404297, -0.20075035095214844, -1.7230782508850098, 2.8373260498046875, -0.163330078125, 0.11409854888916016, 1.2048618793487549, -0.17684268951416016, -5.773983001708984, -0.6567020416259766, -0.21783828735351562, 1.0580730438232422, 0.04566192626953125, -0.4698028564453125, -0.46520519256591797, -0.25960445404052734, 0.5817761421203613, -1.9653925895690918, 1.1757383346557617, -0.468902587890625, 0.1909961700439453, 0.23973846435546875, 0.5040493011474609, -5.448886871337891, 2.5707130432128906, -1.7522296905517578, -1.1992559432983398, 0.2638511657714844, 14.998443603515625, -2.563260078430176, -1.4597969055175781, 0.3042030334472656, -5.745185852050781, -0.14774131774902344, 0.2946128845214844, 2.007391929626465, -6.953056335449219, -0.7297220230102539, 4.141695022583008, -0.7590847015380859, 0.5107288360595703, -0.35185813903808594, 0.19272994995117188, -0.7478008270263672, -0.3234748840332031, -0.4506568908691406, 0.16547012329101562, 0.19130992889404297, 1.2003765106201172, 0.20050430297851562, 0.3612375259399414, -0.34783172607421875, 0.28055381774902344, 0.06804847717285156, 1.5721988677978516, -0.8372993469238281, 0.5815753936767578, -0.45332813262939453, 2.0514612197875977], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 60416, "num_env_steps_trained": 222960, "num_agent_steps_sampled": 60416, "num_agent_steps_trained": 222960, "last_target_update_ts": 60416, "num_target_updates": 117}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -78.47862520515919, "episode_len_mean": 250.97, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415], "episode_lengths": [259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5340276782525416, "mean_inference_ms": 24.588265623548615, "mean_action_processing_ms": 0.13480959870357492, "mean_env_wait_ms": 4.292873317764076, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -78.47862520515919, "episode_len_mean": 250.97, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-16.088699959218502, -394.4351999387145, -14.158048264682293, -421.01224774867296, 9.623855382204056, -17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415], "episode_lengths": [259, 361, 227, 377, 225, 225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5340276782525416, "mean_inference_ms": 24.588265623548615, "mean_action_processing_ms": 0.13480959870357492, "mean_env_wait_ms": 4.292873317764076, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 60416, "num_agent_steps_trained": 222960, "num_env_steps_sampled": 60416, "num_env_steps_trained": 222960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 60416, "agent_timesteps_total": 60416, "timers": {"training_iteration_time_ms": 340.254, "learn_time_ms": 66.889, "learn_throughput": 3588.035, "synch_weights_time_ms": 21.483}, "counters": {"num_env_steps_sampled": 60416, "num_env_steps_trained": 222960, "num_agent_steps_sampled": 60416, "num_agent_steps_trained": 222960, "last_target_update_ts": 60416, "num_target_updates": 117}, "done": false, "episodes_total": 207, "training_iteration": 59, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-21", "timestamp": 1655478381, "time_this_iter_s": 5.286831378936768, "time_total_s": 311.8652582168579, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 311.8652582168579, "timesteps_since_restore": 0, "iterations_since_restore": 59, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.775, "ram_util_percent": 63.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 12.523163795471191, "min_q": -31.86305809020996, "max_q": 43.13840103149414, "mean_td_error": -0.62969970703125}, "td_error": [1.3198261260986328, 0.6838779449462891, -0.8296031951904297, -0.8066253662109375, 0.06691455841064453, -1.855818748474121, 0.36655521392822266, -0.4948310852050781, 0.05548858642578125, -0.35941314697265625, -0.8981332778930664, 0.2867851257324219, -0.7044897079467773, 0.6965937614440918, -1.1591358184814453, 1.476790428161621, -1.0633902549743652, -2.5347347259521484, -0.2972068786621094, -1.1624393463134766, 0.06691455841064453, -0.8404426574707031, -0.43337249755859375, -0.4213237762451172, 2.6308374404907227, -0.43506717681884766, 0.6482486724853516, -0.43086719512939453, 0.5558948516845703, -0.25012683868408203, -2.303865432739258, 2.2517309188842773, 1.4927339553833008, -0.8366355895996094, -1.9562807083129883, 0.056705474853515625, -7.7250213623046875, -0.5151233673095703, 0.039603233337402344, -0.32327842712402344, -8.8126220703125, -1.9018827676773071, -0.00014400482177734375, -1.951131820678711, -0.6402902603149414, -1.3859500885009766, -5.838879108428955, -0.5087661743164062, -0.4653491973876953, -0.08095836639404297, 0.33117008209228516, 0.6386957168579102, -0.9179458618164062, -0.31332874298095703, 0.09714698791503906, -0.22751998901367188, -0.3217945098876953, 1.0690059661865234, 2.1284255981445312, 1.301961898803711, -12.469650268554688, -0.7409267425537109, -7.080782890319824, -0.39743614196777344, -0.21780014038085938, -0.19355392456054688, 0.2507801055908203, 0.40085411071777344, -1.4545636177062988, -0.4402809143066406, 0.8109464645385742, -0.36397743225097656, -0.3632030487060547, 0.9838705062866211, -0.7346677780151367, 0.3608684539794922, -0.18983840942382812, -0.2961692810058594, -1.3031272888183594, 0.2245330810546875, -0.33814334869384766, 0.023003101348876953, 0.015120506286621094, -0.019872665405273438, 0.9886283874511719, -2.1221795082092285, -0.8406352996826172, -1.299361228942871, 1.2956438064575195, -1.1039366722106934, -2.489353656768799, -0.2785968780517578, -0.4448890686035156, -5.898380279541016, 0.10171699523925781, -7.439210891723633, 0.25431644916534424, 0.5814762115478516, -0.34020328521728516, 0.593592643737793, 2.3152894973754883, 0.7054119110107422, -0.6387310028076172, -1.1082000732421875, 2.3152894973754883, -0.20804977416992188, -2.134432315826416, -0.9971904754638672, -0.5023574829101562, -0.6306324005126953, 0.024759292602539062, -1.5975050926208496, 0.8812408447265625, 0.5167217254638672, -0.7869176864624023, 1.9594039916992188, -0.5733108520507812, -0.21274757385253906, -0.6330699920654297, -0.2408294677734375, -1.2455215454101562, -1.822598934173584, -0.25623607635498047, -0.6489334106445312, -1.4201903343200684, -0.6036977767944336, 0.9309535026550293, -1.3807392120361328, -0.23515701293945312, -1.1786441802978516, -0.6082172393798828, -7.14335823059082, 1.5214033126831055, 1.6422348022460938, 0.758514404296875, -5.727316856384277, -0.38788890838623047, -1.0865411758422852, -1.2091426849365234, -0.46013832092285156, -0.2113037109375, -6.971223831176758, -0.5953006744384766, -0.7029733657836914, 8.182700157165527, -0.5725803375244141, 1.0291552543640137, 0.32691192626953125, 1.214498519897461, -0.4004087448120117, 0.24677658081054688, -2.763948440551758, 0.4857807159423828, -5.435024261474609, 0.06692910194396973, -0.04420900344848633, 1.762953758239746, -0.15945053100585938, -0.3965950012207031, -1.5093574523925781, -6.29408073425293, -0.7750396728515625, -0.13602256774902344, 0.3174114227294922, -0.08199548721313477, 1.762953758239746, 0.5387630462646484, -7.506497383117676, 0.5906562805175781, -0.6670479774475098, -0.3485450744628906, 0.34912776947021484, 0.6508541107177734, 1.4344444274902344, -1.0717182159423828, -0.11368846893310547, -2.825937271118164, 5.842628479003906, 0.702275276184082, -1.5327472686767578, -7.777839183807373, 0.3108081817626953, -0.9428520202636719, -0.3293638229370117, -0.137115478515625, -0.8503279685974121, -0.0288543701171875, -0.4199995994567871, -3.776611804962158, 0.9037117958068848, 0.039150238037109375, -8.070158004760742, -0.8228473663330078, -0.6091518402099609, 0.6733112335205078, -0.7098245620727539, 0.5653476715087891, 0.3633155822753906, 1.7008171081542969, 2.8114161491394043, -1.1896743774414062, 1.0610227584838867, 0.3499307632446289, 1.336040735244751, -0.37947845458984375, 1.7616262435913086, -0.5499191284179688, -0.5548372268676758, -0.11514616012573242, -1.076284408569336, -0.22909164428710938, -0.4144134521484375, 0.24306011199951172, -6.734840393066406, -0.5919284820556641, 1.3208963871002197, 0.33194732666015625, 0.4494762420654297, -0.8187294006347656, -0.009382247924804688, 0.057544708251953125, -1.1232185363769531, -0.8891067504882812, 0.8176403045654297, -0.2632617950439453, 1.7277631759643555, 0.04587745666503906, -6.538241386413574, 0.14374351501464844, -5.511102676391602, 1.4185600280761719, 0.8812732696533203, 0.201127290725708, -0.8962974548339844, -0.5718841552734375, 1.3198261260986328, -0.5197372436523438, -6.505775451660156, -0.5664682388305664, 1.9958229064941406], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 61440, "num_env_steps_trained": 226800, "num_agent_steps_sampled": 61440, "num_agent_steps_trained": 226800, "last_target_update_ts": 61440, "num_target_updates": 119}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -71.2648114093393, "episode_len_mean": 248.2, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364], "episode_lengths": [225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5350492977155065, "mean_inference_ms": 24.624027702171826, "mean_action_processing_ms": 0.13492920780947595, "mean_env_wait_ms": 4.299760335873236, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -71.2648114093393, "episode_len_mean": 248.2, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-17.19999996572733, 2.9000001177191734, -199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364], "episode_lengths": [225, 240, 300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5350492977155065, "mean_inference_ms": 24.624027702171826, "mean_action_processing_ms": 0.13492920780947595, "mean_env_wait_ms": 4.299760335873236, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 61440, "num_agent_steps_trained": 226800, "num_env_steps_sampled": 61440, "num_env_steps_trained": 226800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 61440, "agent_timesteps_total": 61440, "timers": {"training_iteration_time_ms": 348.595, "learn_time_ms": 65.867, "learn_throughput": 3643.695, "synch_weights_time_ms": 20.695}, "counters": {"num_env_steps_sampled": 61440, "num_env_steps_trained": 226800, "num_agent_steps_sampled": 61440, "num_agent_steps_trained": 226800, "last_target_update_ts": 61440, "num_target_updates": 119}, "done": false, "episodes_total": 212, "training_iteration": 60, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-27", "timestamp": 1655478387, "time_this_iter_s": 5.560133218765259, "time_total_s": 317.42539143562317, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 317.42539143562317, "timesteps_since_restore": 0, "iterations_since_restore": 60, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.1875, "ram_util_percent": 63.537499999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 13.927079200744629, "min_q": -30.161842346191406, "max_q": 40.49689483642578, "mean_td_error": -0.1156483069062233}, "td_error": [-4.941956520080566, 0.4237079620361328, 0.05375480651855469, -0.8453998565673828, -0.7211570739746094, 15.716889381408691, 0.7886505126953125, -2.317150115966797, -0.8949737548828125, 1.809071660041809, 0.4181022644042969, 0.4242715835571289, -0.3211355209350586, -0.49956417083740234, -0.1954517364501953, -0.26329898834228516, 0.4204120635986328, -0.7049274444580078, -0.034903526306152344, 0.05493640899658203, -0.38448095321655273, -0.5322284698486328, -0.5416297912597656, -0.7093009948730469, -0.9445590972900391, -0.054691314697265625, 0.36927101016044617, -0.0019845962524414062, 0.2905693054199219, -0.10407829284667969, -0.4768638610839844, 0.7883758544921875, -0.31517601013183594, -1.103257179260254, 0.35718631744384766, -8.852592468261719, -1.0253429412841797, 0.3094978332519531, -0.47311878204345703, -0.20508956909179688, 0.2109813690185547, 0.6227530241012573, 2.0567731857299805, 0.7490377426147461, -0.63397216796875, -0.014684677124023438, -0.910247802734375, -8.969888687133789, 0.25180721282958984, 0.3533821105957031, -8.969888687133789, -0.29939842224121094, 1.4726066589355469, -1.014169692993164, 0.8168735504150391, 0.3583717346191406, 1.5888347625732422, 1.2164535522460938, -0.5591907501220703, 0.1664600372314453, -0.5597934722900391, -0.6510829925537109, 0.051194190979003906, -1.7731876373291016, -0.34258556365966797, -5.959787368774414, 0.4660170078277588, -0.39655303955078125, 0.19381332397460938, -0.25614166259765625, 0.26949214935302734, -0.6762275695800781, -0.5965423583984375, -6.853865623474121, -0.9489965438842773, -5.550436019897461, 0.9419059753417969, 0.7214279174804688, 0.13856983184814453, 1.6765146255493164, -0.05739593505859375, -0.5196380615234375, -0.6161727905273438, 0.05050086975097656, -1.2375507354736328, 0.05050086975097656, -0.8332357406616211, -0.10792922973632812, 0.41379451751708984, 0.7966785430908203, -0.151519775390625, -0.33751392364501953, 0.5364551544189453, 2.738119125366211, -0.3862578868865967, 0.47051912546157837, -0.24134254455566406, 1.6872081756591797, 7.768619060516357, -6.752851486206055, -0.4896831512451172, -0.007293701171875, -0.21358489990234375, -0.45946407318115234, 1.7757854461669922, -0.31734657287597656, -1.0027179718017578, -0.13483428955078125, -5.451417922973633, -1.4392204284667969, -0.34713172912597656, -6.969303607940674, 0.2948570251464844, 1.109130859375, 0.44061756134033203, 0.31770896911621094, 0.6282138824462891, 0.3191852569580078, -0.6838397979736328, -0.6153736114501953, 0.28632640838623047, -1.6273384094238281, 0.10290908813476562, -0.18408203125, 0.3065814971923828, -6.3836164474487305, -1.0120339393615723, 0.9967784881591797, 0.5608844757080078, -6.102426528930664, -1.683328628540039, -9.038063049316406, 0.9384841918945312, 1.1691522598266602, 0.8465846180915833, 0.12163293361663818, -0.3254566192626953, 0.15484237670898438, -0.06079864501953125, 0.1319732666015625, 1.7796297073364258, -1.0679874420166016, -0.7434930801391602, -0.46260833740234375, 0.9773283004760742, -0.050853729248046875, 19.330215454101562, 0.9000949859619141, 0.5133380889892578, 0.7062082290649414, -0.732111930847168, -0.23239707946777344, -0.1558399200439453, -0.4762401580810547, -0.4688911437988281, 0.10770034790039062, 4.089023590087891, 0.6317920684814453, -0.09190559387207031, 1.5122623443603516, 2.9148120880126953, -0.051544189453125, 1.3936614990234375, -0.5933876037597656, 0.4187498092651367, 5.599631309509277, 0.5688533782958984, 0.11522293090820312, 0.06848335266113281, 0.23218727111816406, -0.6160678863525391, -0.5143775939941406, -0.20299386978149414, 0.1662912368774414, 0.43973731994628906, -0.6670703887939453, -0.39910411834716797, 1.2126293182373047, 1.129018783569336, 0.23711585998535156, -0.4273262023925781, -0.8660964965820312, -0.31734657287597656, 1.2591419219970703, -1.4355535507202148, 0.42224597930908203, 20.797996520996094, -0.08734893798828125, -8.933516502380371, 2.6575489044189453, 2.405085563659668, 0.6378421783447266, -0.4479045867919922, 1.1552839279174805, 0.38970088958740234, -0.6334514617919922, -10.101009368896484, -0.22319984436035156, -0.43829345703125, -0.8802413940429688, -1.467972755432129, -0.3578643798828125, 0.0768890380859375, -0.6493587493896484, 0.0581817626953125, 0.035559654235839844, -0.016473770141601562, -0.23459815979003906, -0.23759174346923828, 0.2681121826171875, -7.74691104888916, -0.20999908447265625, -0.39655303955078125, 1.7991352081298828, 1.127856731414795, 0.5422153472900391, 0.2597389221191406, 0.015573501586914062, -9.615147590637207, 0.7184486389160156, -0.17974281311035156, -1.041642189025879, 1.8589630126953125, -0.28722429275512695, -0.6811037063598633, 0.675537109375, 0.41471290588378906, 1.0481481552124023, -5.53978157043457, 0.5222702026367188, -1.2016931772232056, -0.7027454376220703, -0.34943199157714844, 0.7022819519042969, -0.10163497924804688, -0.11676692962646484, 0.5938968658447266, -1.137136459350586, 18.47064781188965, 0.505645751953125], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 62464, "num_env_steps_trained": 230640, "num_agent_steps_sampled": 62464, "num_agent_steps_trained": 230640, "last_target_update_ts": 62464, "num_target_updates": 121}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -72.41220239169895, "episode_len_mean": 248.86, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058], "episode_lengths": [300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5353659537615908, "mean_inference_ms": 24.62101167002164, "mean_action_processing_ms": 0.13476868604489703, "mean_env_wait_ms": 4.299433168707517, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -72.41220239169895, "episode_len_mean": 248.86, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-199.43688210099936, -166.97614414989948, 2.708657532930374, -20.633222565054893, -424.9830047786236, -8.334311500191689, -147.0493225455284, -155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058], "episode_lengths": [300, 278, 242, 244, 351, 246, 276, 273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5353659537615908, "mean_inference_ms": 24.62101167002164, "mean_action_processing_ms": 0.13476868604489703, "mean_env_wait_ms": 4.299433168707517, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 62464, "num_agent_steps_trained": 230640, "num_env_steps_sampled": 62464, "num_env_steps_trained": 230640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 62464, "agent_timesteps_total": 62464, "timers": {"training_iteration_time_ms": 327.7, "learn_time_ms": 66.929, "learn_throughput": 3585.879, "synch_weights_time_ms": 20.289}, "counters": {"num_env_steps_sampled": 62464, "num_env_steps_trained": 230640, "num_agent_steps_sampled": 62464, "num_agent_steps_trained": 230640, "last_target_update_ts": 62464, "num_target_updates": 121}, "done": false, "episodes_total": 214, "training_iteration": 61, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-33", "timestamp": 1655478393, "time_this_iter_s": 5.260889530181885, "time_total_s": 322.68628096580505, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 322.68628096580505, "timesteps_since_restore": 0, "iterations_since_restore": 61, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.7375, "ram_util_percent": 63.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.133011817932129, "min_q": -26.97478485107422, "max_q": 41.31876754760742, "mean_td_error": -0.7570409774780273}, "td_error": [-1.4450721740722656, -0.23936080932617188, -0.2208385467529297, -1.0611743927001953, -0.5057039260864258, -4.930950164794922, -0.36975574493408203, -0.2764778137207031, -0.5394878387451172, -0.4627265930175781, -0.15841293334960938, -0.5592670440673828, 0.0028181076049804688, -0.3710298538208008, -1.2474212646484375, 0.24599075317382812, -1.1289119720458984, -4.3127288818359375, -0.4521217346191406, -0.6657028198242188, -0.4780998229980469, -0.5202112197875977, -0.5617198944091797, -1.6772890090942383, -0.7875566482543945, -1.4210166931152344, -1.0395069122314453, 0.024573326110839844, 0.5072422027587891, -1.219320297241211, -0.4299964904785156, -0.46926307678222656, -0.7089614868164062, -0.33774757385253906, 0.4486246109008789, -0.50384521484375, -0.45995426177978516, -0.5533676147460938, -1.679448127746582, -0.11988639831542969, -0.49901771545410156, -0.5645904541015625, -1.457859992980957, -1.2793073654174805, -0.40561866760253906, -0.03712654113769531, -13.178163528442383, -0.2536659240722656, -0.3819847106933594, -2.0617456436157227, -1.44158935546875, -1.7096519470214844, -6.0163726806640625, -0.5735931396484375, -0.22179806232452393, 0.44951820373535156, -0.689082145690918, -1.4404163360595703, 0.027257919311523438, 1.0112972259521484, -2.4821786880493164, 0.021900177001953125, 0.4076824188232422, -0.2684192657470703, -0.5294399261474609, 0.9918975830078125, -0.9176864624023438, 0.9191021919250488, -0.08123397827148438, -0.7640743255615234, -0.3840351104736328, -2.5257177352905273, -1.4334907531738281, -0.2162799835205078, 0.08736038208007812, -1.3076038360595703, -0.33588504791259766, -0.5196304321289062, -0.7132205963134766, -1.0535755157470703, 1.2423295974731445, -1.2667646408081055, -1.13104248046875, -0.6846790313720703, -1.6630792617797852, -0.8112826347351074, 21.56679916381836, -0.8776369094848633, -0.8430557250976562, -0.5090904235839844, 0.7804546356201172, -2.1375350952148438, -0.3819608688354492, -0.119293212890625, -1.5025978088378906, -0.4944877624511719, -0.8954219818115234, 0.3046388626098633, -1.4425239562988281, -0.5071239471435547, -7.138708114624023, -0.060530662536621094, -3.4458131790161133, 0.059970855712890625, 14.610530853271484, -0.108551025390625, 0.0633249282836914, 0.8492870330810547, -0.6346244812011719, -0.2034893035888672, 0.5775632858276367, -1.003509521484375, -0.24666404724121094, -0.8267745971679688, 1.2277870178222656, -0.4866046905517578, -0.9732742309570312, -0.667755126953125, -1.6266918182373047, 0.15386152267456055, -5.379161834716797, 0.19579124450683594, -0.4696817398071289, 20.397653579711914, -1.508544921875, -0.4551877975463867, -1.5727767944335938, -0.33010387420654297, 1.1349983215332031, -0.4859499931335449, -2.4056453704833984, -1.7644386291503906, -6.430974006652832, -0.5254592895507812, -0.3048820495605469, -1.5394811630249023, -0.3934497833251953, -6.991022109985352, -3.092474937438965, -0.5200233459472656, -2.0221099853515625, -0.9984474182128906, -2.2180447578430176, -0.7100048065185547, 0.575965404510498, -1.331629753112793, -1.2820682525634766, 0.17045021057128906, -0.7945613861083984, 13.58470630645752, -0.4196596145629883, -0.1521930694580078, -1.0474185943603516, -0.7744884490966797, -1.5010147094726562, -0.2984275817871094, -1.7286505699157715, -8.490364074707031, -0.5310821533203125, -0.05256462097167969, -0.030139923095703125, -0.5099887847900391, -0.8920726776123047, -1.8463859558105469, -0.8820724487304688, 0.027257919311523438, 0.250335693359375, -5.03875732421875, -1.255258560180664, -0.5259075164794922, -0.6217250823974609, 0.0509490966796875, -0.8205509185791016, -0.8482742309570312, -0.6393938064575195, -1.7211761474609375, -1.3627090454101562, -0.7303085327148438, -1.0246086120605469, -1.0046234130859375, -0.9375705718994141, -2.0593318939208984, -0.15069007873535156, -0.8963966369628906, -0.18655776977539062, 0.027313232421875, -0.6980800628662109, -7.873371124267578, 0.7917060852050781, -0.7221174240112305, -0.5448799133300781, -1.696981430053711, -7.088747978210449, -0.7603397369384766, -0.9252986907958984, 0.5884208679199219, -2.3668365478515625, -0.8102092742919922, -0.13402843475341797, -2.1229114532470703, -2.85842227935791, -0.4114265441894531, -0.31864452362060547, -1.364603042602539, -1.3442535400390625, -1.526519775390625, 0.7071523666381836, -0.5100765228271484, -2.22298526763916, -0.4251279830932617, -0.7860012054443359, -0.49085235595703125, -0.40808677673339844, -1.232187271118164, -0.16531944274902344, -0.04871368408203125, -0.6243057250976562, -1.0162029266357422, -1.8012734651565552, -0.6018381118774414, -0.7206401824951172, -0.24163436889648438, 1.0748281478881836, -8.798137664794922, -1.045217514038086, -0.30736732482910156, -1.6540679931640625, 0.41559314727783203, -0.16649436950683594, 0.22212982177734375, -6.775808334350586, -3.7995285987854004, -0.06641674041748047, -7.155524253845215, 0.7974672317504883, -0.531926155090332, 0.055889129638671875, -0.5993156433105469, -0.5506992340087891, -0.17139816284179688], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 63488, "num_env_steps_trained": 234480, "num_agent_steps_sampled": 63488, "num_agent_steps_trained": 234480, "last_target_update_ts": 63488, "num_target_updates": 123}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -64.3899331329763, "episode_len_mean": 245.93, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754], "episode_lengths": [273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5371669923750642, "mean_inference_ms": 24.642061285442022, "mean_action_processing_ms": 0.13441015433792208, "mean_env_wait_ms": 4.31204971071291, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -64.3899331329763, "episode_len_mean": 245.93, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-155.36700096726418, -183.577636256814, 11.100000090897083, -107.85617540031672, -407.83948178589344, 5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754], "episode_lengths": [273, 269, 233, 249, 358, 207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5371669923750642, "mean_inference_ms": 24.642061285442022, "mean_action_processing_ms": 0.13441015433792208, "mean_env_wait_ms": 4.31204971071291, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 63488, "num_agent_steps_trained": 234480, "num_env_steps_sampled": 63488, "num_env_steps_trained": 234480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 63488, "agent_timesteps_total": 63488, "timers": {"training_iteration_time_ms": 338.879, "learn_time_ms": 67.007, "learn_throughput": 3581.694, "synch_weights_time_ms": 21.187}, "counters": {"num_env_steps_sampled": 63488, "num_env_steps_trained": 234480, "num_agent_steps_sampled": 63488, "num_agent_steps_trained": 234480, "last_target_update_ts": 63488, "num_target_updates": 123}, "done": false, "episodes_total": 221, "training_iteration": 62, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-38", "timestamp": 1655478398, "time_this_iter_s": 5.582744598388672, "time_total_s": 328.2690255641937, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 328.2690255641937, "timesteps_since_restore": 0, "iterations_since_restore": 62, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.15, "ram_util_percent": 63.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.61811351776123, "min_q": -28.51812171936035, "max_q": 34.01829147338867, "mean_td_error": 0.025957616046071053}, "td_error": [0.9650897979736328, -0.6610145568847656, -1.0297832489013672, 0.8294944763183594, 1.749969482421875, -0.16126632690429688, -2.0863828659057617, 1.3745381832122803, 0.054625511169433594, -7.114902496337891, 0.10688400268554688, -0.4524059295654297, -1.1711807250976562, 0.039216041564941406, -0.49448490142822266, 0.7059831619262695, 0.09257125854492188, -5.362302780151367, 18.815778732299805, 12.961353302001953, -0.373138427734375, -1.3283653259277344, 0.3599891662597656, 0.2797393798828125, -7.3639421463012695, 0.7372326850891113, 0.16805076599121094, 0.3962574005126953, 0.7370834350585938, -1.4148340225219727, -8.669075012207031, 1.2064704895019531, -10.348800659179688, 1.1960430145263672, 0.2945108413696289, 0.5784912109375, -1.465627670288086, 1.2233023643493652, -0.2075643539428711, -1.8224773406982422, 1.3416023254394531, 2.9150733947753906, 0.7326316833496094, -0.08212852478027344, -0.9730854034423828, 2.8128514289855957, 0.39433765411376953, 2.624837875366211, -0.40680980682373047, -0.9069051742553711, 0.008821487426757812, -0.2700977325439453, -22.586820602416992, 0.5301437377929688, 0.4829425811767578, -0.8665103912353516, -1.1355514526367188, 1.7996158599853516, -0.5525259971618652, 0.44431114196777344, 0.002246856689453125, -0.14542388916015625, -0.5166797637939453, -0.77496337890625, -1.2433099746704102, 0.3206939697265625, -0.8037872314453125, 0.1168975830078125, -0.1662578582763672, 0.5487403869628906, 1.4715404510498047, 0.48611927032470703, -1.2093000411987305, 1.3988165855407715, -1.158041000366211, 0.5725889205932617, 0.2913799285888672, -0.3412609100341797, -0.4422464370727539, -2.689004898071289, 0.2084646224975586, 22.076478958129883, 0.30298805236816406, -0.40305519104003906, 0.03728485107421875, 0.021030902862548828, -0.15975379943847656, -0.19664859771728516, -1.1888952255249023, 13.535368919372559, -0.26387691497802734, -0.57672119140625, -5.592413902282715, -6.050685882568359, 0.6049718856811523, 0.2242450714111328, 0.4213981628417969, -0.9201326370239258, -0.8574733734130859, -0.9851512908935547, 1.9225730895996094, -5.397937774658203, 0.9201269149780273, -3.8489952087402344, -0.05266857147216797, 0.4220752716064453, -0.06015205383300781, 0.9915180206298828, 0.26868438720703125, 1.9211311340332031, 0.013181686401367188, 2.345472812652588, 1.1239323616027832, 0.38413524627685547, 8.609060287475586, -6.683704376220703, -0.4640693664550781, 0.1831378936767578, -0.20758438110351562, 0.03425407409667969, -4.582700729370117, 0.7323474884033203, -0.015491485595703125, 1.9724502563476562, 0.008873939514160156, -0.176513671875, -1.3104209899902344, -0.7273044586181641, -1.0252094268798828, -0.24139022827148438, 0.5738191604614258, 0.9682464599609375, -0.36493873596191406, 0.5120868682861328, 0.4035968780517578, -0.05646705627441406, 0.01183319091796875, -0.815582275390625, 0.4155759811401367, 1.687831163406372, 0.13065338134765625, -9.580636978149414, 0.6868476867675781, -0.4263019561767578, 0.1944866180419922, 0.647658109664917, 1.088547706604004, 0.4012775421142578, -0.031780242919921875, -0.009824752807617188, 0.2054424285888672, -0.020326614379882812, 0.5788459777832031, 0.14956092834472656, -0.8972654342651367, -0.008687973022460938, -1.9552850723266602, -0.7048196792602539, -0.2699394226074219, -0.2865467071533203, -10.889636993408203, -1.3640003204345703, -0.6498422622680664, 0.7627277374267578, 1.3831939697265625, -0.5362548828125, -5.15804386138916, 1.116654396057129, 0.9727058410644531, 1.2741241455078125, 0.22938060760498047, 1.117422103881836, 0.11151885986328125, -0.09231185913085938, 0.3420257568359375, 1.9524240493774414, -7.32869815826416, 0.262420654296875, 0.0634765625, 2.171205520629883, 0.039216041564941406, 2.125822067260742, 0.08685302734375, 16.11685562133789, 0.8216762542724609, 0.12201881408691406, 0.5034523010253906, -0.45586204528808594, 1.0528030395507812, -0.04060554504394531, -0.011851310729980469, 0.6356430053710938, -0.0043487548828125, 3.717696189880371, 1.9509963989257812, 0.30938148498535156, -1.2801990509033203, -1.029409408569336, -0.21596622467041016, -8.721342086791992, -0.9871730804443359, 11.518379211425781, -0.5115032196044922, 0.36386871337890625, 0.11268424987792969, 0.19954872131347656, -0.3234062194824219, 1.2742137908935547, -0.9900798797607422, 0.25122833251953125, 0.5419654846191406, -0.10060691833496094, -0.19291378557682037, 0.7036895751953125, 0.4056129455566406, 0.5250682830810547, -0.22952651977539062, 0.1837158203125, -0.27823543548583984, 1.8682022094726562, -0.1646270751953125, 1.7081317901611328, 0.05011558532714844, 2.5211639404296875, 2.0659570693969727, 0.3267059326171875, -0.09087944030761719, -0.8063907623291016, -0.4473609924316406, 0.9514579772949219, -0.6446342468261719, 0.3545036315917969, 0.14306068420410156, -2.061208724975586, 0.13886451721191406, 0.5652236938476562, -1.2429485321044922, -0.009946823120117188, 0.9514579772949219, 0.22837257385253906], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 64512, "num_env_steps_trained": 238320, "num_agent_steps_sampled": 64512, "num_agent_steps_trained": 238320, "last_target_update_ts": 64512, "num_target_updates": 125}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -56.486334244161846, "episode_len_mean": 243.27, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246], "episode_lengths": [207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5384665530089184, "mean_inference_ms": 24.64822167776581, "mean_action_processing_ms": 0.1346975091935282, "mean_env_wait_ms": 4.316386242784326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -56.486334244161846, "episode_len_mean": 243.27, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [5.3000000566244125, 3.7389137372374535, 10.610635615885258, -78.19263193756342, -52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246], "episode_lengths": [207, 226, 209, 271, 253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5384665530089184, "mean_inference_ms": 24.64822167776581, "mean_action_processing_ms": 0.1346975091935282, "mean_env_wait_ms": 4.316386242784326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 64512, "num_agent_steps_trained": 238320, "num_env_steps_sampled": 64512, "num_env_steps_trained": 238320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 64512, "agent_timesteps_total": 64512, "timers": {"training_iteration_time_ms": 341.328, "learn_time_ms": 66.349, "learn_throughput": 3617.218, "synch_weights_time_ms": 21.0}, "counters": {"num_env_steps_sampled": 64512, "num_env_steps_trained": 238320, "num_agent_steps_sampled": 64512, "num_agent_steps_trained": 238320, "last_target_update_ts": 64512, "num_target_updates": 125}, "done": false, "episodes_total": 226, "training_iteration": 63, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-44", "timestamp": 1655478404, "time_this_iter_s": 5.49041748046875, "time_total_s": 333.7594430446625, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 333.7594430446625, "timesteps_since_restore": 0, "iterations_since_restore": 63, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.9625, "ram_util_percent": 63.6125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.024011611938477, "min_q": -26.47618293762207, "max_q": 32.460289001464844, "mean_td_error": -0.4388866126537323}, "td_error": [-0.35301780700683594, 0.4117317199707031, 0.2774524688720703, 0.19110965728759766, 11.265987396240234, 0.31082916259765625, -0.4022541046142578, -1.1329269409179688, 0.012575149536132812, 0.12014484405517578, -0.0990142822265625, 0.3116130828857422, -7.110774993896484, 0.15249872207641602, -7.082571029663086, -0.5624265670776367, 1.1303024291992188, -0.4518604278564453, -6.1356964111328125, -0.2617912292480469, -0.5661487579345703, -0.5594682693481445, 0.04057884216308594, -0.4069957733154297, -0.8278999328613281, -0.5011577606201172, -0.3064274787902832, 20.21361541748047, -0.2931528091430664, 0.11126708984375, -5.080623626708984, -1.495849609375, 0.06568527221679688, -0.4478464126586914, 0.14890480041503906, -0.7109813690185547, -0.7444963455200195, -7.9015679359436035, -0.934138298034668, -0.48822021484375, -2.418405532836914, -0.49791717529296875, -0.38792991638183594, -1.1624507904052734, -0.5906925201416016, 0.3450784683227539, -0.40204715728759766, 1.140507698059082, -7.391950607299805, 0.2107677459716797, -0.588496208190918, 0.9526882171630859, -7.657728672027588, 0.5311851501464844, 0.4095582962036133, -0.7741975784301758, 0.9347429275512695, -0.3071422576904297, -0.36391639709472656, -0.22124195098876953, 11.918207168579102, -0.13115692138671875, 0.1687793731689453, -0.7873439788818359, 0.6992340087890625, -0.726008415222168, -4.797380447387695, -1.5659160614013672, -0.2791404724121094, 0.43118858337402344, -0.1553363800048828, -0.66131591796875, 0.5624666213989258, -0.039038658142089844, -1.3629734516143799, -0.39167022705078125, 0.9434814453125, 1.0738887786865234, -0.9738550186157227, -0.0050601959228515625, 0.007323265075683594, -0.30517005920410156, -0.22728872299194336, 0.23784732818603516, -2.6989517211914062, 0.0087432861328125, -0.30940914154052734, -0.3014087677001953, 0.5292320251464844, -1.1972179412841797, 0.3117694854736328, -0.39377784729003906, 0.150909423828125, -0.33540821075439453, -0.7397942543029785, -7.12352180480957, -1.0431432723999023, 0.9108200073242188, 0.5869646072387695, -1.5041217803955078, 0.11196517944335938, 0.2757749557495117, 0.08349227905273438, -0.4217987060546875, 1.3653850555419922, 0.2636451721191406, -0.5323047637939453, -0.2584066390991211, -0.11296939849853516, 0.7867240905761719, 0.13806915283203125, 0.9000949859619141, 1.3676013946533203, 0.14388465881347656, -0.98980712890625, -0.3762645721435547, 0.1024932861328125, 0.004679858684539795, -0.7659482955932617, -0.19202041625976562, -0.5044479370117188, 0.3932228088378906, -1.3213119506835938, -0.3204202651977539, 0.30028343200683594, -12.336931228637695, -1.8606595993041992, -7.1806230545043945, -0.4022541046142578, 0.8505697250366211, 0.10221672058105469, -0.09755325317382812, -1.3088083267211914, 0.12874126434326172, -0.22531604766845703, 1.101557731628418, -0.9690828323364258, -0.46361637115478516, 0.9720916748046875, -0.0940093994140625, 1.4516220092773438, 0.06677627563476562, 0.3705253601074219, -0.32296228408813477, 0.1513051986694336, -9.17049789428711, -0.5223217010498047, 0.028173446655273438, -0.20146846771240234, -0.4299774169921875, -6.8056793212890625, 0.17798519134521484, 0.3594398498535156, -0.7660732269287109, -1.2924766540527344, 1.1767082214355469, -1.948434829711914, -0.7681121826171875, 2.0561532974243164, -7.264561653137207, 1.0984764099121094, -1.1619482040405273, -0.32311534881591797, -0.28768157958984375, -0.4869880676269531, -0.03679084777832031, 8.096006393432617, 0.1275959014892578, -0.6065273284912109, 0.24457168579101562, -7.36578369140625, 1.6471061706542969, 0.22629737854003906, -7.087466716766357, -2.173440933227539, -0.607673168182373, -0.6529960632324219, 0.33000850677490234, 0.0007991790771484375, 0.7288417816162109, 0.2042522430419922, -0.5546541213989258, -0.6726617813110352, 3.4734249114990234, -0.31201171875, -1.0930852890014648, -2.045840263366699, -0.2279491424560547, -1.3592538833618164, -0.4353371858596802, -0.09298515319824219, 5.112260818481445, 0.01557159423828125, -6.642223358154297, -1.958292007446289, -0.5763111114501953, -1.134073257446289, -0.3704538345336914, -0.5597553253173828, 0.24053287506103516, 12.611319541931152, -0.19559860229492188, -2.8764095306396484, 0.0979013442993164, -0.044386863708496094, -1.6929092407226562, 1.3379316329956055, -0.9389324188232422, 0.39118480682373047, 1.8378105163574219, 0.1507730484008789, -0.21522235870361328, -0.06396293640136719, -0.24755001068115234, 0.8766212463378906, -0.6237525939941406, -0.06865310668945312, 0.10049057006835938, -0.5118026733398438, -1.1244592666625977, -0.05689048767089844, -0.3029289245605469, -0.7377967834472656, -0.45116233825683594, -0.26514625549316406, 0.6431198120117188, -5.612856864929199, -1.2255144119262695, -0.6720352172851562, -0.7448825836181641, 0.30925655364990234, 0.038814544677734375, 0.03756999969482422, 1.2033424377441406, 0.04497528076171875, -7.658456325531006, 1.2328262329101562, 0.15443992614746094, 0.11049509048461914, -0.05770111083984375], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 65536, "num_env_steps_trained": 242160, "num_agent_steps_sampled": 65536, "num_agent_steps_trained": 242160, "last_target_update_ts": 65536, "num_target_updates": 127}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -57.43649754360318, "episode_len_mean": 243.69, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346], "episode_lengths": [253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5391692897098298, "mean_inference_ms": 24.663844393263517, "mean_action_processing_ms": 0.13462824535924678, "mean_env_wait_ms": 4.322559798644924, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -57.43649754360318, "episode_len_mean": 243.69, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-52.004113011062145, 7.9137153178453445, 31.712017722427845, 5.90000007301569, -28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346], "episode_lengths": [253, 199, 210, 199, 237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5391692897098298, "mean_inference_ms": 24.663844393263517, "mean_action_processing_ms": 0.13462824535924678, "mean_env_wait_ms": 4.322559798644924, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 65536, "num_agent_steps_trained": 242160, "num_env_steps_sampled": 65536, "num_env_steps_trained": 242160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 65536, "agent_timesteps_total": 65536, "timers": {"training_iteration_time_ms": 351.033, "learn_time_ms": 68.668, "learn_throughput": 3495.053, "synch_weights_time_ms": 21.789}, "counters": {"num_env_steps_sampled": 65536, "num_env_steps_trained": 242160, "num_agent_steps_sampled": 65536, "num_agent_steps_trained": 242160, "last_target_update_ts": 65536, "num_target_updates": 127}, "done": false, "episodes_total": 230, "training_iteration": 64, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-50", "timestamp": 1655478410, "time_this_iter_s": 5.561349391937256, "time_total_s": 339.32079243659973, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 339.32079243659973, "timesteps_since_restore": 0, "iterations_since_restore": 64, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 37.5, "ram_util_percent": 63.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.605183601379395, "min_q": -26.970596313476562, "max_q": 33.52455139160156, "mean_td_error": -0.3862072229385376}, "td_error": [-7.747112274169922, -0.6103944778442383, -0.4474048614501953, 0.43021392822265625, -0.08604049682617188, -0.7757053375244141, -0.9197177886962891, -0.31124305725097656, -0.3704681396484375, -2.2779064178466797, -0.2530498504638672, -0.4769935607910156, 1.0195059776306152, -0.19838333129882812, -0.08907890319824219, -0.22817039489746094, 0.6526393890380859, 0.05081939697265625, 1.0665302276611328, 0.09385299682617188, 1.783393144607544, -0.7785406112670898, -0.4389810562133789, -0.5776786804199219, 0.1699962615966797, -0.18271446228027344, -1.4807014465332031, -0.34831905364990234, 0.044704437255859375, 0.14519119262695312, 1.5159626007080078, -0.5306921005249023, 0.6471700668334961, -4.97770881652832, -0.3262481689453125, 1.5971736907958984, 0.05373191833496094, 1.1168689727783203, -0.6377735137939453, -0.9329853057861328, -0.28518009185791016, -0.042591094970703125, 0.29642677307128906, -0.9833106994628906, -0.33890247344970703, -0.3924560546875, -0.34738731384277344, -1.0791015625, -0.6181631088256836, -0.1048116683959961, -0.041167259216308594, 0.8952049016952515, -1.041015625, -0.6072425842285156, 0.5400180816650391, -1.7595195770263672, -0.6896152496337891, -0.2075328826904297, 0.10698127746582031, 1.020181655883789, 0.17683982849121094, 20.133819580078125, 0.1334095001220703, 0.023097991943359375, -1.8193416595458984, -0.6525936126708984, -0.1276702880859375, -0.35214996337890625, -0.37950897216796875, -0.39308929443359375, 0.24264836311340332, -0.5850429534912109, 0.4779205322265625, -0.42647361755371094, -1.4603767395019531, -1.467702865600586, -0.6115360260009766, 0.7227516174316406, 0.15654945373535156, 0.03602790832519531, -0.031406402587890625, -0.518547534942627, 0.10918617248535156, -0.2202606201171875, -0.13373279571533203, -0.6209163665771484, -0.35559654235839844, -1.1551856994628906, -0.8614501953125, -0.17462158203125, -0.201507568359375, -0.4096088409423828, -0.15608882904052734, -0.02214527130126953, -0.5693540573120117, 0.3148508071899414, -0.36714744567871094, -0.30226707458496094, 0.3212871551513672, 1.4574260711669922, 0.0850982666015625, 0.41631221771240234, -1.3900327682495117, 0.5304431915283203, -0.36933326721191406, -0.29328155517578125, 0.0049896240234375, -0.38886260986328125, -0.5115108489990234, -0.3990058898925781, 0.9633884429931641, 0.2633056640625, -0.12005615234375, -0.6445465087890625, -0.6877622604370117, -0.41257667541503906, 0.874302864074707, -7.097718238830566, -0.4857395887374878, -0.2291736602783203, 0.42079639434814453, 0.3154335021972656, -2.0932605266571045, -0.9626140594482422, -0.5463333129882812, 1.0321989059448242, 0.031577110290527344, 0.5121536254882812, -0.17418146133422852, -7.113157272338867, -0.2627449035644531, 0.2327861785888672, 0.378173828125, -0.15429925918579102, -0.1596050262451172, -0.46848487854003906, -0.35787105560302734, -0.8167047500610352, 1.0871238708496094, -0.3352012634277344, -0.7017974853515625, -0.43009471893310547, 0.23424053192138672, 0.0013408660888671875, -0.6058034896850586, -22.519628524780273, -0.2878570556640625, 0.5488226413726807, -0.09878730773925781, -0.055563926696777344, -0.2181873321533203, 0.755218505859375, 0.21909713745117188, -6.927835464477539, 0.39415550231933594, -0.2463531494140625, -0.8771724700927734, -0.20323944091796875, 0.2960205078125, -0.7833757400512695, -1.1319150924682617, -0.1806812286376953, -0.735041618347168, 0.4006462097167969, 0.7886075973510742, -0.752960205078125, -0.10883712768554688, -4.145725250244141, -0.1264476776123047, 0.07412433624267578, 0.2378520965576172, -0.4233207702636719, 0.8948516845703125, 0.7835292816162109, -0.29193687438964844, -0.642308235168457, -1.0978240966796875, -0.049015045166015625, -0.6021080017089844, -0.17922115325927734, -0.7479305267333984, -1.3726787567138672, -0.542424201965332, -0.17644596099853516, -0.38283729553222656, -0.4095735549926758, -0.08707714080810547, 0.0743255615234375, -0.7671051025390625, -1.668771743774414, -0.2581062316894531, 0.8903541564941406, 0.23117828369140625, -0.2578449249267578, -0.5631275177001953, 0.06504535675048828, 1.1114873886108398, -0.5080223083496094, 0.8894081115722656, 0.230316162109375, 0.3455781936645508, -0.20864486694335938, -0.14517974853515625, -0.0292205810546875, -0.33521461486816406, -0.2732839584350586, 0.08486294746398926, -2.2537918090820312, -0.7896251678466797, -0.4351825714111328, -1.8921642303466797, -0.30585289001464844, -0.4227581024169922, 0.40192699432373047, -0.4408302307128906, -0.1425952911376953, 0.9963560104370117, 0.1668682098388672, -7.966413497924805, -0.40132951736450195, 0.5913000106811523, -0.7595720291137695, -0.16667556762695312, -0.8691368103027344, 0.5326290130615234, -0.8658227920532227, -0.5391912460327148, 0.7668495178222656, 0.03744316101074219, 0.7864933013916016, -0.24084854125976562, -7.381368637084961, 0.4751873016357422, -0.4761085510253906, 0.5050735473632812, 0.7988772392272949, 0.3461647033691406, 0.8936185836791992, -0.7105598449707031, 1.3676872253417969], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 66560, "num_env_steps_trained": 246000, "num_agent_steps_sampled": 66560, "num_agent_steps_trained": 246000, "last_target_update_ts": 66560, "num_target_updates": 129}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -56.811289353147146, "episode_len_mean": 243.43, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065], "episode_lengths": [237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.54033510827467, "mean_inference_ms": 24.65713015916083, "mean_action_processing_ms": 0.13444911697078213, "mean_env_wait_ms": 4.327044987202451, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -56.811289353147146, "episode_len_mean": 243.43, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-28.593677200376987, -123.37150660157204, 1.0999997556209564, -464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065], "episode_lengths": [237, 287, 244, 378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.54033510827467, "mean_inference_ms": 24.65713015916083, "mean_action_processing_ms": 0.13444911697078213, "mean_env_wait_ms": 4.327044987202451, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 66560, "num_agent_steps_trained": 246000, "num_env_steps_sampled": 66560, "num_env_steps_trained": 246000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 66560, "agent_timesteps_total": 66560, "timers": {"training_iteration_time_ms": 342.818, "learn_time_ms": 66.948, "learn_throughput": 3584.846, "synch_weights_time_ms": 20.689}, "counters": {"num_env_steps_sampled": 66560, "num_env_steps_trained": 246000, "num_agent_steps_sampled": 66560, "num_agent_steps_trained": 246000, "last_target_update_ts": 66560, "num_target_updates": 129}, "done": false, "episodes_total": 234, "training_iteration": 65, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-06-56", "timestamp": 1655478416, "time_this_iter_s": 5.510188817977905, "time_total_s": 344.83098125457764, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 344.83098125457764, "timesteps_since_restore": 0, "iterations_since_restore": 65, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 37.25, "ram_util_percent": 63.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.14988136291504, "min_q": -27.84221649169922, "max_q": 36.24213409423828, "mean_td_error": -0.016290489584207535}, "td_error": [-0.9876518249511719, 0.3848228454589844, -1.7147388458251953, 0.8085622787475586, -0.2851982116699219, -0.3024101257324219, 0.2932868003845215, -0.5976028442382812, 0.6466808319091797, -0.4064617156982422, -0.8869972229003906, 0.4514427185058594, -0.08970832824707031, 1.3850317001342773, 0.10161399841308594, -5.772419452667236, 0.4775049686431885, -0.09605693817138672, -0.3024101257324219, 0.37528514862060547, 0.4775049686431885, -3.9497337341308594, -0.21048259735107422, -0.2779674530029297, -0.11489009857177734, -0.5779943466186523, 1.1918017864227295, 1.3777294158935547, -0.029613494873046875, 0.09861183166503906, 0.04306793212890625, -0.7335472106933594, -0.6866931915283203, 0.675201416015625, -0.08073997497558594, 0.5331525802612305, -0.21312332153320312, 0.8853673934936523, -0.20334529876708984, 0.9574546813964844, -2.412189483642578, 0.9318523406982422, -0.3180046081542969, 1.0964279174804688, -0.04311180114746094, 2.3939361572265625, -0.21319007873535156, 1.3777294158935547, 1.8555364608764648, -0.4222888946533203, 0.01387643814086914, 0.21290206909179688, 1.8474621772766113, -0.028131484985351562, -0.3972768783569336, 0.6228189468383789, 1.1575136184692383, -0.3428516387939453, 0.7488842010498047, -0.46993446350097656, 0.03739452362060547, -0.1716289520263672, 0.525050163269043, -2.989166259765625, -0.49785423278808594, -0.3953056335449219, 0.12017250061035156, -0.2227783203125, 1.5447807312011719, 0.48858165740966797, -0.7933330535888672, 0.34947967529296875, -0.6123733520507812, -0.3131537437438965, 1.2397174835205078, 0.20611953735351562, 2.1659998893737793, 0.3511772155761719, -0.9327068328857422, 0.9486007690429688, 8.001660346984863, 0.9327850341796875, 0.3543109893798828, -0.1391925811767578, 14.836483001708984, 0.44449901580810547, 1.2225691080093384, -5.617441177368164, -0.5524709224700928, 0.49747657775878906, -0.49027061462402344, -0.12086677551269531, -0.5536231994628906, -1.0572834014892578, 0.9734344482421875, -0.28672218322753906, -0.4908180236816406, -0.22908878326416016, 0.6043777465820312, 0.4159374237060547, 1.158278465270996, -1.439870834350586, -6.545218467712402, 0.6039609909057617, 0.8081512451171875, -0.4445533752441406, -6.668168067932129, -1.7752037048339844, 1.0521917343139648, -0.7531852722167969, -1.0848960876464844, 0.28763771057128906, 0.5358810424804688, -6.979764938354492, -0.8654193878173828, -0.25821685791015625, 0.31420135498046875, -0.3681755065917969, -0.6857147216796875, 1.2100486755371094, -0.195953369140625, -0.9253196716308594, -0.6804275512695312, 1.9424691200256348, -0.2703819274902344, -1.8475313186645508, 0.3854098320007324, -1.2518386840820312, 0.07373619079589844, 0.19923019409179688, -0.24831771850585938, -0.43042469024658203, -1.1186714172363281, -0.12507057189941406, -3.9497337341308594, -0.4295177459716797, -0.052138328552246094, 0.3650360107421875, -0.38332176208496094, 0.9398822784423828, 0.41738319396972656, 17.329240798950195, -5.70109748840332, 0.08295440673828125, -0.714599609375, 0.8980255126953125, -0.1726551055908203, 0.11267852783203125, -0.3972434997558594, 0.8295574188232422, 0.2261962890625, 0.0070819854736328125, -0.2026214599609375, -0.7587175369262695, 0.6222085952758789, -0.6107959747314453, 0.4041109085083008, -0.8261966705322266, -0.4378204345703125, -0.45012664794921875, 0.2827262878417969, 0.3582782745361328, 0.005904197692871094, 0.17551231384277344, -0.6991424560546875, 2.5427093505859375, -0.2099285125732422, 0.38069915771484375, -0.08363723754882812, -0.26407432556152344, -0.4967803955078125, 0.09920692443847656, -0.2406620979309082, -0.24111366271972656, -0.44287872314453125, 0.18454933166503906, 0.2764158248901367, -5.9208984375, -0.20784568786621094, -7.367282867431641, -0.3574066162109375, 1.1210517883300781, 1.395538330078125, 0.35315895080566406, 0.15891075134277344, 1.8539910316467285, 0.03739452362060547, 0.1756420135498047, 0.9342479705810547, 0.46096324920654297, -0.4082183837890625, 0.3810882568359375, 0.063446044921875, 0.7758731842041016, 0.011346817016601562, -0.19925308227539062, 0.8296909332275391, -0.7530860900878906, 0.7607135772705078, -0.37633323669433594, -0.38654470443725586, 0.8371000289916992, -8.585447311401367, -1.021636962890625, -0.008678436279296875, 0.8882474899291992, 1.04819655418396, -0.8249340057373047, -0.4054422378540039, -0.2395782470703125, -0.43478965759277344, -2.302774429321289, 0.9793109893798828, -0.38056325912475586, 0.09950065612792969, 1.307535171508789, -0.08931732177734375, 1.858389139175415, -0.704742431640625, 2.4041690826416016, 0.9375438690185547, 0.098175048828125, -0.53228759765625, 0.12327098846435547, 1.9000377655029297, 0.5805234909057617, -0.18828773498535156, 0.42871570587158203, 0.2052297592163086, 2.3292112350463867, -0.8951282501220703, -0.7548542022705078, -0.8664169311523438, 0.29711151123046875, -0.40950489044189453, -0.09818458557128906, -0.09175777435302734, -0.23761940002441406, 1.5362262725830078, 1.5322895050048828], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 67584, "num_env_steps_trained": 249840, "num_agent_steps_sampled": 67584, "num_agent_steps_trained": 249840, "last_target_update_ts": 67584, "num_target_updates": 131}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -55.94369094185531, "episode_len_mean": 242.79, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598], "episode_lengths": [378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5409382219053289, "mean_inference_ms": 24.664847246205294, "mean_action_processing_ms": 0.13440752446032989, "mean_env_wait_ms": 4.330718287211353, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -55.94369094185531, "episode_len_mean": 242.79, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-464.14498011022806, -433.62605672329664, -206.62695945054293, -71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598], "episode_lengths": [378, 350, 321, 241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5409382219053289, "mean_inference_ms": 24.664847246205294, "mean_action_processing_ms": 0.13440752446032989, "mean_env_wait_ms": 4.330718287211353, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 67584, "num_agent_steps_trained": 249840, "num_env_steps_sampled": 67584, "num_env_steps_trained": 249840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 67584, "agent_timesteps_total": 67584, "timers": {"training_iteration_time_ms": 333.146, "learn_time_ms": 66.98, "learn_throughput": 3583.164, "synch_weights_time_ms": 20.389}, "counters": {"num_env_steps_sampled": 67584, "num_env_steps_trained": 249840, "num_agent_steps_sampled": 67584, "num_agent_steps_trained": 249840, "last_target_update_ts": 67584, "num_target_updates": 131}, "done": false, "episodes_total": 237, "training_iteration": 66, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-01", "timestamp": 1655478421, "time_this_iter_s": 5.390476942062378, "time_total_s": 350.22145819664, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 350.22145819664, "timesteps_since_restore": 0, "iterations_since_restore": 66, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 38.425, "ram_util_percent": 63.7875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.166690826416016, "min_q": -28.53175163269043, "max_q": 34.53854751586914, "mean_td_error": 0.2688741981983185}, "td_error": [0.21531295776367188, 0.03847503662109375, -0.0696878433227539, 0.4772186279296875, 1.4232006072998047, -7.261728286743164, -0.102081298828125, -0.22717761993408203, 0.060207366943359375, 0.6975822448730469, 1.1452388763427734, 0.3805580139160156, 0.5392227172851562, -0.056232452392578125, 0.7695140838623047, 0.28545093536376953, 1.1062908172607422, -0.6022796630859375, 0.64556884765625, 0.09423065185546875, 0.30187225341796875, 0.0024461746215820312, 2.5558300018310547, 0.6447086334228516, 0.09059524536132812, 1.7130050659179688, 0.44530296325683594, 0.22733116149902344, -0.022602081298828125, 0.3391227722167969, -1.0335369110107422, 0.1729898452758789, -1.0260162353515625, 1.7502079010009766, 0.55743408203125, 0.37073707580566406, 0.060172080993652344, 0.7619152069091797, 0.36687374114990234, 1.2076950073242188, 1.558919906616211, 0.05745506286621094, 0.13181304931640625, -5.275701522827148, 0.5925998687744141, 1.3068170547485352, 0.6416282653808594, -0.48732948303222656, 0.008515357971191406, 0.692474365234375, 0.09267616271972656, 0.00014972686767578125, -0.5447797775268555, 0.28545093536376953, -0.17482948303222656, 0.5648308992385864, 0.24629592895507812, -0.6494197845458984, 0.5219249725341797, -0.1667613983154297, -1.5452728271484375, 2.610614776611328, -0.7429618835449219, -0.3585700988769531, 0.32859325408935547, 0.598114013671875, -0.41085243225097656, 0.2555389404296875, 0.41926002502441406, 0.2849159240722656, 0.49530792236328125, -4.4828948974609375, 0.056270599365234375, 0.8096795082092285, 0.6979236602783203, 2.5054373741149902, -0.11674118041992188, 0.4387388229370117, -0.4783039093017578, -0.2264842987060547, -1.381429672241211, -8.957213401794434, 0.964848518371582, 0.9650239944458008, -0.1942434310913086, 0.6923027038574219, 0.47307682037353516, 1.6185989379882812, 0.5420284271240234, 0.053737640380859375, 0.5885677337646484, 0.9246120452880859, 0.1589374542236328, 0.24512863159179688, -0.7131309509277344, -6.193336486816406, 16.67641258239746, 1.3128013610839844, 0.24066734313964844, 3.391134262084961, 0.06780815124511719, -8.263629913330078, 2.0222530364990234, 0.19150543212890625, 1.0765743255615234, 0.6606531143188477, -0.0682373046875, 0.07696914672851562, 0.39569854736328125, -0.10014724731445312, 0.29274559020996094, -0.21672821044921875, 0.740631103515625, 1.1849008798599243, -6.548490524291992, 1.1062078475952148, -0.5262131690979004, -1.0816431045532227, 0.3777008056640625, 0.7063369750976562, 0.2373809814453125, -0.43175411224365234, 0.3593025207519531, -2.1979026794433594, -1.8029155731201172, 17.822650909423828, 0.2065420150756836, 0.026829957962036133, 0.8206939697265625, -7.543914794921875, 0.19341278076171875, 0.6005935668945312, 0.1794424057006836, 16.67641258239746, 0.9254646301269531, -0.27188968658447266, -1.1217279434204102, 0.7269878387451172, 2.2400598526000977, 1.2297344207763672, -2.009744644165039, 1.841257095336914, -0.3886241912841797, 0.5605602264404297, -0.22534751892089844, 0.362396240234375, 0.3310871124267578, 0.4092597961425781, 0.03052043914794922, 0.901677131652832, -0.25673389434814453, 0.18723106384277344, 0.14894866943359375, -0.14544296264648438, -6.2931060791015625, -1.449789047241211, 0.1342334747314453, 11.90136432647705, 0.393463134765625, -0.33722686767578125, -1.6322879791259766, 2.1811580657958984, 0.08254146575927734, -0.19956493377685547, 0.6819953918457031, 0.8115959167480469, -0.32796287536621094, 1.1442413330078125, -0.9008159637451172, -0.43764591217041016, 1.8770689964294434, -0.7068052291870117, 1.9661931991577148, -0.022548675537109375, -0.11714935302734375, 0.6810131072998047, -0.19577789306640625, 21.149066925048828, 0.4912834167480469, -0.22055625915527344, -0.16623497009277344, 0.4675445556640625, 0.4379310607910156, -1.796535611152649, -0.37848424911499023, 0.3776092529296875, 0.3191795349121094, 0.6212062835693359, -1.1803779602050781, 0.18289947509765625, -6.38902473449707, 0.3115367889404297, -0.47628211975097656, -0.10189533233642578, 0.30814629793167114, 0.1662893295288086, 0.2619342803955078, 0.04954338073730469, 0.2849159240722656, 0.18638896942138672, 2.5799484252929688, 0.4291095733642578, 0.02581024169921875, 0.7301025390625, -0.1387195587158203, 1.9568328857421875, 0.6104583740234375, -0.22113800048828125, -0.23954200744628906, -0.7617149353027344, 0.32152748107910156, -5.823890686035156, 0.44573402404785156, 0.2291555404663086, -0.200927734375, -3.951030731201172, -0.3585700988769531, -0.01869964599609375, -0.25032711029052734, 2.4334774017333984, 0.6682672500610352, -1.2977066040039062, -0.5751838684082031, -0.11942291259765625, 0.9256668090820312, 2.252042770385742, -0.0696878433227539, 0.5000209808349609, 0.7017478942871094, -0.04185676574707031, 0.38826942443847656, 0.056591033935546875, 0.3223876953125, -0.5443649291992188, 0.5278167724609375, -6.296064376831055, 0.58929443359375, 0.6178112030029297, 0.3997459411621094, -0.1253185272216797], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 68608, "num_env_steps_trained": 253680, "num_agent_steps_sampled": 68608, "num_agent_steps_trained": 253680, "last_target_update_ts": 68608, "num_target_updates": 133}, "sampler_results": {"episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -45.630276977866885, "episode_len_mean": 239.46, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305], "episode_lengths": [241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5414830566072942, "mean_inference_ms": 24.675701098989002, "mean_action_processing_ms": 0.13435678378561117, "mean_env_wait_ms": 4.335389784298866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 55.95134108513594, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -45.630276977866885, "episode_len_mean": 239.46, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-71.99536229670048, 1.3000000566244125, 5.000000022351742, 55.95134108513594, 15.864785932004452, -115.06526366621256, -133.79536256194115, -8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305], "episode_lengths": [241, 200, 194, 204, 199, 264, 286, 224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5414830566072942, "mean_inference_ms": 24.675701098989002, "mean_action_processing_ms": 0.13435678378561117, "mean_env_wait_ms": 4.335389784298866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 68608, "num_agent_steps_trained": 253680, "num_env_steps_sampled": 68608, "num_env_steps_trained": 253680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 68608, "agent_timesteps_total": 68608, "timers": {"training_iteration_time_ms": 338.638, "learn_time_ms": 66.87, "learn_throughput": 3589.059, "synch_weights_time_ms": 20.787}, "counters": {"num_env_steps_sampled": 68608, "num_env_steps_trained": 253680, "num_agent_steps_sampled": 68608, "num_agent_steps_trained": 253680, "last_target_update_ts": 68608, "num_target_updates": 133}, "done": false, "episodes_total": 240, "training_iteration": 67, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-07", "timestamp": 1655478427, "time_this_iter_s": 5.365658760070801, "time_total_s": 355.5871169567108, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 355.5871169567108, "timesteps_since_restore": 0, "iterations_since_restore": 67, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.387499999999996, "ram_util_percent": 63.7375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.179759979248047, "min_q": -27.519495010375977, "max_q": 33.44161605834961, "mean_td_error": 0.20273041725158691}, "td_error": [0.44526195526123047, 0.7748165130615234, 0.372100830078125, 1.3169355392456055, 0.6890525817871094, 0.18244171142578125, 0.5510129928588867, -0.19578933715820312, 0.44526195526123047, -0.4507484436035156, 1.463431715965271, 0.06475830078125, 0.2849922180175781, 0.3153724670410156, 0.3814716339111328, 0.08875465393066406, -0.04495048522949219, -0.09703731536865234, 0.0084075927734375, 0.2576770782470703, 0.14739418029785156, -0.08127975463867188, 1.4680862426757812, 0.26499176025390625, -1.7614612579345703, -7.340462684631348, -1.6052780151367188, 0.48661136627197266, 0.9448890686035156, 0.18559837341308594, -0.26804256439208984, 0.8251972198486328, 1.3084707260131836, 0.21228981018066406, -9.318746566772461, -0.16918182373046875, -0.2661304473876953, 0.7079328894615173, -1.1649847030639648, 1.3466100692749023, 1.0343132019042969, -0.08412551879882812, 1.463431715965271, 0.25788021087646484, -0.30762481689453125, 0.16015052795410156, 0.12051582336425781, -0.8522319793701172, 0.1851024627685547, 0.3467559814453125, -0.3677024841308594, -2.350008010864258, 0.5026874542236328, -1.3614082336425781, -0.113067626953125, -0.35752201080322266, 0.5902128219604492, -0.22674131393432617, -0.4917469024658203, -0.43611907958984375, -0.1461329460144043, 1.0291519165039062, -0.05207252502441406, 0.486053466796875, 0.3405332565307617, -0.045963287353515625, 0.17803382873535156, -0.33219146728515625, -0.13681411743164062, -0.33676910400390625, 0.5320835113525391, -0.26421546936035156, -0.4771385192871094, 0.33329200744628906, -0.2951831817626953, 0.2876901626586914, -0.2608928680419922, -0.22240638732910156, -0.029584884643554688, 9.690454483032227, -0.27152252197265625, 0.3151435852050781, -0.08945465087890625, -0.19320297241210938, -0.40437889099121094, -5.217456817626953, -0.2585115432739258, 23.057710647583008, 1.097757339477539, 0.5992088317871094, 0.37438201904296875, 3.684420585632324, 0.35204124450683594, -0.028795242309570312, -0.6863164901733398, -9.779869079589844, 0.31154441833496094, 0.3386077880859375, -0.5166263580322266, 1.3207931518554688, -0.3134422302246094, 1.3642158508300781, 0.6374454498291016, -8.899497985839844, -0.2951831817626953, 0.03930997848510742, 0.31531715393066406, -8.99428939819336, 0.38665199279785156, -1.0192756652832031, 0.44365501403808594, 1.031397819519043, 0.4147930145263672, 0.4648876190185547, 0.42441749572753906, -0.12324714660644531, 0.7130899429321289, 0.64215087890625, 1.0260944366455078, 1.6016712188720703, 17.786972045898438, -5.486989974975586, -0.8651332855224609, 0.8156318664550781, 0.33185577392578125, 0.784794807434082, -0.25954437255859375, 0.710205078125, -5.484687805175781, -1.0245389938354492, 0.23466205596923828, 0.05269145965576172, 0.5131282806396484, 0.5760936737060547, 1.4588232040405273, 19.6136474609375, -0.1978473663330078, 0.2030162811279297, -0.5104084014892578, 0.44176673889160156, -0.06333732604980469, -4.34355354309082, 0.49527549743652344, 0.08038711547851562, -0.2887458801269531, -0.36739158630371094, 0.7920503616333008, 0.021836280822753906, 0.2392597198486328, 0.02143096923828125, -0.21367835998535156, -0.3151416778564453, -0.7454433441162109, 0.03590965270996094, 0.04758453369140625, 0.5637664794921875, -0.019239425659179688, -0.2378215789794922, 0.36595726013183594, -8.920398712158203, -1.2660503387451172, -0.12479209899902344, 0.0001735687255859375, 0.39345359802246094, -0.2569236755371094, -0.25792503356933594, 0.18798351287841797, 0.5577125549316406, -0.5799655914306641, -0.05795097351074219, 0.6040153503417969, -0.09597635269165039, 0.025972366333007812, -0.14239501953125, -0.29357147216796875, -0.6316766738891602, 0.7959394454956055, -0.3920021057128906, 17.726184844970703, 0.9733428955078125, 0.9572324752807617, -0.5147304534912109, -0.32961082458496094, 0.5213146209716797, 0.6890525817871094, 0.4315338134765625, 0.26560020446777344, 0.3357086181640625, -0.1234598159790039, 4.104413986206055, -0.2608928680419922, 0.8943710327148438, 0.014219284057617188, 0.07137203216552734, 13.076889038085938, 0.14752197265625, 0.023088455200195312, -1.0383193492889404, 0.6118068695068359, 0.662078857421875, 0.4393186569213867, -1.6014652252197266, 0.44991302490234375, 0.20919036865234375, 0.5883693695068359, 0.7645502090454102, 1.0006294250488281, 0.05831336975097656, 0.11824226379394531, 0.13440799713134766, 0.1395263671875, 0.35481947660446167, -0.545781135559082, 0.8722362518310547, 0.3938102722167969, 0.6811428070068359, 0.31649208068847656, -6.238365173339844, 0.8267574310302734, 0.46513843536376953, -6.2235918045043945, -0.34172916412353516, -6.9018964767456055, 0.44526195526123047, 1.2742033004760742, -0.11825370788574219, 0.9270439147949219, -0.38906002044677734, -0.1425914764404297, -0.3230314254760742, 0.347015380859375, -0.20452880859375, 0.4785041809082031, 0.13977909088134766, 0.32175445556640625, 0.5734691619873047, -0.33213043212890625, 0.29845619201660156, -0.3342857360839844, 0.5540370941162109], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 69632, "num_env_steps_trained": 257520, "num_agent_steps_sampled": 69632, "num_agent_steps_trained": 257520, "last_target_update_ts": 69632, "num_target_updates": 135}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -48.5163999581337, "episode_len_mean": 241.76, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543], "episode_lengths": [224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5432978569832734, "mean_inference_ms": 24.71419532657982, "mean_action_processing_ms": 0.13432447848508397, "mean_env_wait_ms": 4.34695082972407, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -48.5163999581337, "episode_len_mean": 241.76, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-8.081406638026237, 4.999999865889549, 7.7106354758143425, 13.600902698934078, 6.80000015348196, -151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543], "episode_lengths": [224, 240, 221, 202, 209, 305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5432978569832734, "mean_inference_ms": 24.71419532657982, "mean_action_processing_ms": 0.13432447848508397, "mean_env_wait_ms": 4.34695082972407, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 69632, "num_agent_steps_trained": 257520, "num_env_steps_sampled": 69632, "num_env_steps_trained": 257520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 69632, "agent_timesteps_total": 69632, "timers": {"training_iteration_time_ms": 353.531, "learn_time_ms": 67.569, "learn_throughput": 3551.925, "synch_weights_time_ms": 20.885}, "counters": {"num_env_steps_sampled": 69632, "num_env_steps_trained": 257520, "num_agent_steps_sampled": 69632, "num_agent_steps_trained": 257520, "last_target_update_ts": 69632, "num_target_updates": 135}, "done": false, "episodes_total": 247, "training_iteration": 68, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-13", "timestamp": 1655478433, "time_this_iter_s": 5.684288501739502, "time_total_s": 361.2714054584503, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 361.2714054584503, "timesteps_since_restore": 0, "iterations_since_restore": 68, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 39.724999999999994, "ram_util_percent": 64.19999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.402685165405273, "min_q": -27.966053009033203, "max_q": 33.11052703857422, "mean_td_error": 0.2567099630832672}, "td_error": [1.1246771812438965, 0.6787242889404297, 0.40180206298828125, 1.3533153533935547, 1.6613759994506836, 0.2841987609863281, 0.36693477630615234, 0.7388515472412109, -0.25690269470214844, -0.19147300720214844, 0.620147705078125, 11.57260513305664, 0.5512819290161133, -0.3916177749633789, 1.3609619140625, 0.6930065155029297, 0.7223262786865234, 2.106630325317383, 0.6341638565063477, 1.098165512084961, -0.09446334838867188, -0.12203788757324219, 0.7747554779052734, 0.5808944702148438, 0.9481697082519531, 1.3587675094604492, 1.093475341796875, 0.15450477600097656, -4.432781219482422, 0.10394287109375, 0.18093585968017578, 0.9308500289916992, 0.3676910400390625, -6.07318115234375, 1.1246771812438965, -0.3576164245605469, 0.45096588134765625, 0.023960113525390625, 0.42751121520996094, -1.3315792083740234, -0.26959896087646484, -0.7330770492553711, 0.39277076721191406, 0.18270301818847656, 1.594090461730957, 0.7657890319824219, 1.4713134765625, 0.43731689453125, -0.4623260498046875, 0.3899364471435547, 0.5940151214599609, 0.6559352874755859, 1.4309911727905273, -1.9346466064453125, 0.44999217987060547, 0.20309925079345703, -0.3033485412597656, -0.5368251800537109, 0.4774055480957031, 0.8264436721801758, 1.3217544555664062, 0.3851337432861328, 0.16429519653320312, -0.3685493469238281, 0.8040695190429688, -0.12079238891601562, 0.2935447692871094, 0.6262302398681641, -0.22997283935546875, -0.016649246215820312, -5.518861770629883, 0.3851337432861328, 0.4214019775390625, 0.8550243377685547, 0.43692588806152344, 1.1249628067016602, -0.07378005981445312, 1.3681793212890625, 0.040218353271484375, 1.1765708923339844, 0.1579427719116211, -0.0863800048828125, 0.9011249542236328, 0.7966976165771484, -9.706502914428711, 0.5343093872070312, -1.8061466217041016, 0.4659576416015625, -3.8276939392089844, -0.01759815216064453, -0.3978404998779297, 1.2008380889892578, -0.4260749816894531, 0.4363059997558594, 0.25191307067871094, 0.34128284454345703, 1.1305103302001953, 0.06436347961425781, 0.9633388519287109, 0.6360301971435547, 0.3899364471435547, 0.8172454833984375, 0.9729270935058594, 0.7617053985595703, 0.8177108764648438, 1.128260612487793, -6.664329528808594, -0.04548835754394531, -0.11778640747070312, -0.2686786651611328, -0.6183352470397949, 0.38492584228515625, 1.7019052505493164, -6.784272193908691, 1.520552635192871, 0.8940620422363281, 1.9185800552368164, 0.6623725891113281, 1.1131439208984375, 2.0196762084960938, 0.45581817626953125, 12.217514038085938, 0.28107261657714844, 0.47875022888183594, 0.9866065979003906, 0.6379327774047852, 0.42699432373046875, -0.008606910705566406, 1.1647348403930664, 2.6391968727111816, 0.26776123046875, -0.3612384796142578, -6.853343963623047, 0.4913349151611328, -0.22415542602539062, 1.984330177307129, 0.696141242980957, 1.5052127838134766, 12.351831436157227, -6.08409309387207, -6.628156661987305, -6.794920921325684, 0.22174358367919922, 0.6711196899414062, 1.1664905548095703, 0.4028282165527344, 0.4520072937011719, -0.5996685028076172, 1.367131233215332, -0.19797515869140625, 0.2691669464111328, 0.6092643737792969, 0.10685157775878906, 0.9695701599121094, 0.07863616943359375, -0.012071609497070312, 1.8270606994628906, 0.6512584686279297, 0.32459163665771484, 0.6796607971191406, 0.0858917236328125, -1.1170849800109863, 4.406440734863281, -0.8816728591918945, 1.156881332397461, 0.17499923706054688, 2.600710868835449, 1.6914825439453125, 0.7806100845336914, 0.32213592529296875, 1.3564945459365845, 0.61083984375, 1.1905097961425781, 0.8604183197021484, -6.08409309387207, 0.9862632751464844, 0.6737689971923828, 0.11742496490478516, 0.6619071960449219, 0.8808460235595703, 0.0014133453369140625, 0.6362314224243164, 0.6899566650390625, 0.7207908630371094, 0.3068523406982422, -0.013532638549804688, 0.8080902099609375, 0.28734779357910156, 0.18140220642089844, 0.8423881530761719, -0.13428115844726562, -0.07692337036132812, 0.43051719665527344, -0.36293601989746094, -8.964460372924805, -0.1550750732421875, 0.3849315643310547, 1.9347171783447266, -0.02747058868408203, 0.9168186187744141, -0.21120643615722656, -0.09149169921875, 0.225372314453125, 0.5539836883544922, 0.2907829284667969, 0.7117938995361328, -0.7125329971313477, 1.1379203796386719, 0.0032100677490234375, 1.5302066802978516, 0.9770145416259766, 1.351222038269043, 0.6458015441894531, 1.1257190704345703, 0.1672039031982422, -0.001514434814453125, 1.6489315032958984, 0.13814973831176758, 0.7717361450195312, -0.31854724884033203, 1.4428234100341797, 0.08074188232421875, 0.9308500289916992, 0.6182804107666016, 0.15430831909179688, 0.5223560333251953, -0.4401092529296875, 0.8809032440185547, -0.4168834686279297, -0.7414951324462891, 0.11360549926757812, 0.8226909637451172, 1.8165721893310547, 1.7422142028808594, -7.4516754150390625, 0.81646728515625, 0.45594215393066406, -0.4585294723510742, -0.17814064025878906, 1.2938480377197266], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 70656, "num_env_steps_trained": 261360, "num_agent_steps_sampled": 70656, "num_agent_steps_trained": 261360, "last_target_update_ts": 70656, "num_target_updates": 137}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -49.862290033847096, "episode_len_mean": 242.45, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914], "episode_lengths": [305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5445587446559107, "mean_inference_ms": 24.71124993440466, "mean_action_processing_ms": 0.13408939401017286, "mean_env_wait_ms": 4.351786247472185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -49.862290033847096, "episode_len_mean": 242.45, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-151.0271491035819, -270.25468330830336, -181.70047122985125, -62.56704868376255, 21.53190628439188, 12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914], "episode_lengths": [305, 295, 306, 257, 206, 201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5445587446559107, "mean_inference_ms": 24.71124993440466, "mean_action_processing_ms": 0.13408939401017286, "mean_env_wait_ms": 4.351786247472185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 70656, "num_agent_steps_trained": 261360, "num_env_steps_sampled": 70656, "num_env_steps_trained": 261360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 70656, "agent_timesteps_total": 70656, "timers": {"training_iteration_time_ms": 343.043, "learn_time_ms": 67.483, "learn_throughput": 3556.462, "synch_weights_time_ms": 21.788}, "counters": {"num_env_steps_sampled": 70656, "num_env_steps_trained": 261360, "num_agent_steps_sampled": 70656, "num_agent_steps_trained": 261360, "last_target_update_ts": 70656, "num_target_updates": 137}, "done": false, "episodes_total": 252, "training_iteration": 69, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-18", "timestamp": 1655478438, "time_this_iter_s": 5.510083436965942, "time_total_s": 366.78148889541626, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 366.78148889541626, "timesteps_since_restore": 0, "iterations_since_restore": 69, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.6375, "ram_util_percent": 64.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.464460372924805, "min_q": -29.541255950927734, "max_q": 33.23868942260742, "mean_td_error": 0.2904055416584015}, "td_error": [0.2213878631591797, -0.2855358123779297, 0.5484676361083984, -0.1619720458984375, -0.3261585235595703, 1.409830093383789, -0.5496902465820312, 0.15576934814453125, -0.1793193817138672, 0.2525653839111328, 5.744823455810547, -4.869838714599609, -5.714831352233887, 0.036907196044921875, 0.07907676696777344, 0.38897132873535156, -0.02896595001220703, -0.03237628936767578, 0.7323942184448242, -0.36386919021606445, 0.49797725677490234, 1.246016502380371, 0.5350008010864258, -0.08194923400878906, -1.4086408615112305, -0.2272510528564453, -0.35315799713134766, 0.14258575439453125, -1.0225696563720703, -0.43889808654785156, -0.6310291290283203, -0.19545364379882812, 0.25746917724609375, -0.7359695434570312, 0.7160811424255371, 0.42665767669677734, -0.4783639907836914, 0.7399425506591797, 1.1663265228271484, 0.06804656982421875, -0.10902214050292969, -0.5286216735839844, 1.1143722534179688, 17.700054168701172, -0.15642166137695312, 2.8599109649658203, 0.059665679931640625, -0.4388771057128906, 0.22760772705078125, 0.12227058410644531, 0.14445877075195312, 0.4715995788574219, 0.3953819274902344, 22.619491577148438, 2.231752395629883, 0.020372390747070312, 0.44550228118896484, 0.4102134704589844, -1.0698699951171875, -0.6005439758300781, 2.250741958618164, 0.2373332977294922, -0.2648582458496094, -0.36188507080078125, 0.01177215576171875, 0.16086101531982422, -7.062857627868652, 0.42005443572998047, -0.9511871337890625, -1.0825309753417969, 0.087615966796875, -0.15179920196533203, 0.8817863464355469, -0.7228584289550781, 0.05036163330078125, -0.47566795349121094, -6.195399284362793, 1.1872482299804688, 0.13351821899414062, 0.06952476501464844, -0.3897418975830078, -0.219940185546875, 1.7682514190673828, 0.32562828063964844, 0.5877695083618164, 1.2655143737792969, -0.6509628295898438, -0.14380264282226562, -0.24404525756835938, 0.19910049438476562, 0.27983570098876953, -0.16367340087890625, -0.7460269927978516, 0.7978849411010742, 0.0342254638671875, 0.39020729064941406, 1.1682958602905273, 0.31266021728515625, -0.3577156066894531, 0.33290767669677734, -0.8330459594726562, 0.03617286682128906, -0.29636192321777344, -1.0535507202148438, 0.8013324737548828, 0.8088836669921875, 1.1398429870605469, 0.1990337371826172, 0.4171104431152344, 0.08921432495117188, -0.1922931671142578, -0.0076141357421875, 0.9221096038818359, 0.3396129608154297, -2.050748825073242, 1.1333253383636475, -0.471832275390625, -0.020732879638671875, 0.2903757095336914, 0.113861083984375, 1.2451443672180176, -0.49204063415527344, -0.19187164306640625, -1.312544822692871, -5.259357452392578, 0.34745025634765625, -1.7884197235107422, 0.2464447021484375, 0.5850696563720703, 2.0998916625976562, 0.13320541381835938, -0.5012245178222656, 14.33968734741211, 0.31981849670410156, -0.0076141357421875, 0.039351463317871094, -0.5181121826171875, 0.7173147201538086, 0.1427135467529297, 0.24954605102539062, 1.3286266326904297, -0.4921398162841797, -0.34623289108276367, 0.5934238433837891, -0.025754928588867188, 1.195922613143921, -5.543548583984375, 0.8677301406860352, -0.7646083831787109, 0.7305591106414795, 15.87563705444336, -0.06954383850097656, 0.3893718719482422, 0.3913841247558594, 1.5160961151123047, 0.440216064453125, -1.3499298095703125, 0.27392101287841797, -1.0199756622314453, 0.07362747192382812, -0.48660850524902344, -0.16438865661621094, -0.20552825927734375, 0.8656721115112305, -0.2313709259033203, 0.9135217666625977, -0.6367683410644531, 0.3914203643798828, -0.19472885131835938, 0.2468891143798828, 0.19910049438476562, -0.12227058410644531, 0.20101547241210938, 0.11083984375, 1.6169319152832031, -1.1585044860839844, -4.968242645263672, -0.24986839294433594, 0.4577140808105469, -0.9109745025634766, 0.5719871520996094, 0.3780708312988281, 0.6374750137329102, -4.807233810424805, -0.03371620178222656, -0.21462440490722656, -0.27678585052490234, -0.4349842071533203, -0.05919170379638672, 0.37309837341308594, 0.2323904037475586, 0.17533111572265625, -0.3511085510253906, -0.40787506103515625, 0.12395095825195312, -0.31348323822021484, 0.1527252197265625, 0.4715995788574219, 1.1423282623291016, 0.3529658317565918, 0.304107666015625, 0.18288803100585938, 1.5931148529052734, 0.09738349914550781, 2.0856170654296875, 0.29805946350097656, -0.21950149536132812, 1.0867385864257812, -6.87660026550293, -0.6113090515136719, 0.007534027099609375, 0.3968496322631836, 0.6345195770263672, 0.304107666015625, 0.10387802124023438, -0.3058595657348633, 0.032817840576171875, -0.9679317474365234, 2.962212324142456, -4.841346740722656, 0.2139577865600586, -0.04691314697265625, 1.2728824615478516, -0.5636653900146484, -0.14127731323242188, 0.8097381591796875, -0.7756423950195312, -0.17811203002929688, 0.46845531463623047, -0.39646244049072266, -0.9525966644287109, 0.6834497451782227, 0.12006378173828125, 0.3818321228027344, -0.45363903045654297, -0.10747909545898438, -0.8515729904174805, 18.66253662109375, -1.3026604652404785, 1.4085487127304077], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 71680, "num_env_steps_trained": 265200, "num_agent_steps_sampled": 71680, "num_agent_steps_trained": 265200, "last_target_update_ts": 71680, "num_target_updates": 139}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -43.0922459807992, "episode_len_mean": 238.67, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633], "episode_lengths": [201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5459279382818416, "mean_inference_ms": 24.741617089601796, "mean_action_processing_ms": 0.1344020282811903, "mean_env_wait_ms": 4.360417437541204, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -43.0922459807992, "episode_len_mean": 238.67, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [12.26478610932827, -188.11373940110207, 4.2077552899718285, -9.79909722507, 18.407755620777607, -332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633], "episode_lengths": [201, 322, 242, 215, 202, 357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5459279382818416, "mean_inference_ms": 24.741617089601796, "mean_action_processing_ms": 0.1344020282811903, "mean_env_wait_ms": 4.360417437541204, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 71680, "num_agent_steps_trained": 265200, "num_env_steps_sampled": 71680, "num_env_steps_trained": 265200, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 71680, "agent_timesteps_total": 71680, "timers": {"training_iteration_time_ms": 353.931, "learn_time_ms": 67.768, "learn_throughput": 3541.476, "synch_weights_time_ms": 21.487}, "counters": {"num_env_steps_sampled": 71680, "num_env_steps_trained": 265200, "num_agent_steps_sampled": 71680, "num_agent_steps_trained": 265200, "last_target_update_ts": 71680, "num_target_updates": 139}, "done": false, "episodes_total": 257, "training_iteration": 70, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-24", "timestamp": 1655478444, "time_this_iter_s": 5.521677255630493, "time_total_s": 372.30316615104675, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 372.30316615104675, "timesteps_since_restore": 0, "iterations_since_restore": 70, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 36.487500000000004, "ram_util_percent": 64.4375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 17.49042510986328, "min_q": -29.471725463867188, "max_q": 35.82264709472656, "mean_td_error": -0.02961173839867115}, "td_error": [0.5056114196777344, 0.6237125396728516, 0.7986774444580078, 1.292989730834961, 0.7627029418945312, -0.06998062133789062, -6.303869247436523, -0.5270423889160156, 0.5939826965332031, 0.4866447448730469, -0.021062850952148438, 0.0254974365234375, 0.1375446319580078, -0.053737640380859375, 0.248046875, -1.0164432525634766, -0.7034988403320312, 0.5015182495117188, -0.13951873779296875, 17.51903533935547, -0.7487597465515137, 0.9660530090332031, 0.2413043975830078, 0.3073596954345703, 0.025861740112304688, -0.2874870300292969, 0.22181320190429688, -1.1548528671264648, 0.8748817443847656, 0.7275848388671875, -0.5560626983642578, 0.00543212890625, 0.6095008850097656, 0.1524486541748047, 1.3546724319458008, 0.2132587432861328, -0.4677772521972656, 1.4246540069580078, 0.15447616577148438, 0.022077560424804688, 0.0736846923828125, 0.5298404693603516, -0.053882598876953125, 0.6658058166503906, 0.09138774871826172, 0.8866405487060547, 0.6801719665527344, -1.5994234085083008, -0.9202804565429688, -1.1574535369873047, -0.17150497436523438, -1.404456377029419, 0.2211894989013672, 17.363048553466797, 1.5200834274291992, -0.5034260749816895, 1.0131340026855469, -1.3190221786499023, -0.4413738250732422, -2.641693115234375, -0.36846923828125, -0.4840669631958008, 0.8524341583251953, -0.2901144027709961, -0.22017860412597656, 1.162710189819336, 1.299530029296875, -0.767329216003418, 0.22331619262695312, -0.3022308349609375, 0.3139781951904297, 0.4074745178222656, -0.46442222595214844, -5.02934455871582, -7.648445129394531, 0.2725982666015625, 0.8300628662109375, -4.236896514892578, 0.6998062133789062, -0.3686656951904297, -6.514865875244141, 2.024524688720703, 0.15544891357421875, -0.7909002304077148, 0.5328578948974609, -0.6258144378662109, -0.41458892822265625, 0.2217082977294922, -7.600732803344727, 1.4214668273925781, -0.19191360473632812, -0.13431358337402344, 1.2355608940124512, 0.5696163177490234, -0.07792377471923828, -1.513051986694336, 0.8236122131347656, -0.33205223083496094, 0.31445884704589844, 0.16535377502441406, 0.28833580017089844, 0.22275161743164062, 1.2451238632202148, 0.8210563659667969, -0.7262201309204102, 0.2953510284423828, 1.2736034393310547, 1.7576236724853516, 1.1966266632080078, 1.0158443450927734, 0.14917564392089844, -6.387943744659424, 0.6606016159057617, 0.2386617660522461, 0.2490825653076172, -1.1146793365478516, -0.6559634208679199, 1.2996978759765625, 0.7903709411621094, 14.241881370544434, -0.10026359558105469, -7.533904075622559, 0.16930198669433594, -0.0499725341796875, 0.3391914367675781, 0.28596019744873047, -1.0947132110595703, -0.9784641265869141, -0.25240516662597656, 0.4094047546386719, -0.5092124938964844, 0.5188126564025879, -0.04496574401855469, 0.21625709533691406, -0.1258535385131836, -0.29296016693115234, -1.4872798919677734, 0.3908405303955078, 0.11797332763671875, 0.4857921600341797, 1.1743888854980469, 1.0158443450927734, 0.30695343017578125, -0.16412830352783203, 0.2829856872558594, 0.19690513610839844, -0.9406452178955078, -0.5482921600341797, 1.2815790176391602, 1.4088916778564453, 0.1316089630126953, -5.419985771179199, 0.3505897521972656, 0.2651023864746094, -3.3853073120117188, 0.3600749969482422, 1.3439140319824219, 0.7385387420654297, -0.059566497802734375, -0.8052806854248047, -0.8564987182617188, -0.9846315383911133, -0.15192031860351562, 2.126089096069336, 0.38808250427246094, -0.1097421646118164, -0.2986631393432617, -0.21440410614013672, 0.16015243530273438, -0.3777732849121094, -3.0995521545410156, -0.6968517303466797, -0.07720565795898438, -0.23731422424316406, -1.107980728149414, 0.33341407775878906, 0.018087387084960938, -0.35897064208984375, 0.1624469757080078, 0.2276172637939453, 0.3059844970703125, 0.4297351837158203, 0.0483245849609375, 0.2885932922363281, 0.7686576843261719, 0.06465339660644531, 0.21191787719726562, -1.1147661209106445, -0.050445556640625, 0.10521697998046875, -4.661642074584961, -0.1240701675415039, 0.07641220092773438, 0.2497096061706543, 0.014458656311035156, 0.21240806579589844, 0.6205997467041016, 0.06322479248046875, 0.17911148071289062, 0.6337356567382812, -0.8694953918457031, 0.2851448059082031, -3.6024417877197266, -0.17150497436523438, -0.5259208679199219, 0.08380603790283203, 0.25899314880371094, 0.6319894790649414, -0.33666038513183594, 0.07068634033203125, -0.1705303192138672, 0.4346046447753906, -0.159881591796875, 0.9169340133666992, -0.2330455780029297, -0.5162982940673828, 0.3174567222595215, -6.018190383911133, -2.9484004974365234, 0.0483245849609375, -0.39761924743652344, 0.16466236114501953, -0.4264059066772461, 0.3874645233154297, -1.2161903381347656, -0.375030517578125, -4.808492660522461, -0.7549114227294922, -1.3822689056396484, -0.8126449584960938, 10.737029075622559, -0.13713455200195312, -0.016845703125, 0.2444782257080078, -0.3798198699951172, -0.5052814483642578, 0.2708158493041992, 0.6516628265380859, 0.4668903350830078, -1.067556381225586], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 72704, "num_env_steps_trained": 269040, "num_agent_steps_sampled": 72704, "num_agent_steps_trained": 269040, "last_target_update_ts": 72704, "num_target_updates": 141}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -41.51851864248514, "episode_len_mean": 237.35, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575], "episode_lengths": [357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5470543546244878, "mean_inference_ms": 24.735422854867135, "mean_action_processing_ms": 0.1343297202401673, "mean_env_wait_ms": 4.365387690530526, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -41.51851864248514, "episode_len_mean": 237.35, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-332.6150178089738, 16.793099842965603, -233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575], "episode_lengths": [357, 197, 315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5470543546244878, "mean_inference_ms": 24.735422854867135, "mean_action_processing_ms": 0.1343297202401673, "mean_env_wait_ms": 4.365387690530526, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 72704, "num_agent_steps_trained": 269040, "num_env_steps_sampled": 72704, "num_env_steps_trained": 269040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 72704, "agent_timesteps_total": 72704, "timers": {"training_iteration_time_ms": 350.833, "learn_time_ms": 68.567, "learn_throughput": 3500.201, "synch_weights_time_ms": 20.489}, "counters": {"num_env_steps_sampled": 72704, "num_env_steps_trained": 269040, "num_agent_steps_sampled": 72704, "num_agent_steps_trained": 269040, "last_target_update_ts": 72704, "num_target_updates": 141}, "done": false, "episodes_total": 262, "training_iteration": 71, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-30", "timestamp": 1655478450, "time_this_iter_s": 5.526576519012451, "time_total_s": 377.8297426700592, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 377.8297426700592, "timesteps_since_restore": 0, "iterations_since_restore": 71, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 37.725, "ram_util_percent": 64.42500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 18.30410385131836, "min_q": -19.462459564208984, "max_q": 36.0682258605957, "mean_td_error": 0.033583130687475204}, "td_error": [0.5712776184082031, 0.07653045654296875, 0.022951126098632812, -0.3970909118652344, 0.24835777282714844, 0.5122566223144531, 0.3895225524902344, 0.3116893768310547, -0.35113525390625, 0.0112152099609375, -0.4746971130371094, 0.027675628662109375, -0.2615318298339844, -0.5018253326416016, 0.19927024841308594, -0.47270965576171875, 0.7468814849853516, 0.1752185821533203, 0.3793678283691406, 0.22799015045166016, 0.38086700439453125, 0.5535659790039062, 0.5410251617431641, 1.4636211395263672, 1.0900516510009766, 0.6863117218017578, 0.2605171203613281, 0.8753280639648438, -0.6549186706542969, 1.2682857513427734, -0.1290607452392578, 0.8879642486572266, -0.5776615142822266, 0.1330718994140625, 0.7408065795898438, 0.5400028228759766, -0.18180084228515625, -0.47344970703125, 0.9116172790527344, -1.1003799438476562, 0.46429443359375, -0.3069572448730469, -0.30327415466308594, -0.22118854522705078, 0.47125244140625, -0.9105892181396484, -0.09701061248779297, -0.0634918212890625, 0.074310302734375, 0.21837711334228516, 0.4603424072265625, 0.6024818420410156, 0.7751221656799316, 0.9317169189453125, -0.37680625915527344, 0.27712535858154297, -0.304962158203125, 0.7842979431152344, 0.5886001586914062, -0.8237476348876953, -0.26763439178466797, 0.9732093811035156, -0.383331298828125, 0.3284034729003906, -0.14582443237304688, -1.1050710678100586, 0.23638629913330078, -1.634932041168213, 12.745644569396973, -7.4284210205078125, 0.09554672241210938, -0.1601104736328125, 0.2113208770751953, 11.699384689331055, -0.31880760192871094, 0.5259666442871094, 2.024700164794922, -0.4058513641357422, 0.48578834533691406, 0.3207550048828125, 0.5836467742919922, -0.5913639068603516, 0.5660381317138672, -0.5951576232910156, 0.72515869140625, 0.7159976959228516, -0.6068572998046875, 0.4986238479614258, -0.3419475555419922, 0.2894153594970703, -2.837083339691162, -0.6008663177490234, 0.48578834533691406, -7.5011396408081055, -1.0437202453613281, 2.116884231567383, 11.744848251342773, -0.6722431182861328, 0.044554710388183594, 0.725067138671875, 0.28925132751464844, 0.412933349609375, 0.8448200225830078, -8.569141387939453, 18.414487838745117, 0.2989463806152344, 0.5625553131103516, -9.28097152709961, 1.0023670196533203, -4.013525009155273, -7.432425498962402, 0.11219406127929688, 1.191720962524414, 0.6810197830200195, 0.3387279510498047, -0.6418857574462891, 1.3467903137207031, -2.8259620666503906, -0.2707691192626953, -1.1585893630981445, 0.012456893920898438, 2.281431198120117, 0.44253110885620117, 0.4752216339111328, 0.2371845245361328, 0.44793701171875, -0.10889148712158203, 0.7174701690673828, 0.6991157531738281, -0.7730522155761719, -1.186279296875, -0.45332813262939453, -0.24181556701660156, -1.4960813522338867, 1.2984428405761719, 0.738006591796875, -0.29055213928222656, -0.4078693389892578, 15.30712604522705, 0.32059288024902344, -0.12802696228027344, 0.25226593017578125, -0.20653438568115234, 0.0836944580078125, 2.3187427520751953, 0.6606712341308594, -0.09177589416503906, -0.44149303436279297, 0.49427032470703125, -0.9018630981445312, 0.291900634765625, 0.7282390594482422, -1.2973651885986328, -0.06707763671875, 0.5804958343505859, 0.6344566345214844, -0.6473045349121094, 0.3143768310546875, -0.05348396301269531, -0.399505615234375, -0.7762556076049805, -0.5487079620361328, -0.3393421173095703, -0.7200393676757812, 0.22794151306152344, -0.7401943206787109, -0.06018352508544922, 0.46492576599121094, -0.02275562286376953, -5.527103424072266, -0.28865909576416016, -0.06641483306884766, 0.8453540802001953, -0.4468269348144531, 0.24792098999023438, 0.18944740295410156, -0.6010494232177734, 0.18980789184570312, -0.08293914794921875, 0.6364994049072266, 0.733616828918457, 1.2368698120117188, 0.15813636779785156, -0.5884571075439453, -0.2975177764892578, 0.16420555114746094, -0.6899700164794922, 0.3765983581542969, 0.17269611358642578, 0.8064308166503906, 0.5732078552246094, 1.0255508422851562, -0.10704803466796875, 0.11168670654296875, 1.0974311828613281, -8.287979125976562, 1.006657600402832, 0.6408729553222656, -0.4777231216430664, -0.10895729064941406, 0.36208152770996094, 0.33190345764160156, -0.3791050910949707, 1.772979736328125, -5.41246223449707, -0.731938362121582, -0.18272018432617188, -0.20081233978271484, 0.0039768218994140625, 0.9606733322143555, 0.07268524169921875, -0.02806568145751953, 0.14734268188476562, -0.09240341186523438, -0.7513542175292969, -0.37401580810546875, -5.928661346435547, -0.4128246307373047, -0.5711116790771484, -0.25758838653564453, -0.027614593505859375, 0.4478034973144531, 0.650568962097168, -2.06134033203125, 0.9759616851806641, 0.6758174896240234, -1.200775146484375, -7.901926040649414, 1.2710762023925781, 0.3275909423828125, 0.7720861434936523, -1.2244679927825928, -9.14210319519043, 0.8569259643554688, 0.28017425537109375, -1.198603630065918, -0.4804658889770508, 3.44805908203125, 0.14293289184570312, -0.8545722961425781], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 73728, "num_env_steps_trained": 272880, "num_agent_steps_sampled": 73728, "num_agent_steps_trained": 272880, "last_target_update_ts": 73728, "num_target_updates": 143}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -37.729375983923674, "episode_len_mean": 235.98, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876], "episode_lengths": [315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5479916392571473, "mean_inference_ms": 24.75229168523859, "mean_action_processing_ms": 0.1342979724886002, "mean_env_wait_ms": 4.370568376805324, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -37.729375983923674, "episode_len_mean": 235.98, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-233.0484202876687, 4.538949340581894, -28.720606073737144, -24.299737878143787, 29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876], "episode_lengths": [315, 212, 221, 225, 217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5479916392571473, "mean_inference_ms": 24.75229168523859, "mean_action_processing_ms": 0.1342979724886002, "mean_env_wait_ms": 4.370568376805324, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 73728, "num_agent_steps_trained": 272880, "num_env_steps_sampled": 73728, "num_env_steps_trained": 272880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 73728, "agent_timesteps_total": 73728, "timers": {"training_iteration_time_ms": 332.841, "learn_time_ms": 68.468, "learn_throughput": 3505.277, "synch_weights_time_ms": 21.182}, "counters": {"num_env_steps_sampled": 73728, "num_env_steps_trained": 272880, "num_agent_steps_sampled": 73728, "num_agent_steps_trained": 272880, "last_target_update_ts": 73728, "num_target_updates": 143}, "done": false, "episodes_total": 264, "training_iteration": 72, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-35", "timestamp": 1655478455, "time_this_iter_s": 5.189277410507202, "time_total_s": 383.0190200805664, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 383.0190200805664, "timesteps_since_restore": 0, "iterations_since_restore": 72, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.5625, "ram_util_percent": 64.55000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.35951805114746, "min_q": -26.607200622558594, "max_q": 32.384613037109375, "mean_td_error": 0.1200312077999115}, "td_error": [0.7129726409912109, 0.45882129669189453, 0.6057987213134766, -1.1284008026123047, -0.2061481475830078, -0.2539634704589844, 0.06997489929199219, -0.09292984008789062, -0.3472623825073242, 0.26650047302246094, -0.26419639587402344, -0.2399272918701172, -6.275388717651367, -0.25919437408447266, 0.23917007446289062, -0.6895542144775391, 0.3800697326660156, 0.3400154113769531, -0.1514444351196289, -0.18773841857910156, -6.2659759521484375, 0.20784378051757812, 0.2405872344970703, 1.0359525680541992, 0.1656789779663086, 0.6244831085205078, 0.7110385894775391, 0.7241582870483398, -0.27890491485595703, 3.187755584716797, 0.9589939117431641, 0.20874786376953125, 1.2097606658935547, 0.09568023681640625, 0.40705108642578125, 1.8636445999145508, -0.05567359924316406, -0.5416145324707031, 0.8220338821411133, 0.09853267669677734, 0.01929187774658203, 0.8766851425170898, 0.027696609497070312, -2.8146414756774902, -0.8253583908081055, -0.9117183685302734, -0.6464900970458984, 2.200039863586426, -0.5982208251953125, 0.0845193862915039, 1.905160903930664, 0.22235488891601562, 0.18337249755859375, 1.5284035205841064, -0.13451004028320312, -0.16892623901367188, -0.21444320678710938, 1.2259483337402344, 0.4141263961791992, -0.3242511749267578, 0.28122520446777344, 0.42236995697021484, 0.023591995239257812, 0.47646141052246094, 0.3540515899658203, 11.68738079071045, -0.9680356979370117, 0.9383268356323242, 0.6706485748291016, -0.23577213287353516, 16.48876953125, 0.4731769561767578, -0.3762197494506836, -1.3174057006835938, 0.13908004760742188, -6.216042518615723, -0.2513427734375, 0.2476634979248047, -0.4424314498901367, -0.3978090286254883, 0.570164680480957, 0.20078468322753906, -0.23816871643066406, -0.8366947174072266, 1.5084819793701172, 0.7219991683959961, 0.3061332702636719, 0.0376434326171875, -0.18117523193359375, -4.628793716430664, -0.13495159149169922, -0.6273536682128906, 0.10215568542480469, -0.03966522216796875, -0.19707202911376953, 0.1798095703125, -0.22474956512451172, 0.3245372772216797, 0.9830837249755859, 0.11020469665527344, -0.11433601379394531, -0.07565879821777344, 2.252004623413086, 0.278045654296875, -0.698735237121582, 0.41051292419433594, 1.0584831237792969, -0.1844654083251953, -0.1754302978515625, 0.1671772003173828, -0.6800098419189453, 0.5320072174072266, 0.8050975799560547, 0.3341503143310547, 0.3445425033569336, 1.369959831237793, 0.3226041793823242, -0.2050342559814453, -7.093534469604492, -2.066549301147461, -0.21712112426757812, 0.11179256439208984, -0.0767364501953125, 0.49150657653808594, 0.7433042526245117, 0.22415685653686523, 1.6191740036010742, 11.991312026977539, -0.2104034423828125, 0.2720947265625, -0.2558784484863281, 0.4959983825683594, 1.8636445999145508, -0.4409923553466797, 17.84635353088379, 0.5644636154174805, 0.47147369384765625, 0.8165321350097656, 0.666325569152832, -0.04671669006347656, 0.8789691925048828, 0.34250640869140625, 0.281585693359375, -0.33063602447509766, -0.2510089874267578, 0.5458974838256836, 0.5887002944946289, 0.04489326477050781, 0.03569984436035156, 0.022975921630859375, 0.694580078125, 2.7442569732666016, -0.08602333068847656, 1.3104724884033203, 1.218801498413086, -0.3189125061035156, 0.03171348571777344, 0.6000423431396484, 0.002964019775390625, 1.2368755340576172, 0.49487876892089844, -1.7174797058105469, 0.3881359100341797, 0.4103403091430664, -3.64278507232666, 0.07835769653320312, 0.5749588012695312, 0.5812282562255859, -0.2372894287109375, 0.04920387268066406, 0.8327579498291016, -0.07633590698242188, -0.039818763732910156, 0.3084239959716797, -0.1406688690185547, 0.01585674285888672, 0.048381805419921875, 0.6001358032226562, 1.3104724884033203, 0.40100669860839844, -0.14166831970214844, -0.22567367553710938, -11.012788772583008, 0.803009033203125, 0.8897037506103516, 1.1071391105651855, -0.33524417877197266, -0.17628955841064453, -0.8484077453613281, 0.3770313262939453, 0.15671730041503906, -0.2669973373413086, -1.2982168197631836, -0.003810882568359375, -0.13180255889892578, 0.13263320922851562, -10.307319641113281, 0.7240562438964844, 0.5519790649414062, 0.009765625, 0.1384105682373047, -0.9695835113525391, -1.264204978942871, 0.21807289123535156, -0.5314712524414062, -1.228968620300293, -0.35431480407714844, -0.04932212829589844, -5.937166213989258, -0.4653139114379883, 0.4553413391113281, -0.05224418640136719, 1.9095706939697266, -0.7980289459228516, -0.0030460357666015625, 0.24315643310546875, 0.2600059509277344, 0.0524139404296875, 0.2432537078857422, 0.6886081695556641, 0.24477005004882812, -0.7126350402832031, 2.3287715911865234, -5.7866129875183105, 0.16215133666992188, 0.09548187255859375, 0.0698394775390625, -0.6176576614379883, -5.629556655883789, 0.4187355041503906, 0.44516944885253906, -0.15539932250976562, -0.3403034210205078, -0.6167640686035156, 0.42292213439941406, 0.3937416076660156, 0.3158740997314453, 0.4041738510131836, 0.5942249298095703, 0.4862995147705078], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 74752, "num_env_steps_trained": 276720, "num_agent_steps_sampled": 74752, "num_agent_steps_trained": 276720, "last_target_update_ts": 74752, "num_target_updates": 145}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -35.54613265655935, "episode_len_mean": 236.01, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084], "episode_lengths": [217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5485820274416146, "mean_inference_ms": 24.739013976937873, "mean_action_processing_ms": 0.13418186697374596, "mean_env_wait_ms": 4.3735144017698016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -35.54613265655935, "episode_len_mean": 236.01, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [29.31559234112501, 26.996726736426353, -20.39999981224537, -114.53232014924288, -82.26014828681946, -52.515544071793556, 21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084], "episode_lengths": [217, 200, 230, 253, 275, 251, 222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5485820274416146, "mean_inference_ms": 24.739013976937873, "mean_action_processing_ms": 0.13418186697374596, "mean_env_wait_ms": 4.3735144017698016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 74752, "num_agent_steps_trained": 276720, "num_env_steps_sampled": 74752, "num_env_steps_trained": 276720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 74752, "agent_timesteps_total": 74752, "timers": {"training_iteration_time_ms": 351.232, "learn_time_ms": 69.669, "learn_throughput": 3444.844, "synch_weights_time_ms": 21.088}, "counters": {"num_env_steps_sampled": 74752, "num_env_steps_trained": 276720, "num_agent_steps_sampled": 74752, "num_agent_steps_trained": 276720, "last_target_update_ts": 74752, "num_target_updates": 145}, "done": false, "episodes_total": 268, "training_iteration": 73, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-41", "timestamp": 1655478461, "time_this_iter_s": 5.594472169876099, "time_total_s": 388.6134922504425, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 388.6134922504425, "timesteps_since_restore": 0, "iterations_since_restore": 73, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.1375, "ram_util_percent": 64.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.998504638671875, "min_q": -29.479257583618164, "max_q": 32.46775817871094, "mean_td_error": 0.26629722118377686}, "td_error": [-0.01479339599609375, -6.470125198364258, -0.08145809173583984, 0.11014747619628906, 18.658451080322266, -0.22110939025878906, 0.5271759033203125, -1.2612342834472656, -6.243950843811035, -0.4255847930908203, -0.11734962463378906, 0.06333160400390625, -0.25810909271240234, 0.35935306549072266, 0.3084259033203125, 0.04140186309814453, 8.893482208251953, 1.9832496643066406, 1.0157909393310547, 0.13324356079101562, 0.06615829467773438, -0.6605920791625977, -0.5253801345825195, -0.2770404815673828, -0.5409660339355469, 0.44821739196777344, 0.08458900451660156, -0.13793373107910156, -0.2877349853515625, 0.2731609344482422, -6.825750350952148, 0.24111557006835938, -8.260238647460938, 0.7142810821533203, 0.17536354064941406, 0.21371936798095703, 1.323974609375, -0.02411651611328125, 1.1026439666748047, 0.727393627166748, -0.41776466369628906, 0.6155967712402344, 0.44013214111328125, -0.5552535057067871, -0.06897354125976562, -0.2610321044921875, -0.7429313659667969, -0.34589576721191406, 0.6349277496337891, 1.9220619201660156, 0.47883033752441406, -0.21834182739257812, -0.14353275299072266, 0.10134410858154297, 0.484161376953125, 0.35312843322753906, -0.3154468536376953, -0.22696876525878906, 0.23571205139160156, 0.5575180053710938, -1.4143543243408203, -0.38540172576904297, 0.7142810821533203, 0.06065177917480469, -0.4860191345214844, 0.9119606018066406, 0.6551704406738281, 0.5520114898681641, -1.834981918334961, 0.3666267395019531, -0.2578315734863281, -0.2650489807128906, -0.05711174011230469, -0.9989681243896484, 0.32582759857177734, -0.6410808563232422, 0.6493110656738281, 0.2680034637451172, 16.305248260498047, 0.12546730041503906, 0.20833396911621094, -0.023708343505859375, -0.18721389770507812, 0.014970779418945312, -0.2086200714111328, -0.28186607360839844, 0.4133033752441406, -1.1189231872558594, 0.6789760589599609, -0.04733085632324219, 0.623077392578125, 3.9818763732910156, 0.6948623657226562, -0.8529319763183594, 1.1856775283813477, 0.986088752746582, 1.2039475440979004, -0.5402889251708984, -0.11899757385253906, 0.2710857391357422, 1.0441360473632812, -5.518117904663086, 0.19467926025390625, -0.3571510314941406, -0.0894327163696289, 1.123514175415039, -0.14364910125732422, 0.4556255340576172, -0.6861820220947266, -0.2566566467285156, -0.4236564636230469, 0.5535058975219727, 0.29172706604003906, 0.18149185180664062, -6.689120292663574, -0.10835075378417969, 1.1893749237060547, 0.10594558715820312, 0.14165115356445312, -0.6056022644042969, -0.16879653930664062, -1.2008190155029297, 0.23226356506347656, 0.109283447265625, -0.4577503204345703, -0.1957530975341797, 0.16104984283447266, 0.8252019882202148, 0.7543811798095703, -0.19011402130126953, 0.07987594604492188, -0.09125900268554688, 0.898712158203125, 0.2244091033935547, 0.6728687286376953, -4.21048641204834, 1.7743377685546875, -0.3422060012817383, 0.986088752746582, 1.9220619201660156, -0.08622169494628906, -0.19237518310546875, -0.4761695861816406, 0.0003414154052734375, 0.36882877349853516, -0.36708641052246094, -0.11728477478027344, -0.2597675323486328, -0.0023593902587890625, -2.337583541870117, -0.36842918395996094, 0.2371501922607422, -0.2302837371826172, -0.009687423706054688, 0.2155017852783203, -0.030490875244140625, 16.716276168823242, -0.21100139617919922, 0.3651618957519531, -6.219047546386719, -0.1393280029296875, -0.09746551513671875, 0.07752799987792969, 0.2980928421020508, 0.9078788757324219, 0.4692211151123047, -0.8030567169189453, -1.3710975646972656, 0.06781768798828125, -6.506173133850098, -1.3984498977661133, -5.038421630859375, -0.8116588592529297, 0.38995933532714844, 0.4990720748901367, 0.15851974487304688, -0.18123435974121094, 1.3055400848388672, 0.09029579162597656, -1.1271438598632812, -0.5567398071289062, 0.46010303497314453, 0.41339683532714844, 22.649574279785156, 0.546933650970459, -0.8026447296142578, 1.7088699340820312, 1.6224555969238281, 2.093729019165039, 10.086195945739746, -0.008592605590820312, 0.06258010864257812, 1.5160274505615234, 0.10935783386230469, -0.28731727600097656, 1.1662178039550781, 0.154693603515625, 0.004383087158203125, -0.5541515350341797, -0.13343429565429688, 0.19878768920898438, 0.3663177490234375, 0.017347335815429688, -0.1468029022216797, -2.459440231323242, -0.30059051513671875, 0.4383220672607422, -1.3491077423095703, 0.6208324432373047, 0.8043127059936523, 0.06984806060791016, -0.2772083282470703, 1.480210304260254, 1.2022771835327148, -0.15952491760253906, -0.36583900451660156, 0.6741962432861328, -0.4923572540283203, -0.14837646484375, 0.17246437072753906, -1.6830635070800781, -0.8264198303222656, 0.1763477325439453, 0.47540855407714844, 0.05256080627441406, -0.88323974609375, 0.3857440948486328, -0.17865943908691406, -0.21347904205322266, 0.8089170455932617, 0.24349021911621094, -0.3243885040283203, 0.33153724670410156, 12.685698509216309, 0.2890148162841797, 1.5224485397338867, 0.031920433044433594, -3.599090576171875, -0.6471061706542969, -0.1406230926513672], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 75776, "num_env_steps_trained": 280560, "num_agent_steps_sampled": 75776, "num_agent_steps_trained": 280560, "last_target_update_ts": 75776, "num_target_updates": 147}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -36.147972553297876, "episode_len_mean": 235.87, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753], "episode_lengths": [222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5497240011385154, "mean_inference_ms": 24.75107010688623, "mean_action_processing_ms": 0.13429701273562325, "mean_env_wait_ms": 4.381454682597347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -36.147972553297876, "episode_len_mean": 235.87, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [21.411538034677505, -18.620605997741222, -2.4610505923628807, 11.50000012665987, -84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753], "episode_lengths": [222, 233, 229, 201, 273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5497240011385154, "mean_inference_ms": 24.75107010688623, "mean_action_processing_ms": 0.13429701273562325, "mean_env_wait_ms": 4.381454682597347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 75776, "num_agent_steps_trained": 280560, "num_env_steps_sampled": 75776, "num_env_steps_trained": 280560, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 75776, "agent_timesteps_total": 75776, "timers": {"training_iteration_time_ms": 335.791, "learn_time_ms": 66.921, "learn_throughput": 3586.327, "synch_weights_time_ms": 20.884}, "counters": {"num_env_steps_sampled": 75776, "num_env_steps_trained": 280560, "num_agent_steps_sampled": 75776, "num_agent_steps_trained": 280560, "last_target_update_ts": 75776, "num_target_updates": 147}, "done": false, "episodes_total": 274, "training_iteration": 74, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-47", "timestamp": 1655478467, "time_this_iter_s": 5.592844247817993, "time_total_s": 394.2063364982605, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 394.2063364982605, "timesteps_since_restore": 0, "iterations_since_restore": 74, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 36.4375, "ram_util_percent": 64.4625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.35414695739746, "min_q": -27.891799926757812, "max_q": 31.560426712036133, "mean_td_error": 0.31667575240135193}, "td_error": [-1.5444002151489258, -4.986666679382324, 0.9076261520385742, 0.8298797607421875, 0.2788276672363281, -0.2801342010498047, -0.3374443054199219, -0.2878894805908203, -0.37752342224121094, 10.082221031188965, -0.7266445159912109, -1.1896095275878906, -0.03793144226074219, 12.552392959594727, -9.39197826385498, 1.8516935110092163, -0.5063505172729492, 0.18255233764648438, 0.19386863708496094, 0.04354095458984375, 0.37849903106689453, -0.10431671142578125, -0.13734054565429688, -0.5580291748046875, 0.7790317535400391, -0.8179798126220703, -0.28151512145996094, -0.09699249267578125, -2.3102760314941406, 0.0317072868347168, -0.9140119552612305, -0.8920860290527344, -0.20541000366210938, -0.8332424163818359, 16.727230072021484, 0.051367759704589844, 1.0796709060668945, -0.02100372314453125, 0.16339874267578125, 11.437538146972656, -5.038455963134766, -1.027292251586914, -0.3161001205444336, -0.011835098266601562, 1.3084545135498047, -0.006374359130859375, -0.4344291687011719, 0.0317072868347168, 0.06126213073730469, 0.09052276611328125, -0.2053394317626953, -0.18616485595703125, -0.3088188171386719, 0.4246807098388672, 0.2677440643310547, -0.05321502685546875, -0.2787342071533203, 0.03817939758300781, -5.701594352722168, 0.07187843322753906, -4.986666679382324, -0.06844806671142578, -0.08113861083984375, 0.0920419692993164, 0.3282794952392578, -0.05406379699707031, 0.3757896423339844, -0.25775909423828125, 0.8168525695800781, 0.07925033569335938, 0.04620647430419922, 1.6646143198013306, -0.7562685012817383, -1.2651939392089844, -0.1591777801513672, 0.09888267517089844, -0.7762737274169922, -0.39366912841796875, 0.5154361724853516, -0.017576217651367188, -0.10198402404785156, -0.3433418273925781, 2.978435516357422, 0.05374908447265625, 14.2255859375, 0.5137500762939453, 0.4104433059692383, -4.572727203369141, 0.08994674682617188, -0.07656478881835938, -1.3254075050354004, 13.11260986328125, 2.4265785217285156, 0.048603057861328125, 13.029306411743164, -0.5217809677124023, 0.19736480712890625, -0.0545654296875, 21.811180114746094, -0.6767120361328125, 0.3872509002685547, 0.10918617248535156, 1.0097131729125977, -1.5160609483718872, -0.3290700912475586, 0.49408531188964844, 0.04010772705078125, -1.2809486389160156, -1.3837003707885742, 0.06425094604492188, 0.4286785125732422, 0.06794500350952148, -0.04117584228515625, -0.3838939666748047, -0.6618251800537109, 2.1871461868286133, -0.19901084899902344, -0.9610118865966797, 0.02258133888244629, -0.12109375, 2.0123214721679688, -0.48531436920166016, -0.48474693298339844, -1.3865289688110352, 0.4097013473510742, -0.15477943420410156, -0.1851215362548828, -0.8063068389892578, -1.3456039428710938, -0.25579261779785156, -0.08649826049804688, 0.108154296875, -0.17287349700927734, -0.5340142250061035, 0.8072714805603027, -0.17580032348632812, 1.7062349319458008, -0.572418212890625, -0.1729717254638672, 0.129852294921875, 0.2258739471435547, 2.052692413330078, 0.45438289642333984, -0.20789718627929688, 0.46734619140625, -0.056671142578125, 1.2153329849243164, -0.0024576187133789062, -0.10807991027832031, 0.2391223907470703, 0.6743412017822266, -0.12016487121582031, -0.7318668365478516, 0.260467529296875, -0.2175464630126953, 0.3018951416015625, 0.14113998413085938, 0.2691783905029297, 2.2691421508789062, -0.5340142250061035, 0.14771652221679688, -0.22177696228027344, 1.5464611053466797, -1.556290626525879, 0.5643672943115234, -0.3181896209716797, 0.24851608276367188, 0.6506462097167969, -0.1950836181640625, 0.16725921630859375, 0.021953582763671875, 1.6684417724609375, -0.1709880828857422, 0.5628843307495117, -0.05516624450683594, 0.4658775329589844, 0.10250663757324219, 0.14012718200683594, -0.5018596649169922, 0.006053924560546875, -0.1957530975341797, -0.5016574859619141, -0.4383697509765625, 0.37076854705810547, -0.4173851013183594, -2.1622257232666016, -1.2651939392089844, 0.7735443115234375, 0.7407064437866211, 0.16185379028320312, -0.6161003112792969, 0.37981224060058594, -0.06884384155273438, -0.11835098266601562, 18.839317321777344, 0.11160087585449219, -4.872030258178711, 0.5138406753540039, -0.34517478942871094, -0.11997222900390625, 0.8049230575561523, -0.23553466796875, 0.09619140625, 0.11092948913574219, 0.018642425537109375, -0.015082359313964844, -0.17348480224609375, 0.8940792083740234, -5.455753326416016, -0.7619397640228271, -0.327239990234375, 0.25107765197753906, 0.9938545227050781, -0.8978729248046875, 0.4616374969482422, 0.7291355133056641, 0.38180065155029297, 0.24390316009521484, 0.1775350570678711, 0.1749248504638672, 0.010568618774414062, -1.2857866287231445, 0.6665477752685547, -0.19316864013671875, -7.915470123291016, -0.3214893341064453, 0.36837196350097656, 0.4869861602783203, 0.4958820343017578, -0.1867389678955078, -1.7244510650634766, -0.5760936737060547, 0.1539020538330078, -0.6139717102050781, -0.001850128173828125, 0.04812431335449219, 0.009334564208984375, 0.3175525665283203, -4.882732391357422, 0.8670368194580078], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 76800, "num_env_steps_trained": 284400, "num_agent_steps_sampled": 76800, "num_agent_steps_trained": 284400, "last_target_update_ts": 76800, "num_target_updates": 149}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -38.01726405099034, "episode_len_mean": 237.41, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107], "episode_lengths": [273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5507740390468836, "mean_inference_ms": 24.77395192736206, "mean_action_processing_ms": 0.13438676697868648, "mean_env_wait_ms": 4.385601256733394, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -776.0234723091125, "episode_reward_mean": -38.01726405099034, "episode_len_mean": 237.41, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-84.44644282013178, 7.200000032782555, -776.0234723091125, 12.621270820498466, -120.27816956490278, 19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107], "episode_lengths": [273, 187, 450, 227, 281, 235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5507740390468836, "mean_inference_ms": 24.77395192736206, "mean_action_processing_ms": 0.13438676697868648, "mean_env_wait_ms": 4.385601256733394, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 76800, "num_agent_steps_trained": 284400, "num_env_steps_sampled": 76800, "num_env_steps_trained": 284400, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 76800, "agent_timesteps_total": 76800, "timers": {"training_iteration_time_ms": 348.834, "learn_time_ms": 69.568, "learn_throughput": 3449.862, "synch_weights_time_ms": 20.889}, "counters": {"num_env_steps_sampled": 76800, "num_env_steps_trained": 284400, "num_agent_steps_sampled": 76800, "num_agent_steps_trained": 284400, "last_target_update_ts": 76800, "num_target_updates": 149}, "done": false, "episodes_total": 278, "training_iteration": 75, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-52", "timestamp": 1655478472, "time_this_iter_s": 5.621320724487305, "time_total_s": 399.8276572227478, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 399.8276572227478, "timesteps_since_restore": 0, "iterations_since_restore": 75, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.32222222222222, "ram_util_percent": 64.46666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 17.565210342407227, "min_q": -23.636363983154297, "max_q": 36.29359436035156, "mean_td_error": 0.56706702709198}, "td_error": [9.763540267944336, 1.364974021911621, -0.5311183929443359, -0.07200145721435547, 14.526630401611328, -1.368911623954773, 0.5786037445068359, 1.7281169891357422, 0.2361459732055664, 0.11982345581054688, 0.02921295166015625, 0.4684934616088867, 0.4918498992919922, 1.906637191772461, 0.0055065155029296875, -1.123579502105713, 1.6595678329467773, 0.8469123840332031, -1.085601806640625, 0.4590263366699219, 0.9962291717529297, 0.4039011001586914, 0.9087238311767578, 0.1391000747680664, 0.36556053161621094, 9.920883178710938, -4.954429626464844, -0.5222959518432617, 0.6182260513305664, 0.43448638916015625, -0.24648094177246094, 1.3963985443115234, -0.02733612060546875, 1.169123649597168, -0.29236793518066406, -4.02061653137207, -0.3674812316894531, 0.07770919799804688, 0.3584766387939453, 1.8170533180236816, -0.7661571502685547, 0.09129142761230469, 1.692683219909668, 0.5862617492675781, 1.0697021484375, 0.025083541870117188, 0.35307884216308594, 1.0460433959960938, 0.22974205017089844, -0.12556838989257812, -0.6510658264160156, 0.3161144256591797, -2.0741443634033203, -0.5721569061279297, -8.842777252197266, 0.389556884765625, -1.2849843502044678, -0.49559879302978516, 1.2731590270996094, 1.9761848449707031, 1.23468017578125, 0.38813209533691406, 0.8716869354248047, -0.4350757598876953, 2.311397075653076, -0.15695571899414062, 0.7136497497558594, -0.22974205017089844, -0.387908935546875, 0.6149911880493164, 0.14159011840820312, -0.6386098861694336, -1.8235173225402832, -0.0464019775390625, 0.23190784454345703, 0.4844627380371094, 0.7694511413574219, -4.773265838623047, 10.899272918701172, 0.009171485900878906, 0.564605712890625, -0.8133754730224609, 2.3336713314056396, 1.559096336364746, 20.951644897460938, 0.8162260055541992, -0.1634044647216797, -0.2576732635498047, 0.40138816833496094, -0.27893924713134766, -0.10658645629882812, 0.3793926239013672, 0.15793418884277344, -0.6380348205566406, 0.5577621459960938, -0.9705791473388672, -0.12125205993652344, 14.068479537963867, 2.437274932861328, -0.7455482482910156, -4.886375427246094, -0.035327911376953125, 1.1199111938476562, -0.11217880249023438, -0.07511711120605469, -0.06570816040039062, -0.8098888397216797, 0.3006458282470703, 0.850947380065918, 0.3490161895751953, 0.47071075439453125, 0.8901271820068359, 16.160715103149414, 0.11747550964355469, -0.7571086883544922, -0.17392921447753906, 1.0840816497802734, 1.9535694122314453, -0.1376361846923828, 0.32762718200683594, -1.2541084289550781, 0.6354103088378906, -0.40010547637939453, 0.7370243072509766, 1.1852703094482422, 0.8967962265014648, 0.8134479522705078, 0.7712135314941406, -5.237067222595215, 0.9429283142089844, 1.6575088500976562, 1.322427749633789, 1.741903305053711, -0.33585453033447266, -0.41464805603027344, 1.6698064804077148, 0.28904247283935547, -0.17536163330078125, 0.8232288360595703, -0.3547992706298828, 0.12727737426757812, 0.5848331451416016, 0.5140495300292969, -0.17667770385742188, 2.370178699493408, 0.9818258285522461, 0.4194221496582031, 1.263753890991211, 14.834877014160156, 0.4809885025024414, -5.97496223449707, 0.6596393585205078, 0.6152229309082031, -7.514891624450684, 0.04916572570800781, -7.108331680297852, 0.8386125564575195, -1.2159194946289062, 0.05722618103027344, -7.611793518066406, 0.3589324951171875, -0.8098869323730469, 0.7006931304931641, -0.08624839782714844, 0.8776450157165527, 1.2799768447875977, 0.8042316436767578, 0.7603168487548828, 0.49019813537597656, -0.8133754730224609, 0.7234840393066406, -0.029272079467773438, -0.8816928863525391, -0.000579833984375, -0.0850982666015625, 1.0140609741210938, 0.25705528259277344, -0.24324798583984375, 0.45835304260253906, 1.3212776184082031, 0.2931861877441406, 0.2761573791503906, -0.3280601501464844, -0.4095592498779297, 0.4958610534667969, -0.08624839782714844, 0.8045806884765625, 1.3131170272827148, 0.07943534851074219, 0.8500709533691406, -0.6066169738769531, 0.5439577102661133, 0.6856231689453125, 0.9204587936401367, 1.375737190246582, 13.799386024475098, 1.2723007202148438, -0.6324520111083984, 0.2758007049560547, -0.17597579956054688, 1.1479988098144531, -0.5490970611572266, -0.596287727355957, -0.3802356719970703, -0.06042289733886719, 0.3390235900878906, 0.9161777496337891, 0.6607227325439453, -1.4337115287780762, -5.237067222595215, -1.4337115287780762, 13.287720680236816, -0.21383190155029297, 0.8909683227539062, 0.2855796813964844, 1.349954605102539, 2.299680709838867, -0.230072021484375, -1.0066795349121094, 0.8593330383300781, 0.5631732940673828, 1.6188491582870483, -2.334071159362793, 1.1946163177490234, 0.1371002197265625, 0.5374908447265625, 0.18649959564208984, 0.3169746398925781, -4.5814056396484375, 0.4296398162841797, -0.4764251708984375, 0.23276710510253906, 0.1479206085205078, -0.1595935821533203, 0.9664621353149414, -0.05638313293457031, 0.22188377380371094, -0.2027873992919922, 0.46659183502197266, 0.3408985137939453], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 77824, "num_env_steps_trained": 288240, "num_agent_steps_sampled": 77824, "num_agent_steps_trained": 288240, "last_target_update_ts": 77824, "num_target_updates": 151}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -669.312836073339, "episode_reward_mean": -27.841920133829117, "episode_len_mean": 233.65, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689], "episode_lengths": [235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5519430302574746, "mean_inference_ms": 24.776868828421094, "mean_action_processing_ms": 0.13422428975747866, "mean_env_wait_ms": 4.393335728344671, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -669.312836073339, "episode_reward_mean": -27.841920133829117, "episode_len_mean": 233.65, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [19.396844260394573, 6.60775550454855, -126.62867104262114, 14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689], "episode_lengths": [235, 198, 299, 202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5519430302574746, "mean_inference_ms": 24.776868828421094, "mean_action_processing_ms": 0.13422428975747866, "mean_env_wait_ms": 4.393335728344671, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 77824, "num_agent_steps_trained": 288240, "num_env_steps_sampled": 77824, "num_env_steps_trained": 288240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 77824, "agent_timesteps_total": 77824, "timers": {"training_iteration_time_ms": 346.202, "learn_time_ms": 68.933, "learn_throughput": 3481.627, "synch_weights_time_ms": 22.287}, "counters": {"num_env_steps_sampled": 77824, "num_env_steps_trained": 288240, "num_agent_steps_sampled": 77824, "num_agent_steps_trained": 288240, "last_target_update_ts": 77824, "num_target_updates": 151}, "done": false, "episodes_total": 283, "training_iteration": 76, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-07-58", "timestamp": 1655478478, "time_this_iter_s": 5.534031867980957, "time_total_s": 405.36168909072876, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 405.36168909072876, "timesteps_since_restore": 0, "iterations_since_restore": 76, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.5125, "ram_util_percent": 64.4875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.802845001220703, "min_q": -25.718629837036133, "max_q": 31.280954360961914, "mean_td_error": -0.3099990785121918}, "td_error": [-0.5666732788085938, -0.6964988708496094, 0.7067422866821289, 4.426851272583008, -0.27039527893066406, 0.7895431518554688, -0.8486194610595703, 0.4866170883178711, -0.4810924530029297, -0.9379806518554688, -0.2996540069580078, -0.4583244323730469, -0.7297096252441406, -1.3403854370117188, 1.0036845207214355, -0.3227691650390625, -0.47408485412597656, -1.4191341400146484, -0.4525318145751953, -0.8948326110839844, -1.3793373107910156, -0.19145584106445312, 0.2525510787963867, -0.4872856140136719, -0.21709060668945312, -0.5664043426513672, -0.26185035705566406, 0.2581291198730469, -0.20165634155273438, 0.3373851776123047, 0.484344482421875, -0.7250137329101562, -1.0346879959106445, 21.18366050720215, -0.40056800842285156, -4.219808578491211, -0.013370513916015625, 0.016571044921875, 0.34693336486816406, -1.9783439636230469, -0.15787506103515625, 0.2604866027832031, 2.3300552368164062, -0.19832324981689453, -0.42010498046875, -4.7943572998046875, 0.4825286865234375, -0.38312244415283203, -5.28422737121582, -0.7085533142089844, -0.17444419860839844, -1.8436813354492188, 0.5078926086425781, -0.7260150909423828, -0.964202880859375, -0.6160554885864258, -0.47922706604003906, -1.115560531616211, -0.49945640563964844, 0.02053213119506836, -0.7629499435424805, -1.0077266693115234, -7.013866424560547, 0.7146749496459961, 0.21335124969482422, 0.4049406051635742, -1.0709705352783203, -9.728958129882812, -1.5198230743408203, -0.3512001037597656, -11.071283340454102, -0.27553558349609375, -0.07496070861816406, -0.012043952941894531, -0.6476192474365234, 0.3844585418701172, -0.5259761810302734, 0.22739601135253906, -0.4179344177246094, -0.28648948669433594, 0.11427879333496094, -0.7104482650756836, 0.089202880859375, -7.026787757873535, 0.4792776107788086, -1.4304685592651367, 8.938986778259277, -0.8669137954711914, 0.6972074508666992, -0.9271259307861328, 0.18430709838867188, -0.30792999267578125, -0.3751335144042969, -1.863260269165039, -0.0023212432861328125, -0.5284318923950195, -1.355661392211914, -0.16942596435546875, 1.4984431266784668, -0.5414752960205078, -0.009383201599121094, -0.8981513977050781, 0.6717910766601562, -0.05682945251464844, -0.6052322387695312, -0.2630634307861328, -0.3405609130859375, 11.818572044372559, -1.0502281188964844, -0.208526611328125, -0.3687572479248047, -0.05853843688964844, -1.029886245727539, -0.45823097229003906, -0.9649772644042969, -0.02057647705078125, 0.15027809143066406, 0.10009193420410156, -0.8127670288085938, -0.8388872146606445, -0.9066905975341797, -0.9581441879272461, -4.743068695068359, 0.46572113037109375, -1.0378227233886719, -0.618072509765625, -0.4368858337402344, -0.1901378631591797, -0.012481689453125, -0.5356454849243164, -0.44503211975097656, 0.15462112426757812, -0.34915924072265625, -0.10563850402832031, -0.579315185546875, -0.8825912475585938, 0.20573663711547852, -0.4655113220214844, -4.111980438232422, -1.7281131744384766, -0.15388107299804688, -1.0201473236083984, -0.6535720825195312, -0.7207846641540527, -0.9470119476318359, 0.7876071929931641, 22.839540481567383, -4.860639572143555, 0.9774923324584961, -0.09207630157470703, -0.5969524383544922, -0.9969215393066406, -1.1958675384521484, -0.6469383239746094, -1.229452133178711, -0.1571788787841797, -0.09531593322753906, 0.6122722625732422, -0.2778167724609375, -0.13982391357421875, -0.8871974945068359, 0.23086261749267578, -0.3130035400390625, -0.7869129180908203, 11.149232864379883, -0.1974945068359375, 0.5250053405761719, -1.1905078887939453, -6.889244556427002, -0.5846767425537109, 0.5990447998046875, 0.13636398315429688, -0.8818845748901367, -1.9557552337646484, -0.4614391326904297, -11.585209846496582, 1.0012187957763672, -0.033931732177734375, -0.44339942932128906, 0.141754150390625, -0.2902812957763672, 1.8921012878417969, -0.6770534515380859, -0.6732463836669922, -0.9454593658447266, 0.1616753339767456, 0.2561454772949219, 0.215240478515625, -0.046539306640625, -0.4506034851074219, -0.8111114501953125, 0.0660696029663086, 0.5180225372314453, -0.3775444030761719, -0.8625288009643555, -0.06862449645996094, -0.14676570892333984, 1.4229345321655273, -0.1518402099609375, -0.6421432495117188, -0.3462867736816406, 0.10826683044433594, -0.01987171173095703, -0.5437240600585938, 0.07954978942871094, -0.634674072265625, -0.07123947143554688, -0.8177890777587891, -0.3250141143798828, -0.45228004455566406, -0.07963371276855469, -0.9390926361083984, 0.3285503387451172, -0.7677860260009766, -0.3455944061279297, -0.2329883575439453, 0.14937305450439453, -0.6211700439453125, -0.2918510437011719, -1.2790451049804688, 0.32365989685058594, 0.40746021270751953, -0.05385780334472656, -1.5741329193115234, -0.6484336853027344, -0.5504932403564453, 0.7001819610595703, -0.49102210998535156, -0.8007640838623047, -0.9157829284667969, -0.3829994201660156, -0.3290519714355469, -0.11452007293701172, -0.7056732177734375, 0.12004280090332031, -1.249216079711914, -0.36165904998779297, -2.117669105529785, 0.19830703735351562, -0.3551349639892578], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 78848, "num_env_steps_trained": 292080, "num_agent_steps_sampled": 78848, "num_agent_steps_trained": 292080, "last_target_update_ts": 78848, "num_target_updates": 153}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -669.312836073339, "episode_reward_mean": -26.293279142677783, "episode_len_mean": 232.76, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203], "episode_lengths": [202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5521188590472667, "mean_inference_ms": 24.758086646978146, "mean_action_processing_ms": 0.13419339661306545, "mean_env_wait_ms": 4.394245692260972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -669.312836073339, "episode_reward_mean": -26.293279142677783, "episode_len_mean": 232.76, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [14.91063528507948, -40.88453683257103, 14.11063552647829, 14.200902424752712, -11.192244552075863, -171.15617545694113, 6.500000096857548, 15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203], "episode_lengths": [202, 248, 209, 239, 211, 304, 214, 217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5521188590472667, "mean_inference_ms": 24.758086646978146, "mean_action_processing_ms": 0.13419339661306545, "mean_env_wait_ms": 4.394245692260972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 78848, "num_agent_steps_trained": 292080, "num_env_steps_sampled": 78848, "num_env_steps_trained": 292080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 78848, "agent_timesteps_total": 78848, "timers": {"training_iteration_time_ms": 347.084, "learn_time_ms": 68.918, "learn_throughput": 3482.424, "synch_weights_time_ms": 20.892}, "counters": {"num_env_steps_sampled": 78848, "num_env_steps_trained": 292080, "num_agent_steps_sampled": 78848, "num_agent_steps_trained": 292080, "last_target_update_ts": 78848, "num_target_updates": 153}, "done": false, "episodes_total": 286, "training_iteration": 77, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-04", "timestamp": 1655478484, "time_this_iter_s": 5.533849239349365, "time_total_s": 410.8955383300781, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 410.8955383300781, "timesteps_since_restore": 0, "iterations_since_restore": 77, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 36.4875, "ram_util_percent": 64.51249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 17.202974319458008, "min_q": -30.48323631286621, "max_q": 34.48344802856445, "mean_td_error": -0.24246083199977875}, "td_error": [0.33724212646484375, 2.2957394123077393, -0.550750732421875, -1.0059242248535156, -0.3359355926513672, 0.2298564910888672, -0.16579341888427734, 0.7965974807739258, -0.29992103576660156, 0.5161323547363281, 1.1452369689941406, -5.636816024780273, 0.9882278442382812, 0.013034820556640625, 0.7384490966796875, -0.7512636184692383, 1.026254653930664, -5.941864013671875, -0.41153717041015625, -0.5192623138427734, 1.5031347274780273, -6.184209823608398, 1.1134834289550781, 0.19106483459472656, 0.7058753967285156, 0.3391294479370117, 0.35867881774902344, 0.10836219787597656, -0.6586856842041016, -0.12814712524414062, 2.5636844635009766, -8.088245391845703, -0.13785362243652344, -6.171762466430664, -0.10796928405761719, -7.293954849243164, -5.8657379150390625, 0.4530506134033203, -1.1632709503173828, 0.4587879180908203, 0.06079387664794922, -0.03540992736816406, 0.7194595336914062, -0.47110748291015625, -0.07162666320800781, -6.06413459777832, 0.9740419387817383, 0.3521871566772461, -0.043872833251953125, -0.03821372985839844, -0.16258466243743896, 0.31592845916748047, 0.5429286956787109, 0.454653263092041, 0.04599952697753906, 0.9367942810058594, -0.09925460815429688, -1.3048839569091797, 1.6395139694213867, -0.4614410400390625, 0.5217437744140625, 0.050604820251464844, 0.15598678588867188, -0.8680400848388672, 0.3933734893798828, 12.70413589477539, 1.0301566123962402, -0.2745840549468994, -0.2835197448730469, -0.138946533203125, 0.12448310852050781, -0.08159446716308594, -1.8708515167236328, -1.777029037475586, 2.9587860107421875, -0.8827724456787109, 0.1056523323059082, 0.7442741394042969, 0.6943473815917969, 0.3128085136413574, 0.6272487640380859, -0.7862339019775391, -0.1539449691772461, -0.1361856460571289, -0.5109081268310547, -0.8402137756347656, 17.651302337646484, -0.7659206390380859, 0.1790313720703125, -0.9571800231933594, -6.706690788269043, -0.269622802734375, -0.7291240692138672, -0.08568763732910156, -0.2360248565673828, -0.7133522033691406, -0.2485637664794922, 0.017669677734375, 0.8951740264892578, 0.2479114532470703, 0.5250377655029297, -0.5608921051025391, -0.7836513519287109, -0.3339424133300781, -0.4478034973144531, -0.5409040451049805, 0.09309101104736328, -1.031158447265625, -0.8563385009765625, -0.09851455688476562, -0.09526824951171875, -0.2516326904296875, 0.4920921325683594, 0.8046884536743164, -0.3813304901123047, -2.0093917846679688, -0.26727294921875, -1.4680500030517578, -0.00688934326171875, 2.35646915435791, -0.11338520050048828, 0.08649635314941406, -1.087148666381836, -0.06572914123535156, 0.2230520248413086, -0.6016273498535156, 1.1065788269042969, -0.4066276550292969, -6.012199401855469, 0.504119873046875, -0.346343994140625, 0.39629077911376953, -1.093475341796875, 0.2791929244995117, 0.054805755615234375, 0.08178138732910156, 0.0009708404541015625, -0.3326263427734375, -0.4242572784423828, -0.06141090393066406, -1.3505020141601562, -0.22292137145996094, 0.24995040893554688, 0.43194580078125, -0.1313343048095703, -0.13009357452392578, 0.6974563598632812, -0.07819938659667969, 0.021860122680664062, -0.43841552734375, -0.7393283843994141, 0.812748908996582, 0.18029022216796875, 0.21759033203125, -0.8497800827026367, -1.8197212219238281, -0.6225566864013672, -0.07987451553344727, -2.170762538909912, -0.17005634307861328, -0.6757335662841797, 13.025540351867676, -0.2415027618408203, -0.24193572998046875, -1.45343017578125, 0.3812294006347656, -0.6121559143066406, -0.41153717041015625, 0.17313194274902344, -0.010248184204101562, -0.6058673858642578, -0.11164283752441406, -0.1403656005859375, -0.9271221160888672, -1.4622993469238281, -0.49779605865478516, -0.45502281188964844, -0.18427371978759766, 0.9047069549560547, -1.4911775588989258, -0.3269481658935547, 0.6178131103515625, 0.40231800079345703, -3.9730224609375, -0.13701820373535156, -2.6979799270629883, -0.14520645141601562, -9.372993469238281, -1.02789306640625, 0.78302001953125, -0.5515766143798828, -3.7183117866516113, -0.49241065979003906, -0.2734699249267578, -0.28765869140625, -0.8782367706298828, -0.2567710876464844, 16.609195709228516, 0.24506759643554688, -0.6126308441162109, 0.12622642517089844, 0.10836219787597656, -4.682741165161133, 0.0200042724609375, 0.2586669921875, 0.9166927337646484, -0.7042531967163086, -0.2794647216796875, -1.612372875213623, -1.5146560668945312, 0.1430797576904297, -1.3764839172363281, -0.41153717041015625, 0.2979698181152344, -0.17706680297851562, -0.9949831962585449, -0.1145172119140625, 0.6315889358520508, -0.14445114135742188, -0.6626968383789062, -1.7002906799316406, -0.36972808837890625, 0.1117696762084961, -0.4426286220550537, 1.0912914276123047, 1.0755863189697266, 0.36507320404052734, 0.9915561676025391, -0.10548210144042969, -0.12173652648925781, -0.3860616683959961, -0.21736812591552734, -4.837493896484375, -0.5330686569213867, -1.199981689453125, -0.5155811309814453, -0.29595375061035156, -1.4115028381347656, -0.3135948181152344, -1.056234359741211], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 79872, "num_env_steps_trained": 295920, "num_agent_steps_sampled": 79872, "num_agent_steps_trained": 295920, "last_target_update_ts": 79872, "num_target_updates": 155}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -669.312836073339, "episode_reward_mean": -27.32922901391983, "episode_len_mean": 233.28, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071], "episode_lengths": [217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5535589923821794, "mean_inference_ms": 24.804659707499486, "mean_action_processing_ms": 0.13428817782531016, "mean_env_wait_ms": 4.407416409805578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -669.312836073339, "episode_reward_mean": -27.32922901391983, "episode_len_mean": 233.28, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [15.913220204412937, 17.10090249031782, 6.900000169873238, 21.72957156598568, -669.312836073339, 7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071], "episode_lengths": [217, 225, 216, 222, 438, 219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5535589923821794, "mean_inference_ms": 24.804659707499486, "mean_action_processing_ms": 0.13428817782531016, "mean_env_wait_ms": 4.407416409805578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 79872, "num_agent_steps_trained": 295920, "num_env_steps_sampled": 79872, "num_env_steps_trained": 295920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 79872, "agent_timesteps_total": 79872, "timers": {"training_iteration_time_ms": 357.935, "learn_time_ms": 67.681, "learn_throughput": 3546.064, "synch_weights_time_ms": 20.884}, "counters": {"num_env_steps_sampled": 79872, "num_env_steps_trained": 295920, "num_agent_steps_sampled": 79872, "num_agent_steps_trained": 295920, "last_target_update_ts": 79872, "num_target_updates": 155}, "done": false, "episodes_total": 293, "training_iteration": 78, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-10", "timestamp": 1655478490, "time_this_iter_s": 5.625376224517822, "time_total_s": 416.52091455459595, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 416.52091455459595, "timesteps_since_restore": 0, "iterations_since_restore": 78, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 36.725, "ram_util_percent": 64.4625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.66956901550293, "min_q": -28.488197326660156, "max_q": 35.54587173461914, "mean_td_error": 0.11172602325677872}, "td_error": [0.3458423614501953, -0.2416095733642578, -2.2727088928222656, -0.8491525650024414, -0.8659572601318359, -0.6920309066772461, 0.7006263732910156, -0.5621967315673828, -1.6326465606689453, 0.3692331314086914, 0.09369468688964844, 0.46447181701660156, -0.23712539672851562, -0.6947593688964844, 1.1180143356323242, 17.038747787475586, 0.722010612487793, 0.7385063171386719, -0.7913398742675781, 0.44895267486572266, -10.29383659362793, 0.43730926513671875, -0.1748504638671875, -0.43124961853027344, -0.6470355987548828, -0.131988525390625, -10.000139236450195, -0.7885627746582031, 0.17450523376464844, 0.054749488830566406, 15.400243759155273, -6.208854675292969, -0.7377700805664062, -0.10061836242675781, -0.07670211791992188, 0.7120809555053711, -0.45642662048339844, 0.07982063293457031, 0.017101287841796875, -0.18858909606933594, 0.05545234680175781, -0.6019964218139648, 17.459041595458984, -0.5938816070556641, 1.0445137023925781, -0.6331024169921875, 17.429643630981445, -0.5144615173339844, 2.31827449798584, -0.4035301208496094, 0.7298469543457031, 0.8882303237915039, 0.18372154235839844, 1.6254148483276367, -0.5004425048828125, -0.4311542510986328, -0.6751384735107422, -0.03449821472167969, 0.9141597747802734, -0.4928874969482422, -0.43818092346191406, -1.1920089721679688, 0.6664752960205078, -0.5948104858398438, -7.026021957397461, -0.5076560974121094, 0.6376142501831055, -0.8371868133544922, -0.3214569091796875, -0.4146881103515625, -0.759124755859375, -1.044809341430664, 0.27751827239990234, -0.38838958740234375, -0.5827245712280273, -5.315093994140625, -0.27544212341308594, -10.247186660766602, -10.701313018798828, -1.8860645294189453, -0.022426605224609375, 1.1689033508300781, 0.19469642639160156, 0.16150665283203125, 1.3950138092041016, 0.4282360076904297, -0.6632785797119141, 0.7007989883422852, -0.4908590316772461, -0.8452663421630859, 0.9817361831665039, -0.5336780548095703, 0.5765647888183594, -0.6110324859619141, -5.748420715332031, -0.7102813720703125, -0.1984872817993164, -0.4472522735595703, -0.5966777801513672, 1.4966793060302734, 0.35661888122558594, 0.24996185302734375, 0.5654211044311523, -0.019666671752929688, -0.7899665832519531, -0.37604331970214844, -0.411529541015625, -0.8978157043457031, -0.2773914337158203, 1.3563432693481445, -0.8678493499755859, 0.024387359619140625, -0.04279136657714844, 0.08883285522460938, 1.2972650527954102, -0.8695755004882812, 13.746932029724121, -0.2680625915527344, -0.8150043487548828, -0.34935951232910156, 0.5285110473632812, -0.014159202575683594, -0.6062545776367188, -0.2458648681640625, 0.2989645004272461, -0.09502983093261719, 0.40183258056640625, -0.9668922424316406, -1.7771186828613281, -0.5826492309570312, 1.086252212524414, -0.11477470397949219, -0.6564445495605469, -0.5194969177246094, -0.6068038940429688, -0.37152099609375, 0.987541675567627, 1.2734785079956055, 0.703704833984375, 0.5210094451904297, -0.9729862213134766, -0.3453865051269531, 0.37053489685058594, -0.8199386596679688, -0.13115406036376953, 0.9909558296203613, 1.0826420783996582, -0.43667125701904297, -0.32414817810058594, 0.24419403076171875, 9.217103004455566, 1.086252212524414, 0.42348670959472656, -1.4237656593322754, -0.8272495269775391, -0.1236114501953125, 0.42348670959472656, -0.5052499771118164, 0.0065364837646484375, 0.5223417282104492, -0.5468158721923828, -0.6270627975463867, -0.4141120910644531, 0.3892326354980469, -0.27544212341308594, 0.4385814666748047, -0.2739582061767578, 0.008784294128417969, -0.47603607177734375, -0.39507007598876953, -0.5010509490966797, -0.5575380325317383, -0.3100852966308594, 0.4370403289794922, 0.4882183074951172, -1.1913576126098633, 0.6803131103515625, -1.4284985065460205, 0.2994556427001953, -0.3562278747558594, -0.07872581481933594, -0.5794429779052734, -0.5288867950439453, 0.5493602752685547, -0.27880859375, -1.0636615753173828, -0.4525337219238281, -0.5954246520996094, -0.6942214965820312, -0.5305976867675781, -0.4079246520996094, 1.0119647979736328, -0.5328502655029297, -0.2881793975830078, -0.6248893737792969, 1.056656837463379, 0.15253067016601562, -0.9531688690185547, -0.14024925231933594, -1.1518821716308594, -0.08988380432128906, 25.02445411682129, 0.9486656188964844, -0.3289966583251953, -1.0790424346923828, 0.38060569763183594, -0.3034381866455078, -0.6326789855957031, 0.058864593505859375, 0.16326236724853516, 22.013225555419922, -1.1489639282226562, 0.2997007369995117, -6.301686763763428, -0.8218202590942383, -0.355501651763916, -0.3324871063232422, -1.1627140045166016, -0.46275901794433594, -0.3762540817260742, 0.27368927001953125, 1.3179588317871094, -0.5103311538696289, -0.4860706329345703, -0.5882720947265625, 0.29933786392211914, 0.11335563659667969, 0.43392181396484375, -0.4978370666503906, -0.09866714477539062, 1.1088356971740723, -0.9242582321166992, -0.13498497009277344, -0.45641231536865234, -0.28124427795410156, 0.2848930358886719, -0.9414463043212891, 0.6073598861694336, -1.0787792205810547, -8.672038078308105], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 80896, "num_env_steps_trained": 299760, "num_agent_steps_sampled": 80896, "num_agent_steps_trained": 299760, "last_target_update_ts": 80896, "num_target_updates": 157}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -22.0891877309978, "episode_len_mean": 231.52, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664], "episode_lengths": [219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5550769703844872, "mean_inference_ms": 24.804557927376756, "mean_action_processing_ms": 0.13418347867788738, "mean_env_wait_ms": 4.414818815198697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -22.0891877309978, "episode_len_mean": 231.52, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [7.000000074505806, -77.89223864674568, 35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664], "episode_lengths": [219, 270, 223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5550769703844872, "mean_inference_ms": 24.804557927376756, "mean_action_processing_ms": 0.13418347867788738, "mean_env_wait_ms": 4.414818815198697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 80896, "num_agent_steps_trained": 299760, "num_env_steps_sampled": 80896, "num_env_steps_trained": 299760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 80896, "agent_timesteps_total": 80896, "timers": {"training_iteration_time_ms": 339.995, "learn_time_ms": 67.925, "learn_throughput": 3533.296, "synch_weights_time_ms": 20.288}, "counters": {"num_env_steps_sampled": 80896, "num_env_steps_trained": 299760, "num_agent_steps_sampled": 80896, "num_agent_steps_trained": 299760, "last_target_update_ts": 80896, "num_target_updates": 157}, "done": false, "episodes_total": 298, "training_iteration": 79, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-15", "timestamp": 1655478495, "time_this_iter_s": 5.274181604385376, "time_total_s": 421.7950961589813, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 421.7950961589813, "timesteps_since_restore": 0, "iterations_since_restore": 79, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.412499999999994, "ram_util_percent": 64.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 18.24941635131836, "min_q": -26.776065826416016, "max_q": 37.3291130065918, "mean_td_error": 0.4294740557670593}, "td_error": [-6.12077522277832, -0.21155738830566406, 0.11309337615966797, 0.9396762847900391, 0.37851619720458984, -4.651433944702148, -0.419586181640625, 0.8460445404052734, 0.3381538391113281, 0.240142822265625, 0.20003509521484375, 3.0403881072998047, 0.1850452423095703, 0.7877912521362305, 0.6001567840576172, -0.0014467239379882812, 0.24950408935546875, 0.3545494079589844, -1.0933418273925781, 0.3006458282470703, -0.6870937347412109, -0.7085962295532227, -2.0066356658935547, -0.017246246337890625, -0.25559234619140625, 1.0563764572143555, 0.07144737243652344, 2.1782779693603516, 0.33143043518066406, 0.464569091796875, 0.25250244140625, 0.18096923828125, 0.05877876281738281, 0.5824966430664062, 0.9161872863769531, 0.2152252197265625, 0.5541868209838867, 1.1438369750976562, -0.19571399688720703, 0.017589569091796875, 0.1772308349609375, 0.0938262939453125, -0.2199859619140625, -1.1227989196777344, 0.09466743469238281, 0.6584339141845703, -0.11979341506958008, -0.16924762725830078, 0.7994613647460938, 0.7039203643798828, -0.15221405029296875, -0.06328392028808594, 0.3324604034423828, 0.11960411071777344, 0.1283588409423828, 0.1260356903076172, 0.2334156036376953, -0.8122415542602539, 0.725982666015625, 0.0441741943359375, 1.256434440612793, 0.2540454864501953, 0.43163108825683594, -0.051380157470703125, -1.3863739967346191, 0.011829376220703125, 1.6293373107910156, -6.397947311401367, 17.4299259185791, 0.07171440124511719, -7.413909912109375, 9.521042823791504, 0.1393728256225586, 0.27474403381347656, 0.030050277709960938, -0.05193901062011719, 0.31923675537109375, 0.646977424621582, 0.2003326416015625, -0.060455322265625, 1.044912338256836, 0.32192420959472656, -0.21218490600585938, 0.3525409698486328, -0.0768585205078125, -1.8058948516845703, 0.32500648498535156, 0.9981193542480469, 0.046347618103027344, 1.557210922241211, -0.32854652404785156, -0.9885921478271484, -3.0385189056396484, 0.6317510604858398, 0.7579164505004883, -0.27489185333251953, 0.10983657836914062, -0.08190059661865234, -5.122714996337891, 14.418354988098145, 3.4696054458618164, 0.3788604736328125, 0.03341865539550781, 0.074066162109375, 0.6523723602294922, -0.056400299072265625, -3.4816665649414062, 1.592926025390625, 0.03726387023925781, 0.6490211486816406, 0.31871795654296875, 0.3286266326904297, -0.1353435516357422, -0.09700775146484375, 0.33585166931152344, 0.4469470977783203, 1.0973267555236816, 19.031267166137695, 0.3453330993652344, 0.6584339141845703, 0.5073375701904297, -0.8568153381347656, -1.2016570568084717, 1.7213611602783203, -0.029985427856445312, 0.10046958923339844, 0.5462589263916016, -9.44662857055664, 0.7113847732543945, 0.17860984802246094, 0.3205757141113281, 0.13979721069335938, 0.2916278839111328, -0.5241165161132812, 1.3731822967529297, 0.5705575942993164, 0.35266828536987305, 0.6647529602050781, 0.24568748474121094, 1.0088329315185547, -0.19220495223999023, 26.959455490112305, -0.062000274658203125, 0.35478782653808594, -0.9248189926147461, -0.9551849365234375, 0.6731700897216797, 1.566117286682129, -0.4482889175415039, 0.9142951965332031, 0.9946231842041016, -0.10597038269042969, 0.7251224517822266, 0.42816162109375, 0.28673744201660156, 0.2191448211669922, 0.44734859466552734, -0.10160255432128906, 0.047901153564453125, 0.7067375183105469, 0.8583278656005859, 0.7329673767089844, -0.6091117858886719, -0.08062934875488281, 0.8067874908447266, 1.0563488006591797, -5.685403823852539, 1.1018009185791016, 0.6809139251708984, -0.4716196060180664, -0.7854366302490234, -0.9429473876953125, -0.0707252025604248, 0.3594169616699219, 1.698129653930664, 0.8344268798828125, 0.3834047317504883, -0.3059978485107422, 0.6325168609619141, 1.4067702293395996, 1.8641777038574219, 0.8210134506225586, 0.4789848327636719, 4.698160171508789, 0.3171863555908203, 0.04912376403808594, 0.3105030059814453, 1.4956083297729492, 0.07837963104248047, 1.2698478698730469, -0.16117286682128906, 16.455331802368164, 0.9640941619873047, 0.40293312072753906, 1.4507255554199219, 0.8897266387939453, -1.7781944274902344, -0.5606441497802734, 1.0323963165283203, 0.8460731506347656, 0.26665306091308594, -3.011058807373047, 1.4067702293395996, -0.32779884338378906, -0.2980690002441406, 0.6113643646240234, 0.8269691467285156, 1.1785812377929688, 0.25634765625, 0.13183212280273438, 0.17876434326171875, -0.10199356079101562, 0.235931396484375, -9.065710067749023, 0.3105030059814453, -9.16511344909668, 1.4396591186523438, 0.5678930282592773, 0.4010334014892578, -0.43802452087402344, 0.5585222244262695, -0.4636726379394531, 0.43129920959472656, 0.21425437927246094, 1.564600944519043, -0.4993553161621094, 1.4588680267333984, 0.6445999145507812, 0.23824691772460938, 0.3577289581298828, -1.2139225006103516, 0.00814056396484375, 0.9531097412109375, -0.013767242431640625, 0.05891227722167969, -1.4261417388916016, -0.3575286865234375, -0.3604869842529297, 1.557210922241211, 0.25228118896484375], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 81920, "num_env_steps_trained": 303600, "num_agent_steps_sampled": 81920, "num_agent_steps_trained": 303600, "last_target_update_ts": 81920, "num_target_updates": 159}, "sampler_results": {"episode_reward_max": 38.46270017325878, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -21.149869531989097, "episode_len_mean": 231.04, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683], "episode_lengths": [223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.555414545576339, "mean_inference_ms": 24.800352646018528, "mean_action_processing_ms": 0.1341339875227338, "mean_env_wait_ms": 4.416754452912888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 38.46270017325878, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -21.149869531989097, "episode_len_mean": 231.04, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [35.481845423579216, 28.062302857637405, -21.500000067055225, -12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683], "episode_lengths": [223, 185, 245, 214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.555414545576339, "mean_inference_ms": 24.800352646018528, "mean_action_processing_ms": 0.1341339875227338, "mean_env_wait_ms": 4.416754452912888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 81920, "num_agent_steps_trained": 303600, "num_env_steps_sampled": 81920, "num_env_steps_trained": 303600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 81920, "agent_timesteps_total": 81920, "timers": {"training_iteration_time_ms": 329.957, "learn_time_ms": 68.384, "learn_throughput": 3509.61, "synch_weights_time_ms": 21.388}, "counters": {"num_env_steps_sampled": 81920, "num_env_steps_trained": 303600, "num_agent_steps_sampled": 81920, "num_agent_steps_trained": 303600, "last_target_update_ts": 81920, "num_target_updates": 159}, "done": false, "episodes_total": 300, "training_iteration": 80, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-21", "timestamp": 1655478501, "time_this_iter_s": 5.21576189994812, "time_total_s": 427.01085805892944, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 427.01085805892944, "timesteps_since_restore": 0, "iterations_since_restore": 80, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 38.271428571428565, "ram_util_percent": 64.47142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.52638816833496, "min_q": -26.50861358642578, "max_q": 35.00904083251953, "mean_td_error": 0.19639822840690613}, "td_error": [-0.48470497131347656, -0.3258495330810547, -0.029264450073242188, 0.4739542007446289, -4.146726608276367, 1.0825691223144531, 1.8585186004638672, 0.4860668182373047, -0.23481178283691406, 0.5439300537109375, 18.583881378173828, -0.24953269958496094, 1.6422786712646484, 1.1158084869384766, -0.8693370819091797, -24.50861358642578, 0.9969120025634766, 0.9234199523925781, -0.6195259094238281, -0.45232391357421875, 2.378662109375, 0.26657962799072266, 0.33289051055908203, -0.5668411254882812, 0.2795829772949219, 0.6934986114501953, 0.9232387542724609, 0.26764965057373047, -0.22965431213378906, -6.818849563598633, 0.2566404342651367, -0.4508647918701172, 1.042740821838379, 0.8000993728637695, -0.17194557189941406, 0.7224874496459961, 0.4336986541748047, 0.6067657470703125, 0.9268684387207031, -0.4010505676269531, 0.3237342834472656, 1.6357126235961914, -1.4990606307983398, 2.5805864334106445, 0.49333953857421875, 0.26764965057373047, -0.9164628982543945, -5.904634475708008, 0.8180923461914062, -0.23658180236816406, 0.256622314453125, -0.21191787719726562, -0.47954750061035156, 2.3622541427612305, 0.5464801788330078, 0.9717330932617188, 0.8175811767578125, -0.3299102783203125, 0.7067279815673828, 1.3851876258850098, -0.4818897247314453, 0.25316619873046875, 1.3712348937988281, -0.15027999877929688, 1.2670154571533203, -0.8054351806640625, -0.5199756622314453, 0.47339439392089844, -0.11886024475097656, -0.05242919921875, -0.5001249313354492, 0.6520862579345703, 0.11184310913085938, 0.5514521598815918, -0.7844810485839844, 0.5820674896240234, -0.09849739074707031, 1.5496540069580078, 0.48853206634521484, -1.571044921875, 0.8505496978759766, 0.8632879257202148, -7.823917388916016, -0.7234697341918945, 0.39415740966796875, -0.207672119140625, 0.24182891845703125, -0.4945945739746094, 0.131439208984375, 1.0942106246948242, 1.4462471008300781, 0.5826396942138672, -1.0787506103515625, 0.7202472686767578, -0.4017162322998047, 1.097203254699707, -1.2171516418457031, 0.6880702972412109, -0.2910022735595703, -1.3968658447265625, 1.2215709686279297, 0.24609375, 1.4536352157592773, 1.3470420837402344, 1.4766082763671875, 0.7082252502441406, 0.08874320983886719, -0.5630712509155273, -1.568251609802246, -7.051506042480469, 1.2939634323120117, -0.1657562255859375, -0.037281036376953125, 0.4012584686279297, 0.5938987731933594, 0.7257766723632812, 0.505523681640625, 0.6741308569908142, 0.3805961608886719, 0.8795661926269531, -0.7391452789306641, -0.020009994506835938, 0.23441123962402344, -0.687957763671875, 1.035848617553711, 0.107147216796875, 0.26799774169921875, 1.1848649978637695, 1.5191802978515625, -0.9649944305419922, -0.011019706726074219, 0.19659805297851562, 0.7276515960693359, 0.9693622589111328, -0.8276653289794922, 1.4043807983398438, 1.8095512390136719, -5.920300483703613, 1.156209945678711, -1.0058517456054688, 0.4056663513183594, 0.5639553070068359, -0.7326908111572266, 1.0037364959716797, 1.2377662658691406, -0.6333274841308594, 13.73045539855957, 0.9866733551025391, 17.64297866821289, 0.5089454650878906, 0.7885608673095703, 0.2814750671386719, 0.05753517150878906, -0.3826923370361328, 0.9553251266479492, 0.5265111923217773, 0.45400428771972656, 0.393951416015625, -0.3114013671875, -0.8298959732055664, -0.8672256469726562, 0.6643447875976562, 1.3409919738769531, 0.20842742919921875, -5.2817840576171875, 1.1412763595581055, 0.4663095474243164, -0.9535007476806641, -0.3797798156738281, -3.2409563064575195, -0.5197372436523438, 1.5553722381591797, -0.6595420837402344, 1.1824512481689453, -0.3847646713256836, -1.2562332153320312, -0.09428977966308594, 0.8041706085205078, 0.9401216506958008, -0.3847923278808594, 0.08724594116210938, 1.2963104248046875, -0.5715360641479492, 0.5776138305664062, -0.12127113342285156, -0.027156829833984375, 0.9678096771240234, 0.040191650390625, 0.6128740310668945, 0.5059642791748047, -0.2759265899658203, 0.1765575408935547, 0.5862998962402344, 0.32291221618652344, 0.5233736038208008, 1.5721006393432617, 0.1284961700439453, 1.0693492889404297, -0.091400146484375, 0.014706611633300781, 0.3025364875793457, 0.19265365600585938, -0.09671401977539062, 1.1823654174804688, -5.009471893310547, 0.6697597503662109, 1.5328197479248047, 0.14116477966308594, -0.273712158203125, 0.45393848419189453, 0.7719821929931641, 0.10139846801757812, 0.5292634963989258, 1.0200872421264648, -0.3227252960205078, 0.6093997955322266, -0.19680404663085938, -0.16656875610351562, 0.07338714599609375, 1.1175899505615234, -0.5860748291015625, 0.8698644638061523, 1.7812843322753906, 0.46659088134765625, 1.9494743347167969, -0.3658790588378906, 0.5472116470336914, 0.3310871124267578, -0.7086563110351562, -0.760655403137207, 0.058704376220703125, 0.056884765625, 0.49782562255859375, 0.8862524032592773, 1.263138771057129, 1.4349498748779297, -0.23740196228027344, -0.43926239013671875, -0.6258144378662109, -0.64483642578125], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 82944, "num_env_steps_trained": 307440, "num_agent_steps_sampled": 82944, "num_agent_steps_trained": 307440, "last_target_update_ts": 82944, "num_target_updates": 161}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -22.544611307010054, "episode_len_mean": 231.79, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735], "episode_lengths": [214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5552463364638235, "mean_inference_ms": 24.81275663576856, "mean_action_processing_ms": 0.13430126442329304, "mean_env_wait_ms": 4.420333371309581, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -22.544611307010054, "episode_len_mean": 231.79, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-12.800000108778477, -88.34760616719723, -78.65924606472254, 6.1000000685453415, -82.77078351378441, 4.939851634204388, -34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735], "episode_lengths": [214, 248, 269, 232, 236, 225, 241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5552463364638235, "mean_inference_ms": 24.81275663576856, "mean_action_processing_ms": 0.13430126442329304, "mean_env_wait_ms": 4.420333371309581, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 82944, "num_agent_steps_trained": 307440, "num_env_steps_sampled": 82944, "num_env_steps_trained": 307440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 82944, "agent_timesteps_total": 82944, "timers": {"training_iteration_time_ms": 349.898, "learn_time_ms": 69.876, "learn_throughput": 3434.671, "synch_weights_time_ms": 20.689}, "counters": {"num_env_steps_sampled": 82944, "num_env_steps_trained": 307440, "num_agent_steps_sampled": 82944, "num_agent_steps_trained": 307440, "last_target_update_ts": 82944, "num_target_updates": 161}, "done": false, "episodes_total": 303, "training_iteration": 81, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-26", "timestamp": 1655478506, "time_this_iter_s": 5.5325071811676025, "time_total_s": 432.54336524009705, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 432.54336524009705, "timesteps_since_restore": 0, "iterations_since_restore": 81, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.462500000000006, "ram_util_percent": 64.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.510936737060547, "min_q": -22.843297958374023, "max_q": 36.03066635131836, "mean_td_error": 0.04633072763681412}, "td_error": [-0.13951492309570312, -0.1108245849609375, -0.060553550720214844, 16.48142433166504, -0.9550409317016602, 0.49314308166503906, -1.4978270530700684, 0.8230199813842773, -0.4037017822265625, 0.14859294891357422, -0.7649993896484375, 0.2056255340576172, 0.3805999755859375, 0.4902191162109375, 0.7749176025390625, -0.14841461181640625, -0.3475313186645508, -0.26029396057128906, -0.4368133544921875, 1.4158802032470703, 0.697504997253418, -0.3297920227050781, 0.1216278076171875, 0.6966152191162109, -0.5666770935058594, -0.24168014526367188, 0.174102783203125, -0.5078287124633789, 0.8040657043457031, 0.29500389099121094, -0.21762752532958984, 0.4000816345214844, -0.11412811279296875, 0.3852105140686035, 0.22542095184326172, 0.8098869323730469, -0.5826835632324219, 0.13246536254882812, -0.6037273406982422, 0.8351726531982422, 1.8045978546142578, 0.369171142578125, 1.3302230834960938, -10.448942184448242, 0.3500938415527344, -0.10465812683105469, 0.10903358459472656, 0.20879364013671875, -0.4106292724609375, -1.1601581573486328, -4.567829132080078, 1.5539779663085938, 0.5370893478393555, -0.11703872680664062, 1.3106842041015625, 1.2123947143554688, -0.3632049560546875, -0.6080684661865234, -0.18175697326660156, 0.25409698486328125, -0.4373922348022461, 1.0191726684570312, -1.4844655990600586, -0.07595443725585938, 0.2542896270751953, 0.21921634674072266, 0.8437271118164062, 0.28071022033691406, 0.2028656005859375, -0.3275938034057617, -6.8780412673950195, 0.6479530334472656, -0.16433334350585938, -0.3027000427246094, 1.0336427688598633, 0.17523956298828125, -0.22921085357666016, 0.1753101348876953, 0.2592735290527344, 0.07529640197753906, -0.45899009704589844, 0.15359783172607422, 0.7606468200683594, -0.041736602783203125, -0.040775299072265625, 0.21529006958007812, 0.367431640625, 0.3028087615966797, 0.22149276733398438, 0.11086082458496094, 0.1442394256591797, -1.4844655990600586, 1.3899602890014648, 0.9689998626708984, 0.21362686157226562, -0.46039772033691406, -1.8247032165527344, -0.045828819274902344, -0.274505615234375, 1.1661710739135742, -0.09023284912109375, -0.10853958129882812, -0.4996347427368164, -2.198178768157959, -0.6864013671875, -1.2498836517333984, 0.37291812896728516, 0.7310872077941895, -0.15523338317871094, -1.124814510345459, -0.2357330322265625, -5.244565963745117, 0.30785560607910156, -0.2258930206298828, -0.2313518524169922, 0.3155097961425781, -0.13823699951171875, 0.5793852806091309, 0.04163837432861328, 0.15488243103027344, 0.5837936401367188, -0.14451980590820312, -1.7001304626464844, 0.34314918518066406, -0.025690078735351562, 0.08185195922851562, 0.4886198043823242, -0.4048194885253906, -0.04465770721435547, 0.024805068969726562, 0.6418476104736328, 0.8809566497802734, 0.19214725494384766, 0.3353843688964844, -0.6377792358398438, -7.3084564208984375, 0.2169361114501953, 0.19819068908691406, 0.11774539947509766, -0.5398311614990234, 0.06779098510742188, 0.43975353240966797, 1.6627082824707031, 0.1271953582763672, 1.3891029357910156, 0.08966636657714844, 0.5221853256225586, 0.21410179138183594, -0.6349735260009766, -0.24387741088867188, 0.7827987670898438, -6.501479148864746, -1.496145248413086, -0.12279605865478516, -0.5020103454589844, 1.3197498321533203, 0.6506137847900391, 0.33013057708740234, -0.09215164184570312, -1.0511913299560547, 0.12810611724853516, 0.6198272705078125, -0.3227081298828125, 0.33142948150634766, -0.8425827026367188, 0.9181623458862305, 14.529894828796387, -1.1413211822509766, -0.0077800750732421875, -0.6486186981201172, 0.01107025146484375, -7.365809440612793, 0.40488338470458984, 1.218038558959961, 0.2351818084716797, 10.700573921203613, -0.2837638854980469, -0.45124244689941406, 0.22244644165039062, 1.5497283935546875, -0.20564556121826172, -0.008579254150390625, -0.2583160400390625, -0.8010196685791016, 0.15465927124023438, -1.4465808868408203, 0.05428314208984375, 0.3146505355834961, -0.3117790222167969, 0.44091176986694336, -0.2422657012939453, 0.16333770751953125, 0.21557235717773438, 0.23714637756347656, 0.9289512634277344, 0.446685791015625, -0.4307289123535156, -0.24365615844726562, -0.6267796754837036, -0.3735542297363281, 0.09038162231445312, -0.48945140838623047, 0.316192626953125, 0.9183979034423828, 0.35236644744873047, -0.4995613098144531, -0.4974546432495117, 0.4394378662109375, 16.40569496154785, 0.7649078369140625, -1.721400260925293, 12.095439910888672, -0.09549331665039062, -1.130105972290039, 0.10202789306640625, -0.11426162719726562, 0.5990667343139648, -0.9516992568969727, -0.6435127258300781, 0.5670433044433594, 0.9397592544555664, -5.02641487121582, -0.5788784027099609, 0.6625423431396484, -0.07679939270019531, 0.10273551940917969, 0.10295867919921875, 0.5231571197509766, 1.7302722930908203, -0.35652923583984375, -0.36629676818847656, 1.4158802032470703, -10.372550964355469, -0.8548469543457031, -0.04161643981933594, -0.7245988845825195, -0.2094125747680664, -4.838892936706543, -1.4700584411621094, -0.5766754150390625], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 83968, "num_env_steps_trained": 311280, "num_agent_steps_sampled": 83968, "num_agent_steps_trained": 311280, "last_target_update_ts": 83968, "num_target_updates": 163}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -21.35778037160635, "episode_len_mean": 232.32, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519], "episode_lengths": [241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5567871465105766, "mean_inference_ms": 24.833442606504814, "mean_action_processing_ms": 0.13422408568035193, "mean_env_wait_ms": 4.4279374070025215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -21.35778037160635, "episode_len_mean": 232.32, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-34.852088898420334, 9.665033899247646, -11.67097406834364, -116.96692609786987, -12.072171986103058, -6.300000101327896, 5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519], "episode_lengths": [241, 222, 248, 284, 247, 243, 194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5567871465105766, "mean_inference_ms": 24.833442606504814, "mean_action_processing_ms": 0.13422408568035193, "mean_env_wait_ms": 4.4279374070025215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 83968, "num_agent_steps_trained": 311280, "num_env_steps_sampled": 83968, "num_env_steps_trained": 311280, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 83968, "agent_timesteps_total": 83968, "timers": {"training_iteration_time_ms": 345.235, "learn_time_ms": 69.77, "learn_throughput": 3439.866, "synch_weights_time_ms": 20.689}, "counters": {"num_env_steps_sampled": 83968, "num_env_steps_trained": 311280, "num_agent_steps_sampled": 83968, "num_agent_steps_trained": 311280, "last_target_update_ts": 83968, "num_target_updates": 163}, "done": false, "episodes_total": 309, "training_iteration": 82, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-32", "timestamp": 1655478512, "time_this_iter_s": 5.605679988861084, "time_total_s": 438.14904522895813, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 438.14904522895813, "timesteps_since_restore": 0, "iterations_since_restore": 82, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 38.65555555555555, "ram_util_percent": 64.50000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.57052230834961, "min_q": -25.092529296875, "max_q": 31.986495971679688, "mean_td_error": -0.12226460129022598}, "td_error": [-0.5472946166992188, 1.6645221710205078, -6.181312561035156, -0.1782093048095703, 1.1301383972167969, -0.20101547241210938, -0.946929931640625, 2.6779251098632812, 0.20009326934814453, -1.043191909790039, -0.5914325714111328, -0.3605632781982422, -0.5243396759033203, -0.3593006134033203, 0.3609123229980469, -0.09442901611328125, 0.026905059814453125, -0.6227493286132812, -0.04910469055175781, 0.07730484008789062, -1.0347728729248047, 0.24686813354492188, -0.6640281677246094, -0.24065208435058594, 0.0706472396850586, -0.6471271514892578, -0.34148597717285156, -0.9298763275146484, -0.9990224838256836, -0.3513355255126953, -0.3258991241455078, -0.49472904205322266, -0.3440265655517578, 0.017848968505859375, 0.4894571304321289, -0.7082939147949219, -0.07304000854492188, -0.17350006103515625, -0.6830997467041016, -0.5026912689208984, 0.3475961685180664, 1.6307849884033203, -7.286604881286621, 1.5702457427978516, 0.3443794250488281, -0.3475513458251953, 0.26842498779296875, 1.7497310638427734, 1.5085277557373047, -0.3620414733886719, 0.5349540710449219, 0.09617424011230469, -0.1776590347290039, -0.9880332946777344, -5.443159103393555, -1.3140335083007812, 0.12554550170898438, -0.03794097900390625, -0.5358953475952148, 0.8257379531860352, 0.3699798583984375, 0.34854888916015625, 1.1665287017822266, 0.010906219482421875, -10.000276565551758, -0.818974494934082, -0.008745193481445312, -2.418729782104492, 0.42847728729248047, -0.18371009826660156, -2.5272531509399414, -0.170074462890625, 0.16298675537109375, -0.5505466461181641, -0.2895469665527344, -0.06537818908691406, -0.41322898864746094, 0.3644142150878906, 0.33888816833496094, -0.05299949645996094, -0.026444435119628906, -0.4807472229003906, -0.6572837829589844, -0.3863391876220703, -0.034374237060546875, -7.366985321044922, -7.457103252410889, 0.1348094940185547, 0.8348312377929688, -0.6941671371459961, -0.5243396759033203, 0.35658931732177734, -0.7949833869934082, -0.17037200927734375, 0.04675483703613281, -0.4479084014892578, -0.28173065185546875, -0.24111461639404297, 15.642533302307129, -1.4100933074951172, 0.6124229431152344, -0.3990631103515625, -0.12674713134765625, -7.118369102478027, 0.8778648376464844, 0.15788650512695312, 0.2435159683227539, 0.43567466735839844, 14.260967254638672, -0.36560535430908203, -0.07199478149414062, -0.015140533447265625, -1.3557538986206055, -6.961399078369141, -0.2117900848388672, 21.488096237182617, -0.946314811706543, -7.4884490966796875, 0.15633010864257812, -0.27255821228027344, 0.16123199462890625, 0.016567230224609375, 0.16640853881835938, -0.7425098419189453, -0.9490680694580078, 0.5030612945556641, 0.4774646759033203, -0.11299514770507812, -7.882852554321289, 0.5498809814453125, -5.429025650024414, -0.6797275543212891, 0.5303802490234375, -0.47511959075927734, -0.7321357727050781, -2.2641220092773438, -1.21588134765625, -1.739701271057129, -0.18164634704589844, -0.2023181915283203, 0.3447532653808594, -0.3103952407836914, -0.35782337188720703, 0.1279582977294922, -0.2664070129394531, -0.17251205444335938, -0.8612375259399414, -0.02466583251953125, -0.4263019561767578, 0.024784088134765625, 0.2341785430908203, 0.25834083557128906, -0.6544935703277588, -0.2748270034790039, -0.9522838592529297, -0.2759971618652344, -0.2117481231689453, -0.0362396240234375, -0.7570838928222656, -0.3579568862915039, -0.8225555419921875, -1.1334161758422852, -0.4742298126220703, -0.7272834777832031, 0.08153533935546875, -0.9446544647216797, -1.1437444686889648, -0.9250802993774414, 0.4774646759033203, -0.859649658203125, -0.23442840576171875, -0.6521902084350586, -0.2305889129638672, 0.07028388977050781, 0.04793548583984375, -2.759341239929199, 0.16222524642944336, 0.4057178497314453, 0.9329872131347656, -3.4142608642578125, -6.922842979431152, 0.08296966552734375, -0.0067901611328125, -0.08270454406738281, -0.0608673095703125, 2.1757640838623047, 0.20620155334472656, 0.11031913757324219, -0.23965835571289062, 0.5014801025390625, 0.9159092903137207, -0.2749004364013672, 0.3318328857421875, -0.6685905456542969, 0.6634979248046875, -1.0065956115722656, -0.32891082763671875, -5.044626235961914, -0.790557861328125, 0.16257095336914062, -0.2429943084716797, 22.461729049682617, 16.356239318847656, -6.0351762771606445, -1.2875328063964844, -0.7807865142822266, -6.631620407104492, -0.2770195007324219, -0.018947601318359375, -0.5573902130126953, -0.9197940826416016, 13.406414985656738, -0.48522186279296875, -0.21234893798828125, -0.10341644287109375, 0.37346458435058594, 0.5346250534057617, -0.2700157165527344, 1.1509723663330078, 0.626678466796875, -1.3814563751220703, -0.09415245056152344, -0.9746494293212891, -0.27585411071777344, -0.6022539138793945, -0.36357879638671875, 1.5965442657470703, -0.6698493957519531, 0.26813507080078125, 16.086145401000977, -0.4875822067260742, -0.45853137969970703, 0.0720977783203125, -0.056041717529296875, -2.633289337158203, -0.8138790130615234, -1.343214750289917, -0.7031230926513672, 0.12033843994140625, -0.03605842590332031], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 84992, "num_env_steps_trained": 315120, "num_agent_steps_sampled": 84992, "num_agent_steps_trained": 315120, "last_target_update_ts": 84992, "num_target_updates": 165}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -19.180563332363963, "episode_len_mean": 230.99, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654], "episode_lengths": [194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5584368559871808, "mean_inference_ms": 24.835868682284154, "mean_action_processing_ms": 0.13413766484964562, "mean_env_wait_ms": 4.435711368988822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -19.180563332363963, "episode_len_mean": 230.99, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [5.000000081956387, -115.26193322986364, 38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654], "episode_lengths": [194, 280, 203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5584368559871808, "mean_inference_ms": 24.835868682284154, "mean_action_processing_ms": 0.13413766484964562, "mean_env_wait_ms": 4.435711368988822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 84992, "num_agent_steps_trained": 315120, "num_env_steps_sampled": 84992, "num_env_steps_trained": 315120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 84992, "agent_timesteps_total": 84992, "timers": {"training_iteration_time_ms": 353.531, "learn_time_ms": 71.166, "learn_throughput": 3372.394, "synch_weights_time_ms": 21.188}, "counters": {"num_env_steps_sampled": 84992, "num_env_steps_trained": 315120, "num_agent_steps_sampled": 84992, "num_agent_steps_trained": 315120, "last_target_update_ts": 84992, "num_target_updates": 165}, "done": false, "episodes_total": 315, "training_iteration": 83, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-38", "timestamp": 1655478518, "time_this_iter_s": 5.632315635681152, "time_total_s": 443.7813608646393, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 443.7813608646393, "timesteps_since_restore": 0, "iterations_since_restore": 83, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 40.0375, "ram_util_percent": 64.525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.985666275024414, "min_q": -25.03495216369629, "max_q": 28.574764251708984, "mean_td_error": 0.49372151494026184}, "td_error": [-0.17795944213867188, 0.19032764434814453, -0.03937244415283203, -0.2132720947265625, 0.2708568572998047, -0.04639625549316406, -0.2670097351074219, 0.0055599212646484375, 0.24791336059570312, -0.3651237487792969, -0.6234264373779297, -0.4689044952392578, -0.3885002136230469, 1.3133373260498047, -0.5697021484375, 0.12261199951171875, 2.026434898376465, -0.20958614349365234, -0.4009990692138672, 0.4452552795410156, -0.021160125732421875, -0.6992301940917969, 0.07788276672363281, -0.7530975341796875, -0.15469932556152344, 0.3241615295410156, -0.03777313232421875, 18.35858154296875, -0.03668975830078125, -0.05135345458984375, -0.3068361282348633, 0.8040294647216797, -0.3021984100341797, -0.04143714904785156, 15.949997901916504, 0.17027854919433594, 0.24716854095458984, -0.2768115997314453, 0.027606964111328125, 13.391196250915527, 4.800885200500488, -0.2674541473388672, -0.25102710723876953, 0.3046112060546875, 0.1486663818359375, 0.18998336791992188, -1.4568777084350586, 0.1325359344482422, 0.04641151428222656, 1.0948524475097656, -0.08340644836425781, -0.30696678161621094, 0.1940593719482422, -0.1392679214477539, 0.10390663146972656, -0.3321342468261719, 1.2785797119140625, -0.8217983245849609, -0.6794023513793945, 0.28290748596191406, 0.00016117095947265625, 0.3565692901611328, -1.4531230926513672, -1.794276237487793, 0.38665199279785156, 0.8874053955078125, -0.023064613342285156, 0.12888336181640625, 0.08706951141357422, 0.42830657958984375, 0.7594778537750244, -0.07861518859863281, -0.012247085571289062, -0.19078540802001953, -0.5533046722412109, 1.3109416961669922, 11.573240280151367, 0.2720069885253906, 0.5131402015686035, -0.4939842224121094, -0.08358955383300781, 11.302840232849121, 0.4132575988769531, 0.5215969085693359, -0.5862636566162109, 0.030707359313964844, 0.3104124069213867, -0.7345237731933594, -0.1037139892578125, 0.8512191772460938, 0.03745555877685547, 0.07036590576171875, 0.7900638580322266, 0.36650657653808594, 0.9490337371826172, 0.015189170837402344, -0.07714462280273438, 0.08880805969238281, -0.7069664001464844, -0.6381130218505859, -0.1295948028564453, -0.7547245025634766, 1.8425140380859375, -0.9537033438682556, -0.2465801239013672, 0.1325359344482422, -0.17386436462402344, -0.24263381958007812, -0.8779735565185547, -0.07151031494140625, -0.16657638549804688, -0.00262451171875, 0.35123348236083984, 0.49210166931152344, 0.36267852783203125, -0.11618423461914062, -0.260040283203125, -0.3413810729980469, -0.5011978149414062, -0.4252433776855469, 0.2788066864013672, 0.019964218139648438, 0.22007179260253906, 1.2851448059082031, 0.8646574020385742, 0.9399075508117676, 0.10389137268066406, -0.27872467041015625, 0.014975547790527344, 0.559575080871582, -1.4133920669555664, 0.5999011993408203, -0.2495126724243164, -0.2209920883178711, 0.5198459625244141, 0.07555198669433594, 0.3877696990966797, -0.018474578857421875, -0.41809654235839844, -0.018396377563476562, -0.050652503967285156, 0.32835960388183594, -0.4567375183105469, 0.9459056854248047, 10.592179298400879, -0.23320484161376953, -0.0111236572265625, -0.11294174194335938, 0.06820487976074219, -0.35326671600341797, 0.6052141189575195, 0.3437185287475586, -0.1924457550048828, 0.4406614303588867, 0.2271270751953125, 0.1956653594970703, 1.0589818954467773, -0.8822727203369141, -0.3939085006713867, 0.200592041015625, 0.0069866180419921875, -4.586334228515625, -0.45296573638916016, 0.4679412841796875, 0.1687793731689453, 0.11536407470703125, -0.46737098693847656, -0.0391845703125, 0.4340972900390625, 1.6581602096557617, -0.15125370025634766, -0.1367816925048828, 0.2640247344970703, 1.7049503326416016, -0.6538572311401367, -0.3683338165283203, 0.1189422607421875, -0.8692188262939453, -0.21913909912109375, 0.22147560119628906, -0.21059226989746094, 1.1607847213745117, -0.007145881652832031, -5.133203506469727, 0.782928466796875, -0.4384956359863281, 0.018751144409179688, -0.20574569702148438, 0.3356046676635742, 0.9064903259277344, 0.5146408081054688, 0.12189483642578125, 0.6532230377197266, 0.19705486297607422, 0.35178184509277344, -0.5733585357666016, -0.13084697723388672, 0.2241992950439453, 0.0028705596923828125, 2.287748336791992, 0.6273317337036133, -0.20999813079833984, 0.27642059326171875, -9.75627326965332, -0.7330169677734375, 0.40828514099121094, 0.2301769256591797, 0.43140316009521484, 0.2487812042236328, -7.057513236999512, 0.035007476806640625, 0.5649566650390625, 0.028066635131835938, 0.1325359344482422, 0.4273395538330078, -0.0167236328125, -1.7691526412963867, -0.7055835723876953, 15.726882934570312, -0.4240436553955078, -0.547637939453125, -0.29703712463378906, 0.481781005859375, -0.14155006408691406, -0.1613006591796875, 1.0443115234375, 0.6007366180419922, 10.592179298400879, 0.006481170654296875, -6.340476989746094, 0.5796318054199219, 0.10218429565429688, -0.003168821334838867, 9.940821647644043, 0.05048370361328125, -0.022268295288085938, 0.2607707977294922, 0.9074172973632812, -1.2270317077636719, 15.95500659942627], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 86016, "num_env_steps_trained": 318960, "num_agent_steps_sampled": 86016, "num_agent_steps_trained": 318960, "last_target_update_ts": 86016, "num_target_updates": 167}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -17.620593011155723, "episode_len_mean": 230.62, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563], "episode_lengths": [203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5583709980286079, "mean_inference_ms": 24.814781082533923, "mean_action_processing_ms": 0.13415432736917887, "mean_env_wait_ms": 4.435440573046867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -17.620593011155723, "episode_len_mean": 230.62, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [38.46270017325878, -42.52457873523235, 7.785699397325516, -49.63919182121754, 6.9000000804662704, 15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563], "episode_lengths": [203, 236, 241, 247, 190, 227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5583709980286079, "mean_inference_ms": 24.814781082533923, "mean_action_processing_ms": 0.13415432736917887, "mean_env_wait_ms": 4.435440573046867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 86016, "num_agent_steps_trained": 318960, "num_env_steps_sampled": 86016, "num_env_steps_trained": 318960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 86016, "agent_timesteps_total": 86016, "timers": {"training_iteration_time_ms": 329.566, "learn_time_ms": 68.591, "learn_throughput": 3498.978, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 86016, "num_env_steps_trained": 318960, "num_agent_steps_sampled": 86016, "num_agent_steps_trained": 318960, "last_target_update_ts": 86016, "num_target_updates": 167}, "done": false, "episodes_total": 317, "training_iteration": 84, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-43", "timestamp": 1655478523, "time_this_iter_s": 5.25900936126709, "time_total_s": 449.0403702259064, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 449.0403702259064, "timesteps_since_restore": 0, "iterations_since_restore": 84, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 32.957142857142856, "ram_util_percent": 64.48571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.726190567016602, "min_q": -20.1361026763916, "max_q": 31.07117462158203, "mean_td_error": 0.01893555372953415}, "td_error": [1.1926937103271484, -0.1000967025756836, -0.20857572555541992, 4.754585266113281, 0.3373279571533203, -0.19960975646972656, 0.3334517478942871, -0.20068645477294922, -1.9062261581420898, -0.22338008880615234, -0.9028425216674805, 0.3258953094482422, -1.6951122283935547, 0.03371238708496094, -0.36600685119628906, 0.5783071517944336, -0.017316818237304688, -0.12206459045410156, 0.003620147705078125, 0.15061378479003906, 0.11352157592773438, 0.23956871032714844, -1.1455421447753906, -0.2780933380126953, -0.7376384735107422, 0.5490951538085938, -0.2853069305419922, -0.39745473861694336, 0.560420036315918, -0.6406497955322266, -0.8976402282714844, 0.9137020111083984, -0.1762847900390625, -2.251340866088867, 0.10215377807617188, 0.1743011474609375, -0.2837944030761719, -0.12151145935058594, 0.5839252471923828, 0.36935901641845703, -0.1252899169921875, -0.3113727569580078, -0.6222343444824219, 3.233243942260742, -1.0844993591308594, 0.5565166473388672, -0.03400993347167969, 0.35932064056396484, -0.8207645416259766, 0.7223663330078125, 0.022377967834472656, 0.1909198760986328, -0.42682456970214844, -0.3228569030761719, -0.42751312255859375, 1.4664897918701172, 0.39919090270996094, -0.030881881713867188, 0.2569732666015625, -0.35544681549072266, 0.26814842224121094, 1.0274772644042969, -0.07157135009765625, 0.6659336090087891, 1.0873374938964844, 0.16665077209472656, -0.7085456848144531, -0.4929542541503906, -1.4336318969726562, 0.717010498046875, 0.5920801162719727, -6.309690475463867, 0.7351722717285156, -0.37644195556640625, -0.013355255126953125, 0.7363491058349609, -0.6414623260498047, -0.11533927917480469, -0.31178855895996094, -0.848872184753418, 1.0711679458618164, -0.07195854187011719, 1.5593070983886719, -0.028209686279296875, 0.2583160400390625, -0.7332592010498047, 0.6028575897216797, 0.4713630676269531, 0.5045032501220703, -0.6764392852783203, -0.1448230743408203, 13.849947929382324, -0.330047607421875, 0.21215438842773438, 0.8478870391845703, 0.022568702697753906, -5.2889556884765625, 0.6112403869628906, 1.2364072799682617, -0.27846789360046387, -0.3582897186279297, -0.5774984359741211, -0.1862049102783203, 1.1875181198120117, 0.4732961654663086, -0.6410746574401855, -0.7795219421386719, 0.8660802841186523, -0.8497409820556641, -0.9290294647216797, -0.737396240234375, 0.3258953094482422, -0.8010330200195312, -0.11098098754882812, -0.2722454071044922, 0.34728240966796875, -0.2785043716430664, 0.2840385437011719, 0.2460174560546875, -0.2046184539794922, -0.2864971160888672, 1.2617759704589844, -0.055706024169921875, 0.1814594268798828, 0.30570220947265625, -0.20194625854492188, -0.2061328887939453, -0.5834102630615234, -0.1712627410888672, -0.19415283203125, -0.2046184539794922, 0.6755781173706055, 0.01665496826171875, -0.2259988784790039, 0.8476190567016602, 0.3373279571533203, 0.48108673095703125, -0.5334262847900391, 0.19049644470214844, 0.1460285186767578, -0.0468902587890625, 0.18869400024414062, -0.027179718017578125, 1.1334662437438965, 0.24629974365234375, -0.4032917022705078, -0.4115743637084961, -1.7362232208251953, 0.2631664276123047, 0.25572967529296875, -0.6508598327636719, -0.5172929763793945, 0.05627632141113281, 0.2590217590332031, -0.13791847229003906, -1.7246780395507812, -1.0995826721191406, -0.31043243408203125, -0.5693721771240234, 0.4866189956665039, -0.2557253837585449, -0.37718677520751953, 1.2829523086547852, -0.8679409027099609, -0.5769271850585938, 0.17924880981445312, 0.3430347442626953, -0.31943416595458984, 0.7791366577148438, -0.214752197265625, -1.3391494750976562, -7.707159042358398, 0.06605720520019531, -0.6355457305908203, -0.44420623779296875, -0.06954002380371094, -0.14562606811523438, -1.0850286483764648, -0.40541934967041016, 0.30736541748046875, 4.674166679382324, -0.04969596862792969, -5.852198600769043, -0.6286087036132812, 0.25916481018066406, -0.44116878509521484, 14.752107620239258, 2.171280860900879, -0.8457746505737305, 0.18915557861328125, -0.4746518135070801, 0.6837959289550781, -0.8909444808959961, 0.23529052734375, -0.5566844940185547, -0.32643985748291016, -1.2554259300231934, -0.06613540649414062, -0.43605995178222656, 0.2266407012939453, -4.870187759399414, 0.2519493103027344, 0.2178487777709961, -0.5487239360809326, 0.14119625091552734, 0.9080829620361328, -1.0111751556396484, -0.5302858352661133, -0.4082212448120117, 0.1360931396484375, 0.3065214157104492, -0.6301193237304688, 0.5796394348144531, 1.1926937103271484, -0.9508047103881836, -0.20952415466308594, -0.9353389739990234, 13.963349342346191, 0.1971759796142578, -1.902456283569336, 0.3087577819824219, 0.32731056213378906, -0.32518959045410156, 0.4866189956665039, -0.7086067199707031, 0.3308677673339844, -0.5280418395996094, 0.560420036315918, -1.4193239212036133, -0.09337711334228516, -0.03918647766113281, -0.43404674530029297, -0.007793426513671875, 0.11727333068847656, -1.7032318115234375, -0.3555870056152344, -0.9698429107666016, 0.3158397674560547, -0.15470123291015625, -0.15470123291015625], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 87040, "num_env_steps_trained": 322800, "num_agent_steps_sampled": 87040, "num_agent_steps_trained": 322800, "last_target_update_ts": 87040, "num_target_updates": 169}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -17.354642127752303, "episode_len_mean": 230.62, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892], "episode_lengths": [227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5591148620946114, "mean_inference_ms": 24.856408739064822, "mean_action_processing_ms": 0.13424020593077374, "mean_env_wait_ms": 4.445811704290273, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -17.354642127752303, "episode_len_mean": 230.62, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [15.190568581223488, -22.900000132620335, 6.600000083446503, -58.970974050462246, -113.27078383415937, 6.00000012665987, -11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892], "episode_lengths": [227, 221, 214, 264, 273, 194, 253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5591148620946114, "mean_inference_ms": 24.856408739064822, "mean_action_processing_ms": 0.13424020593077374, "mean_env_wait_ms": 4.445811704290273, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 87040, "num_agent_steps_trained": 322800, "num_env_steps_sampled": 87040, "num_env_steps_trained": 322800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 87040, "agent_timesteps_total": 87040, "timers": {"training_iteration_time_ms": 349.739, "learn_time_ms": 69.173, "learn_throughput": 3469.551, "synch_weights_time_ms": 20.688}, "counters": {"num_env_steps_sampled": 87040, "num_env_steps_trained": 322800, "num_agent_steps_sampled": 87040, "num_agent_steps_trained": 322800, "last_target_update_ts": 87040, "num_target_updates": 169}, "done": false, "episodes_total": 322, "training_iteration": 85, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-49", "timestamp": 1655478529, "time_this_iter_s": 5.472644567489624, "time_total_s": 454.513014793396, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 454.513014793396, "timesteps_since_restore": 0, "iterations_since_restore": 85, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 31.7375, "ram_util_percent": 64.4875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.041433334350586, "min_q": -22.27448844909668, "max_q": 30.52678108215332, "mean_td_error": -0.01567482203245163}, "td_error": [-0.2635383605957031, 0.9653005599975586, -5.806646347045898, -0.623448371887207, 0.11264610290527344, -1.4718780517578125, -0.35724830627441406, -0.2467355728149414, -5.596746444702148, -0.11073493957519531, -0.42351722717285156, 0.20325756072998047, -0.1608448028564453, -0.3077564239501953, 0.1063699722290039, -1.019507884979248, -5.310176849365234, -0.5599660873413086, 0.0208740234375, -0.24769210815429688, -0.3601875305175781, -0.4003143310546875, -4.005409240722656, -0.407073974609375, 0.05215263366699219, -0.2723865509033203, 1.1380720138549805, -0.44022178649902344, 1.4190216064453125, -0.2864408493041992, -0.6778526306152344, 0.6119289398193359, -0.07227897644042969, 0.15665435791015625, 0.29414939880371094, 0.0551300048828125, 2.709728240966797, -0.007328033447265625, 0.10220575332641602, -0.4013519287109375, -0.39084625244140625, -0.5139188766479492, -0.16039657592773438, -0.5100059509277344, -10.148868560791016, -0.7942180633544922, -1.7135334014892578, -0.7532386779785156, 0.053648948669433594, -0.3809185028076172, -0.04125785827636719, 0.6481609344482422, -0.4723548889160156, 0.35286426544189453, -0.4139251708984375, -0.22284698486328125, 0.12257003784179688, -0.3139762878417969, -0.43761444091796875, -6.830110549926758, -0.3218860626220703, 0.1508646011352539, -0.4824638366699219, -0.834935188293457, 0.12429618835449219, -0.05610466003417969, -0.02984905242919922, -0.47746849060058594, 14.01528549194336, -0.18765830993652344, -0.2157440185546875, 1.231180191040039, -0.1488170623779297, 9.494991302490234, -0.5848121643066406, -0.06988048553466797, -0.827178955078125, -7.355632305145264, -0.4541597366333008, -0.6858129501342773, -0.11602020263671875, -0.7267246246337891, -0.47222900390625, -0.11906814575195312, 0.6302080154418945, -0.6909570693969727, 2.7063961029052734, 0.07481765747070312, -0.1416797637939453, 0.020355224609375, -0.0268402099609375, -0.676417350769043, -0.23445510864257812, -0.3303356170654297, 0.34345006942749023, -5.726779937744141, -0.3867950439453125, 0.09391593933105469, 0.7071757316589355, -0.19260406494140625, 0.21727561950683594, 0.7662220001220703, 1.0668163299560547, -0.41391563415527344, -0.4691429138183594, -0.8064985275268555, 1.1990242004394531, -0.6081609725952148, -0.9021425247192383, -0.9139480590820312, -0.053577423095703125, -0.29772186279296875, -0.02487945556640625, -0.3302650451660156, -0.5889377593994141, 11.139154434204102, 0.3882713317871094, 0.3386211395263672, -0.0675802230834961, -1.1414995193481445, -0.28937530517578125, 15.021239280700684, 0.20160961151123047, -0.08559036254882812, 0.18966960906982422, -1.0483694076538086, 0.06909847259521484, -0.1294116973876953, -0.10346412658691406, -0.9799022674560547, -0.3763999938964844, -0.21380043029785156, -0.38139915466308594, -0.23451614379882812, -0.6992874145507812, -0.3713560104370117, -7.390772819519043, 0.17738580703735352, -0.5251026153564453, 2.446608543395996, -0.23378753662109375, -0.2784137725830078, -0.07427406311035156, -0.33722877502441406, -0.04150676727294922, -0.3874492645263672, 1.0114021301269531, 0.1382598876953125, 0.03676795959472656, 1.0011539459228516, -0.6993694305419922, -0.04607105255126953, -5.148359298706055, 1.0114021301269531, 0.5638656616210938, -0.6949787139892578, -0.030748367309570312, 0.08702468872070312, -0.9139480590820312, -0.37938690185546875, -0.11121749877929688, -0.3515167236328125, -0.7927761077880859, -1.7732772827148438, -5.858831405639648, 14.244670867919922, -9.542858123779297, -0.16299819946289062, 0.5390024185180664, -0.025037765502929688, 10.805123329162598, -0.08538818359375, -0.12006759643554688, 0.05928802490234375, 0.6248207092285156, -0.25408458709716797, -1.023249626159668, -0.3140106201171875, -0.11548233032226562, -1.100815773010254, -0.1263599395751953, 0.5170643329620361, -0.7057838439941406, -0.5938739776611328, -0.6215620040893555, -0.24262619018554688, 0.21039962768554688, 15.838449478149414, -0.47965240478515625, -0.2519092559814453, 0.6799545288085938, 13.272526741027832, 2.3313770294189453, -0.6666946411132812, 1.002767562866211, -7.285305023193359, -0.8913211822509766, -1.4355239868164062, -0.5924501419067383, -1.2432098388671875, -0.20169830322265625, -0.2527475357055664, 0.2635154724121094, 0.1834125518798828, -0.7477149963378906, -0.09175872802734375, 0.14386749267578125, -0.08544540405273438, 0.13157033920288086, 0.10433316230773926, -0.2529163360595703, -0.1567249298095703, -0.24506759643554688, -0.1636333465576172, -1.3015251159667969, 0.012247085571289062, -0.4397296905517578, -0.2874889373779297, 1.6519718170166016, -0.04189872741699219, -0.49542236328125, 0.6906261444091797, 0.31964874267578125, -0.10612297058105469, -0.4972515106201172, -0.9908065795898438, -0.6993694305419922, 0.1912546157836914, 8.46229076385498, -0.2593841552734375, -0.2049875259399414, -0.46584415435791016, -0.17863750457763672, -0.9536418914794922, 0.4359397888183594, 0.150177001953125, -0.2364177703857422, -0.8297300338745117, 0.17052078247070312, -0.4123096466064453], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 88064, "num_env_steps_trained": 326640, "num_agent_steps_sampled": 88064, "num_agent_steps_trained": 326640, "last_target_update_ts": 88064, "num_target_updates": 171}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -15.533287407383323, "episode_len_mean": 229.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896], "episode_lengths": [253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5607346512360172, "mean_inference_ms": 24.857817850565915, "mean_action_processing_ms": 0.13413682443718217, "mean_env_wait_ms": 4.453221362739212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -15.533287407383323, "episode_len_mean": 229.36, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-11.935807339847088, -34.35282142460346, 19.39285448938608, 13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896], "episode_lengths": [253, 235, 209, 221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5607346512360172, "mean_inference_ms": 24.857817850565915, "mean_action_processing_ms": 0.13413682443718217, "mean_env_wait_ms": 4.453221362739212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 88064, "num_agent_steps_trained": 326640, "num_env_steps_sampled": 88064, "num_env_steps_trained": 326640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 88064, "agent_timesteps_total": 88064, "timers": {"training_iteration_time_ms": 342.82, "learn_time_ms": 67.852, "learn_throughput": 3537.092, "synch_weights_time_ms": 20.489}, "counters": {"num_env_steps_sampled": 88064, "num_env_steps_trained": 326640, "num_agent_steps_sampled": 88064, "num_agent_steps_trained": 326640, "last_target_update_ts": 88064, "num_target_updates": 171}, "done": false, "episodes_total": 328, "training_iteration": 86, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-08-55", "timestamp": 1655478535, "time_this_iter_s": 5.472103118896484, "time_total_s": 459.9851179122925, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 459.9851179122925, "timesteps_since_restore": 0, "iterations_since_restore": 86, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.337500000000006, "ram_util_percent": 64.4875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.760279655456543, "min_q": -21.028244018554688, "max_q": 29.487754821777344, "mean_td_error": 0.06346891075372696}, "td_error": [-0.1194000244140625, 1.3937530517578125, 0.5768795013427734, -1.6177358627319336, 1.1895322799682617, 0.6360197067260742, 1.007798194885254, 0.09002900123596191, 0.3979167938232422, 0.04137611389160156, -0.4861268997192383, -0.9183664321899414, -0.1565570831298828, -0.04068946838378906, -0.7278280258178711, 0.06661033630371094, -0.4328498840332031, -0.2044239044189453, 0.6610231399536133, 0.2215557098388672, -0.2814483642578125, -6.36182975769043, -0.06566238403320312, 0.012856483459472656, 14.263294219970703, 0.6040410995483398, -0.8238716125488281, -0.04567527770996094, -0.7370939254760742, -0.03623771667480469, -0.027457237243652344, 0.11139869689941406, 2.9650354385375977, 0.10540008544921875, 0.23911094665527344, 0.08124160766601562, 0.1254730224609375, -7.514621734619141, 0.10490036010742188, 1.2010471820831299, 0.15258407592773438, -0.09241867065429688, -0.2214488983154297, 0.16189861297607422, -0.3565826416015625, -0.10970306396484375, 0.35871410369873047, 1.3937530517578125, -0.10500717163085938, -0.8023843765258789, -0.28008270263671875, 1.2486145496368408, 0.2568092346191406, -0.804046630859375, -0.06817436218261719, -0.20699310302734375, 1.5307538509368896, -4.584737777709961, -0.6061697006225586, -0.6701984405517578, 0.00202178955078125, -0.07227516174316406, -0.0910797119140625, -0.2301044464111328, 0.6016950607299805, -0.14055824279785156, -0.6308441162109375, -0.19557762145996094, 0.09554481506347656, -0.16530895233154297, -0.5363168716430664, 0.0075664520263671875, -0.1283283233642578, 1.8245739936828613, 0.07082080841064453, -0.05021858215332031, 0.8135318756103516, -5.4940032958984375, -0.09585189819335938, -6.292811393737793, -0.4530048370361328, 0.23384571075439453, 0.14622116088867188, 0.6016583442687988, 0.5546302795410156, -0.037967681884765625, 0.2857379913330078, 0.499176025390625, 16.67491340637207, 0.2358875274658203, -0.2321033477783203, 0.882171630859375, 11.969511985778809, 0.18730545043945312, 0.129425048828125, -0.20419883728027344, 0.6200523376464844, 0.21132659912109375, 0.22580337524414062, 0.06793212890625, 0.31622314453125, 0.20676231384277344, -1.6071748733520508, 0.3718595504760742, 1.3163738250732422, 0.3301677703857422, 2.0479674339294434, -0.22472476959228516, 0.0014810562133789062, 0.14218521118164062, -0.06983470916748047, 12.917730331420898, -0.08914566040039062, -0.0036478042602539062, 0.14974212646484375, -0.7972536087036133, 1.7627754211425781, -0.15644264221191406, 0.1747608184814453, 0.4088573455810547, -0.6443920135498047, -0.4298868179321289, 0.2547025680541992, -0.5228633880615234, -0.4549875259399414, 0.08526611328125, 0.5717144012451172, 0.6799964904785156, -0.11736488342285156, 0.05156135559082031, -0.6732940673828125, 0.4088573455810547, 0.11775016784667969, 0.4129505157470703, -0.7595176696777344, -0.4860076904296875, -0.4378929138183594, -0.036304473876953125, -0.665614128112793, 0.12786293029785156, -0.08932685852050781, -0.9622211456298828, -0.07573127746582031, -0.10301399230957031, -0.15664100646972656, -0.18916034698486328, 0.33382606506347656, 0.04098701477050781, -1.4736003875732422, 0.3408851623535156, -0.6657400131225586, -0.0916290283203125, -0.2499217987060547, 0.057282447814941406, -0.34986114501953125, 0.190643310546875, 0.026571273803710938, -0.23768043518066406, -1.5868072509765625, -1.4956550598144531, 0.06924843788146973, 0.7733211517333984, -0.09544181823730469, 0.1108551025390625, -0.5769081115722656, 0.5059528350830078, -0.06915473937988281, -0.4958648681640625, 0.05262184143066406, -0.19402313232421875, -0.2557811737060547, 0.8185018301010132, -0.19577980041503906, 0.4488563537597656, -0.3942985534667969, -0.16954803466796875, -0.27155303955078125, 0.18625831604003906, -0.5878992080688477, -0.08142471313476562, 0.26644325256347656, -5.062944412231445, 1.3185615539550781, -0.41956043243408203, 0.31641578674316406, 0.030818939208984375, 1.2756843566894531, -0.2563800811767578, -0.1446208953857422, 0.43025684356689453, 0.05876350402832031, 0.2503538131713867, -0.2675762176513672, -0.9289131164550781, 0.1489391326904297, -0.42908668518066406, -0.0304718017578125, -0.39504432678222656, -0.3433647155761719, 0.037021636962890625, -0.008417129516601562, -0.09149360656738281, 0.8872814178466797, 0.1491222381591797, -0.6824417114257812, -0.38971853256225586, 0.3123149871826172, 0.5686054229736328, 1.1481924057006836, -0.3903656005859375, -2.1700191497802734, -0.4336395263671875, -6.894885063171387, -0.4197540283203125, -0.11028671264648438, -0.373565673828125, -0.1342315673828125, 0.15726947784423828, 0.4218759536743164, -0.12120246887207031, 0.6548252105712891, 1.3735146522521973, -0.3343467712402344, 0.019784927368164062, -1.2144298553466797, 0.10918045043945312, -0.09026908874511719, 0.300689697265625, -0.3095226287841797, 0.9876995086669922, 0.4225120544433594, -5.522405624389648, 0.3693122863769531, -0.00717926025390625, -0.3438549041748047, 1.3937530517578125, -0.46282100677490234, -0.5203351974487305, -0.06915473937988281, 0.08890342712402344], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 89088, "num_env_steps_trained": 330480, "num_agent_steps_sampled": 89088, "num_agent_steps_trained": 330480, "last_target_update_ts": 89088, "num_target_updates": 173}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -17.999953301027418, "episode_len_mean": 229.73, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037], "episode_lengths": [221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5613214610427032, "mean_inference_ms": 24.86079015641685, "mean_action_processing_ms": 0.13413700354862101, "mean_env_wait_ms": 4.457412428643728, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -299.9575631842017, "episode_reward_mean": -17.999953301027418, "episode_len_mean": 229.73, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [13.428313940763474, 11.610635258257389, 11.610635459423065, 23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037], "episode_lengths": [221, 181, 224, 225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5613214610427032, "mean_inference_ms": 24.86079015641685, "mean_action_processing_ms": 0.13413700354862101, "mean_env_wait_ms": 4.457412428643728, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 89088, "num_agent_steps_trained": 330480, "num_env_steps_sampled": 89088, "num_env_steps_trained": 330480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 89088, "agent_timesteps_total": 89088, "timers": {"training_iteration_time_ms": 349.033, "learn_time_ms": 69.767, "learn_throughput": 3439.998, "synch_weights_time_ms": 20.29}, "counters": {"num_env_steps_sampled": 89088, "num_env_steps_trained": 330480, "num_agent_steps_sampled": 89088, "num_agent_steps_trained": 330480, "last_target_update_ts": 89088, "num_target_updates": 173}, "done": false, "episodes_total": 331, "training_iteration": 87, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-00", "timestamp": 1655478540, "time_this_iter_s": 5.425479173660278, "time_total_s": 465.41059708595276, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 465.41059708595276, "timesteps_since_restore": 0, "iterations_since_restore": 87, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.6875, "ram_util_percent": 64.4625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 16.841041564941406, "min_q": -13.172406196594238, "max_q": 33.100833892822266, "mean_td_error": 0.3457511365413666}, "td_error": [-0.34407711029052734, 0.21228623390197754, 0.6758232116699219, 0.4728507995605469, -0.08087825775146484, 0.005565643310546875, 0.28829383850097656, -0.7313690185546875, 0.35700416564941406, 0.561309814453125, -1.0514392852783203, 0.28533363342285156, -0.45966339111328125, -0.3658447265625, 1.0646581649780273, -0.1835336685180664, 0.15078163146972656, 0.31725311279296875, 0.014055252075195312, -0.3651294708251953, -0.4044208526611328, 0.08788299560546875, -0.1606616973876953, 0.46421003341674805, 0.30941200256347656, 0.17655563354492188, 0.42583656311035156, -0.2011098861694336, 0.7311782836914062, -1.0339927673339844, -0.08188056945800781, -0.42861366271972656, 3.8892555236816406, 0.16194820404052734, 0.4777984619140625, -0.11133193969726562, 0.4518728256225586, 0.4251880645751953, 0.6158237457275391, 0.6343832015991211, 0.9656915664672852, -0.029497146606445312, -0.04342937469482422, -5.334157943725586, 0.30141639709472656, -0.2796516418457031, 0.21718215942382812, -0.356201171875, -0.040283203125, -0.051357269287109375, -0.1310567855834961, -0.3036041259765625, 0.15058517456054688, 1.078465461730957, 0.3015403747558594, -0.28179168701171875, -0.23753929138183594, -0.20735740661621094, 13.619906425476074, -0.3662605285644531, -0.5374002456665039, -0.019036293029785156, 0.11209487915039062, 0.3604888916015625, -0.5109596252441406, -0.06156349182128906, 0.9142189025878906, 0.6905670166015625, -0.6974868774414062, -0.16568660736083984, 1.8649187088012695, 0.7257499694824219, 0.4139280319213867, 0.7491645812988281, -0.0942230224609375, -0.34389495849609375, -0.16397666931152344, 0.07985305786132812, 0.5936717987060547, -0.05568122863769531, -0.7017374038696289, 0.04152679443359375, 0.07359695434570312, -0.3968172073364258, -0.3953828811645508, 1.156167984008789, 0.1838226318359375, -0.4229698181152344, -0.05229377746582031, 0.77716064453125, -0.04381752014160156, 0.4228801727294922, -0.49179840087890625, 0.1555309295654297, -0.1577930450439453, 0.02635955810546875, 15.11893081665039, 0.8068933486938477, -0.29790306091308594, 0.09714698791503906, 0.1282501220703125, -0.09757280349731445, 0.532902717590332, -0.28502655029296875, -0.3957386016845703, 1.2599163055419922, -0.8390893936157227, -0.7715082168579102, 0.2940101623535156, -0.30005645751953125, -0.07669925689697266, -0.7410831451416016, -0.07647705078125, 0.06264686584472656, -0.08924102783203125, -0.046935081481933594, -0.03133201599121094, 0.46848297119140625, -0.7226896286010742, 14.442713737487793, -1.1326770782470703, -2.273151397705078, 0.6248130798339844, -0.5218037366867065, 0.2895832061767578, 0.19326353073120117, 0.1893177032470703, -0.17253446578979492, 0.07831764221191406, -1.8988656997680664, -0.12840843200683594, 0.10743427276611328, 1.6813640594482422, 0.029611587524414062, -0.4456596374511719, 0.17354393005371094, 0.5029706954956055, -0.2162160873413086, -0.08644485473632812, -2.190598487854004, 0.11304569244384766, 0.8560523986816406, -0.0807952880859375, 0.2711925506591797, -0.188201904296875, 0.3041839599609375, 0.1741619110107422, -0.1782989501953125, -0.2560443878173828, 0.11173248291015625, 0.9270057678222656, 0.9802494049072266, -0.34404754638671875, 0.19675064086914062, 0.41467857360839844, 0.6471748352050781, -0.09112739562988281, 0.4593238830566406, 0.5287494659423828, 17.329715728759766, 12.41030216217041, 0.12846946716308594, -0.8646106719970703, 0.12210655212402344, 0.1516246795654297, -0.0963592529296875, 0.04770851135253906, 0.20236587524414062, 0.7387142181396484, 0.16397380828857422, -0.026414871215820312, 0.05833911895751953, -0.3060283660888672, 1.1455097198486328, -1.4909791946411133, -0.13754653930664062, 0.6132907867431641, -0.5613250732421875, 1.7475090026855469, 0.09658622741699219, -0.38744640350341797, -0.09627914428710938, -0.18540000915527344, 0.4703330993652344, -0.18458080291748047, -0.1530294418334961, 1.2712757587432861, 0.31357574462890625, -0.0969858169555664, -0.04325294494628906, -0.007297515869140625, -0.517024040222168, 0.24997901916503906, -0.6012058258056641, 0.11362266540527344, 0.05576610565185547, 0.3275604248046875, -0.0725860595703125, -6.759493350982666, -0.17167091369628906, 0.13974571228027344, -0.3204517364501953, 0.16904640197753906, -0.6735234260559082, 0.17655563354492188, 19.12689971923828, 0.25647449493408203, 0.009923934936523438, -0.36907958984375, 0.1893749237060547, 0.11166572570800781, -0.8503055572509766, -0.0621185302734375, 0.08702659606933594, -0.21631240844726562, -0.359710693359375, 0.34009647369384766, 0.7879114151000977, -0.8634281158447266, -0.03096771240234375, -0.3488807678222656, 0.0012540817260742188, 0.09084701538085938, -0.39313697814941406, -0.08658027648925781, -0.2944965362548828, 0.801513671875, -0.3398103713989258, -0.1526813507080078, -0.2893695831298828, -0.27342796325683594, -0.10288429260253906, 3.447819232940674, -0.37084197998046875, -0.0930633544921875, -2.4759440422058105, -0.7951107025146484, -6.368846893310547, -0.5394868850708008, 0.5711746215820312], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 90112, "num_env_steps_trained": 334320, "num_agent_steps_sampled": 90112, "num_agent_steps_trained": 334320, "last_target_update_ts": 90112, "num_target_updates": 175}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -23.985726705119014, "episode_len_mean": 231.86, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962], "episode_lengths": [225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5615532740043174, "mean_inference_ms": 24.86552525060743, "mean_action_processing_ms": 0.1343204568657237, "mean_env_wait_ms": 4.4583676071769025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -23.985726705119014, "episode_len_mean": 231.86, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [23.00629895925522, -24.674756482243538, -62.43688539415598, -67.92138607054949, -1.8352140337228775, -3.2999997809529305, -220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962], "episode_lengths": [225, 217, 262, 279, 218, 219, 335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5615532740043174, "mean_inference_ms": 24.86552525060743, "mean_action_processing_ms": 0.1343204568657237, "mean_env_wait_ms": 4.4583676071769025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 90112, "num_agent_steps_trained": 334320, "num_env_steps_sampled": 90112, "num_env_steps_trained": 334320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 90112, "agent_timesteps_total": 90112, "timers": {"training_iteration_time_ms": 344.284, "learn_time_ms": 69.125, "learn_throughput": 3471.971, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 90112, "num_env_steps_trained": 334320, "num_agent_steps_sampled": 90112, "num_agent_steps_trained": 334320, "last_target_update_ts": 90112, "num_target_updates": 175}, "done": false, "episodes_total": 334, "training_iteration": 88, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-06", "timestamp": 1655478546, "time_this_iter_s": 5.463114976882935, "time_total_s": 470.8737120628357, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 470.8737120628357, "timesteps_since_restore": 0, "iterations_since_restore": 88, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.087500000000006, "ram_util_percent": 64.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.634851455688477, "min_q": -22.129297256469727, "max_q": 34.46186065673828, "mean_td_error": 0.08335287123918533}, "td_error": [-0.33835989236831665, -0.3202972412109375, -0.5988420248031616, -0.03414154052734375, -0.33594512939453125, -6.371543884277344, -0.7939815521240234, -0.3948936462402344, -6.3843536376953125, 0.01104736328125, -0.8422327041625977, 0.6250734329223633, 0.07120037078857422, -0.16951560974121094, -20.129297256469727, -0.19324302673339844, -0.23733139038085938, -0.5920953750610352, 0.9153966903686523, 1.2724781036376953, 0.11282825469970703, 1.1644134521484375, -0.2851219177246094, -0.02296161651611328, 10.119497299194336, -0.44569969177246094, 0.028303146362304688, 0.2362194061279297, -0.12682151794433594, 0.25945568084716797, 0.3036365509033203, 1.2208385467529297, -0.02139759063720703, -1.0489692687988281, 0.3496532440185547, -1.032257318496704, 14.714507102966309, 0.015264511108398438, 8.496136665344238, -0.27364444732666016, -0.08719158172607422, 0.45531558990478516, 0.36407470703125, 0.05132770538330078, -6.021150588989258, 0.04162788391113281, 0.6740493774414062, -0.37114715576171875, 0.08589744567871094, 0.24817371368408203, 1.793874740600586, 0.9585940837860107, 0.11369705200195312, -0.1873931884765625, -0.006495475769042969, 0.18114280700683594, -0.39298534393310547, -0.5633525848388672, 0.31523895263671875, -0.042733192443847656, 10.370680809020996, -0.21936416625976562, 1.2853240966796875, -0.05269813537597656, 0.3202791213989258, 0.48618316650390625, 0.23905563354492188, -0.41286754608154297, -0.34163475036621094, 0.06473016738891602, -0.24776649475097656, 0.5305910110473633, -0.31508541107177734, -0.09543418884277344, -0.008068084716796875, 0.5032644271850586, 0.6480503082275391, 0.09826850891113281, 1.1942448616027832, -0.2899513244628906, 0.35616111755371094, 0.12103080749511719, 0.10413837432861328, -1.032257318496704, 0.31580162048339844, -0.22902774810791016, -0.22198867797851562, 0.35906410217285156, 0.4971752166748047, 0.28696155548095703, 0.008164405822753906, 0.14723587036132812, -0.8610572814941406, -0.11742019653320312, 0.12121105194091797, 0.15515899658203125, 1.2161550521850586, 0.6870346069335938, -0.6807823181152344, 0.3972311019897461, -0.2470245361328125, 0.8782100677490234, 0.1139516830444336, -2.2569918632507324, -0.22417449951171875, -0.06366729736328125, -0.46639442443847656, -0.08624839782714844, 0.17049789428710938, 1.4334592819213867, 0.494781494140625, 0.6044826507568359, -0.29769134521484375, 0.5316390991210938, 0.10173606872558594, 0.3289928436279297, -4.878303527832031, 0.6870346069335938, 0.10825347900390625, -0.5893468856811523, 0.15275955200195312, -0.12927818298339844, 0.16616058349609375, -0.18748855590820312, 0.2591972351074219, -0.19696044921875, -0.543248176574707, 1.3085308074951172, -0.021970748901367188, -0.10518074035644531, -0.2208690643310547, -0.6412734985351562, 0.3422203063964844, 0.41384315490722656, -0.22369384765625, -0.48967647552490234, -0.47759532928466797, 0.03222846984863281, 9.004048347473145, 2.0164127349853516, 1.3397035598754883, 0.12700843811035156, 2.9145238399505615, 0.1813488006591797, 0.04446220397949219, 0.6473579406738281, -0.10787582397460938, -0.23038673400878906, -0.05780029296875, -6.989975929260254, 0.0006885528564453125, 0.2859153747558594, -1.1499881744384766, 0.0702056884765625, 0.07696151733398438, 16.62413215637207, 0.4276275634765625, -2.188654899597168, -0.06622123718261719, 0.7118864059448242, 0.10792922973632812, -0.3569183349609375, 0.08621597290039062, 0.5777902603149414, 0.0830526351928711, -0.010486602783203125, 0.21531105041503906, -0.21173095703125, -6.386085510253906, 1.181736946105957, 0.17527294158935547, 0.5834360122680664, -0.5665960311889648, -0.6470813751220703, 1.6460399627685547, -0.3633899688720703, 0.5987110137939453, -0.02801513671875, 1.2501778602600098, -1.8997888565063477, 0.16425704956054688, -0.12173843383789062, 0.08910751342773438, 0.41005706787109375, 0.7199134826660156, 0.251861572265625, 0.24236488342285156, -9.668201446533203, 0.17586135864257812, 1.8809490203857422, -1.8931350708007812, 0.4691190719604492, 0.3539257049560547, -1.9770441055297852, -7.137304306030273, -1.164036750793457, -0.017606735229492188, -0.060016632080078125, 1.3197517395019531, -0.2867412567138672, 1.1377782821655273, -0.4607105255126953, 0.1495361328125, 0.4170951843261719, 0.18484878540039062, 0.4986143112182617, 0.06958961486816406, -0.0729227066040039, 0.7560501098632812, 0.6013526916503906, 1.5472373962402344, 0.052799224853515625, 0.3014974594116211, -0.008068084716796875, -0.20186805725097656, 0.35918521881103516, 0.33469200134277344, -0.14518165588378906, -0.04637718200683594, -0.32176971435546875, 0.8335409164428711, -0.7577271461486816, 0.47080230712890625, -0.5738239288330078, 0.4142799377441406, -0.016630172729492188, -0.7373781204223633, 0.4933509826660156, -0.15773582458496094, -1.154088020324707, 1.8712072372436523, 0.15273284912109375, 0.19160079956054688, 0.9987125396728516, 0.6765823364257812, 0.7727165222167969, 0.030496597290039062, -0.22097206115722656, 1.1333990097045898, -0.7403249740600586], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 91136, "num_env_steps_trained": 338160, "num_agent_steps_sampled": 91136, "num_agent_steps_trained": 338160, "last_target_update_ts": 91136, "num_target_updates": 177}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -27.19576863795519, "episode_len_mean": 232.71, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525], "episode_lengths": [335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5627122572496617, "mean_inference_ms": 24.87966308549743, "mean_action_processing_ms": 0.13429409065956557, "mean_env_wait_ms": 4.46733953604247, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -27.19576863795519, "episode_len_mean": 232.71, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-220.18118298053741, 29.488175936043262, 18.786502294242382, -34.0738540366292, 11.266470454633236, -111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525], "episode_lengths": [335, 205, 235, 259, 206, 272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5627122572496617, "mean_inference_ms": 24.87966308549743, "mean_action_processing_ms": 0.13429409065956557, "mean_env_wait_ms": 4.46733953604247, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 91136, "num_agent_steps_trained": 338160, "num_env_steps_sampled": 91136, "num_env_steps_trained": 338160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 91136, "agent_timesteps_total": 91136, "timers": {"training_iteration_time_ms": 358.215, "learn_time_ms": 70.158, "learn_throughput": 3420.836, "synch_weights_time_ms": 20.889}, "counters": {"num_env_steps_sampled": 91136, "num_env_steps_trained": 338160, "num_agent_steps_sampled": 91136, "num_agent_steps_trained": 338160, "last_target_update_ts": 91136, "num_target_updates": 177}, "done": false, "episodes_total": 340, "training_iteration": 89, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-12", "timestamp": 1655478552, "time_this_iter_s": 5.693145036697388, "time_total_s": 476.5668570995331, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 476.5668570995331, "timesteps_since_restore": 0, "iterations_since_restore": 89, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.94444444444444, "ram_util_percent": 64.44444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.377701759338379, "min_q": -10.069557189941406, "max_q": 27.8184757232666, "mean_td_error": -0.11389044672250748}, "td_error": [-0.06335258483886719, -0.2755436897277832, 0.4198589324951172, -4.885841369628906, -0.00687408447265625, 0.23086833953857422, -0.44783782958984375, -1.0772247314453125, 0.5547027587890625, -0.0017499923706054688, 0.4263334274291992, -0.36061954498291016, 1.8034029006958008, -0.0051631927490234375, 0.05681133270263672, 0.41178131103515625, -1.6844596862792969, 0.03497123718261719, 1.3602895736694336, -0.023229598999023438, 0.4219675064086914, -0.12835121154785156, 1.0634937286376953, 0.17243576049804688, -0.12408638000488281, -0.04351615905761719, -0.5751209259033203, 0.30232810974121094, -0.2025432586669922, 0.13051605224609375, -0.7211160659790039, -0.2046489715576172, 0.09589767456054688, 0.19347763061523438, 3.517632484436035, -0.0009818077087402344, 0.6491832733154297, -0.3812141418457031, 0.36541175842285156, -0.2731170654296875, -0.6646251678466797, -1.8491954803466797, -10.069557189941406, 0.21234512329101562, -0.08435916900634766, 0.01284027099609375, -0.6531162261962891, -0.13335609436035156, -0.3608055114746094, -9.810134887695312, -0.42864990234375, -0.44696760177612305, -0.8462128639221191, 0.6320514678955078, 0.25513458251953125, 0.6399526596069336, 0.2025299072265625, -0.11079597473144531, 0.02468109130859375, 1.6376991271972656, -0.2692680358886719, -0.4186058044433594, 0.09180259704589844, -0.15137863159179688, 0.1047821044921875, 0.1477375030517578, 1.0493927001953125, 1.0307645797729492, 0.08789348602294922, 0.1361684799194336, 0.10920333862304688, 1.335442066192627, 0.31680774688720703, 0.9698286056518555, 0.05612754821777344, 0.12657546997070312, -0.1370067596435547, 0.48200416564941406, 0.4804801940917969, 0.16026782989501953, -0.016736984252929688, 0.21958351135253906, 0.5692863464355469, 1.7296943664550781, 0.09890937805175781, 1.158233642578125, 0.0522308349609375, -0.7727251052856445, 1.6376991271972656, 0.08417129516601562, 0.16618728637695312, 0.49871063232421875, -1.5760316848754883, -1.3749092817306519, 0.22321510314941406, -0.1807231903076172, -0.7401142120361328, 10.527923583984375, -2.3860106468200684, -9.593265533447266, -0.9408924579620361, 0.1633453369140625, -0.09953880310058594, 0.4829292297363281, -0.2889089584350586, -0.7208843231201172, -0.018404006958007812, -0.2681751251220703, 0.35950660705566406, 1.2553634643554688, 0.43676185607910156, 0.1446056365966797, 0.15974807739257812, 0.35213756561279297, -0.6367237567901611, -0.1956195831298828, -0.29767417907714844, -0.18515396118164062, 0.35213756561279297, 0.6980457305908203, -0.014667510986328125, 15.97844123840332, -0.1338939666748047, -0.9139909744262695, -0.2006664276123047, 0.41420745849609375, 0.13289451599121094, -0.16487693786621094, 0.2503795623779297, -0.1876506805419922, 0.38590240478515625, 0.5672159194946289, 0.7310810089111328, -2.6460719108581543, 0.6155433654785156, 0.0865316390991211, 0.5106353759765625, 14.985770225524902, -0.814845085144043, 0.13153648376464844, -0.6223087310791016, 0.4949989318847656, 0.3013343811035156, 0.35587215423583984, -0.2572746276855469, -0.12203025817871094, -0.025785446166992188, -0.2472667694091797, -0.2346935272216797, -5.884542465209961, -0.047351837158203125, -0.9952545166015625, -0.2946305274963379, 0.024606704711914062, -0.21509552001953125, 0.3224363327026367, 0.2356863021850586, 0.2105855941772461, -0.11599349975585938, -0.03521728515625, 0.3234138488769531, -0.18769454956054688, -0.30901336669921875, -0.28234946727752686, -0.49642372131347656, -0.05163764953613281, 0.34016895294189453, 0.4658079147338867, 0.4930992126464844, 0.33157920837402344, -0.04019737243652344, 0.4153308868408203, 0.04032325744628906, 0.28202056884765625, -0.3346672058105469, 0.11051750183105469, -0.2668285369873047, 0.11001968383789062, -1.9690628051757812, 0.6923694610595703, 0.026470184326171875, -1.0479989051818848, -0.19358444213867188, -5.606710433959961, -1.1694024801254272, -9.303878784179688, 0.32390403747558594, -0.3045792579650879, 0.054886817932128906, 0.38903331756591797, 0.04130363464355469, -0.0042171478271484375, -0.24335765838623047, 1.3602895736694336, 0.4730072021484375, 1.6376991271972656, -0.8359165191650391, 0.5642948150634766, 0.18171119689941406, 0.2991361618041992, 3.931079864501953, -0.182830810546875, 0.4401881694793701, -0.4816932678222656, 0.4006805419921875, -7.038641929626465, -5.582758903503418, -0.21413803100585938, -7.402083396911621, 0.3394489288330078, 0.313629150390625, -0.8723659515380859, -0.28617095947265625, -0.7222509384155273, 0.4136199951171875, 0.4095115661621094, 0.46155357360839844, 0.32953643798828125, 0.11478710174560547, -0.0054798126220703125, 0.391937255859375, -1.9929351806640625, 0.022914886474609375, -0.5186443328857422, 0.24943923950195312, 0.13294029235839844, 1.1844682693481445, -1.1426191329956055, -0.3766803741455078, -4.841655731201172, 0.2515373229980469, -0.02770233154296875, 0.2127208709716797, 0.6628074645996094, 0.2189311981201172, 0.8319854736328125, 0.32781219482421875, -1.0826759338378906, -1.1273765563964844, 0.3818674087524414], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 92160, "num_env_steps_trained": 342000, "num_agent_steps_sampled": 92160, "num_agent_steps_trained": 342000, "last_target_update_ts": 92160, "num_target_updates": 179}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -25.510203597918153, "episode_len_mean": 231.67, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967], "episode_lengths": [272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5638467929532803, "mean_inference_ms": 24.872610237529067, "mean_action_processing_ms": 0.13428313096181696, "mean_env_wait_ms": 4.468977037353335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -25.510203597918153, "episode_len_mean": 231.67, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-111.68160951137543, -224.95666161179543, -15.619703441858292, 3.7999999597668648, -132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967], "episode_lengths": [272, 306, 228, 236, 296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5638467929532803, "mean_inference_ms": 24.872610237529067, "mean_action_processing_ms": 0.13428313096181696, "mean_env_wait_ms": 4.468977037353335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 92160, "num_agent_steps_trained": 342000, "num_env_steps_sampled": 92160, "num_env_steps_trained": 342000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 92160, "agent_timesteps_total": 92160, "timers": {"training_iteration_time_ms": 356.63, "learn_time_ms": 69.366, "learn_throughput": 3459.913, "synch_weights_time_ms": 20.789}, "counters": {"num_env_steps_sampled": 92160, "num_env_steps_trained": 342000, "num_agent_steps_sampled": 92160, "num_agent_steps_trained": 342000, "last_target_update_ts": 92160, "num_target_updates": 179}, "done": false, "episodes_total": 345, "training_iteration": 90, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-18", "timestamp": 1655478558, "time_this_iter_s": 5.5803375244140625, "time_total_s": 482.14719462394714, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 482.14719462394714, "timesteps_since_restore": 0, "iterations_since_restore": 90, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.6875, "ram_util_percent": 64.4375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.818891525268555, "min_q": -19.81608009338379, "max_q": 28.734500885009766, "mean_td_error": 0.269940048456192}, "td_error": [-0.6156719923019409, -0.016109466552734375, 0.15272045135498047, 0.5048761367797852, 0.5476913452148438, -0.0973358154296875, -0.37222766876220703, 0.09418392181396484, 5.636970520019531, 0.4716815948486328, 0.17230606079101562, 0.4358654022216797, -0.6156719923019409, 0.6011905670166016, 0.29105663299560547, 0.7795581817626953, -0.9460220336914062, 0.26603221893310547, 0.4850921630859375, 0.6722221374511719, 0.9829111099243164, -0.4041929244995117, -4.802274703979492, 0.2703127861022949, 0.8084812164306641, 0.3596677780151367, -0.17625141143798828, 0.28032493591308594, 1.5622978210449219, 0.7941932678222656, -0.2684497833251953, 0.9889564514160156, 0.658935546875, -1.0682334899902344, 1.173813819885254, 0.4664783477783203, 0.3451385498046875, 0.5299243927001953, -0.6617469787597656, -9.40064811706543, 0.5797090530395508, 0.945979118347168, -0.2379741668701172, -0.15621376037597656, 0.6428737640380859, -0.6798739433288574, 0.7876033782958984, 1.0523567199707031, 0.6169114112854004, -1.5007412433624268, 0.19861316680908203, 0.3866004943847656, 0.5664663314819336, -0.1561756134033203, 1.7710280418395996, 0.20746803283691406, 0.34880638122558594, 2.924494743347168, 0.5201549530029297, 1.237563133239746, -0.46692657470703125, 2.055889129638672, 0.9232940673828125, -0.15689420700073242, -0.18620586395263672, 0.8317890167236328, 0.8483772277832031, 0.6529979705810547, 0.7740020751953125, 0.9196758270263672, 0.23630714416503906, -0.1127634048461914, -5.336078643798828, -4.493833541870117, 0.6626453399658203, 1.1390228271484375, -0.12838459014892578, 0.5714244842529297, 0.1404857635498047, 0.2305927276611328, 0.13357257843017578, 0.2300891876220703, 0.2928142547607422, 0.6240644454956055, -0.7983903884887695, -0.08550834655761719, 10.153229713439941, 0.37366485595703125, 11.981596946716309, 0.4676055908203125, 0.43031883239746094, -0.604987621307373, 1.6470403671264648, -1.0535473823547363, 0.2474079132080078, 0.33983421325683594, 0.6766223907470703, -0.5086517333984375, 0.1725177764892578, 0.28963565826416016, 0.9058723449707031, 0.5662851333618164, -0.011203765869140625, 0.4643697738647461, -0.8456811904907227, 0.7182559967041016, 0.6070346832275391, 0.8969326019287109, -0.604987621307373, -0.18417024612426758, 0.4839315414428711, 1.1696662902832031, 0.22000694274902344, -5.392457962036133, -0.3891286849975586, 1.4096689224243164, -0.06324577331542969, -0.2937583923339844, -0.9067401885986328, 0.13994598388671875, 0.12936115264892578, 0.17877960205078125, -0.2911500930786133, 0.112518310546875, -0.29015541076660156, 1.3970909118652344, 1.5383977890014648, -0.12777137756347656, 0.7394294738769531, -0.17142486572265625, 0.6055116653442383, 0.2241687774658203, -0.2328968048095703, 0.9177207946777344, 0.9234237670898438, 0.09842777252197266, 1.0106163024902344, 0.5833320617675781, 0.3754138946533203, 0.24654388427734375, 0.4758739471435547, 0.5485477447509766, 0.263458251953125, 0.3222169876098633, 0.6190347671508789, -0.22237300872802734, 0.04813671112060547, 0.3927736282348633, -5.995889663696289, 11.516120910644531, 0.5299243927001953, 1.429534912109375, 0.7078132629394531, 0.812779426574707, 0.4714336395263672, 0.11299514770507812, -1.3006954193115234, 0.25884056091308594, 1.1249761581420898, 0.17360591888427734, 0.7962055206298828, 0.18039703369140625, -10.259387016296387, -0.651336669921875, 0.1314849853515625, -0.34647178649902344, -0.12885665893554688, 1.3846435546875, 0.40576839447021484, 0.8084812164306641, 12.808094024658203, -0.20647239685058594, -5.503453254699707, 1.0462646484375, -4.536052703857422, 10.65954875946045, 0.7290620803833008, 0.5379886627197266, 0.28963565826416016, 0.9947452545166016, 0.3292045593261719, 0.7441139221191406, 0.5633525848388672, 0.13954925537109375, 0.2731895446777344, -0.22999095916748047, 1.0572795867919922, 1.636627197265625, -0.7976055145263672, 0.27750492095947266, -0.8398332595825195, -6.136465072631836, 1.2620735168457031, -0.3722724914550781, 0.23998451232910156, 1.9934453964233398, 1.0516605377197266, 0.9166660308837891, 0.9889564514160156, 0.6382150650024414, 1.052433967590332, 0.4059314727783203, 1.0516948699951172, 0.286590576171875, 0.3782234191894531, -4.700860977172852, 0.6856307983398438, 0.9548454284667969, -0.3243117332458496, -0.6479597091674805, 0.30638694763183594, -0.011816978454589844, 0.2771759033203125, 0.9855709075927734, -4.680727005004883, 0.5402412414550781, 0.4525327682495117, -1.389892578125, 0.21739959716796875, 0.9662351608276367, 0.31853485107421875, 0.48444652557373047, 0.8162288665771484, 0.8652076721191406, 0.6712455749511719, -0.29541683197021484, 0.035396575927734375, -0.27839088439941406, 0.12912750244140625, -0.8489818572998047, 0.10390090942382812, 0.9764156341552734, 0.8561620712280273, 0.85125732421875, 0.4783191680908203, 0.6771678924560547, -5.342336177825928, 0.37017822265625, -0.40251636505126953, 0.43330955505371094], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 93184, "num_env_steps_trained": 345840, "num_agent_steps_sampled": 93184, "num_agent_steps_trained": 345840, "last_target_update_ts": 93184, "num_target_updates": 181}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -25.322774515971542, "episode_len_mean": 230.39, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197], "episode_lengths": [296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5640968586260308, "mean_inference_ms": 24.87284638966946, "mean_action_processing_ms": 0.13428152044111877, "mean_env_wait_ms": 4.4726436223885235, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -25.322774515971542, "episode_len_mean": 230.39, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-132.97078359127045, 6.400000013411045, 28.831611044704914, -4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197], "episode_lengths": [296, 193, 212, 215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5640968586260308, "mean_inference_ms": 24.87284638966946, "mean_action_processing_ms": 0.13428152044111877, "mean_env_wait_ms": 4.4726436223885235, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 93184, "num_agent_steps_trained": 345840, "num_env_steps_sampled": 93184, "num_env_steps_trained": 345840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 93184, "agent_timesteps_total": 93184, "timers": {"training_iteration_time_ms": 345.443, "learn_time_ms": 70.075, "learn_throughput": 3424.922, "synch_weights_time_ms": 20.888}, "counters": {"num_env_steps_sampled": 93184, "num_env_steps_trained": 345840, "num_agent_steps_sampled": 93184, "num_agent_steps_trained": 345840, "last_target_update_ts": 93184, "num_target_updates": 181}, "done": false, "episodes_total": 349, "training_iteration": 91, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-23", "timestamp": 1655478563, "time_this_iter_s": 5.44148063659668, "time_total_s": 487.5886752605438, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 487.5886752605438, "timesteps_since_restore": 0, "iterations_since_restore": 91, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 36.050000000000004, "ram_util_percent": 64.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.365601539611816, "min_q": -15.59976577758789, "max_q": 33.171592712402344, "mean_td_error": -0.011862355284392834}, "td_error": [0.08386611938476562, -0.4856719970703125, 0.50531005859375, 0.24029159545898438, 0.3859834671020508, -0.37306976318359375, 0.3310127258300781, 0.6108694076538086, -0.30315589904785156, 1.2445697784423828, 0.3714313507080078, -0.3973560333251953, 0.9732418060302734, 0.0905303955078125, 3.3948450088500977, -0.08156967163085938, -0.3221549987792969, -0.23293495178222656, 1.458963394165039, -0.3236122131347656, 0.665257453918457, -0.8513202667236328, 0.21880531311035156, 0.6717643737792969, 0.41962623596191406, -0.1224355697631836, 0.24222373962402344, -0.26145172119140625, 0.6211328506469727, -10.346810340881348, 0.20206069946289062, -0.4415855407714844, -7.593158721923828, -1.2190256118774414, -0.3686351776123047, 0.60577392578125, -0.49526214599609375, 0.27290916442871094, -5.182376861572266, 0.4870328903198242, -0.3273811340332031, 0.058841705322265625, 1.4608821868896484, -1.7993335723876953, -0.24223804473876953, 1.3027267456054688, -0.1408834457397461, -0.21692752838134766, 1.8225736618041992, 0.41870975494384766, 0.7383098602294922, 0.34917354583740234, -0.20512771606445312, 1.0484561920166016, -1.5570249557495117, 0.6760787963867188, -0.3963775634765625, 0.2553386688232422, 1.771371841430664, -0.31360816955566406, -6.266279220581055, 0.7664318084716797, 0.27477455139160156, 0.0003223419189453125, -0.05541038513183594, 1.6680183410644531, 3.680116653442383, 0.20865249633789062, 0.36832427978515625, -0.3067817687988281, -0.03178596496582031, -0.49526214599609375, 0.12737369537353516, -1.0397357940673828, -4.736766815185547, -0.8685970306396484, 0.5794944763183594, -0.6134195327758789, 0.6983146667480469, -0.20795822143554688, 0.357607364654541, -3.2866287231445312, 0.7207355499267578, 0.16499900817871094, 0.7560434341430664, 0.8225250244140625, -0.5923480987548828, 8.927267074584961, -0.5563507080078125, 1.141824722290039, -0.7253284454345703, -0.18327903747558594, 0.5015029907226562, -0.0082855224609375, 0.3435087203979492, 1.3328704833984375, 0.05336952209472656, -0.2252368927001953, -0.2175140380859375, 0.3093986511230469, -0.07386589050292969, 12.444433212280273, 0.1289958953857422, 0.7723388671875, 0.24948322772979736, 0.2403545379638672, 0.3735208511352539, 0.19451904296875, -0.5042283535003662, -0.33052730560302734, 0.4156637191772461, 0.043808937072753906, 0.2617149353027344, 0.33374595642089844, 0.3361225128173828, 1.2739295959472656, -1.9149770736694336, -0.2291393280029297, -0.6903247833251953, 0.2471609115600586, 10.49960708618164, -0.14572906494140625, -1.4758539199829102, 0.03130626678466797, -1.5193023681640625, 0.7310061454772949, -1.8491976261138916, -2.5980191230773926, 1.1530961990356445, 0.5028438568115234, -0.6796197891235352, -0.16303062438964844, 0.5319385528564453, 1.2288637161254883, -0.07721519470214844, 0.11270713806152344, 0.5091896057128906, 0.9718265533447266, 0.0849008560180664, 0.1372232437133789, 1.066917896270752, 0.44744110107421875, -1.3830814361572266, -10.675178527832031, 0.16184234619140625, 0.10634422302246094, 0.47092437744140625, 0.16324234008789062, 1.5156774520874023, 2.469270706176758, 0.0524139404296875, -1.0492134094238281, 0.19343948364257812, -0.26887035369873047, -0.0754246711730957, -0.1043558120727539, -0.6958503723144531, 0.13001060485839844, 0.23002243041992188, 0.5272912979125977, 0.2784395217895508, -0.3550300598144531, 0.2106170654296875, 0.7383670806884766, 0.011810302734375, 0.6826949119567871, -0.09028053283691406, 0.2665691375732422, 0.24967455863952637, 0.027629852294921875, 0.8168725967407227, 0.8070864677429199, 0.41951656341552734, -0.4304370880126953, 0.10375595092773438, -1.6731071472167969, 0.19741249084472656, -0.5258922576904297, 0.8311479091644287, -0.12903976440429688, -0.09662818908691406, -10.255229949951172, -0.08403778076171875, -0.48478126525878906, -0.6734428405761719, -0.22672271728515625, -0.13754653930664062, -0.1838207244873047, 0.5069007873535156, 0.32735252380371094, -0.06964302062988281, 12.001848220825195, -0.4347724914550781, -5.968381881713867, -0.3541107177734375, 1.8024959564208984, 1.1832752227783203, 1.1269121170043945, 0.7053203582763672, -0.22956275939941406, -0.8605518341064453, 0.1105659008026123, 1.0657453536987305, 1.0599727630615234, 0.23659515380859375, 0.38641929626464844, -1.942528247833252, -0.23613643646240234, -5.032571792602539, 0.16587162017822266, 0.47058963775634766, 0.12677228450775146, -0.42664527893066406, -0.1489410400390625, -0.00276947021484375, -0.3220853805541992, 0.6332492828369141, 0.05612945556640625, -5.235982894897461, -0.28106141090393066, -0.07941150665283203, -0.1717815399169922, -0.8953113555908203, -0.3384857177734375, 0.9022121429443359, 0.07501220703125, -1.1351985931396484, -0.8860569000244141, 0.4947338104248047, 0.6809577941894531, 0.29070281982421875, 0.24780654907226562, -0.19278526306152344, 0.4519648551940918, 0.07265281677246094, 0.11985588073730469, 0.12463951110839844, -0.37433815002441406, 1.2288637161254883, -1.8069849014282227], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 94208, "num_env_steps_trained": 349680, "num_agent_steps_sampled": 94208, "num_agent_steps_trained": 349680, "last_target_update_ts": 94208, "num_target_updates": 183}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -24.032967452555894, "episode_len_mean": 229.49, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794], "episode_lengths": [215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5649962239879958, "mean_inference_ms": 24.89671527947912, "mean_action_processing_ms": 0.13431226708981778, "mean_env_wait_ms": 4.4793615193560585, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -373.0521286651492, "episode_reward_mean": -24.032967452555894, "episode_len_mean": 229.49, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-4.400000140070915, 8.210635423660278, -4.599999889731407, 22.46568849682808, 11.31063537299633, 8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794], "episode_lengths": [215, 193, 223, 182, 178, 220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5649962239879958, "mean_inference_ms": 24.89671527947912, "mean_action_processing_ms": 0.13431226708981778, "mean_env_wait_ms": 4.4793615193560585, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 94208, "num_agent_steps_trained": 349680, "num_env_steps_sampled": 94208, "num_env_steps_trained": 349680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 94208, "agent_timesteps_total": 94208, "timers": {"training_iteration_time_ms": 355.73, "learn_time_ms": 71.064, "learn_throughput": 3377.249, "synch_weights_time_ms": 22.187}, "counters": {"num_env_steps_sampled": 94208, "num_env_steps_trained": 349680, "num_agent_steps_sampled": 94208, "num_agent_steps_trained": 349680, "last_target_update_ts": 94208, "num_target_updates": 183}, "done": false, "episodes_total": 352, "training_iteration": 92, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-29", "timestamp": 1655478569, "time_this_iter_s": 5.508370399475098, "time_total_s": 493.0970456600189, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 493.0970456600189, "timesteps_since_restore": 0, "iterations_since_restore": 92, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 34.675, "ram_util_percent": 64.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.721417427062988, "min_q": -15.220893859863281, "max_q": 30.62526512145996, "mean_td_error": 0.06919533759355545}, "td_error": [-0.061325788497924805, -1.9314627647399902, 0.07366180419921875, 0.49129581451416016, 0.03138160705566406, 1.121164321899414, -0.07575416564941406, -0.0059490203857421875, 0.8900070190429688, -5.781790733337402, 0.0525054931640625, -0.6799125671386719, 0.6524757146835327, 0.4994926452636719, 1.7767152786254883, -0.22248268127441406, -0.10014724731445312, 1.1056725978851318, 0.10849761962890625, -5.710463523864746, 0.10977935791015625, 0.6792454719543457, -6.012225151062012, -0.7838048934936523, -0.3171253204345703, 0.16082000732421875, 0.23400020599365234, 0.6289262771606445, -0.4956092834472656, -1.3927860260009766, -0.26922035217285156, -0.05948448181152344, 0.901118278503418, 0.9320468902587891, 0.2813682556152344, 0.5335893630981445, 0.3361082077026367, 0.7359256744384766, 0.15830326080322266, 0.04831123352050781, 1.2846012115478516, -0.05932807922363281, 0.2774791717529297, 1.6104850769042969, -0.05240821838378906, -0.26415252685546875, -0.21898460388183594, 0.526118278503418, 0.2525930404663086, -0.5949115753173828, -0.2201061248779297, -0.09391975402832031, -0.1853041648864746, 0.39614295959472656, -0.46709632873535156, -0.7607183456420898, -0.028982162475585938, 0.3094482421875, 1.1749000549316406, -0.3674488067626953, -0.08508491516113281, 0.055817604064941406, -0.41257190704345703, -0.5051498413085938, 0.22234153747558594, -0.4432840347290039, -0.717564582824707, -0.6267032623291016, -0.167938232421875, -0.22580242156982422, 0.4512481689453125, 0.16044235229492188, 0.18799781799316406, 0.8086204528808594, 0.07133293151855469, 0.3259906768798828, 10.596160888671875, -1.3018512725830078, 0.2543773651123047, 0.3122291564941406, -0.07212066650390625, -0.6157550811767578, -7.266798973083496, -0.3412322998046875, -0.2706565856933594, 0.03530120849609375, -0.29779052734375, -0.0870981216430664, 1.33514404296875, -0.2437305450439453, 10.596160888671875, 0.5160579681396484, 0.18270111083984375, -0.7508621215820312, 0.11720466613769531, -0.3853464126586914, 0.043010711669921875, -0.1824779510498047, 0.03542518615722656, 0.34239864349365234, -0.2205638885498047, 0.30488014221191406, -0.1451587677001953, -0.33777427673339844, -0.3719218969345093, -9.247770309448242, -0.02019500732421875, 0.6046295166015625, 0.04204559326171875, -0.20760726928710938, 7.07945442199707, -0.9512386322021484, 0.3083038330078125, 0.16255497932434082, -0.1365528106689453, 0.3268852233886719, 1.401595115661621, -0.309323787689209, -0.3098602294921875, 0.6727313995361328, -1.2304515838623047, -0.13035964965820312, -0.013278961181640625, 0.16207504272460938, 0.1401824951171875, 0.4588813781738281, -0.044178009033203125, -1.1835284233093262, -0.03983592987060547, 0.31337738037109375, 0.03446388244628906, -0.28619384765625, -0.028644561767578125, -0.3126029968261719, -1.7956619262695312, 0.6515665054321289, -0.18712997436523438, 1.553628921508789, -0.32232093811035156, 0.04234886169433594, -0.11527061462402344, 0.17601299285888672, -0.9293937683105469, 0.10698890686035156, -0.28319549560546875, -0.18259811401367188, 0.6353054046630859, 0.48900318145751953, -9.279138565063477, 0.6105566024780273, -0.3171253204345703, -0.27234649658203125, 0.1619110107421875, -0.3723869323730469, 0.3943367004394531, 0.39676952362060547, 1.1042907238006592, 0.3027801513671875, 11.29141616821289, 0.45823097229003906, 0.1399974822998047, -0.2028656005859375, 0.04857921600341797, -0.13829612731933594, -0.05119895935058594, 0.24201297760009766, 0.04393768310546875, 0.28699302673339844, -0.09528923034667969, 0.09152030944824219, -1.795393466949463, -0.23946762084960938, -0.09771156311035156, 0.30584239959716797, 0.41847705841064453, -0.8319072723388672, -0.6285734176635742, 1.3957271575927734, 0.440915584564209, -0.2119312286376953, 0.5091695785522461, -0.2553577423095703, -0.8850035667419434, -6.138018608093262, -0.08522415161132812, 1.135115146636963, 0.1777362823486328, -0.1853041648864746, 0.5391635894775391, -0.4932979941368103, -0.5574369430541992, 0.23087120056152344, -0.11237716674804688, -0.48125410079956055, 0.4370250701904297, -0.1698446273803711, 3.975025177001953, -1.0674610137939453, 0.36299896240234375, 0.5590448379516602, 1.1477546691894531, -0.04283714294433594, 1.1183443069458008, 0.9185690879821777, -0.37122344970703125, -0.12332820892333984, 0.02079486846923828, 0.008098602294921875, -0.07896614074707031, 9.875313758850098, -0.15040016174316406, 0.03621101379394531, -0.2871055603027344, -0.7294514179229736, -0.19860506057739258, 0.09600067138671875, 1.6104850769042969, -0.03799724578857422, 0.5356950759887695, 0.17519569396972656, 0.5673122406005859, 1.133310317993164, 0.2489604949951172, -0.4284048080444336, 0.15362167358398438, 0.08269309997558594, 0.23479175567626953, 0.7097434997558594, 0.022108078002929688, 0.30506324768066406, -0.4010276794433594, -0.1462993621826172, -0.030271530151367188, -0.7056732177734375, -0.023481369018554688, -0.02942657470703125, 0.7820887565612793, 0.3299980163574219, -0.15552330017089844, 0.20279407501220703], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 95232, "num_env_steps_trained": 353520, "num_agent_steps_sampled": 95232, "num_agent_steps_trained": 353520, "last_target_update_ts": 95232, "num_target_updates": 185}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -28.288102614954113, "episode_len_mean": 231.98, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835], "episode_lengths": [220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.565294091346068, "mean_inference_ms": 24.90628072591962, "mean_action_processing_ms": 0.13424378256724986, "mean_env_wait_ms": 4.4826872411266185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -28.288102614954113, "episode_len_mean": 231.98, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [8.200000017881393, 12.824683412909508, 1.1000000461935997, 5.000000171363354, -32.784489423036575, 35.16021978110075, 27.932128109037876, 16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835], "episode_lengths": [220, 185, 190, 204, 251, 228, 189, 235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.565294091346068, "mean_inference_ms": 24.90628072591962, "mean_action_processing_ms": 0.13424378256724986, "mean_env_wait_ms": 4.4826872411266185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 95232, "num_agent_steps_trained": 353520, "num_env_steps_sampled": 95232, "num_env_steps_trained": 353520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 95232, "agent_timesteps_total": 95232, "timers": {"training_iteration_time_ms": 363.621, "learn_time_ms": 70.367, "learn_throughput": 3410.672, "synch_weights_time_ms": 20.584}, "counters": {"num_env_steps_sampled": 95232, "num_env_steps_trained": 353520, "num_agent_steps_sampled": 95232, "num_agent_steps_trained": 353520, "last_target_update_ts": 95232, "num_target_updates": 185}, "done": false, "episodes_total": 357, "training_iteration": 93, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-35", "timestamp": 1655478575, "time_this_iter_s": 5.729216814041138, "time_total_s": 498.82626247406006, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 498.82626247406006, "timesteps_since_restore": 0, "iterations_since_restore": 93, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.212500000000006, "ram_util_percent": 64.6125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.094929695129395, "min_q": -16.940555572509766, "max_q": 33.57330322265625, "mean_td_error": 0.28278008103370667}, "td_error": [0.5379500389099121, 1.4242238998413086, 0.21250534057617188, -0.21776199340820312, -0.2199087142944336, 0.33754730224609375, 0.296600341796875, -1.6066036224365234, 0.5750513076782227, -1.1740589141845703, -1.1079492568969727, 0.21658897399902344, 0.3625164031982422, 0.2183208465576172, -5.547473907470703, 0.22747039794921875, -0.77362060546875, -0.4792900085449219, 0.08926200866699219, -0.6660776138305664, 0.27886962890625, -0.12073802947998047, 0.17374610900878906, -0.6260528564453125, -0.11755180358886719, -12.367105484008789, -0.21675777435302734, -1.0570545196533203, -0.4020118713378906, -0.6237039566040039, 0.6846489906311035, 0.6233124732971191, 0.44573974609375, 0.1369915008544922, 0.3299751281738281, -0.7050361633300781, 1.0193767547607422, 0.09169769287109375, -0.2156229019165039, 0.3294563293457031, -0.6467866897583008, 0.6825594902038574, -0.8452205657958984, -0.3063678741455078, 13.361454010009766, 0.5479946136474609, -0.5007743835449219, 0.5487155914306641, -0.4037437438964844, 0.4726982116699219, 3.2784910202026367, 0.24210739135742188, 0.24692821502685547, 1.0880799293518066, -0.21378135681152344, -0.5299835205078125, 1.2153339385986328, -7.0756330490112305, -2.317516803741455, -0.22093096375465393, 0.2661724090576172, 0.5348560810089111, 13.095978736877441, -0.8020000457763672, -1.2432937622070312, 0.23000144958496094, 1.3460451364517212, 1.138143539428711, 0.9033379554748535, 0.0037384033203125, 0.7281293869018555, -0.031230926513671875, 1.0358734130859375, -4.429668426513672, 0.35106849670410156, -1.2350990772247314, -1.5989818572998047, -0.14223861694335938, -3.8215951919555664, 0.2822608947753906, -0.9264430999755859, 11.132328033447266, 0.012228012084960938, -0.04956245422363281, 0.9033622741699219, -1.2943668365478516, 0.1481170654296875, -3.3716654777526855, -1.1821613311767578, 0.07163429260253906, -0.9438438415527344, 0.28240060806274414, -0.4835672378540039, 0.3572673797607422, 9.187653541564941, 0.41900062561035156, -4.932306289672852, 0.03768754005432129, 0.7068052291870117, -0.4342842102050781, -0.3877429962158203, -0.13143348693847656, -1.4518661499023438, 0.92987060546875, 0.2762775421142578, -0.17096233367919922, 0.7069339752197266, 0.29558658599853516, 0.10033798217773438, -0.10202789306640625, 0.28690147399902344, 11.324535369873047, 0.5064525604248047, 0.5529594421386719, -0.2448558807373047, 0.013071060180664062, -0.6112833023071289, 0.2300243377685547, -6.093055725097656, -1.7765178680419922, 0.05124855041503906, -0.020772933959960938, 0.5882701873779297, -0.1369190216064453, -0.7617242336273193, 0.1644763946533203, 0.8921022415161133, 2.2615346908569336, -0.9719324111938477, 0.2585010528564453, 0.15565109252929688, -0.32614707946777344, -0.0075130462646484375, 0.04142951965332031, -0.11523246765136719, 0.3371753692626953, 0.48424243927001953, -0.9746379852294922, 1.4009819030761719, 0.1843118667602539, -0.6197285652160645, -0.2715873718261719, -0.6979837417602539, -1.6814312934875488, 0.4205513000488281, -0.01980304718017578, 0.04680442810058594, 1.7574739456176758, 0.0768899917602539, -0.7617242336273193, 0.37182044982910156, 0.0971822738647461, 0.6825594902038574, 0.30183887481689453, 0.28197765350341797, 2.9740753173828125, 0.2661724090576172, 0.3571748733520508, 0.028329849243164062, -1.1695556640625, 0.39783287048339844, -0.31241607666015625, 0.49443817138671875, 16.428321838378906, 0.3818645477294922, 0.7057151794433594, -6.503623008728027, 0.4419136047363281, 0.3646812438964844, 0.22444438934326172, -0.24165725708007812, -0.42772769927978516, 11.035393714904785, 13.576310157775879, -0.02724742889404297, -0.21852493286132812, 0.07543563842773438, 0.6135025024414062, -0.33234405517578125, 0.6255772113800049, 0.05163764953613281, 1.1830635070800781, -0.4196920394897461, 0.3043346405029297, -0.5132284164428711, -9.982192993164062, -1.0126609802246094, 1.0944538116455078, 0.2070636749267578, -0.049765586853027344, 0.7681312561035156, 0.35354137420654297, 8.808403968811035, 0.4992637634277344, 0.026917457580566406, -0.2228069305419922, 1.1741752624511719, -0.10608673095703125, 0.584259033203125, 0.2540855407714844, -0.004105567932128906, 0.03768754005432129, -1.473189353942871, 13.095978736877441, -0.1101827621459961, -0.8184452056884766, -1.81850266456604, 0.4606361389160156, -0.6187572479248047, 1.8303719758987427, 0.6138744354248047, 2.5025906562805176, 0.38820457458496094, -0.4129142761230469, 0.3538932800292969, -0.7082080841064453, 0.8066444396972656, 0.8257217407226562, -1.3695287704467773, -0.32626914978027344, 1.007227897644043, -1.6054010391235352, -0.06838035583496094, 0.09566497802734375, 0.6862821578979492, -2.2463808059692383, 0.198614239692688, 0.27776145935058594, 0.6038627624511719, -0.01980304718017578, -0.37580108642578125, -0.1951446533203125, 0.3567848205566406, -0.5662860870361328, -0.0036983489990234375, 0.4628429412841797, -0.1586284637451172, 0.5980014801025391, 0.3010978698730469, -0.4838552474975586], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 96256, "num_env_steps_trained": 357360, "num_agent_steps_sampled": 96256, "num_agent_steps_trained": 357360, "last_target_update_ts": 96256, "num_target_updates": 187}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -30.12760965436697, "episode_len_mean": 233.37, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068], "episode_lengths": [235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.565964757419502, "mean_inference_ms": 24.902080475727274, "mean_action_processing_ms": 0.13427006074985456, "mean_env_wait_ms": 4.486456719715276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -30.12760965436697, "episode_len_mean": 233.37, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [16.364785812795162, 7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068], "episode_lengths": [235, 229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.565964757419502, "mean_inference_ms": 24.902080475727274, "mean_action_processing_ms": 0.13427006074985456, "mean_env_wait_ms": 4.486456719715276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 96256, "num_agent_steps_trained": 357360, "num_env_steps_sampled": 96256, "num_env_steps_trained": 357360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 96256, "agent_timesteps_total": 96256, "timers": {"training_iteration_time_ms": 356.33, "learn_time_ms": 70.667, "learn_throughput": 3396.229, "synch_weights_time_ms": 20.989}, "counters": {"num_env_steps_sampled": 96256, "num_env_steps_trained": 357360, "num_agent_steps_sampled": 96256, "num_agent_steps_trained": 357360, "last_target_update_ts": 96256, "num_target_updates": 187}, "done": false, "episodes_total": 364, "training_iteration": 94, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-41", "timestamp": 1655478581, "time_this_iter_s": 5.617587089538574, "time_total_s": 504.44384956359863, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 504.44384956359863, "timesteps_since_restore": 0, "iterations_since_restore": 94, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 35.5, "ram_util_percent": 64.64999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.068854331970215, "min_q": -16.360902786254883, "max_q": 28.1079158782959, "mean_td_error": -0.03775244578719139}, "td_error": [0.38632774353027344, -0.6582717895507812, -0.011583328247070312, 0.69061279296875, 0.5023384094238281, 0.08449363708496094, -0.9021825790405273, 0.06567001342773438, 0.05656147003173828, 0.08498287200927734, 0.22074127197265625, 0.7455358505249023, -1.2770576477050781, 0.27663230895996094, -0.2682323455810547, -0.018720626831054688, 0.4466285705566406, -0.15341758728027344, -0.4974689483642578, 0.43086814880371094, -0.5440759658813477, -0.028074264526367188, 0.9914665222167969, -0.1745290756225586, 0.6239433288574219, 0.08696508407592773, 0.12993621826171875, -0.25577735900878906, -0.5518455505371094, -0.35686492919921875, -0.6739177703857422, -0.3902606964111328, -0.10816383361816406, 0.7944965362548828, 0.3713855743408203, -0.5852222442626953, -0.3545398712158203, 0.7245979309082031, -4.877355575561523, -0.25215721130371094, -0.09552383422851562, 0.7479219436645508, -0.04908943176269531, 0.06981086730957031, -0.46302032470703125, 9.824132919311523, -1.606832504272461, 0.04390716552734375, -0.027318954467773438, -0.1773815155029297, 0.1371469497680664, -0.09574699401855469, -0.040818214416503906, -0.6561679840087891, -0.5277090072631836, 0.18212223052978516, 0.8853015899658203, 0.6470870971679688, 0.5631256103515625, 0.34252262115478516, 0.5783061981201172, -6.9811553955078125, -0.4912261962890625, 1.0477399826049805, 0.5671548843383789, -0.39669227600097656, -0.47351932525634766, -0.2265615463256836, 0.05890083312988281, 0.6891031265258789, 0.2800636291503906, 0.047083377838134766, 0.05873298645019531, 0.03429126739501953, -0.11424636840820312, -0.29241180419921875, -0.3767852783203125, 0.3040428161621094, -7.303556442260742, -0.48781585693359375, 12.805981636047363, 0.22022247314453125, 0.4899311065673828, -0.13378334045410156, 1.3262834548950195, 0.30443859100341797, 0.2840137481689453, 1.6165523529052734, -0.17662715911865234, 0.03459930419921875, -0.7802391052246094, 0.7132129669189453, 0.5019960403442383, -0.6282386779785156, -0.25518035888671875, -0.1860675811767578, -0.07389450073242188, -0.3196907043457031, 0.2948780059814453, 1.1212635040283203, -0.3778228759765625, -0.055980682373046875, -0.24318695068359375, -0.6097373962402344, -0.037276268005371094, -0.6021146774291992, -6.154012680053711, -0.4513216018676758, -0.9175281524658203, -1.7076454162597656, -0.04229545593261719, -12.307756423950195, -0.6540699005126953, -0.3038778305053711, 0.14608478546142578, 0.31886768341064453, -0.05972766876220703, 1.7148332595825195, -6.156037330627441, 0.2982444763183594, -7.86441707611084, -0.27913475036621094, -0.1698474884033203, 0.01923370361328125, -0.029605865478515625, -0.034824371337890625, -0.5705242156982422, -0.18118667602539062, -0.017747879028320312, 0.3492755889892578, 0.2505931854248047, 0.5300235748291016, -0.19933128356933594, -0.6569480895996094, -0.0072879791259765625, -1.0545921325683594, -0.1620941162109375, 0.06150054931640625, 0.42163658142089844, 0.04686737060546875, 0.7179322242736816, 0.8506155014038086, 11.744706153869629, -0.23366069793701172, -0.20675086975097656, 0.03504467010498047, 0.7155489921569824, -0.8099365234375, 0.31922149658203125, 0.09954547882080078, -0.826207160949707, 1.0614299774169922, -0.9169938564300537, -2.0082385540008545, -0.4185314178466797, 16.159618377685547, 0.2203369140625, 0.06044960021972656, -0.3038778305053711, -0.5186452865600586, 0.9125356674194336, -0.5237770080566406, 1.026336669921875, -1.2113628387451172, -1.0821621417999268, 1.238703727722168, 1.2545223236083984, 0.7111406326293945, -0.9437236785888672, 0.1903400421142578, -0.20339584350585938, 0.34252262115478516, -0.35991477966308594, -0.5908365249633789, -0.1224222183227539, 0.9935159683227539, -0.018720626831054688, 2.4677200317382812, 0.5082881450653076, 0.30553436279296875, 0.5567283630371094, -0.2453937530517578, -1.2208118438720703, -0.6282386779785156, -0.3658590316772461, 0.12796401977539062, 14.327953338623047, -0.20574378967285156, -0.9654350280761719, 1.750485897064209, -1.6849350929260254, -1.2879257202148438, 0.12404060363769531, -0.009000778198242188, -0.39238548278808594, 1.941206932067871, 0.7568674087524414, -0.20883560180664062, 0.41391944885253906, -0.1784038543701172, -0.14470291137695312, -0.26708221435546875, -9.359004974365234, 0.5941305160522461, 0.3096199035644531, 0.12092018127441406, -0.15314102172851562, -1.0878067016601562, -0.03747749328613281, 0.4476490020751953, -0.1450481414794922, -0.06961250305175781, -0.5197429656982422, -0.26265716552734375, -0.8705358505249023, -0.1747303009033203, 0.3545665740966797, 0.0052585601806640625, 1.6947574615478516, -0.6780567169189453, -1.8946585655212402, -0.7744207382202148, 0.09527873992919922, 0.6966495513916016, -0.057351112365722656, -4.0577545166015625, -0.4492158889770508, 0.0047168731689453125, -5.622472763061523, 0.8837528228759766, 0.7479219436645508, 0.12993621826171875, -4.608329772949219, -0.8788909912109375, 1.6165523529052734, 0.08546829223632812, -0.2058734893798828, -0.3577537536621094, 2.3787240982055664, -0.2010784149169922], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 97280, "num_env_steps_trained": 361200, "num_agent_steps_sampled": 97280, "num_agent_steps_trained": 361200, "last_target_update_ts": 97280, "num_target_updates": 189}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -30.535974375009538, "episode_len_mean": 233.03, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506], "episode_lengths": [229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5660645291649827, "mean_inference_ms": 24.908167047676898, "mean_action_processing_ms": 0.13437001343906718, "mean_env_wait_ms": 4.487012350610252, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -30.535974375009538, "episode_len_mean": 233.03, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [7.36841943114996, -42.87168623507023, -44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506], "episode_lengths": [229, 246, 266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5660645291649827, "mean_inference_ms": 24.908167047676898, "mean_action_processing_ms": 0.13437001343906718, "mean_env_wait_ms": 4.487012350610252, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 97280, "num_agent_steps_trained": 361200, "num_env_steps_sampled": 97280, "num_env_steps_trained": 361200, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 97280, "agent_timesteps_total": 97280, "timers": {"training_iteration_time_ms": 329.352, "learn_time_ms": 69.277, "learn_throughput": 3464.359, "synch_weights_time_ms": 21.189}, "counters": {"num_env_steps_sampled": 97280, "num_env_steps_trained": 361200, "num_agent_steps_sampled": 97280, "num_agent_steps_trained": 361200, "last_target_update_ts": 97280, "num_target_updates": 189}, "done": false, "episodes_total": 365, "training_iteration": 95, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-46", "timestamp": 1655478586, "time_this_iter_s": 5.2126171588897705, "time_total_s": 509.6564667224884, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 509.6564667224884, "timesteps_since_restore": 0, "iterations_since_restore": 95, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 36.025, "ram_util_percent": 64.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 14.563188552856445, "min_q": -12.267790794372559, "max_q": 33.41836929321289, "mean_td_error": -0.004690591711550951}, "td_error": [0.41095924377441406, 0.9314002990722656, -0.9976644515991211, 0.41689109802246094, -0.15891075134277344, -1.8766965866088867, 0.08515739440917969, -0.20115089416503906, 1.7565841674804688, 0.30042076110839844, -0.12595176696777344, -0.8544178009033203, 1.285989761352539, 4.252101898193359, -0.3437671661376953, -0.07745361328125, 0.08801555633544922, 0.39046382904052734, -0.23164939880371094, 0.2218475341796875, 0.10437202453613281, -17.627519607543945, 0.1907501220703125, -0.31250953674316406, 0.1409740447998047, -0.36071205139160156, 10.883647918701172, -1.4424972534179688, 0.26477813720703125, -0.9503822326660156, 0.1982860565185547, -0.7308025360107422, -0.5522565841674805, -0.08160781860351562, -0.05387401580810547, 0.9799175262451172, -0.2803926467895508, -0.0855255126953125, -0.20291996002197266, -0.685943603515625, -0.186553955078125, 0.7311553955078125, 0.3114156723022461, -0.8040704727172852, -0.6727790832519531, -0.4358043670654297, -0.5537681579589844, 0.3924903869628906, 0.34696006774902344, 0.06102561950683594, -4.304960250854492, 1.081319808959961, 0.09687232971191406, -0.26059627532958984, 0.5106449127197266, -1.7666330337524414, -0.2726707458496094, -1.7529850006103516, 0.23654556274414062, 0.22330284118652344, 10.883647918701172, 0.6732997894287109, 0.01245880126953125, 0.7737770080566406, -0.6691341400146484, 0.47236061096191406, 0.40679359436035156, -0.4045443534851074, -0.22701358795166016, 10.537384033203125, -2.418287754058838, 0.4647026062011719, 14.459956169128418, 0.1700115203857422, 0.5962505340576172, -0.6249666213989258, -17.82685089111328, -0.5532798767089844, 0.042308807373046875, -1.3846855163574219, -0.855919361114502, 1.1677746772766113, 1.2703018188476562, 0.3435831069946289, -0.4498157501220703, 0.1131887435913086, 3.9505910873413086, -0.05139350891113281, -6.132437705993652, -5.794168472290039, -0.5137042999267578, 0.19919967651367188, 15.570039749145508, -0.1416616439819336, -0.028772354125976562, 0.6029453277587891, -0.2540302276611328, 0.2761211395263672, 0.07886886596679688, -1.166046142578125, 1.0052261352539062, 0.33485281467437744, -0.01904296875, 0.24023056030273438, 0.1934795379638672, 1.4332218170166016, -0.16737842559814453, -0.9430675506591797, 1.240152359008789, -0.9275074005126953, 0.5617256164550781, -0.5457887649536133, -0.4420442581176758, 1.2011661529541016, 0.2640218734741211, 0.4166841506958008, 0.7004871368408203, 0.34165191650390625, -4.241106033325195, -0.7986412048339844, -0.41237878799438477, 0.2937889099121094, -0.552882194519043, -0.4916572570800781, 0.02288055419921875, -1.1830997467041016, -0.06254768371582031, -9.616266250610352, -0.24953365325927734, -0.7326846122741699, 0.16469573974609375, -0.11912918090820312, 0.15282440185546875, 0.51458740234375, 0.09177589416503906, 0.3692760467529297, 0.2490692138671875, -0.3963146209716797, -0.32178592681884766, 2.8825759887695312, 0.5805087089538574, 0.05382347106933594, -0.2843303680419922, -0.17704486846923828, 0.904799222946167, 0.5299868583679199, 0.18793773651123047, 0.3780193328857422, -0.5128698348999023, 0.36765480041503906, -5.0078277587890625, -0.27309608459472656, 0.18595314025878906, -0.8301181793212891, -1.320424199104309, -0.6060161590576172, -0.14102745056152344, -0.3361072540283203, -0.19804000854492188, 0.00893402099609375, 10.015013694763184, 0.014513015747070312, -0.6503944396972656, -0.7797336578369141, -0.6365137100219727, -0.19058609008789062, 0.16424942016601562, 0.4391489028930664, 0.8612709045410156, 0.7833805084228516, -0.1294708251953125, 0.36238670349121094, 2.134300947189331, 2.3542633056640625, 0.23342514038085938, 0.3487873077392578, 0.33905982971191406, 0.00661468505859375, -0.048397064208984375, -1.615429401397705, -0.05797767639160156, 0.5805087089538574, 0.7334518432617188, 0.4550361633300781, 0.49210119247436523, 0.05296134948730469, 1.1026592254638672, -0.45221614837646484, 0.5425319671630859, 0.31583213806152344, 0.0683135986328125, 0.000667572021484375, -0.12185859680175781, -0.8658456802368164, -0.6425061225891113, 0.1957225799560547, 0.2497539520263672, 0.15742874145507812, -0.06574821472167969, 0.32547950744628906, -0.24020767211914062, 0.4448204040527344, -1.589742660522461, -0.5061588287353516, 0.569493293762207, -10.27946662902832, -0.824007511138916, 0.5072917938232422, 0.9509463310241699, -0.3680248260498047, -1.387956976890564, -5.679988861083984, 0.31714439392089844, 0.14586162567138672, -1.403451919555664, 0.31876182556152344, -0.49170780181884766, 0.9300193786621094, 0.10280036926269531, 0.025094985961914062, 2.134300947189331, 0.5376205444335938, 0.23517990112304688, -0.06466102600097656, 0.44918251037597656, 0.9548397064208984, -0.18618297576904297, -0.45922088623046875, 0.1694316864013672, 0.33574485778808594, -1.2907600402832031, 0.2039966583251953, 0.07260322570800781, 0.034229278564453125, 0.2478618621826172, 1.4221925735473633, -0.30630016326904297, 0.14615440368652344, 0.3656044006347656, 0.07878684997558594], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 98304, "num_env_steps_trained": 365040, "num_agent_steps_sampled": 98304, "num_agent_steps_trained": 365040, "last_target_update_ts": 98304, "num_target_updates": 191}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -32.7284069904685, "episode_len_mean": 233.56, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506, 23.527325369417667, -278.27385371923447], "episode_lengths": [266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201, 204, 324]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5666742408224791, "mean_inference_ms": 24.917678232662553, "mean_action_processing_ms": 0.13439910874753422, "mean_env_wait_ms": 4.4921844206440245, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -32.7284069904685, "episode_len_mean": 233.56, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-44.067001171410084, -15.074756629765034, -6.299999870359898, -299.9575631842017, 10.528313666582108, 30.92217344790697, 6.302149653434753, -8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506, 23.527325369417667, -278.27385371923447], "episode_lengths": [266, 217, 224, 341, 213, 202, 215, 233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201, 204, 324]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5666742408224791, "mean_inference_ms": 24.917678232662553, "mean_action_processing_ms": 0.13439910874753422, "mean_env_wait_ms": 4.4921844206440245, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 98304, "num_agent_steps_trained": 365040, "num_env_steps_sampled": 98304, "num_env_steps_trained": 365040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 98304, "agent_timesteps_total": 98304, "timers": {"training_iteration_time_ms": 335.428, "learn_time_ms": 69.556, "learn_throughput": 3450.436, "synch_weights_time_ms": 20.183}, "counters": {"num_env_steps_sampled": 98304, "num_env_steps_trained": 365040, "num_agent_steps_sampled": 98304, "num_agent_steps_trained": 365040, "last_target_update_ts": 98304, "num_target_updates": 191}, "done": false, "episodes_total": 367, "training_iteration": 96, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-52", "timestamp": 1655478592, "time_this_iter_s": 5.442281484603882, "time_total_s": 515.0987482070923, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 515.0987482070923, "timesteps_since_restore": 0, "iterations_since_restore": 96, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.83749999999999, "ram_util_percent": 64.9625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.163572311401367, "min_q": -9.961549758911133, "max_q": 32.13018798828125, "mean_td_error": 0.3278351426124573}, "td_error": [-0.5180788040161133, 0.1072397232055664, 0.042652130126953125, 0.2724342346191406, 0.6898345947265625, 0.2520484924316406, -0.4791126251220703, 0.10429000854492188, 0.2508735656738281, 14.512517929077148, 0.8676776885986328, -0.3692359924316406, -0.2250661849975586, -0.20369338989257812, -5.327188491821289, -0.19427871704101562, -0.30251455307006836, -1.128565788269043, -0.11247062683105469, -1.8713359832763672, 0.049472808837890625, 0.6190147399902344, -0.4780540466308594, -0.9613018035888672, -0.1496896743774414, 0.18410158157348633, 0.1172027587890625, 0.25084877014160156, 0.2759208679199219, 0.3063011169433594, -0.7719440460205078, 4.0587005615234375, -0.3210639953613281, -0.17813682556152344, 0.057857513427734375, -0.6002664566040039, -0.49030113220214844, 0.1409473419189453, -0.06540489196777344, 0.2294759750366211, -0.0889129638671875, 1.288691520690918, -0.9039316177368164, 0.06025505065917969, 0.8668498992919922, -0.24963665008544922, -1.0136899948120117, 0.07810401916503906, -7.999588489532471, -0.353363037109375, -1.2451858520507812, 0.5051727294921875, 1.3902873992919922, -0.35126304626464844, -0.23479843139648438, -2.776287078857422, -0.12931060791015625, 9.356511116027832, -1.2289276123046875, 12.082037925720215, -0.3574686050415039, 1.2384529113769531, -0.14506816864013672, 0.1598949432373047, 21.89872169494629, -0.21187925338745117, 0.23153305053710938, -0.17082977294921875, -1.258173942565918, -0.44987964630126953, 0.04278564453125, 0.6848878860473633, 0.19585037231445312, 0.8417720794677734, 0.14493942260742188, -0.09767723083496094, 0.01082611083984375, 0.913884162902832, -0.6395149230957031, -0.03462409973144531, 0.36267662048339844, 1.0316953659057617, -0.34796714782714844, 0.3996734619140625, 0.058872222900390625, 1.5350513458251953, 1.1617012023925781, -0.7954463958740234, 0.0663604736328125, 1.0502872467041016, -0.5551490783691406, 0.6930465698242188, 0.14926719665527344, -0.37843942642211914, -0.023319244384765625, 0.24859046936035156, 0.2964611053466797, -0.12246894836425781, 1.6824951171875, 0.41637611389160156, 0.4192161560058594, 0.4180431365966797, 0.18469619750976562, -0.10638809204101562, 0.0013751983642578125, -0.18273544311523438, 2.2733144760131836, 1.398092269897461, 0.6298141479492188, -0.04792022705078125, -0.31182861328125, 0.28287220001220703, -0.39453697204589844, 1.0390510559082031, -1.102630615234375, 0.028769493103027344, -0.3897581100463867, -1.0955810546875, 0.02860546112060547, -0.27712440490722656, -0.22826194763183594, -0.1461029052734375, -0.5726785659790039, -0.5406112670898438, -1.1789674758911133, -0.13400280475616455, -0.1673126220703125, -0.28414344787597656, 9.883713722229004, -0.5031635165214539, -0.2098674774169922, -0.200225830078125, -0.13143157958984375, 0.6847038269042969, 0.6032838821411133, -0.31405067443847656, 0.2135143280029297, 0.44229984283447266, 0.018309593200683594, -0.20604324340820312, 11.287735939025879, 0.4605693817138672, -0.797760009765625, 0.3549461364746094, 0.22644805908203125, -0.5333595275878906, 1.9661073684692383, 0.8668498992919922, 0.6725549697875977, 0.044852256774902344, 0.4463329315185547, -0.8547821044921875, 0.20423507690429688, 0.17396926879882812, 0.5138368606567383, -0.09821891784667969, 0.009032726287841797, -0.01830291748046875, 0.4051084518432617, -0.557220458984375, 0.02191162109375, 0.03594779968261719, -0.6848230361938477, 1.046438455581665, -2.417529821395874, -0.30505943298339844, 0.020694732666015625, 0.17813491821289062, -0.13228797912597656, 0.20166397094726562, -0.3740372657775879, 0.46370792388916016, 0.011136054992675781, -0.09732913970947266, -2.3006248474121094, 0.28815460205078125, 0.6940898895263672, -0.4023857116699219, 0.1900196075439453, -0.3707704544067383, -0.22187423706054688, 0.49051856994628906, 0.2755546569824219, 1.1962337493896484, -0.003467559814453125, 3.52276611328125, -0.6272954940795898, 0.16621780395507812, -0.13115501403808594, 0.5803909301757812, -1.0946273803710938, -0.5279951095581055, -0.6132323741912842, -0.03368949890136719, 0.1956777572631836, -0.5284023284912109, -0.01323699951171875, 0.7545146942138672, 0.07018470764160156, 0.7575387954711914, -0.9207735061645508, 1.6149940490722656, 0.8335838317871094, -0.06252861022949219, -0.8199605941772461, -0.47801971435546875, -0.7837123870849609, 0.7682561874389648, -0.5279951095581055, 0.04400920867919922, -0.7030525207519531, 0.06679153442382812, 0.8579883575439453, -0.2081756591796875, -0.12721538543701172, -0.27868175506591797, 0.02846527099609375, 0.3006248474121094, 0.08678436279296875, 0.7822599411010742, 0.6467609405517578, 0.991511344909668, 2.395730972290039, 0.027467727661132812, -0.7950878143310547, -0.4116497039794922, 0.07398223876953125, -0.25830078125, 3.2801475524902344, -0.07633399963378906, -0.41317176818847656, -0.27226877212524414, 0.9499635696411133, -0.3148612976074219, -0.47613525390625, -0.11610031127929688, -0.44396018981933594, -0.44196510314941406, -0.08292102813720703, 1.4421463012695312], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 99328, "num_env_steps_trained": 368880, "num_agent_steps_sampled": 99328, "num_agent_steps_trained": 368880, "last_target_update_ts": 99328, "num_target_updates": 193}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -33.440776860490445, "episode_len_mean": 234.62, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506, 23.527325369417667, -278.27385371923447, -131.14746566861868, 10.699999831616879, -19.87902470678091, -65.18539191037416, -63.84121210873127, -130.505997993052, 10.975421465933323], "episode_lengths": [233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201, 204, 324, 295, 217, 228, 261, 258, 284, 241]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5676614834690477, "mean_inference_ms": 24.93669274110357, "mean_action_processing_ms": 0.13423864101328933, "mean_env_wait_ms": 4.498232229494737, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -33.440776860490445, "episode_len_mean": 234.62, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-8.581986710429192, -26.745184876024723, 16.6725410297513, -156.4446376413107, 11.399999894201756, 14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506, 23.527325369417667, -278.27385371923447, -131.14746566861868, 10.699999831616879, -19.87902470678091, -65.18539191037416, -63.84121210873127, -130.505997993052, 10.975421465933323], "episode_lengths": [233, 262, 234, 310, 185, 216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201, 204, 324, 295, 217, 228, 261, 258, 284, 241]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5676614834690477, "mean_inference_ms": 24.93669274110357, "mean_action_processing_ms": 0.13423864101328933, "mean_env_wait_ms": 4.498232229494737, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 99328, "num_agent_steps_trained": 368880, "num_env_steps_sampled": 99328, "num_env_steps_trained": 368880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 99328, "agent_timesteps_total": 99328, "timers": {"training_iteration_time_ms": 336.02, "learn_time_ms": 70.85, "learn_throughput": 3387.444, "synch_weights_time_ms": 20.988}, "counters": {"num_env_steps_sampled": 99328, "num_env_steps_trained": 368880, "num_agent_steps_sampled": 99328, "num_agent_steps_trained": 368880, "last_target_update_ts": 99328, "num_target_updates": 193}, "done": false, "episodes_total": 374, "training_iteration": 97, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-09-57", "timestamp": 1655478597, "time_this_iter_s": 5.5401647090911865, "time_total_s": 520.6389129161835, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 520.6389129161835, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.6875, "ram_util_percent": 64.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 15.026460647583008, "min_q": -15.49979305267334, "max_q": 30.19432258605957, "mean_td_error": 0.06827966123819351}, "td_error": [-0.34198570251464844, -0.08214759826660156, -0.7911033630371094, -0.3609004020690918, -0.19483566284179688, -0.3141498565673828, 0.061676025390625, -0.11295127868652344, -0.018899917602539062, -0.1951732635498047, 16.926530838012695, -0.45282745361328125, 0.6845016479492188, -0.30037498474121094, 13.334345817565918, -0.8761669993400574, -0.1925058364868164, -0.2813835144042969, 0.1679668426513672, 0.029750823974609375, 0.2332897186279297, -0.15627479553222656, -0.3179664611816406, -9.791769981384277, 0.124542236328125, -0.0638418197631836, 0.3535299301147461, -0.12246227264404297, -0.3685111999511719, 0.34464073181152344, 0.5870256423950195, 0.14889907836914062, -0.18972206115722656, -0.6070919036865234, -0.05881500244140625, 0.3535299301147461, 0.4379730224609375, -1.0533065795898438, -0.4566802978515625, -0.31604957580566406, -0.692234992980957, -0.07926368713378906, -0.2125377655029297, -0.1573648452758789, -0.3884124755859375, 0.34464073181152344, 3.055544853210449, 0.20773696899414062, 0.09397697448730469, 0.7035369873046875, -0.6065235137939453, 0.04722785949707031, -0.1936016082763672, -6.899128437042236, -1.2220191955566406, 0.016679763793945312, -0.811147153377533, 0.2931938171386719, -1.4562854766845703, 0.19960308074951172, -0.10392379760742188, -0.17545366287231445, 0.3767719268798828, -0.9373493194580078, -0.043792724609375, 0.975865364074707, -0.30637407302856445, -0.741452693939209, 0.46534061431884766, -0.6921272277832031, -0.03625917434692383, -0.169403076171875, -0.17012596130371094, 0.8436431884765625, 0.11985588073730469, -1.2775020599365234, -0.21628665924072266, 0.573765754699707, 1.3129968643188477, 0.9703655242919922, 0.4877777099609375, -0.03302001953125, 0.04586601257324219, -0.2931060791015625, -0.05733299255371094, -1.1057639122009277, 0.7872543334960938, -0.537898063659668, -0.5505561828613281, -0.35208702087402344, 9.304423332214355, 0.5181441307067871, 0.2699565887451172, 0.16592025756835938, 0.33234596252441406, 0.12643814086914062, 0.026708602905273438, -0.03939628601074219, -1.2084789276123047, -0.2038402557373047, -0.23951148986816406, -0.03307342529296875, -5.8298139572143555, -0.1909503936767578, -6.634786605834961, -0.09502029418945312, -0.22317790985107422, 1.517324447631836, 0.8691158294677734, 0.4379730224609375, -0.6457691192626953, -0.09009933471679688, -0.01094818115234375, -0.6034946441650391, -0.3787193298339844, 0.027353286743164062, 0.2540264129638672, -0.29653167724609375, 0.2522296905517578, -0.007373809814453125, 0.13869094848632812, -0.8449029922485352, 1.0357332229614258, 0.048806190490722656, -0.22295188903808594, 0.6296520233154297, -0.37634849548339844, -6.766786575317383, 0.1280517578125, 0.9560403823852539, 3.714961051940918, 0.481231689453125, 0.5402355194091797, 0.07351493835449219, -0.37908935546875, -0.0557403564453125, -0.5227851867675781, -0.5071611404418945, -0.9889345169067383, 1.954925537109375, -0.05451774597167969, 0.06656455993652344, 3.5645360946655273, 0.11606168746948242, -0.18399906158447266, -0.08423995971679688, -1.0107221603393555, 0.2673026919364929, 0.18717002868652344, -0.24723243713378906, -0.3141956329345703, 0.3535299301147461, -1.1286430358886719, 0.1948986053466797, -0.0562286376953125, -0.52496337890625, -0.37670040130615234, -0.3009014129638672, -0.6457853317260742, -0.1801013946533203, 0.058788299560546875, -0.9472079277038574, -0.2798032760620117, 0.12631797790527344, -0.2798032760620117, -0.6303424835205078, 7.504021167755127, -0.09355926513671875, 1.1434478759765625, -0.5721826553344727, -0.8449029922485352, -0.5357017517089844, 0.2918357849121094, -0.1551227569580078, -0.2518157958984375, -0.8376607894897461, -0.8978061676025391, 0.6556634902954102, -0.2813873291015625, 0.7676506042480469, 0.3104267120361328, -0.06509971618652344, -4.028509140014648, 0.038135528564453125, 0.02577972412109375, -0.3584880828857422, -0.5081243515014648, -1.5373649597167969, 0.40140724182128906, -0.09715652465820312, -0.3504047393798828, 0.08989906311035156, 19.918773651123047, -0.3018321990966797, -0.04868030548095703, -10.751867294311523, -4.65773868560791, 10.891549110412598, -0.3857231140136719, 0.27686119079589844, -0.15795135498046875, -6.370016098022461, -0.04767799377441406, -0.2311229705810547, 0.31365013122558594, 9.494481086730957, -0.552741289138794, 0.2624197006225586, 0.2798938751220703, -0.7627496719360352, 0.8664340972900391, 0.1391468048095703, 0.012819290161132812, 0.4932565689086914, -1.563389778137207, 0.13344764709472656, 0.004433631896972656, -0.1425619125366211, 0.5821695327758789, 0.4958209991455078, -5.4379777908325195, -0.015422821044921875, -4.94801139831543, -0.3735227584838867, -0.30984973907470703, 13.316521644592285, -0.39690399169921875, 0.10020732879638672, 12.909768104553223, -0.4250316619873047, 0.16378021240234375, -9.897286415100098, -4.17780876159668, -0.03357696533203125, -5.048186302185059, 0.21661376953125, 1.6431856155395508, 0.05206108093261719, -0.17534446716308594, -0.05168724060058594], "custom_metrics": {}, "num_agent_steps_trained": 240}}, "num_env_steps_sampled": 100352, "num_env_steps_trained": 372720, "num_agent_steps_sampled": 100352, "num_agent_steps_trained": 372720, "last_target_update_ts": 100352, "num_target_updates": 195}, "sampler_results": {"episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -32.690092612802985, "episode_len_mean": 234.44, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506, 23.527325369417667, -278.27385371923447, -131.14746566861868, 10.699999831616879, -19.87902470678091, -65.18539191037416, -63.84121210873127, -130.505997993052, 10.975421465933323, -21.173853926360607, 17.013220228254795, -109.90915897488594, 17.038949340581894, 8.399999797344208], "episode_lengths": [216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201, 204, 324, 295, 217, 228, 261, 258, 284, 241, 258, 228, 269, 219, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5678916088360334, "mean_inference_ms": 24.920282293978918, "mean_action_processing_ms": 0.1342717243295266, "mean_env_wait_ms": 4.499461107031732, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 45.54760716855526, "episode_reward_min": -449.335781916976, "episode_reward_mean": -32.690092612802985, "episode_len_mean": 234.44, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [14.27800602465868, 14.16478594392538, 0.8000000491738319, 15.96478596329689, 3.200000122189522, 24.816172190010548, 26.223855525255203, -141.15636587142944, -9.899999968707561, -70.42105733603239, 0.413220077753067, 10.699999786913395, -83.9424699768424, 17.20090265572071, 3.200000010430813, -126.07078342884779, 19.99513454735279, 12.110635422170162, 7.100000098347664, 17.839581191539764, 5.200000137090683, -149.7776365429163, 45.54760716855526, 6.800000086426735, 17.07542109489441, -11.572171971201897, -33.02060602605343, 19.05206447094679, -26.56153643876314, -97.82786174118519, 3.2037349566817284, 19.313220024108887, 11.651904128491879, 25.175421096384525, -31.085391871631145, 17.265688337385654, 25.86255756765604, 19.872541405260563, 16.595261685550213, -12.071686021983624, 17.113220132887363, 0.39999984204769135, -34.45707820355892, -58.68539223074913, 31.121168226003647, 12.010635510087013, 7.600000210106373, 14.437870994210243, 8.300000101327896, -270.44842022657394, 16.975421257317066, -20.089364670217037, -373.0521286651492, -206.90519883483648, 18.029571749269962, -9.900000184774399, 6.200000055134296, -116.46886671334505, 18.117857463657856, 8.200000070035458, -364.31512677669525, -45.54692813754082, 4.299999929964542, 21.865688525140285, -9.376144655048847, 2.6000000089406967, 4.500000074505806, 7.9000000432133675, -362.5904875919223, 20.47542106360197, 12.728313907980919, 13.913219928741455, 4.599999971687794, 27.229026295244694, 17.110635362565517, -449.335781916976, -4.551707535982132, 17.02127081900835, 23.223855517804623, 7.400000140070915, -103.13145438581705, 12.310635603964329, 17.321270994842052, 10.528313897550106, -94.17078359425068, -24.471686251461506, 23.527325369417667, -278.27385371923447, -131.14746566861868, 10.699999831616879, -19.87902470678091, -65.18539191037416, -63.84121210873127, -130.505997993052, 10.975421465933323, -21.173853926360607, 17.013220228254795, -109.90915897488594, 17.038949340581894, 8.399999797344208], "episode_lengths": [216, 202, 214, 225, 221, 215, 207, 291, 208, 269, 214, 233, 253, 211, 223, 268, 242, 223, 186, 214, 227, 274, 234, 220, 238, 253, 239, 213, 249, 285, 243, 220, 196, 213, 254, 226, 221, 216, 203, 223, 216, 223, 252, 223, 205, 219, 212, 195, 213, 327, 185, 222, 339, 314, 186, 246, 226, 254, 226, 198, 355, 250, 226, 201, 255, 204, 216, 193, 325, 180, 200, 233, 178, 223, 200, 356, 253, 208, 202, 226, 292, 210, 214, 198, 264, 201, 204, 324, 295, 217, 228, 261, 258, 284, 241, 258, 228, 269, 219, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5678916088360334, "mean_inference_ms": 24.920282293978918, "mean_action_processing_ms": 0.1342717243295266, "mean_env_wait_ms": 4.499461107031732, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 100352, "num_agent_steps_trained": 372720, "num_env_steps_sampled": 100352, "num_env_steps_trained": 372720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 3840, "timesteps_total": 100352, "agent_timesteps_total": 100352, "timers": {"training_iteration_time_ms": 322.387, "learn_time_ms": 68.19, "learn_throughput": 3519.595, "synch_weights_time_ms": 20.708}, "counters": {"num_env_steps_sampled": 100352, "num_env_steps_trained": 372720, "num_agent_steps_sampled": 100352, "num_agent_steps_trained": 372720, "last_target_update_ts": 100352, "num_target_updates": 195}, "done": true, "episodes_total": 379, "training_iteration": 98, "trial_id": "f0de0_00014", "experiment_id": "1c9227da999a48738afc4e4f1c37729b", "date": "2022-06-17_18-10-03", "timestamp": 1655478603, "time_this_iter_s": 5.343124628067017, "time_total_s": 525.9820375442505, "pid": 59220, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 240, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 240}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 525.9820375442505, "timesteps_since_restore": 0, "iterations_since_restore": 98, "warmup_time": 15.363666296005249, "perf": {"cpu_util_percent": 33.587500000000006, "ram_util_percent": 64.875}}
