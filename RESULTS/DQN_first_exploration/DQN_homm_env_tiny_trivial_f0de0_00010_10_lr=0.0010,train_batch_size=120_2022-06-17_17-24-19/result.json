{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.34022948145866394, "min_q": -1.342602014541626, "max_q": 0.9716531038284302, "mean_td_error": -0.2342984527349472}, "td_error": [-1.4562283754348755, 1.1833481788635254, -0.5462777018547058, 0.521961510181427, 1.7911664247512817, 0.08247983455657959, -0.7642683982849121, -1.01897394657135, -0.25581642985343933, 2.752002716064453, -0.7080788016319275, 1.7536375522613525, -0.8086502552032471, -0.5881012082099915, 0.07405098527669907, 0.05701360106468201, -1.3845012187957764, -10.837843894958496, -1.5847598314285278, -1.7511627674102783, -0.01787559688091278, 1.4435619115829468, -0.24427348375320435, -1.073800802230835, 0.17850327491760254, 1.8561519384384155, -0.5083292722702026, 0.9280509948730469, 1.7084637880325317, 0.6525564193725586, -0.42469722032546997, -0.8760089874267578, 1.7536375522613525, 0.9220831394195557, 1.0562623739242554, -0.9041672945022583, -1.263188123703003, 2.1896812915802, -1.021165370941162, -0.7755848169326782, -0.951421856880188, -0.8086502552032471, 1.1340548992156982, -0.01787559688091278, -1.3920551538467407, 0.016216091811656952, -1.0370715856552124, 0.1363067626953125, 2.3364737033843994, 1.541786789894104, -0.9239476919174194, 1.7530341148376465, -0.26692312955856323, -2.1217260360717773, 0.010319098830223083, 1.6443884372711182, -0.3145456612110138, -0.7259414196014404, -0.4921759068965912, 0.6973825693130493, -0.248995840549469, -0.29542088508605957, -0.4876469373703003, -0.46092894673347473, -0.5844857096672058, -0.9692045450210571, -0.4552308917045593, -0.47950848937034607, -1.1837589740753174, -0.6978708505630493, -1.1384618282318115, -1.4341273307800293, -0.1785743683576584, -0.6844393014907837, 1.2004011869430542, -0.9610477685928345, -0.97008216381073, -0.5419713258743286, 1.6481952667236328, 0.011212959885597229, -0.5293662548065186, -0.7665312886238098, -0.05926355719566345, -0.40489262342453003, 1.5989845991134644, -0.8920404314994812, 1.2948590517044067, 0.7572058439254761, -0.91665118932724, -2.268474578857422, 0.1929660141468048, -0.6781094670295715, -0.6291794776916504, -1.4341273307800293, 1.5108011960983276, -1.162165880203247, -1.0426322221755981, -0.9692045450210571, -0.503437876701355, -1.9497027397155762, -1.397766351699829, -0.05926355719566345, 1.7911664247512817, -0.8342581987380981, -0.8170111775398254, 1.4117660522460938, 1.6419358253479004, -1.4185699224472046, -0.16806161403656006, -0.6995661854743958, 1.2121604681015015, -0.7565274834632874, -0.7766996622085571, 0.013648316264152527, 0.07789090275764465, -0.8230986595153809, -0.2909615635871887, -1.3971540927886963, 1.4787249565124512, -0.8497486114501953], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 1024, "num_env_steps_trained": 120, "num_agent_steps_sampled": 1024, "num_agent_steps_trained": 120, "last_target_update_ts": 1024, "num_target_updates": 1}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 1024, "num_agent_steps_trained": 120, "num_env_steps_sampled": 1024, "num_env_steps_trained": 120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 120, "timesteps_total": 1024, "agent_timesteps_total": 1024, "timers": {"training_iteration_time_ms": 194.307, "learn_time_ms": 83.961, "learn_throughput": 1429.239, "synch_weights_time_ms": 19.989}, "counters": {"num_env_steps_sampled": 1024, "num_env_steps_trained": 120, "num_agent_steps_sampled": 1024, "num_agent_steps_trained": 120, "last_target_update_ts": 1024, "num_target_updates": 1}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-24-51", "timestamp": 1655475891, "time_this_iter_s": 3.191478967666626, "time_total_s": 3.191478967666626, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3.191478967666626, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 46.379999999999995, "ram_util_percent": 56.74000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.860834002494812, "min_q": -0.7278345227241516, "max_q": 3.772588014602661, "mean_td_error": -0.254326194524765}, "td_error": [1.1449859142303467, -0.21153020858764648, -0.4532630443572998, -5.20072078704834, 0.6711089611053467, 1.32404625415802, 0.9382386207580566, 1.6564420461654663, -0.9876744747161865, 0.1032717227935791, -1.036531686782837, -0.7741191387176514, 1.7036538124084473, 1.3462921380996704, -0.5798578262329102, -0.6964876651763916, -1.3255035877227783, 1.6595373153686523, -0.41701769828796387, -0.4416128396987915, 1.5769872665405273, -1.4245152473449707, -0.4762091636657715, 1.7036538124084473, -0.8397128582000732, 1.1642903089523315, 0.19721555709838867, -0.8773559331893921, 0.27580857276916504, -0.1444535255432129, 0.8719727993011475, -1.478503704071045, -0.5616028904914856, -1.074114441871643, 0.10124897956848145, 1.5400574207305908, -0.9018205404281616, -0.4330317974090576, -0.982079267501831, -0.6661198139190674, 0.23278295993804932, -1.0803918838500977, 0.86490398645401, 1.2668395042419434, 1.7036538124084473, -1.466749668121338, 0.14358949661254883, -0.8743578195571899, 1.1080633401870728, 1.7036538124084473, -0.7681550979614258, -1.3255035877227783, -0.8141498565673828, -1.1469380855560303, 0.1154778003692627, -0.01498425006866455, 0.86490398645401, -0.45367956161499023, 1.3278138637542725, -1.0159862041473389, 1.3130024671554565, 0.0397799015045166, 1.126969575881958, 1.6564420461654663, -0.6565184593200684, 0.5521470308303833, -0.21027636528015137, 1.1283565759658813, 0.4078407287597656, -0.7019996643066406, 0.8256831169128418, -0.7523245811462402, 0.9160637259483337, -0.5556561946868896, -0.7659754753112793, 0.7467184066772461, -0.8848659992218018, -0.1742922067642212, 0.86490398645401, -0.9014118909835815, 0.46315598487854004, -0.28837382793426514, -0.9853174686431885, -0.8900144100189209, -1.1963138580322266, -0.007995247840881348, -1.671424388885498, -0.799447774887085, 0.2031416893005371, -10.61998176574707, -1.9953594207763672, 1.2875218391418457, -0.8199524879455566, -0.7254295349121094, 0.2613559365272522, -2.7733569145202637, 1.0009644031524658, 0.2992666959762573, -0.8702871799468994, 0.2638418674468994, -1.0728003978729248, -1.6734790802001953, -1.3244600296020508, -0.7312355041503906, -0.12635326385498047, -0.2529275417327881, 1.1521886587142944, 1.9154236316680908, -0.28005242347717285, -0.5119340419769287, -0.43154382705688477, -0.7760143280029297, -0.40103840827941895, -2.190654754638672, -1.071692705154419, -1.5553135871887207, -0.7099618911743164, -0.2021350860595703, 0.022619247436523438, -0.7741191387176514], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 2048, "num_env_steps_trained": 2040, "num_agent_steps_sampled": 2048, "num_agent_steps_trained": 2040, "last_target_update_ts": 2048, "num_target_updates": 3}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 2048, "num_agent_steps_trained": 2040, "num_env_steps_sampled": 2048, "num_env_steps_trained": 2040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 2048, "agent_timesteps_total": 2048, "timers": {"training_iteration_time_ms": 335.648, "learn_time_ms": 54.073, "learn_throughput": 2219.225, "synch_weights_time_ms": 19.387}, "counters": {"num_env_steps_sampled": 2048, "num_env_steps_trained": 2040, "num_agent_steps_sampled": 2048, "num_agent_steps_trained": 2040, "last_target_update_ts": 2048, "num_target_updates": 3}, "done": false, "episodes_total": 0, "training_iteration": 2, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-24-56", "timestamp": 1655475896, "time_this_iter_s": 5.2339088916778564, "time_total_s": 8.425387859344482, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 8.425387859344482, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 35.3, "ram_util_percent": 56.9}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.9710519313812256, "min_q": 0.03315460681915283, "max_q": 4.495803356170654, "mean_td_error": 0.28162941336631775}, "td_error": [1.9023127555847168, -0.8315114974975586, 1.378117561340332, 1.7681093215942383, 1.6244699954986572, 1.8874070644378662, 1.3249847888946533, -0.3009803295135498, 2.3409271240234375, -0.19686579704284668, 0.19531464576721191, 2.0799217224121094, 2.804710626602173, 0.6421821117401123, 0.0038678646087646484, -0.24381351470947266, 0.12232208251953125, -0.09224557876586914, -0.11562204360961914, 1.332948923110962, 0.1294841766357422, 1.6147217750549316, 1.5958032608032227, -1.8159189224243164, 0.34173059463500977, 0.544440507888794, 2.130342960357666, 0.7085082530975342, -0.10971760749816895, 2.488532304763794, -5.233184337615967, 0.3341999053955078, 2.2701337337493896, -6.148382186889648, 0.32135009765625, 0.12161469459533691, -0.47243428230285645, 0.7905673980712891, 0.3189072608947754, -0.1644294261932373, -0.10657238960266113, -0.9662494659423828, -0.37226128578186035, 0.26238346099853516, 0.02929973602294922, -0.42185497283935547, 0.15958428382873535, 2.5321273803710938, -0.8091363906860352, -10.262205123901367, 0.7565019130706787, -0.03628706932067871, -0.4046134948730469, 1.568925142288208, -0.9098193645477295, 2.322962522506714, 0.5334327220916748, -1.1979162693023682, 0.46947354078292847, 0.005043506622314453, 0.3237771987915039, -10.548398971557617, 2.902998208999634, -0.21665620803833008, 2.1150965690612793, 0.04984712600708008, -0.2104032039642334, 2.102086305618286, 0.8608365058898926, -0.23058748245239258, 1.6426422595977783, -0.5971834659576416, 2.2942240238189697, 0.3418402671813965, 2.2733840942382812, 1.8767073154449463, -4.696340560913086, 1.6897969245910645, 0.4924628734588623, 2.2330710887908936, 0.5332539081573486, -0.26964712142944336, 1.1772253513336182, -0.04476022720336914, 0.346710205078125, -0.2436213493347168, 2.760152578353882, 0.7241966724395752, 0.18374896049499512, 0.8355269432067871, 0.40352773666381836, 2.0397191047668457, -0.32190990447998047, 2.2591466903686523, 1.9239187240600586, 0.5243401527404785, -0.06700706481933594, 0.20437097549438477, 2.1749401092529297, -0.04115605354309082, -0.1059119701385498, 0.30939722061157227, -1.049581527709961, 1.9405803680419922, 0.318833589553833, -0.6081924438476562, -0.4322376251220703, -0.13596534729003906, -0.03656363487243652, 0.048172712326049805, 0.178358793258667, -0.15668535232543945, 0.34688687324523926, -0.5731058120727539, 1.6305805444717407, -0.3127410411834717, -0.7645626068115234, 1.7321453094482422, -1.0287797451019287, 2.147381067276001], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 3072, "num_env_steps_trained": 3960, "num_agent_steps_sampled": 3072, "num_agent_steps_trained": 3960, "last_target_update_ts": 3072, "num_target_updates": 5}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 3072, "num_agent_steps_trained": 3960, "num_env_steps_sampled": 3072, "num_env_steps_trained": 3960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 3072, "agent_timesteps_total": 3072, "timers": {"training_iteration_time_ms": 283.401, "learn_time_ms": 54.413, "learn_throughput": 2205.367, "synch_weights_time_ms": 19.389}, "counters": {"num_env_steps_sampled": 3072, "num_env_steps_trained": 3960, "num_agent_steps_sampled": 3072, "num_agent_steps_trained": 3960, "last_target_update_ts": 3072, "num_target_updates": 5}, "done": false, "episodes_total": 0, "training_iteration": 3, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-01", "timestamp": 1655475901, "time_this_iter_s": 4.4592390060424805, "time_total_s": 12.884626865386963, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 12.884626865386963, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 42.36666666666667, "ram_util_percent": 57.099999999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.517711877822876, "min_q": 1.10770845413208, "max_q": 5.374839782714844, "mean_td_error": 0.0028465627692639828}, "td_error": [1.8647737503051758, -9.808127403259277, -0.5471868515014648, 0.2020854949951172, -0.36832571029663086, -1.8306047916412354, 1.4112236499786377, -11.00804328918457, -0.4110841751098633, 1.894791841506958, 0.029169321060180664, 1.3862955570220947, -0.9076473712921143, 1.7174491882324219, 1.3703360557556152, -0.6765913963317871, 0.3188748359680176, -0.23540163040161133, -0.10087966918945312, -0.8759305477142334, -0.2273273468017578, 0.03232121467590332, -1.0323774814605713, -0.6561975479125977, -0.355501651763916, 0.08750557899475098, 1.9571096897125244, -0.4582502841949463, 0.8340871334075928, 2.1057939529418945, -0.05871295928955078, -0.4798588752746582, -0.12895703315734863, -0.12061476707458496, -1.0603411197662354, -0.05083012580871582, -0.472088098526001, -0.03769659996032715, 1.364013433456421, -0.35100436210632324, -0.09548664093017578, -0.23117637634277344, -0.24560022354125977, -0.2621030807495117, -0.6343340873718262, 2.451347827911377, -0.039617061614990234, 1.5867969989776611, -0.39204907417297363, -0.9841313362121582, -11.00804328918457, 0.5316071510314941, 1.9018192291259766, 1.463649034500122, -0.057245731353759766, 1.4831438064575195, 0.13833332061767578, 1.9633736610412598, -0.3031129837036133, -0.17741727828979492, 1.5739314556121826, -0.5218863487243652, 2.0111846923828125, 1.8695967197418213, 1.76253080368042, 2.000387668609619, -0.7317428588867188, -0.45758724212646484, -1.1630935668945312, -0.24565696716308594, 1.4468066692352295, 0.13833284378051758, 1.694890022277832, -6.553339958190918, -1.04447340965271, 0.062098026275634766, -0.5026307106018066, -0.21114492416381836, -0.3481132984161377, -0.14706850051879883, 0.5242688655853271, -0.08258652687072754, -0.2123563289642334, 1.6525473594665527, 2.4770870208740234, 0.856236457824707, -0.24840688705444336, 2.0567867755889893, 2.2499537467956543, -0.6545534133911133, 1.6738643646240234, 0.02197432518005371, -0.35100436210632324, -0.23524188995361328, 0.11037921905517578, -0.278933048248291, -0.06709957122802734, -0.18947696685791016, -0.34259653091430664, -0.014087438583374023, -0.518944263458252, -0.24668264389038086, 1.570474624633789, -0.15807199478149414, 1.5739314556121826, -0.37522101402282715, 1.4629225730895996, -0.1548786163330078, -0.45731353759765625, -0.9025871753692627, 1.2317461967468262, 1.1697158813476562, -1.084235668182373, 1.8007681369781494, -0.3959178924560547, 1.1129987239837646, -0.10205388069152832, 2.132935047149658, 1.6978659629821777, -0.0016434192657470703], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 4096, "num_env_steps_trained": 5880, "num_agent_steps_sampled": 4096, "num_agent_steps_trained": 5880, "last_target_update_ts": 4096, "num_target_updates": 7}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -63.603835731744766, "episode_reward_mean": -40.437284809847675, "episode_len_mean": 241.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564], "episode_lengths": [250, 249, 217, 241, 249, 240]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.61708572773618, "mean_inference_ms": 22.465239857575927, "mean_action_processing_ms": 0.14453778471000464, "mean_env_wait_ms": 5.532370003280936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -63.603835731744766, "episode_reward_mean": -40.437284809847675, "episode_len_mean": 241.0, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564], "episode_lengths": [250, 249, 217, 241, 249, 240]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.61708572773618, "mean_inference_ms": 22.465239857575927, "mean_action_processing_ms": 0.14453778471000464, "mean_env_wait_ms": 5.532370003280936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 4096, "num_agent_steps_trained": 5880, "num_env_steps_sampled": 4096, "num_env_steps_trained": 5880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 4096, "agent_timesteps_total": 4096, "timers": {"training_iteration_time_ms": 313.449, "learn_time_ms": 54.072, "learn_throughput": 2219.244, "synch_weights_time_ms": 19.689}, "counters": {"num_env_steps_sampled": 4096, "num_env_steps_trained": 5880, "num_agent_steps_sampled": 4096, "num_agent_steps_trained": 5880, "last_target_update_ts": 4096, "num_target_updates": 7}, "done": false, "episodes_total": 6, "training_iteration": 4, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-05", "timestamp": 1655475905, "time_this_iter_s": 4.875588893890381, "time_total_s": 17.760215759277344, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 17.760215759277344, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.657142857142855, "ram_util_percent": 57.285714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.8759162425994873, "min_q": 1.772926926612854, "max_q": 6.664933681488037, "mean_td_error": 0.11728934943675995}, "td_error": [-0.7743659019470215, -1.065077304840088, 0.0816659927368164, 0.6673067808151245, -0.017481327056884766, -0.08962821960449219, -0.01462697982788086, -0.42539405822753906, 1.0405993461608887, 0.41262292861938477, 1.3096907138824463, -0.10644817352294922, -1.1795029640197754, 1.4523260593414307, 2.300601005554199, -0.7769951820373535, 0.08835792541503906, -1.1776964664459229, -0.4482145309448242, -0.09430265426635742, -0.10484027862548828, 1.9514645338058472, -0.5064160823822021, -0.9592692852020264, 0.03675079345703125, -0.03832054138183594, 4.387081623077393, 0.24096202850341797, 1.525747299194336, 0.08162307739257812, -0.8289999961853027, 2.1848974227905273, -1.2237110137939453, -0.8829655647277832, 2.249203681945801, 1.4531633853912354, 1.594883918762207, 0.06773591041564941, 1.989754557609558, 2.274111747741699, 2.1848974227905273, -0.387453556060791, 2.48006534576416, -0.14780163764953613, -0.06811714172363281, 1.6462204456329346, 1.0811090469360352, -0.06199169158935547, -0.8542110919952393, -2.0404815673828125, -0.03677535057067871, 0.07834649085998535, 2.293806552886963, 2.3926138877868652, -0.15271949768066406, 2.2667059898376465, 1.144165277481079, 2.0626087188720703, -0.8852462768554688, -0.5347459316253662, -0.7088809013366699, 0.3451418876647949, -0.31429362297058105, 0.0008840560913085938, 0.4857306480407715, 1.6799144744873047, -0.46761631965637207, -1.4583146572113037, 2.0907068252563477, -6.774193286895752, 0.6375589370727539, 0.3087038993835449, 1.6646971702575684, 1.563441276550293, 0.4112415313720703, -0.9708857536315918, -4.594219207763672, 1.5907468795776367, 0.927178144454956, 0.15085268020629883, -0.26822471618652344, 1.4313428401947021, 1.8761770725250244, 0.16950511932373047, 1.2056355476379395, 1.3610241413116455, -0.34263181686401367, 0.07971858978271484, -0.09692096710205078, -10.593894004821777, -0.12545180320739746, -0.34427571296691895, 1.9838662147521973, 0.0959930419921875, -0.15271949768066406, -1.0767974853515625, 1.1700191497802734, -0.31611108779907227, -0.3886575698852539, 0.07332277297973633, -0.44513416290283203, -6.712201118469238, -0.05689501762390137, -0.9222688674926758, -0.0721888542175293, -0.3709220886230469, 1.3398892879486084, -6.7490234375, -0.1470165252685547, -0.14132285118103027, -0.8215503692626953, 2.0002388954162598, 0.07971858978271484, -0.2203059196472168, 1.2105538845062256, 1.8297865390777588, 1.6470084190368652, 0.9064536094665527, -0.46580004692077637, 0.7390973567962646], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 5120, "num_env_steps_trained": 7800, "num_agent_steps_sampled": 5120, "num_agent_steps_trained": 7800, "last_target_update_ts": 5120, "num_target_updates": 9}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.66434529889375, "episode_len_mean": 261.3125, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.545888077632276, "mean_inference_ms": 22.55088111469988, "mean_action_processing_ms": 0.14177579360249443, "mean_env_wait_ms": 5.273399489855684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.66434529889375, "episode_len_mean": 261.3125, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.545888077632276, "mean_inference_ms": 22.55088111469988, "mean_action_processing_ms": 0.14177579360249443, "mean_env_wait_ms": 5.273399489855684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 5120, "num_agent_steps_trained": 7800, "num_env_steps_sampled": 5120, "num_env_steps_trained": 7800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 5120, "agent_timesteps_total": 5120, "timers": {"training_iteration_time_ms": 270.371, "learn_time_ms": 54.076, "learn_throughput": 2219.095, "synch_weights_time_ms": 19.788}, "counters": {"num_env_steps_sampled": 5120, "num_env_steps_trained": 7800, "num_agent_steps_sampled": 5120, "num_agent_steps_trained": 7800, "last_target_update_ts": 5120, "num_target_updates": 9}, "done": false, "episodes_total": 16, "training_iteration": 5, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-10", "timestamp": 1655475910, "time_this_iter_s": 4.746731758117676, "time_total_s": 22.50694751739502, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 22.50694751739502, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.18571428571429, "ram_util_percent": 57.47142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.5114104747772217, "min_q": 0.4628015160560608, "max_q": 6.778746604919434, "mean_td_error": -0.27112090587615967}, "td_error": [-0.13086819648742676, -0.6504471302032471, 0.874605655670166, 1.2950439453125, -0.019564151763916016, -5.967526435852051, -1.1929545402526855, -0.6337547302246094, 1.303095817565918, 1.0770342350006104, -0.3689274787902832, 1.7221708297729492, -0.38593554496765137, 1.1927964687347412, 1.1226611137390137, 0.2642393708229065, -0.5221962928771973, -1.5461567640304565, -0.4614686965942383, -0.8928053379058838, 1.3513212203979492, 1.9386959075927734, 0.2005302906036377, -0.5900130271911621, 0.8994119167327881, -5.800833702087402, -4.393238067626953, -0.28110361099243164, -1.0001899003982544, 1.7276372909545898, -0.27812719345092773, 4.119635105133057, 1.1682672500610352, 1.493027687072754, 1.3559675216674805, -0.41532087326049805, 0.08938312530517578, -0.45551061630249023, -0.5639517307281494, -0.7198514938354492, -0.604759693145752, -0.6801223754882812, 0.030850887298583984, 0.0019345283508300781, -1.011784553527832, -5.081066608428955, -1.2579991817474365, -6.305371284484863, -0.43475770950317383, -1.0958900451660156, -1.5056483745574951, 1.4741965532302856, 1.5855388641357422, -0.5716485977172852, -0.4070315361022949, 1.324570655822754, 1.2510437965393066, 0.5806900262832642, 0.5653146505355835, 1.8103971481323242, -4.7576422691345215, 1.4170475006103516, 1.7470359802246094, 0.0956273078918457, 2.1324219703674316, -0.8523521423339844, 0.9337450265884399, 1.1104588508605957, -0.04250192642211914, -0.6610078811645508, -1.056480884552002, 1.585885763168335, 1.276899814605713, -1.0089850425720215, -1.1124200820922852, -1.1717181205749512, -0.7515256404876709, -0.7700333595275879, 1.5401909351348877, -0.7326877117156982, 1.7507429122924805, -0.16559553146362305, -0.6702022552490234, -0.7152845859527588, -0.9675335884094238, -6.367852687835693, -1.2180733680725098, 1.0902843475341797, -1.4295389652252197, 1.8230621814727783, -0.10806798934936523, 0.08993291854858398, -1.2770187854766846, -0.9573841094970703, 1.2198543548583984, 0.09947776794433594, 0.9207746982574463, -0.2117772102355957, 0.07060050964355469, -1.7164011001586914, -0.4201195240020752, -0.9051129817962646, -0.23052549362182617, 1.9032442569732666, 1.6727957725524902, -1.3595314025878906, -0.1422719955444336, -0.9794692993164062, -0.5553464889526367, -0.4017646312713623, -0.5900130271911621, -1.1151142120361328, -1.0508649349212646, -0.18903112411499023, -1.2648944854736328, -1.4802961349487305, -0.6570413112640381, -0.05975770950317383, 0.1662158966064453, -0.6508035659790039], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 6144, "num_env_steps_trained": 9720, "num_agent_steps_sampled": 6144, "num_agent_steps_trained": 9720, "last_target_update_ts": 6144, "num_target_updates": 11}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.66434529889375, "episode_len_mean": 261.3125, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.545888077632276, "mean_inference_ms": 22.55088111469988, "mean_action_processing_ms": 0.14177579360249443, "mean_env_wait_ms": 5.273399489855684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.66434529889375, "episode_len_mean": 261.3125, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.545888077632276, "mean_inference_ms": 22.55088111469988, "mean_action_processing_ms": 0.14177579360249443, "mean_env_wait_ms": 5.273399489855684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 6144, "num_agent_steps_trained": 9720, "num_env_steps_sampled": 6144, "num_env_steps_trained": 9720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 6144, "agent_timesteps_total": 6144, "timers": {"training_iteration_time_ms": 267.927, "learn_time_ms": 53.831, "learn_throughput": 2229.197, "synch_weights_time_ms": 19.49}, "counters": {"num_env_steps_sampled": 6144, "num_env_steps_trained": 9720, "num_agent_steps_sampled": 6144, "num_agent_steps_trained": 9720, "last_target_update_ts": 6144, "num_target_updates": 11}, "done": false, "episodes_total": 16, "training_iteration": 6, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-15", "timestamp": 1655475915, "time_this_iter_s": 4.179442405700684, "time_total_s": 26.686389923095703, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 26.686389923095703, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.316666666666666, "ram_util_percent": 57.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.436769723892212, "min_q": 0.10861988365650177, "max_q": 9.61943244934082, "mean_td_error": -0.2617315649986267}, "td_error": [0.9906216859817505, 0.020044803619384766, -0.1669597625732422, 2.0280866622924805, -1.472083568572998, 1.7103300094604492, -0.5523467063903809, -0.8457386493682861, -7.167018890380859, -0.6708636283874512, -6.159427642822266, -5.5343546867370605, 0.9588313102722168, -7.109360694885254, -0.6656491756439209, -0.849761962890625, -0.8248863220214844, 0.28204822540283203, -0.5457501411437988, 0.4458986520767212, 1.7784786224365234, 0.533348560333252, 2.0538387298583984, 3.1416001319885254, -5.267583847045898, 0.23863554000854492, 0.28937292098999023, -1.1575623750686646, -0.4818692207336426, 0.6955339908599854, 0.9476344585418701, -11.884031295776367, 0.1633014678955078, 0.41059350967407227, -5.023422718048096, 1.4237481355667114, 0.6691689491271973, 0.9865696430206299, -0.41678786277770996, 0.7000958919525146, 0.9167671203613281, -0.29011011123657227, 0.06181955337524414, 0.9461183547973633, -0.3580322265625, 1.2586650848388672, 1.3935794830322266, 0.9200336933135986, -1.7651081085205078, -0.7013921737670898, 1.2589982748031616, -0.9593853950500488, 1.665486454963684, 0.9658397436141968, 1.0472996234893799, 0.8027451038360596, 1.9070115089416504, -0.12659859657287598, 1.0992867946624756, 0.08130598068237305, 2.5902135372161865, 2.6045265197753906, -0.18488645553588867, 1.9640040397644043, 0.6463291645050049, -0.8248863220214844, 1.7278209924697876, -1.0714232921600342, -1.277396559715271, -1.1518962383270264, 0.4688127040863037, 0.10624432563781738, -1.272073745727539, 0.7920153141021729, 0.7043464183807373, -0.8058891296386719, -0.2314763069152832, -1.7962756156921387, -1.284659504890442, -0.6609382629394531, -0.9835469722747803, 0.726067304611206, -0.24422836303710938, -4.146611213684082, 1.8940868377685547, -1.0957112312316895, 1.0625486373901367, -0.2806377410888672, -0.6478209495544434, 0.3971555233001709, 0.9303364753723145, -1.5768755674362183, 0.5087282657623291, 2.5902135372161865, -1.1973011493682861, 1.0211975574493408, -1.1958017349243164, 0.5892128944396973, -0.8400485515594482, 1.8596100807189941, -0.4682135581970215, -1.3389289379119873, -1.2077085971832275, 1.2684924602508545, -0.49847960472106934, -0.23688364028930664, 0.6463291645050049, -1.0121301412582397, -0.7355005741119385, 0.4298405647277832, -0.05686759948730469, 0.8807978630065918, -1.539840579032898, -1.2013444900512695, -0.45519447326660156, -1.4373352527618408, 1.1497735977172852, 0.6913859844207764, 0.26010942459106445, -0.755824089050293], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 7168, "num_env_steps_trained": 11640, "num_agent_steps_sampled": 7168, "num_agent_steps_trained": 11640, "last_target_update_ts": 7168, "num_target_updates": 13}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.66434529889375, "episode_len_mean": 261.3125, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.545888077632276, "mean_inference_ms": 22.55088111469988, "mean_action_processing_ms": 0.14177579360249443, "mean_env_wait_ms": 5.273399489855684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.66434529889375, "episode_len_mean": 261.3125, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.545888077632276, "mean_inference_ms": 22.55088111469988, "mean_action_processing_ms": 0.14177579360249443, "mean_env_wait_ms": 5.273399489855684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 7168, "num_agent_steps_trained": 11640, "num_env_steps_sampled": 7168, "num_env_steps_trained": 11640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 7168, "agent_timesteps_total": 7168, "timers": {"training_iteration_time_ms": 282.465, "learn_time_ms": 55.275, "learn_throughput": 2170.976, "synch_weights_time_ms": 20.089}, "counters": {"num_env_steps_sampled": 7168, "num_env_steps_trained": 11640, "num_agent_steps_sampled": 7168, "num_agent_steps_trained": 11640, "last_target_update_ts": 7168, "num_target_updates": 13}, "done": false, "episodes_total": 16, "training_iteration": 7, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-19", "timestamp": 1655475919, "time_this_iter_s": 4.493855714797974, "time_total_s": 31.180245637893677, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 31.180245637893677, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 42.016666666666666, "ram_util_percent": 57.68333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.2799088954925537, "min_q": -1.5887081623077393, "max_q": 9.94626522064209, "mean_td_error": -0.12469599395990372}, "td_error": [-1.2333462238311768, 2.7416090965270996, 1.907923698425293, -0.2240443229675293, 0.2654540538787842, 1.4343914985656738, -0.9921634197235107, -0.32114171981811523, 0.13534021377563477, 0.7875635623931885, -0.1788942813873291, 1.8174115419387817, -0.7303500175476074, 1.61256742477417, -0.5771908760070801, 1.4373550415039062, 1.9852313995361328, 1.0838196277618408, 2.910034656524658, 1.2472577095031738, 2.1452081203460693, 1.4944195747375488, 2.197094202041626, 1.8370656967163086, -5.170141220092773, -0.922182559967041, 2.2568068504333496, 0.8782293796539307, -0.42506206035614014, 0.30608224868774414, 0.8371748924255371, -0.021836280822753906, -0.6530337333679199, -0.20290422439575195, -10.75224494934082, -10.247291564941406, -4.953376293182373, -0.7086359262466431, -0.2302536964416504, 1.1029763221740723, 2.0323987007141113, 0.4141199588775635, -0.4023113250732422, 1.4681644439697266, 1.6322221755981445, 0.17552852630615234, -1.4524385929107666, -0.8839317560195923, 0.5081784725189209, -0.9590401649475098, -1.3983724117279053, -0.1661977767944336, -0.9262111186981201, 1.7793705463409424, -4.910686492919922, -1.4182276725769043, 0.3289799690246582, 2.2310574054718018, 1.0838196277618408, 0.7335479259490967, 0.6353497505187988, 1.4210641384124756, 1.6624560356140137, 0.8067888617515564, 0.13733720779418945, 1.3630050420761108, -0.49858617782592773, 1.8352559804916382, 1.6348576545715332, -0.18628931045532227, -11.081624984741211, -1.2624070644378662, 1.784860610961914, 0.3691139221191406, 1.7687007188796997, -0.8079862594604492, -1.1541223526000977, 1.0774095058441162, 1.0902881622314453, 1.1081078052520752, -0.16425704956054688, -0.8746206760406494, -0.4459831714630127, 1.743761420249939, -0.6957132816314697, 1.9233713150024414, 0.6353497505187988, -0.5006840229034424, 0.8205273151397705, 1.3412220478057861, 0.023527145385742188, -0.7754918336868286, -9.784642219543457, -1.468108892440796, 0.6809259653091431, -0.3808422088623047, 0.2625293731689453, 0.18863630294799805, -0.0074721574783325195, 0.13825654983520508, -0.32909321784973145, -0.17116975784301758, 2.0599236488342285, 0.012357711791992188, 0.3076515197753906, -0.7543513774871826, 0.7335479259490967, -6.699158668518066, 1.2761950492858887, -1.5540480613708496, 0.3105916976928711, -0.8245165348052979, 1.037740707397461, 1.3818753957748413, -0.48202961683273315, 2.2879676818847656, -0.38539552688598633, -0.9647512435913086, -0.5566816329956055, 0.2390594482421875], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 8192, "num_env_steps_trained": 13560, "num_agent_steps_sampled": 8192, "num_agent_steps_trained": 13560, "last_target_update_ts": 8192, "num_target_updates": 15}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.02373624636846, "episode_len_mean": 261.5882352941176, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5503345297043817, "mean_inference_ms": 22.51671599496401, "mean_action_processing_ms": 0.1408859860157187, "mean_env_wait_ms": 5.236774737827778, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -76.02373624636846, "episode_len_mean": 261.5882352941176, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5503345297043817, "mean_inference_ms": 22.51671599496401, "mean_action_processing_ms": 0.1408859860157187, "mean_env_wait_ms": 5.236774737827778, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 8192, "num_agent_steps_trained": 13560, "num_env_steps_sampled": 8192, "num_env_steps_trained": 13560, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 8192, "agent_timesteps_total": 8192, "timers": {"training_iteration_time_ms": 276.822, "learn_time_ms": 54.607, "learn_throughput": 2197.527, "synch_weights_time_ms": 19.71}, "counters": {"num_env_steps_sampled": 8192, "num_env_steps_trained": 13560, "num_agent_steps_sampled": 8192, "num_agent_steps_trained": 13560, "last_target_update_ts": 8192, "num_target_updates": 15}, "done": false, "episodes_total": 17, "training_iteration": 8, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-24", "timestamp": 1655475924, "time_this_iter_s": 4.409781455993652, "time_total_s": 35.59002709388733, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 35.59002709388733, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.571428571428577, "ram_util_percent": 57.78571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.9820964336395264, "min_q": -2.810483932495117, "max_q": 10.062623023986816, "mean_td_error": -0.879571259021759}, "td_error": [0.7060571908950806, -2.0157127380371094, 1.7373943328857422, -1.043768286705017, -1.1059149503707886, -0.40529727935791016, -1.0306620597839355, 0.1676788330078125, -0.503089427947998, 0.6094117760658264, -1.4760875701904297, 1.5570683479309082, -1.1891460418701172, -0.5676538944244385, -0.355228066444397, 0.07886731624603271, -0.8516139984130859, -12.107179641723633, -0.6554833650588989, -1.1064505577087402, 1.1838352680206299, -0.649412989616394, 0.026523351669311523, -0.10779476165771484, -1.036165714263916, -6.168626308441162, -1.652358055114746, -0.5676538944244385, -1.3537628650665283, -0.23071765899658203, -1.2003717422485352, 2.0941054821014404, -0.39786577224731445, -0.6217319965362549, -1.387624740600586, 0.1676788330078125, -0.2302779257297516, -6.009847164154053, -0.6380653381347656, 2.5521984100341797, -2.3868093490600586, 0.4042472839355469, 0.7728176116943359, -0.4673648476600647, -0.8293307423591614, -0.8617033958435059, -1.1755948066711426, 1.8503503799438477, 1.3533389568328857, 1.598893165588379, 0.4502229690551758, -0.7931919097900391, -1.6593389511108398, -2.9950995445251465, 0.588076114654541, -1.9920586347579956, -0.04526805877685547, 0.6664164066314697, -9.028185844421387, 1.1691818237304688, 2.522441864013672, -0.35126161575317383, -1.3176519870758057, 0.9282407760620117, 1.0167450904846191, -5.2009124755859375, -7.1871819496154785, -0.9345006942749023, -1.2256546020507812, -5.5179290771484375, -0.053440093994140625, -0.915302038192749, -0.7079950571060181, -0.4650726318359375, 0.4712406396865845, 0.71155846118927, -2.4105684757232666, 0.6956720352172852, 0.6386003494262695, -7.801924705505371, -2.016493558883667, -1.7782117128372192, 0.38276660442352295, 1.362189769744873, -1.6246346235275269, 1.0445951223373413, 0.2846968173980713, -0.8201713562011719, 0.057770729064941406, -10.280902862548828, 0.1679173707962036, 0.2882251739501953, -0.6410541534423828, -1.6463663578033447, -1.1181957721710205, -0.8709579706192017, -1.792305588722229, -0.9030327796936035, 0.18522405624389648, -0.7564783096313477, -1.1059149503707886, 1.3992772102355957, -7.1871819496154785, 2.522441864013672, 1.930616855621338, 0.3581216335296631, 2.378537178039551, -0.7251454591751099, -6.518654823303223, -0.8926072716712952, 0.16716080904006958, -0.23125946521759033, -1.289952278137207, 0.5894575119018555, -0.919957160949707, 1.0227150917053223, 1.4386930465698242, -0.7853571772575378, -0.12132075428962708, -0.832763671875], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 9216, "num_env_steps_trained": 15480, "num_agent_steps_sampled": 9216, "num_agent_steps_trained": 15480, "last_target_update_ts": 9216, "num_target_updates": 17}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -78.78993621634112, "episode_len_mean": 263.8888888888889, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5525773774397646, "mean_inference_ms": 22.552292512240165, "mean_action_processing_ms": 0.14047032450865216, "mean_env_wait_ms": 5.215690010635139, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -134.08634646236897, "episode_reward_mean": -78.78993621634112, "episode_len_mean": 263.8888888888889, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5525773774397646, "mean_inference_ms": 22.552292512240165, "mean_action_processing_ms": 0.14047032450865216, "mean_env_wait_ms": 5.215690010635139, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 9216, "num_agent_steps_trained": 15480, "num_env_steps_sampled": 9216, "num_env_steps_trained": 15480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 9216, "agent_timesteps_total": 9216, "timers": {"training_iteration_time_ms": 303.324, "learn_time_ms": 54.644, "learn_throughput": 2196.043, "synch_weights_time_ms": 19.988}, "counters": {"num_env_steps_sampled": 9216, "num_env_steps_trained": 15480, "num_agent_steps_sampled": 9216, "num_agent_steps_trained": 15480, "last_target_update_ts": 9216, "num_target_updates": 17}, "done": false, "episodes_total": 18, "training_iteration": 9, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-29", "timestamp": 1655475929, "time_this_iter_s": 4.7735230922698975, "time_total_s": 40.36355018615723, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 40.36355018615723, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.042857142857144, "ram_util_percent": 57.94285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.1768944263458252, "min_q": -3.6137757301330566, "max_q": 11.117330551147461, "mean_td_error": -0.8944786190986633}, "td_error": [-1.7097887992858887, 1.0692601203918457, -2.0691919326782227, -1.4399627447128296, 0.30619192123413086, -1.877251148223877, 0.5284311771392822, -1.0628554821014404, 1.3624048233032227, -0.2725090980529785, 0.05667924880981445, -0.312711238861084, -7.892189979553223, 0.3005208969116211, 0.44165050983428955, -0.16811394691467285, 1.252570390701294, 0.4049105644226074, 0.028206586837768555, -0.6628847122192383, -0.120147705078125, -0.7761344909667969, -7.081689357757568, 0.10252130031585693, -7.932225227355957, -0.3212904930114746, 1.2918915748596191, -0.7434284687042236, 1.3094160556793213, -1.0114288330078125, -0.42787647247314453, -1.9075562953948975, -2.039302110671997, 0.24518918991088867, 1.3925714492797852, 1.669672966003418, -1.2445745468139648, -1.113450527191162, -0.28867125511169434, -0.008143901824951172, -1.5843223333358765, -0.245161771774292, -0.026543617248535156, -1.9562854766845703, -0.9356896877288818, -1.4614866971969604, -0.13717126846313477, 0.0427854061126709, 0.34155964851379395, 1.1610519886016846, 0.8745222091674805, -2.0183823108673096, 0.8741402626037598, -0.35787534713745117, -2.1068272590637207, -0.15246987342834473, 0.5260289907455444, 0.28562021255493164, -1.8596093654632568, -8.319530487060547, 1.4441523551940918, -1.9031246900558472, 0.21609210968017578, -1.140241026878357, -6.892285346984863, -0.1664867401123047, 2.0587399005889893, 1.7134814262390137, -1.0657014846801758, -1.0037550926208496, -0.1995530128479004, -0.8813391923904419, -2.5734033584594727, 0.05667924880981445, 1.669672966003418, 0.43698596954345703, -0.1258561611175537, -1.630526065826416, -6.571049690246582, -2.9410929679870605, 0.661851167678833, -8.176102638244629, 0.21609210968017578, -1.6079154014587402, -1.665956974029541, -1.623591661453247, -0.06727361679077148, 0.6794942617416382, 0.7560598850250244, 1.9169692993164062, 0.08065056800842285, -0.9971262812614441, -0.043244361877441406, -2.018770694732666, -0.026543617248535156, 0.3064756393432617, -0.3762168884277344, -1.888713002204895, -0.25956296920776367, -0.9943511486053467, -1.7713751792907715, -0.16668176651000977, -7.152641296386719, -1.4226521253585815, -0.5991926193237305, 0.9191670417785645, -9.129144668579102, -1.247804045677185, 0.7539653778076172, -0.26136016845703125, -0.10818195343017578, -0.28412342071533203, 0.34201669692993164, 0.44165050983428955, 0.5565916895866394, -1.302894115447998, -0.21172338724136353, -1.2532126903533936, -0.9579939842224121, -2.0785179138183594], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 10240, "num_env_steps_trained": 17400, "num_agent_steps_sampled": 10240, "num_agent_steps_trained": 17400, "last_target_update_ts": 10240, "num_target_updates": 19}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -340.5154685154557, "episode_reward_mean": -146.05900655394154, "episode_len_mean": 295.25, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5395626055652327, "mean_inference_ms": 22.514459288978706, "mean_action_processing_ms": 0.14298466131449206, "mean_env_wait_ms": 4.963311118689133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -340.5154685154557, "episode_reward_mean": -146.05900655394154, "episode_len_mean": 295.25, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5395626055652327, "mean_inference_ms": 22.514459288978706, "mean_action_processing_ms": 0.14298466131449206, "mean_env_wait_ms": 4.963311118689133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 10240, "num_agent_steps_trained": 17400, "num_env_steps_sampled": 10240, "num_env_steps_trained": 17400, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 10240, "agent_timesteps_total": 10240, "timers": {"training_iteration_time_ms": 324.093, "learn_time_ms": 54.879, "learn_throughput": 2186.636, "synch_weights_time_ms": 19.632}, "counters": {"num_env_steps_sampled": 10240, "num_env_steps_trained": 17400, "num_agent_steps_sampled": 10240, "num_agent_steps_trained": 17400, "last_target_update_ts": 10240, "num_target_updates": 19}, "done": false, "episodes_total": 28, "training_iteration": 10, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-34", "timestamp": 1655475934, "time_this_iter_s": 5.147430419921875, "time_total_s": 45.5109806060791, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 45.5109806060791, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 26.171428571428574, "ram_util_percent": 58.07142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.5373421907424927, "min_q": -6.851590156555176, "max_q": 12.882041931152344, "mean_td_error": -1.2197245359420776}, "td_error": [-1.2983036041259766, -3.2616372108459473, -0.16586685180664062, -0.28769564628601074, 0.062467217445373535, -2.415904998779297, -0.0013335943222045898, 0.2602100372314453, 0.2750377655029297, 0.07512521743774414, 0.03334832191467285, -2.052004337310791, -1.1917738914489746, -2.5540859699249268, -2.33975887298584, -0.025293827056884766, -1.4380543231964111, -1.5866680145263672, -0.9311201572418213, -1.8266273736953735, -2.35422945022583, -1.4023003578186035, 0.29820823669433594, -1.785693883895874, 0.21055221557617188, -1.831041693687439, -3.102915048599243, -2.62424373626709, -0.7314248085021973, 1.052480697631836, -0.21152734756469727, -1.4725379943847656, -2.308877944946289, -0.9944696426391602, 1.2080802917480469, -0.6106786727905273, -6.685652732849121, 0.14530467987060547, 0.061849117279052734, 0.07479047775268555, -3.0765786170959473, -7.2328715324401855, 0.5498232841491699, 0.02453327178955078, -0.14385175704956055, -0.9550909996032715, -2.9384958744049072, -2.0112364292144775, -1.7028048038482666, -0.6786508560180664, 1.0016193389892578, -0.9714856147766113, -0.718646764755249, -2.565502405166626, -2.957754135131836, 0.1396327018737793, -3.9607596397399902, 1.5077414512634277, -0.5064082145690918, 0.16638875007629395, -1.7445764541625977, -1.2917490005493164, -10.928890228271484, -0.9714856147766113, -0.4510536193847656, -6.803001403808594, -1.3485068082809448, -0.13078725337982178, -0.027837157249450684, -1.1853594779968262, 0.43085190653800964, -3.228877544403076, -2.243300199508667, -0.3793678283691406, -0.20575261116027832, -0.33952903747558594, -2.228855609893799, 0.41210508346557617, -0.08730792999267578, 0.6397517919540405, -2.480254650115967, -3.6085128784179688, -0.30064868927001953, 0.8354029655456543, -2.305668830871582, -3.2322099208831787, -8.336942672729492, -0.833986759185791, -0.2010972499847412, -1.7472648620605469, -0.12756633758544922, 0.18107223510742188, 0.2216295301914215, -0.14911198616027832, -2.6950674057006836, 0.19615650177001953, -1.745835781097412, -3.719877004623413, -5.785898208618164, 3.940368175506592, -1.2616708278656006, 1.3345701694488525, -0.5168731212615967, -0.8088126182556152, 0.2563819885253906, -1.0344278812408447, -2.431698799133301, 0.32754063606262207, 0.4132826328277588, -0.2339329719543457, 0.8050966262817383, -2.421624183654785, -0.30064868927001953, -1.9586414098739624, 0.5722143650054932, -2.3490958213806152, -1.7865543365478516, 1.1012449264526367, 0.16707229614257812, -1.4668526649475098], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 11264, "num_env_steps_trained": 19320, "num_agent_steps_sampled": 11264, "num_agent_steps_trained": 19320, "last_target_update_ts": 11264, "num_target_updates": 21}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 11264, "num_agent_steps_trained": 19320, "num_env_steps_sampled": 11264, "num_env_steps_trained": 19320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 11264, "agent_timesteps_total": 11264, "timers": {"training_iteration_time_ms": 278.187, "learn_time_ms": 54.913, "learn_throughput": 2185.291, "synch_weights_time_ms": 19.569}, "counters": {"num_env_steps_sampled": 11264, "num_env_steps_trained": 19320, "num_agent_steps_sampled": 11264, "num_agent_steps_trained": 19320, "last_target_update_ts": 11264, "num_target_updates": 21}, "done": false, "episodes_total": 32, "training_iteration": 11, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-39", "timestamp": 1655475939, "time_this_iter_s": 4.771549940109253, "time_total_s": 50.282530546188354, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 50.282530546188354, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 35.214285714285715, "ram_util_percent": 58.34285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.25360536575317383, "min_q": -9.285662651062012, "max_q": 14.897254943847656, "mean_td_error": -0.6360055208206177}, "td_error": [1.3106751441955566, 4.2472076416015625, 1.6994619369506836, 2.354710102081299, 0.09250259399414062, -1.3976554870605469, 2.2818474769592285, -1.8135724067687988, 0.29261696338653564, 0.0853586196899414, 1.2365117073059082, -0.33032751083374023, -1.7422418594360352, 1.6660871505737305, 0.21467113494873047, -0.3878974914550781, -0.7469031810760498, -0.11893177032470703, -0.3785698413848877, -7.424183368682861, 0.2110605239868164, -9.274508476257324, -1.0613889694213867, 0.2225809097290039, 1.9719865322113037, -10.882108688354492, 1.6559596061706543, 2.920236110687256, 2.0376784801483154, -0.18433642387390137, -2.984025001525879, 0.04262566566467285, 3.5867221355438232, 1.2058472633361816, 2.5143532752990723, 1.533036708831787, -0.1627950668334961, 2.972011089324951, -6.973660945892334, 1.4845619201660156, -0.6135425567626953, 0.8106637001037598, -1.3976554870605469, -0.7480812072753906, -0.05933189392089844, 0.23119211196899414, -6.938302993774414, 1.6777461767196655, -1.6117470264434814, -1.5297199487686157, -1.9744733572006226, -0.601992130279541, -0.1390368938446045, 0.09511375427246094, 0.6332371234893799, 0.5800185203552246, -9.304203987121582, 0.7109136581420898, 0.5478744506835938, -1.9731464385986328, 0.4500889778137207, -1.2552528381347656, -2.295668601989746, 0.2001495361328125, 0.8592338562011719, -0.07931408286094666, -0.29912662506103516, 2.1500496864318848, 0.04364585876464844, -4.498085021972656, -2.0706686973571777, 0.2604026794433594, -0.4446678161621094, 1.6130353212356567, -1.676196575164795, 0.2110605239868164, 5.225731372833252, -1.577965259552002, -1.1672272682189941, 0.7837648391723633, -8.55766773223877, 2.199641227722168, 1.6924421787261963, -1.49415922164917, -0.011476635932922363, 4.541714191436768, 0.20854711532592773, -1.361036777496338, 0.07381772994995117, -8.790605545043945, -0.21394658088684082, -9.265310287475586, -1.0625319480895996, -1.1301405429840088, -1.588724136352539, 2.0535173416137695, -2.3336849212646484, 0.2604026794433594, 0.7451415061950684, 0.4500889778137207, -2.3059544563293457, 0.15803289413452148, -1.3815734386444092, -0.26198291778564453, 0.1834878921508789, -0.45562267303466797, 0.09250259399414062, -0.18062162399291992, -1.0488123893737793, -0.21846485137939453, 1.2879455089569092, -2.3175830841064453, -0.3691840171813965, -8.932352066040039, -0.8965473175048828, -0.9474687576293945, -1.3976554870605469, 0.7215328216552734, -1.3371191024780273, 0.065030038356781], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 12288, "num_env_steps_trained": 21240, "num_agent_steps_sampled": 12288, "num_agent_steps_trained": 21240, "last_target_update_ts": 12288, "num_target_updates": 23}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 12288, "num_agent_steps_trained": 21240, "num_env_steps_sampled": 12288, "num_env_steps_trained": 21240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 12288, "agent_timesteps_total": 12288, "timers": {"training_iteration_time_ms": 300.515, "learn_time_ms": 55.328, "learn_throughput": 2168.873, "synch_weights_time_ms": 19.794}, "counters": {"num_env_steps_sampled": 12288, "num_env_steps_trained": 21240, "num_agent_steps_sampled": 12288, "num_agent_steps_trained": 21240, "last_target_update_ts": 12288, "num_target_updates": 23}, "done": false, "episodes_total": 32, "training_iteration": 12, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-43", "timestamp": 1655475943, "time_this_iter_s": 4.580780982971191, "time_total_s": 54.863311529159546, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 54.863311529159546, "timesteps_since_restore": 0, "iterations_since_restore": 12, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.05, "ram_util_percent": 58.31666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.027162902057170868, "min_q": -9.896965026855469, "max_q": 16.93846893310547, "mean_td_error": -0.5333125591278076}, "td_error": [1.2353672981262207, -1.2072248458862305, -0.8258061408996582, 2.483525276184082, -2.7017853260040283, 0.6109724044799805, 0.15156030654907227, 0.6819939613342285, 0.006803989410400391, 1.185443639755249, -6.9660563468933105, -0.6061009168624878, -1.5403859615325928, -1.0360615253448486, 1.128605842590332, -0.36452150344848633, -1.6735072135925293, -1.1428074836730957, 0.2515850067138672, -0.2937910556793213, 1.8317866325378418, -0.7884116172790527, 1.4047927856445312, 1.4081106185913086, -0.5562822818756104, 0.18918418884277344, -0.9686281681060791, -1.7051305770874023, 0.2414722442626953, -1.3372907638549805, -6.9559478759765625, -0.8855763077735901, -1.4518275260925293, -0.8979333639144897, -0.7460436820983887, -1.2225990295410156, -1.7049574851989746, 0.4248208999633789, -0.1925063133239746, -1.5063440799713135, -3.274674415588379, -1.5063440799713135, -2.7144761085510254, -0.2456350326538086, -0.7606303691864014, 0.8634473085403442, -0.27689647674560547, 1.6860146522521973, -0.2609424591064453, -0.24123454093933105, 0.9488325119018555, 1.7720532417297363, -0.34016990661621094, -0.22870731353759766, 0.5416507720947266, -2.049649238586426, 0.6647944450378418, -2.449596405029297, 0.7340836524963379, 0.9286398887634277, 1.302556037902832, 0.4869551658630371, -0.41188526153564453, -1.961099624633789, -1.6464378833770752, 0.4124889373779297, -0.6210023164749146, -6.0695109367370605, -0.3425617218017578, -0.1475372314453125, 1.178293228149414, -0.3844442367553711, -0.5056452751159668, 1.5098609924316406, 2.1013388633728027, 0.6107196807861328, 2.1366147994995117, 1.3551397323608398, 0.6134576797485352, -7.754422187805176, -2.3204612731933594, 0.9655482769012451, -2.448289394378662, 0.7218623161315918, 0.5295877456665039, 0.22397804260253906, -1.0587239265441895, -0.6591267585754395, 1.1917119026184082, -10.116127967834473, -0.5830941200256348, -0.6731973886489868, 0.0071468353271484375, 1.9495112895965576, 0.8605518341064453, -1.4497861862182617, 0.8120574951171875, 0.31394100189208984, 0.4118480682373047, -0.2456350326538086, 0.337735652923584, -0.8075838088989258, -0.7669878005981445, 0.6384742259979248, 0.49462223052978516, 0.04257011413574219, -1.1363859176635742, -2.1806254386901855, 0.18918418884277344, 1.0308241844177246, -1.0470428466796875, 0.7951688766479492, 0.11630916595458984, -0.5730619430541992, 0.03935956954956055, -0.5730619430541992, -2.0735387802124023, -6.757625102996826, -0.41780853271484375, 0.6067256927490234], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 13312, "num_env_steps_trained": 23160, "num_agent_steps_sampled": 13312, "num_agent_steps_trained": 23160, "last_target_update_ts": 13312, "num_target_updates": 25}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 13312, "num_agent_steps_trained": 23160, "num_env_steps_sampled": 13312, "num_env_steps_trained": 23160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 13312, "agent_timesteps_total": 13312, "timers": {"training_iteration_time_ms": 287.273, "learn_time_ms": 55.181, "learn_throughput": 2174.645, "synch_weights_time_ms": 19.689}, "counters": {"num_env_steps_sampled": 13312, "num_env_steps_trained": 23160, "num_agent_steps_sampled": 13312, "num_agent_steps_trained": 23160, "last_target_update_ts": 13312, "num_target_updates": 25}, "done": false, "episodes_total": 32, "training_iteration": 13, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-48", "timestamp": 1655475948, "time_this_iter_s": 4.5681235790252686, "time_total_s": 59.431435108184814, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 59.431435108184814, "timesteps_since_restore": 0, "iterations_since_restore": 13, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.57142857142857, "ram_util_percent": 58.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.280907392501831, "min_q": -12.019499778747559, "max_q": 19.06329345703125, "mean_td_error": 0.5552520751953125}, "td_error": [0.5154819488525391, 1.4175784587860107, 0.18181228637695312, -0.9178023338317871, 2.480621814727783, -1.2153120040893555, 0.13752460479736328, 1.74882173538208, -0.3050806522369385, -7.358335971832275, 0.662234902381897, 1.7976617813110352, 0.7759733200073242, 0.35515308380126953, 1.2893177270889282, 0.1510772705078125, 1.1063590049743652, 2.285710334777832, 0.7555456161499023, 1.8571748733520508, -1.3377448320388794, -0.20809483528137207, 1.684664249420166, 0.13752460479736328, 1.4561209678649902, 1.8884010314941406, 1.160560131072998, 2.092877149581909, 2.218750476837158, 2.784273147583008, 3.8808650970458984, 1.309281349182129, -0.34479522705078125, 0.5844240188598633, 1.320542335510254, -0.543938159942627, 1.4464762210845947, 1.2311606407165527, 2.3494484424591064, 0.5233993530273438, 1.7149372100830078, 1.4756970405578613, -1.7928285598754883, 1.106931209564209, 0.12257194519042969, 1.467334508895874, 2.772127151489258, -1.0323669910430908, 0.1663355827331543, 2.000910758972168, 1.887803077697754, 0.8126564025878906, 0.5565557479858398, 1.3111755847930908, 0.18503952026367188, 3.368539333343506, -0.2003312110900879, 0.6369714736938477, 1.3819637298583984, -1.316354751586914, -1.7959785461425781, 0.7785007357597351, 2.2994251251220703, 2.64284086227417, 0.7601842880249023, 0.7555456161499023, -0.2003312110900879, 1.634202003479004, 1.2255940437316895, 0.7078313827514648, 0.7025818824768066, -2.7114436626434326, -7.795476913452148, 3.764418601989746, 2.054841995239258, 0.6355657577514648, -4.357791900634766, -2.7084803581237793, -3.145782232284546, 1.2012405395507812, -1.2055528163909912, 0.7085647583007812, 0.9404129981994629, -6.826560020446777, 1.1597294807434082, 1.4464762210845947, 0.42750024795532227, 1.4561209678649902, -0.8879994750022888, 1.9419260025024414, 0.1241464614868164, 3.3775339126586914, -4.200458526611328, 1.8377435207366943, 0.9539222717285156, 0.3898801803588867, -0.5240793228149414, -0.23032474517822266, 5.643075942993164, -3.302250385284424, 1.7752838134765625, 1.6677923202514648, 1.3128910064697266, 3.6514787673950195, 3.1239423751831055, 1.8108339309692383, 0.304412841796875, 0.6499776840209961, -1.8070061206817627, 0.6499776840209961, 0.7748250961303711, 1.576127290725708, 1.714418888092041, 1.390859842300415, -0.2923412322998047, -1.7300708293914795, 0.04842090606689453, 0.8683757781982422, 0.44729137420654297, 1.034078598022461], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 14336, "num_env_steps_trained": 25080, "num_agent_steps_sampled": 14336, "num_agent_steps_trained": 25080, "last_target_update_ts": 14336, "num_target_updates": 27}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -480.63434556126595, "episode_reward_mean": -174.17483039479703, "episode_len_mean": 307.09375, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5308233634885813, "mean_inference_ms": 22.54843215720529, "mean_action_processing_ms": 0.14123916881947846, "mean_env_wait_ms": 4.882311242806909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 14336, "num_agent_steps_trained": 25080, "num_env_steps_sampled": 14336, "num_env_steps_trained": 25080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 14336, "agent_timesteps_total": 14336, "timers": {"training_iteration_time_ms": 303.202, "learn_time_ms": 55.1, "learn_throughput": 2177.864, "synch_weights_time_ms": 19.807}, "counters": {"num_env_steps_sampled": 14336, "num_env_steps_trained": 25080, "num_agent_steps_sampled": 14336, "num_agent_steps_trained": 25080, "last_target_update_ts": 14336, "num_target_updates": 27}, "done": false, "episodes_total": 32, "training_iteration": 14, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-53", "timestamp": 1655475953, "time_this_iter_s": 4.796083211898804, "time_total_s": 64.22751832008362, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 64.22751832008362, "timesteps_since_restore": 0, "iterations_since_restore": 14, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.685714285714287, "ram_util_percent": 58.642857142857146}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.312702655792236, "min_q": -13.465827941894531, "max_q": 17.50873374938965, "mean_td_error": -0.6450660228729248}, "td_error": [0.18625450134277344, 0.6659584045410156, 0.8289031982421875, -0.062497615814208984, -6.918587684631348, -0.6887264251708984, 0.3503284454345703, -0.7985343933105469, 0.2834291458129883, -0.03953361511230469, -5.061342239379883, 0.4816904067993164, -8.322210311889648, -0.06085777282714844, -0.11703681945800781, -0.12710094451904297, -1.725815773010254, 0.6834125518798828, 3.956214427947998, -0.8930225968360901, 0.8075160980224609, 0.5360774993896484, 0.24732494354248047, -7.949603080749512, -2.1884307861328125, -1.6535472869873047, 0.3140525817871094, 0.6430609226226807, -0.7415337562561035, -0.6656084060668945, -1.3504390716552734, 0.4194803237915039, 0.14707374572753906, 0.49672508239746094, -6.642245292663574, 0.9279789924621582, 1.011673927307129, -2.220594882965088, -0.8985214233398438, 1.0495529174804688, 0.6471920013427734, -2.0970706939697266, 1.6580924987792969, -1.0186123847961426, 0.2573885917663574, -1.360976219177246, 0.677454948425293, 1.658529281616211, -0.6123428344726562, 0.31223201751708984, 0.26068592071533203, -2.1048150062561035, -1.314352035522461, 1.131500244140625, -0.961522102355957, 0.3097825050354004, -0.8847923278808594, -0.45993709564208984, 0.04165375232696533, -1.17496919631958, -0.6887264251708984, -1.4571654796600342, -0.45731544494628906, 0.08394336700439453, 0.5168685913085938, 1.698202133178711, -0.8925609588623047, 0.5313396453857422, 0.14580202102661133, -1.7924766540527344, 2.15861177444458, -0.11228275299072266, -0.7820806503295898, 0.9020700454711914, -0.5147361755371094, 0.9540886878967285, -0.45563793182373047, 0.8148312568664551, 0.2713441848754883, -2.438258171081543, -6.786442756652832, -1.1971006393432617, 0.17410540580749512, 0.501983642578125, -0.7038450241088867, 1.0665082931518555, -1.6339473724365234, -2.237987518310547, 0.9844026565551758, -0.40713024139404297, -0.3364074230194092, -0.17262840270996094, 0.45617103576660156, 0.4816904067993164, -1.2561755180358887, -0.8946208953857422, -7.236481666564941, 1.5721373558044434, -0.7482309341430664, 0.34622669219970703, -2.301365852355957, 0.2869691848754883, -2.5425753593444824, -2.249907970428467, 0.4205748438835144, 0.3629035949707031, -1.3452262878417969, -1.824899673461914, 0.8456602096557617, 0.38279056549072266, -2.601513385772705, -1.8131341934204102, 0.40183067321777344, -3.0365545749664307, 0.15367603302001953, 0.30886006355285645, -3.36030912399292, 0.8569984436035156, 0.6663904190063477, -1.353217601776123], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 15360, "num_env_steps_trained": 27000, "num_agent_steps_sampled": 15360, "num_agent_steps_trained": 27000, "last_target_update_ts": 15360, "num_target_updates": 29}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -587.6824223101139, "episode_reward_mean": -193.40984958344524, "episode_len_mean": 312.2647058823529, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5304942794614498, "mean_inference_ms": 22.59456775024737, "mean_action_processing_ms": 0.1407929799074703, "mean_env_wait_ms": 4.843517487413087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -587.6824223101139, "episode_reward_mean": -193.40984958344524, "episode_len_mean": 312.2647058823529, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5304942794614498, "mean_inference_ms": 22.59456775024737, "mean_action_processing_ms": 0.1407929799074703, "mean_env_wait_ms": 4.843517487413087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 15360, "num_agent_steps_trained": 27000, "num_env_steps_sampled": 15360, "num_env_steps_trained": 27000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 15360, "agent_timesteps_total": 15360, "timers": {"training_iteration_time_ms": 323.692, "learn_time_ms": 56.217, "learn_throughput": 2134.6, "synch_weights_time_ms": 19.788}, "counters": {"num_env_steps_sampled": 15360, "num_env_steps_trained": 27000, "num_agent_steps_sampled": 15360, "num_agent_steps_trained": 27000, "last_target_update_ts": 15360, "num_target_updates": 29}, "done": false, "episodes_total": 34, "training_iteration": 15, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-25-58", "timestamp": 1655475958, "time_this_iter_s": 5.054931402206421, "time_total_s": 69.28244972229004, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 69.28244972229004, "timesteps_since_restore": 0, "iterations_since_restore": 15, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.014285714285712, "ram_util_percent": 58.800000000000004}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.701871871948242, "min_q": -16.670419692993164, "max_q": 13.349281311035156, "mean_td_error": -1.3652682304382324}, "td_error": [-2.1261587142944336, -13.426655769348145, 0.6688022613525391, -3.0758285522460938, -0.6270761489868164, -2.6103715896606445, -4.452027320861816, -0.4609091281890869, -1.9656858444213867, -0.9981985092163086, -0.9376764297485352, -2.72705078125, -0.23672866821289062, -1.2698097229003906, -2.1541852951049805, -0.6803255081176758, 0.9557223320007324, -1.1151866912841797, -8.760547637939453, 0.3543586730957031, -0.9689922332763672, -0.9273214340209961, -2.0434446334838867, -0.20844650268554688, -0.7428321838378906, 0.2163677215576172, -0.9825401306152344, -2.1008787155151367, -0.6791534423828125, -1.286111831665039, 0.554297924041748, -0.5958185195922852, 0.0614778995513916, -0.16667461395263672, -1.2603025436401367, -0.20844650268554688, -3.089217185974121, 0.022271156311035156, 0.6599814891815186, -2.131978988647461, 0.3132343292236328, -1.9260950088500977, -1.5961647033691406, -1.9158658981323242, -0.5919399261474609, -9.086743354797363, -3.0497994422912598, -1.0901193618774414, 0.5408964157104492, -0.5755176544189453, -2.062896728515625, -2.774517297744751, 0.29238319396972656, -0.8384456634521484, -1.5509185791015625, -0.6478822231292725, -0.8770613670349121, -2.5439486503601074, -2.618405342102051, -0.6614484786987305, -0.9183268547058105, -2.4997482299804688, -2.8594274520874023, -1.4485845565795898, -0.22179794311523438, -0.49188709259033203, -2.019496202468872, -9.29831314086914, -0.6219387054443359, -3.131643295288086, -0.39643096923828125, -0.47760963439941406, 0.29580068588256836, 0.41054248809814453, 0.2843446731567383, 2.936685562133789, -6.150947093963623, -2.179136276245117, -2.5429420471191406, -1.209317684173584, -1.9799041748046875, -0.041332244873046875, -0.7220277786254883, -0.6441812515258789, -0.6343526840209961, -0.23920536041259766, -0.6614484786987305, 1.5530118942260742, -0.3364565670490265, -0.8655133247375488, -1.887308120727539, -0.1715984344482422, -0.8072153329849243, -1.088953971862793, -0.8363826274871826, -0.5769643783569336, -2.2323408126831055, 1.1479401588439941, -0.5474376678466797, -0.5225210189819336, -0.3583850860595703, -0.3583850860595703, -0.4517087936401367, -1.8754692077636719, -0.9524021148681641, -0.9689922332763672, -2.09403133392334, -3.4101967811584473, -0.4400453567504883, 0.1373729705810547, -2.360551595687866, -2.432915687561035, -2.51885986328125, -2.9880361557006836, 0.018584251403808594, -0.504460334777832, -0.9664850234985352, -0.3378639221191406, -0.9116306304931641, -0.6388006210327148], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 16384, "num_env_steps_trained": 28920, "num_agent_steps_sampled": 16384, "num_agent_steps_trained": 28920, "last_target_update_ts": 16384, "num_target_updates": 31}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -587.6824223101139, "episode_reward_mean": -211.7374077080875, "episode_len_mean": 319.4864864864865, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5288584551344838, "mean_inference_ms": 22.68759127345745, "mean_action_processing_ms": 0.14094779124668014, "mean_env_wait_ms": 4.805187882212198, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -587.6824223101139, "episode_reward_mean": -211.7374077080875, "episode_len_mean": 319.4864864864865, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5288584551344838, "mean_inference_ms": 22.68759127345745, "mean_action_processing_ms": 0.14094779124668014, "mean_env_wait_ms": 4.805187882212198, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 16384, "num_agent_steps_trained": 28920, "num_env_steps_sampled": 16384, "num_env_steps_trained": 28920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 16384, "agent_timesteps_total": 16384, "timers": {"training_iteration_time_ms": 322.916, "learn_time_ms": 55.014, "learn_throughput": 2181.268, "synch_weights_time_ms": 19.689}, "counters": {"num_env_steps_sampled": 16384, "num_env_steps_trained": 28920, "num_agent_steps_sampled": 16384, "num_agent_steps_trained": 28920, "last_target_update_ts": 16384, "num_target_updates": 31}, "done": false, "episodes_total": 37, "training_iteration": 16, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-03", "timestamp": 1655475963, "time_this_iter_s": 5.087347984313965, "time_total_s": 74.369797706604, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 74.369797706604, "timesteps_since_restore": 0, "iterations_since_restore": 16, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.91428571428571, "ram_util_percent": 59.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.032624244689941, "min_q": -18.110204696655273, "max_q": 17.87644386291504, "mean_td_error": -0.46230950951576233}, "td_error": [0.8511629104614258, 0.11586427688598633, -1.0723605155944824, 0.09872221946716309, 1.0701980590820312, -1.4130163192749023, 3.012063980102539, -4.455013275146484, 0.08302783966064453, 0.07955646514892578, -1.3099889755249023, 1.059767723083496, -5.799454689025879, -0.5355691909790039, -0.7865991592407227, 0.10377883911132812, -0.7880334854125977, 0.5923954844474792, 0.9564580917358398, -1.3079938888549805, 0.5453112125396729, 0.23990440368652344, -0.17371654510498047, -0.347259521484375, -1.5741376876831055, 1.70051908493042, -7.844258785247803, -0.49210071563720703, 0.35365962982177734, 0.17445945739746094, -1.9689843654632568, -0.5017591714859009, -2.4659175872802734, -0.27841758728027344, 1.8309111595153809, 0.4035606384277344, 4.36871337890625, -0.2687816619873047, -1.7251815795898438, -0.6612355709075928, -0.312716007232666, -1.1905059814453125, 0.5220985412597656, 0.1752338409423828, -1.35630464553833, -4.759101390838623, -1.1888097524642944, 0.13250732421875, -0.7666254043579102, -1.8339338302612305, -0.2332000732421875, 0.9328732490539551, -7.107143402099609, -0.21127986907958984, 0.3640432357788086, -0.39652347564697266, -0.8333377838134766, 0.9178295135498047, 0.48167896270751953, -0.04432964324951172, -1.3006272315979004, -0.8045969009399414, 0.8474836349487305, 1.303983211517334, 1.0923409461975098, -0.5282583236694336, 0.21524548530578613, -1.5117363929748535, -0.1784381866455078, 0.031003952026367188, -0.2556748390197754, -0.394378662109375, 0.47943782806396484, -0.8468942642211914, 0.3623523712158203, -0.7865991592407227, -0.04603290557861328, 0.14878273010253906, -0.8146953582763672, 0.34999752044677734, -4.052934646606445, -1.0707378387451172, 1.8730015754699707, -2.605670928955078, -2.9424471855163574, -3.1774253845214844, 0.6938323974609375, -0.1391429901123047, -1.8292236328125, -0.25505924224853516, 4.293655872344971, -1.4683856964111328, 0.14217758178710938, -0.4972808361053467, -0.21263408660888672, -0.5483312606811523, -0.7763881683349609, -0.34160804748535156, 0.7224369049072266, 0.4649181365966797, -0.44571971893310547, -1.429098129272461, -0.035030364990234375, -1.493807315826416, -2.110466957092285, 1.4535894393920898, -1.329258918762207, 0.7693362236022949, -0.09127044677734375, -1.2956962585449219, 0.7545218467712402, -1.5936012268066406, 0.7023115158081055, 0.5574154853820801, 0.2568340301513672, 0.5663843154907227, -0.33376359939575195, 0.5980453491210938, -0.1784381866455078, -1.5975828170776367], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 17408, "num_env_steps_trained": 30840, "num_agent_steps_sampled": 17408, "num_agent_steps_trained": 30840, "last_target_update_ts": 17408, "num_target_updates": 33}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -282.65547748829454, "episode_len_mean": 342.27659574468083, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5189982157077009, "mean_inference_ms": 22.847253259026264, "mean_action_processing_ms": 0.14032927074676754, "mean_env_wait_ms": 4.650588410843964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -282.65547748829454, "episode_len_mean": 342.27659574468083, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5189982157077009, "mean_inference_ms": 22.847253259026264, "mean_action_processing_ms": 0.14032927074676754, "mean_env_wait_ms": 4.650588410843964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 17408, "num_agent_steps_trained": 30840, "num_env_steps_sampled": 17408, "num_env_steps_trained": 30840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 17408, "agent_timesteps_total": 17408, "timers": {"training_iteration_time_ms": 314.414, "learn_time_ms": 55.743, "learn_throughput": 2152.721, "synch_weights_time_ms": 19.889}, "counters": {"num_env_steps_sampled": 17408, "num_env_steps_trained": 30840, "num_agent_steps_sampled": 17408, "num_agent_steps_trained": 30840, "last_target_update_ts": 17408, "num_target_updates": 33}, "done": false, "episodes_total": 47, "training_iteration": 17, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-09", "timestamp": 1655475969, "time_this_iter_s": 5.38380241394043, "time_total_s": 79.75360012054443, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 79.75360012054443, "timesteps_since_restore": 0, "iterations_since_restore": 17, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.1, "ram_util_percent": 59.1625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -8.563878059387207, "min_q": -20.75241470336914, "max_q": 20.405275344848633, "mean_td_error": -0.3436804413795471}, "td_error": [0.5341520309448242, -3.742009401321411, -20.75241470336914, -1.7333621978759766, 1.5742950439453125, 0.44226741790771484, -1.0089044570922852, 2.5779895782470703, 0.6247892379760742, -0.7716841697692871, -5.118410587310791, 0.16419410705566406, -0.30384349822998047, 1.100449562072754, -0.5159549713134766, 1.3730659484863281, 0.5599565505981445, -0.9067988395690918, -4.774141311645508, -0.075225830078125, 0.8152179718017578, -1.9050607681274414, 2.146050453186035, -1.4639949798583984, -1.0268621444702148, -0.2784690856933594, -0.6878845691680908, -0.9706840515136719, 0.4348106384277344, 0.13702964782714844, -1.539987564086914, 1.521461009979248, 2.3358263969421387, 1.4148550033569336, -0.18341350555419922, 0.6691865921020508, -0.03845024108886719, 2.115084648132324, 1.9305572509765625, 1.4001884460449219, 0.6371805667877197, 1.8840093612670898, 1.2926788330078125, -3.4575047492980957, -6.057685852050781, -1.877269983291626, -3.617921829223633, -1.2834606170654297, 0.07439613342285156, -0.30106353759765625, -1.5028581619262695, -0.6060514450073242, 0.33502674102783203, -0.20817184448242188, -0.7500109672546387, 0.413330078125, 0.47246646881103516, 1.1011459827423096, 0.799342155456543, 0.12032508850097656, 1.024240493774414, 1.1742973327636719, -0.1685466766357422, -0.3236379623413086, -2.6902008056640625, 1.2007274627685547, 3.110471725463867, 1.1408119201660156, 0.6943486928939819, 2.1600522994995117, -9.496541023254395, 0.3332669138908386, 1.6644058227539062, -0.12612438201904297, 0.24566650390625, 1.228780746459961, -0.2678794860839844, 0.01303863525390625, 0.7745590209960938, 0.1835308074951172, 2.732722759246826, 0.7079811096191406, -9.480231285095215, -1.2147941589355469, 0.2803824543952942, 0.20644760131835938, -0.6872777938842773, -0.7723202705383301, 0.977020263671875, -9.256348609924316, 0.995732307434082, -0.42496442794799805, 1.268606185913086, -1.3017463684082031, -0.2109060287475586, 0.35131072998046875, 1.1640872955322266, 1.5612878799438477, 1.725672721862793, -0.9029064178466797, 0.5356922149658203, 1.3076260089874268, 1.3170242309570312, -1.0991544723510742, 0.9680099487304688, 1.9951801300048828, 0.1315021514892578, 0.7368144989013672, 0.12443351745605469, 1.499183177947998, -0.7284669876098633, -1.1680078506469727, 4.673706531524658, -1.483785629272461, 0.977020263671875, 0.9672751426696777, -6.3008623123168945, -1.9654121398925781, 2.3777480125427246, 0.7560253143310547], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 18432, "num_env_steps_trained": 32760, "num_agent_steps_sampled": 18432, "num_agent_steps_trained": 32760, "last_target_update_ts": 18432, "num_target_updates": 35}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -287.17970298742875, "episode_len_mean": 343.6458333333333, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176490069121676, "mean_inference_ms": 22.869513894064, "mean_action_processing_ms": 0.14004285778173353, "mean_env_wait_ms": 4.639486749563179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -287.17970298742875, "episode_len_mean": 343.6458333333333, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176490069121676, "mean_inference_ms": 22.869513894064, "mean_action_processing_ms": 0.14004285778173353, "mean_env_wait_ms": 4.639486749563179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 18432, "num_agent_steps_trained": 32760, "num_env_steps_sampled": 18432, "num_env_steps_trained": 32760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 18432, "agent_timesteps_total": 18432, "timers": {"training_iteration_time_ms": 273.65, "learn_time_ms": 56.056, "learn_throughput": 2140.734, "synch_weights_time_ms": 19.89}, "counters": {"num_env_steps_sampled": 18432, "num_env_steps_trained": 32760, "num_agent_steps_sampled": 18432, "num_agent_steps_trained": 32760, "last_target_update_ts": 18432, "num_target_updates": 35}, "done": false, "episodes_total": 48, "training_iteration": 18, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-13", "timestamp": 1655475973, "time_this_iter_s": 4.497730016708374, "time_total_s": 84.25133013725281, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 84.25133013725281, "timesteps_since_restore": 0, "iterations_since_restore": 18, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 34.41428571428572, "ram_util_percent": 59.25714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.559103488922119, "min_q": -20.736665725708008, "max_q": 20.984203338623047, "mean_td_error": -0.15490998327732086}, "td_error": [-7.501240253448486, -1.1050529479980469, 0.12505149841308594, 0.7957220077514648, 1.0418834686279297, 1.5883855819702148, -9.499778747558594, 0.5330324172973633, 1.6890840530395508, 0.2728233337402344, 1.1396942138671875, -0.21366596221923828, 1.106107473373413, 1.0617961883544922, 0.5730905532836914, -2.9049487113952637, 1.2900805473327637, 0.3396596908569336, 2.663790702819824, 1.9852193593978882, 0.6431093215942383, 0.13429641723632812, 0.4143409729003906, 0.2919890880584717, 0.42099761962890625, 1.4023103713989258, -2.903390884399414, 0.9900426864624023, 0.8563880920410156, 1.5245275497436523, 2.0951294898986816, -0.03296470642089844, -0.23015403747558594, 1.9234862327575684, -9.790844917297363, -0.4370231628417969, 1.1176180839538574, -0.8298382759094238, 1.1231913566589355, -0.16854000091552734, 0.9710187911987305, -0.04207420349121094, 1.4607763290405273, -0.570582389831543, 0.1074380874633789, 0.5111618041992188, 2.7703351974487305, 0.8816132545471191, -0.2482738494873047, -16.894699096679688, 1.4143320322036743, 0.49332237243652344, -1.2420082092285156, 1.5883855819702148, -5.158785820007324, 1.1638555526733398, 0.3353290557861328, -0.6123442649841309, -0.14062881469726562, 0.6174774169921875, -0.23999905586242676, 0.6525897979736328, 1.1396942138671875, -1.2106924057006836, 0.2642936706542969, -0.16854000091552734, -0.11390876770019531, -1.003730297088623, -0.5003693103790283, 0.7181587219238281, 0.2237706184387207, 0.28595733642578125, 0.8260173797607422, 2.272460460662842, 2.3912739753723145, 0.9058995246887207, 0.2766866683959961, -0.6317768096923828, 3.7397847175598145, 0.1204538345336914, -1.3489532470703125, 1.790431022644043, 1.9377176761627197, 1.2323999404907227, -4.92834997177124, -1.4754447937011719, -0.8463020324707031, 0.5668916702270508, -0.30846405029296875, -4.160459518432617, -0.5358790159225464, 0.23468589782714844, -1.8635902404785156, 0.07858562469482422, -8.665634155273438, -0.6339497566223145, 0.5002622604370117, 1.3237972259521484, 3.503873825073242, 0.15044212341308594, -2.0310468673706055, -0.21475505828857422, 0.28778839111328125, -0.4983062744140625, 0.18622493743896484, 0.48978328704833984, 0.03892993927001953, 1.6582937240600586, 0.9284806251525879, 2.8969030380249023, 0.5531272888183594, 1.142512559890747, 1.1360225677490234, 0.8951740264892578, -1.2663683891296387, 1.0174174308776855, 0.9515876770019531, -0.1144418716430664, -2.7186007499694824, -1.3590612411499023], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 19456, "num_env_steps_trained": 34680, "num_agent_steps_sampled": 19456, "num_agent_steps_trained": 34680, "last_target_update_ts": 19456, "num_target_updates": 37}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -287.17970298742875, "episode_len_mean": 343.6458333333333, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176490069121676, "mean_inference_ms": 22.869513894064, "mean_action_processing_ms": 0.14004285778173353, "mean_env_wait_ms": 4.639486749563179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -287.17970298742875, "episode_len_mean": 343.6458333333333, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176490069121676, "mean_inference_ms": 22.869513894064, "mean_action_processing_ms": 0.14004285778173353, "mean_env_wait_ms": 4.639486749563179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 19456, "num_agent_steps_trained": 34680, "num_env_steps_sampled": 19456, "num_env_steps_trained": 34680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 19456, "agent_timesteps_total": 19456, "timers": {"training_iteration_time_ms": 291.062, "learn_time_ms": 56.674, "learn_throughput": 2117.36, "synch_weights_time_ms": 19.689}, "counters": {"num_env_steps_sampled": 19456, "num_env_steps_trained": 34680, "num_agent_steps_sampled": 19456, "num_agent_steps_trained": 34680, "last_target_update_ts": 19456, "num_target_updates": 37}, "done": false, "episodes_total": 48, "training_iteration": 19, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-18", "timestamp": 1655475978, "time_this_iter_s": 4.585874080657959, "time_total_s": 88.83720421791077, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 88.83720421791077, "timesteps_since_restore": 0, "iterations_since_restore": 19, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 34.949999999999996, "ram_util_percent": 59.300000000000004}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.2963361740112305, "min_q": -21.612789154052734, "max_q": 18.833768844604492, "mean_td_error": 0.6139204502105713}, "td_error": [0.733057975769043, 2.1122961044311523, -1.2939436435699463, -1.0720329284667969, 1.1465063095092773, -0.34688854217529297, -0.6634511947631836, -0.7680172920227051, -0.15799188613891602, 0.4528961181640625, 0.11622333526611328, -0.5246782302856445, 2.8409740924835205, 2.1607606410980225, 0.004204750061035156, 1.0871129035949707, -0.15015602111816406, 0.4349689483642578, 0.6290569305419922, 1.127699613571167, 1.3665962219238281, -0.8102912902832031, 2.0570831298828125, 3.545032262802124, 2.207735061645508, 0.7851700782775879, 2.0985002517700195, 0.9885258674621582, 1.134415626525879, 0.3636317253112793, 0.3687734603881836, 1.9306683540344238, 1.3410358428955078, -0.9876656532287598, 1.1568946838378906, -0.6227550506591797, 1.5169134140014648, -0.8159375190734863, 0.8297319412231445, 0.5225191116333008, -8.405107498168945, 1.0479059219360352, 2.0216064453125, 0.7106008529663086, 1.179758071899414, -1.274587869644165, 0.6666898727416992, 0.7650418281555176, -0.6228189468383789, 1.4240875244140625, 0.11007118225097656, 1.3706645965576172, -1.6515227556228638, 2.5013866424560547, -8.905501365661621, 0.6632528305053711, 0.6965217590332031, 1.3155479431152344, -0.2719740867614746, -0.10770797729492188, -5.419773578643799, -11.350578308105469, 3.001667022705078, 1.6170949935913086, 1.6290254592895508, 3.0876388549804688, 2.7339096069335938, 1.3344110250473022, 0.5233631134033203, 2.5162713527679443, 1.3344110250473022, -0.6097326278686523, -0.18775272369384766, 2.5929336547851562, -5.637758255004883, 1.1678428649902344, 2.6171131134033203, 2.655196189880371, 1.7773923873901367, 2.5170230865478516, 2.053217887878418, 0.8707878589630127, 0.7766513824462891, 1.8350601196289062, 2.3005847930908203, 1.2738828659057617, 0.6858067512512207, 0.910858154296875, 1.5907363891601562, -0.2018451690673828, 2.0829410552978516, 2.3118247985839844, -0.15403366088867188, 0.07779502868652344, 0.3782215118408203, -0.953474223613739, 1.6732501983642578, 0.7238693237304688, 0.8265514373779297, 2.0252652168273926, 2.7847161293029785, 3.4399070739746094, -0.20508384704589844, 0.539576530456543, 1.3410358428955078, 0.4044480323791504, 1.1892242431640625, -0.7484064102172852, 0.06965255737304688, 1.3717994689941406, 2.2651233673095703, 1.0445480346679688, 0.23165130615234375, 1.0678329467773438, 3.1622514724731445, 3.122054100036621, -2.528385639190674, 2.11385440826416, 1.92377769947052, 2.0141401290893555], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 20480, "num_env_steps_trained": 36600, "num_agent_steps_sampled": 20480, "num_agent_steps_trained": 36600, "last_target_update_ts": 20480, "num_target_updates": 39}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -287.17970298742875, "episode_len_mean": 343.6458333333333, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176490069121676, "mean_inference_ms": 22.869513894064, "mean_action_processing_ms": 0.14004285778173353, "mean_env_wait_ms": 4.639486749563179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -287.17970298742875, "episode_len_mean": 343.6458333333333, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176490069121676, "mean_inference_ms": 22.869513894064, "mean_action_processing_ms": 0.14004285778173353, "mean_env_wait_ms": 4.639486749563179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 20480, "num_agent_steps_trained": 36600, "num_env_steps_sampled": 20480, "num_env_steps_trained": 36600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 20480, "agent_timesteps_total": 20480, "timers": {"training_iteration_time_ms": 294.446, "learn_time_ms": 56.062, "learn_throughput": 2140.491, "synch_weights_time_ms": 19.689}, "counters": {"num_env_steps_sampled": 20480, "num_env_steps_trained": 36600, "num_agent_steps_sampled": 20480, "num_agent_steps_trained": 36600, "last_target_update_ts": 20480, "num_target_updates": 39}, "done": false, "episodes_total": 48, "training_iteration": 20, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-23", "timestamp": 1655475983, "time_this_iter_s": 4.664806842803955, "time_total_s": 93.50201106071472, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 93.50201106071472, "timesteps_since_restore": 0, "iterations_since_restore": 20, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.75714285714286, "ram_util_percent": 59.42857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -8.108321189880371, "min_q": -22.105735778808594, "max_q": 22.397212982177734, "mean_td_error": -1.9854493141174316}, "td_error": [-5.652544021606445, -5.438754081726074, -4.921454429626465, -1.3752822875976562, -2.3443450927734375, -11.777481079101562, -0.8497276306152344, 0.21028423309326172, 1.666666030883789, -8.938248634338379, -0.09329605102539062, 0.042960166931152344, 1.163966178894043, 0.2359786033630371, 1.2061591148376465, -0.7015628814697266, -2.867250442504883, -0.9181423187255859, -2.3219850063323975, -7.266594409942627, -4.792677879333496, -7.18614387512207, -1.6310086250305176, -0.03259468078613281, -2.685135841369629, -1.6079673767089844, -3.9324045181274414, -5.625997543334961, -1.6851730346679688, -2.8216371536254883, -1.2232398986816406, -1.1642422676086426, 0.8570294380187988, -2.690091133117676, -0.939453125, -1.275167465209961, -1.7987899780273438, -0.2842082977294922, -2.508565902709961, -2.974440574645996, 1.7240538597106934, -3.7953786849975586, -1.078115463256836, -1.316981315612793, -1.6800975799560547, -3.095001697540283, -0.8507194519042969, -3.161965847015381, 0.9743778705596924, 2.07222318649292, 0.4515256881713867, -0.7408866882324219, -0.8261642456054688, 0.8407113552093506, -4.164292335510254, -0.6356353759765625, 1.2820100784301758, 0.9412956237792969, -0.2619771957397461, 1.1013730764389038, 0.25447750091552734, 0.6323051452636719, -2.8395047187805176, -0.8306384086608887, -2.4550065994262695, -2.650421142578125, 0.14596271514892578, -1.211252212524414, -0.8846244812011719, -1.369908332824707, -4.125116348266602, -2.494898796081543, 0.3434724807739258, -2.708167791366577, -0.6462440490722656, -1.3906364440917969, -2.4164695739746094, -1.0073680877685547, -1.825887680053711, -0.9732770919799805, -3.012308120727539, -10.629928588867188, -5.062058448791504, -2.1373744010925293, -2.827098846435547, -0.6124496459960938, -1.4858579635620117, -15.679555892944336, -13.772456169128418, 1.1013730764389038, -1.5539493560791016, 0.9869785308837891, -1.2689838409423828, -1.2338829040527344, -1.332269549369812, -0.6416988372802734, -1.3284549713134766, -0.2005598545074463, -0.8844470977783203, 0.01058053970336914, -0.5968170166015625, -4.243697166442871, -0.6289024353027344, -1.3763198852539062, 0.010957717895507812, -1.6961445808410645, -3.3499746322631836, -1.9348468780517578, 0.7090091705322266, -1.6851730346679688, -0.2912912368774414, -1.5585556030273438, -3.6120195388793945, -7.504637718200684, -1.199965476989746, -0.9444046020507812, -1.632249355316162, -2.104677200317383, -1.3264751434326172, -4.107917308807373], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 21504, "num_env_steps_trained": 38520, "num_agent_steps_sampled": 21504, "num_agent_steps_trained": 38520, "last_target_update_ts": 21504, "num_target_updates": 41}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -285.69977611805103, "episode_len_mean": 343.48979591836735, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176553143275471, "mean_inference_ms": 22.902513391700104, "mean_action_processing_ms": 0.13973269035555325, "mean_env_wait_ms": 4.633054527111198, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -639.3484534397721, "episode_reward_mean": -285.69977611805103, "episode_len_mean": 343.48979591836735, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176553143275471, "mean_inference_ms": 22.902513391700104, "mean_action_processing_ms": 0.13973269035555325, "mean_env_wait_ms": 4.633054527111198, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 21504, "num_agent_steps_trained": 38520, "num_env_steps_sampled": 21504, "num_env_steps_trained": 38520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 21504, "agent_timesteps_total": 21504, "timers": {"training_iteration_time_ms": 315.136, "learn_time_ms": 57.061, "learn_throughput": 2103.009, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 21504, "num_env_steps_trained": 38520, "num_agent_steps_sampled": 21504, "num_agent_steps_trained": 38520, "last_target_update_ts": 21504, "num_target_updates": 41}, "done": false, "episodes_total": 49, "training_iteration": 21, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-28", "timestamp": 1655475988, "time_this_iter_s": 4.964786767959595, "time_total_s": 98.46679782867432, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 98.46679782867432, "timesteps_since_restore": 0, "iterations_since_restore": 21, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.714285714285715, "ram_util_percent": 59.57142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.693015098571777, "min_q": -23.02630043029785, "max_q": 22.480588912963867, "mean_td_error": -0.3343295156955719}, "td_error": [-0.8297185897827148, 0.8387232422828674, -0.34142112731933594, 1.967421531677246, 0.11383056640625, 0.11383056640625, -1.2879772186279297, 1.495124101638794, -2.1142807006835938, -0.4165048599243164, 0.1273632049560547, 0.16715240478515625, 0.08274459838867188, 2.167060375213623, 0.9574699401855469, -5.053035259246826, 0.16449213027954102, 0.27557373046875, 1.285858154296875, -3.1014175415039062, 0.5289337635040283, -0.39655208587646484, 0.9696716070175171, 3.0010414123535156, 0.3818979263305664, 0.19488000869750977, 1.6689109802246094, 4.9151811599731445, 0.11356830596923828, 1.4827709197998047, -1.9747467041015625, 0.3320121765136719, -2.627924919128418, 0.6561956405639648, -3.5411906242370605, 3.0855278968811035, -0.7470970153808594, -1.3852243423461914, 1.3052124977111816, -1.3914928436279297, 0.4258241653442383, -0.8214325904846191, -7.094720840454102, 2.8834385871887207, 0.5998287200927734, -0.2134389877319336, 1.8864309787750244, -0.7671082019805908, -0.42356300354003906, 1.5315475463867188, 0.40810298919677734, -0.5974369049072266, 0.26910245418548584, -0.24255752563476562, 0.16898155212402344, -0.21321487426757812, 1.9829845428466797, -0.7182540893554688, 1.0872454643249512, -1.2420196533203125, 0.9574699401855469, 0.46419525146484375, 0.2772207260131836, -4.155404567718506, 0.06841659545898438, 0.11046722531318665, -1.042954444885254, 1.2628297805786133, -0.14129257202148438, 0.703155517578125, -0.07136917114257812, -3.296459197998047, 0.48484039306640625, 0.12372493743896484, 1.0400872230529785, -1.2009954452514648, -6.222090721130371, -7.162735939025879, -0.2966804504394531, -0.4062933921813965, 0.35378074645996094, -4.102630615234375, 0.18944454193115234, -2.2561845779418945, 1.5315475463867188, 0.3354320526123047, -0.3033561706542969, 0.13583898544311523, -0.07106208801269531, -0.1722087860107422, -1.6345300674438477, -6.891119956970215, -1.0645771026611328, 1.5683460235595703, -1.1566600799560547, 0.8273793458938599, -0.15780878067016602, 1.1141204833984375, 1.2239093780517578, 0.03595161437988281, 0.017236709594726562, 0.10966205596923828, 3.2591209411621094, -12.501578330993652, 0.026674270629882812, -0.04164695739746094, -0.04938507080078125, 0.9962759017944336, 1.2368431091308594, -0.4015932083129883, 1.3600120544433594, 1.9829845428466797, -2.5051469802856445, 0.9363040924072266, 1.620863914489746, -4.797703742980957, 0.35028076171875, -3.1825408935546875, 0.296875, -1.928426742553711], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 22528, "num_env_steps_trained": 40440, "num_agent_steps_sampled": 22528, "num_agent_steps_trained": 40440, "last_target_update_ts": 22528, "num_target_updates": 43}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -667.4432587623596, "episode_reward_mean": -295.61730803075164, "episode_len_mean": 346.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5157814708994994, "mean_inference_ms": 22.98701351950209, "mean_action_processing_ms": 0.13941203819754194, "mean_env_wait_ms": 4.5665592994338855, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -667.4432587623596, "episode_reward_mean": -295.61730803075164, "episode_len_mean": 346.0, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5157814708994994, "mean_inference_ms": 22.98701351950209, "mean_action_processing_ms": 0.13941203819754194, "mean_env_wait_ms": 4.5665592994338855, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 22528, "num_agent_steps_trained": 40440, "num_env_steps_sampled": 22528, "num_env_steps_trained": 40440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 22528, "agent_timesteps_total": 22528, "timers": {"training_iteration_time_ms": 337.974, "learn_time_ms": 56.81, "learn_throughput": 2112.291, "synch_weights_time_ms": 20.089}, "counters": {"num_env_steps_sampled": 22528, "num_env_steps_trained": 40440, "num_agent_steps_sampled": 22528, "num_agent_steps_trained": 40440, "last_target_update_ts": 22528, "num_target_updates": 43}, "done": false, "episodes_total": 55, "training_iteration": 22, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-33", "timestamp": 1655475993, "time_this_iter_s": 5.398412227630615, "time_total_s": 103.86521005630493, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 103.86521005630493, "timesteps_since_restore": 0, "iterations_since_restore": 22, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.325, "ram_util_percent": 59.775}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.8655548095703125, "min_q": -25.636821746826172, "max_q": 25.252063751220703, "mean_td_error": 0.6384201049804688}, "td_error": [-0.15836811065673828, 0.4734630584716797, -0.49991798400878906, 0.2765827178955078, 0.1765594482421875, -3.1181111335754395, 1.557363510131836, 1.318918228149414, 1.9017810821533203, 0.8669223785400391, 0.49384307861328125, 0.005436897277832031, 1.5831470489501953, -1.1556625366210938, 0.7841887474060059, 2.8483524322509766, -2.0354509353637695, -3.246670722961426, 0.9744815826416016, 1.3693952560424805, 1.3310344219207764, 0.4935302734375, -1.6547422409057617, 1.641524314880371, -2.428119659423828, 0.5930442810058594, 0.7772140502929688, 1.0145692825317383, 1.1150355339050293, 0.2810029983520508, 1.304178237915039, 0.5930442810058594, 1.7458667755126953, 0.5125484466552734, 0.3869659900665283, 1.36334228515625, -0.34424400329589844, 0.9991283416748047, 0.9726219177246094, -1.5221271514892578, 1.2103452682495117, 5.5773539543151855, 0.59527587890625, 0.20716094970703125, 4.261631011962891, 0.47376441955566406, 0.97528076171875, -21.3182373046875, 1.1583375930786133, -0.12742042541503906, 2.1060028076171875, 2.7619080543518066, -3.7101898193359375, 2.4444189071655273, 1.508753776550293, 1.4042348861694336, 0.13931047916412354, 0.12830352783203125, 2.5907018184661865, 2.6078262329101562, 1.8259353637695312, 0.5029487609863281, -0.1653728485107422, 0.3360614776611328, 4.847076416015625, 0.45003414154052734, 0.865386962890625, 2.26104474067688, -0.20787715911865234, 1.1940174102783203, 1.4003257751464844, 1.2005634307861328, 2.6676290035247803, 0.43781185150146484, 0.2718677520751953, 1.066131591796875, 0.16680908203125, 1.8117265701293945, -1.0342330932617188, -3.040154457092285, 2.149962902069092, 0.5700569152832031, 0.5539798736572266, 1.296055793762207, 1.7964775562286377, 0.7960243225097656, 1.1448936462402344, 4.163136005401611, 1.1900863647460938, 3.594074010848999, 0.29151153564453125, 2.389002561569214, 0.34974098205566406, 3.147120952606201, -0.20846271514892578, 0.8378181457519531, 3.225680351257324, 1.8368377685546875, 1.6181716918945312, 1.8350801467895508, -3.4176812171936035, 3.4387011528015137, 2.863574981689453, 2.5907018184661865, 1.2663116455078125, 0.9726219177246094, 1.489694595336914, 0.44262123107910156, 0.6041574478149414, 2.236353874206543, 0.4616355895996094, 1.6852798461914062, 2.1039814949035645, 0.28910255432128906, 0.19504737854003906, 0.5294780731201172, 1.0786526203155518, -0.458221435546875, 0.9120006561279297, -10.695026397705078], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 23552, "num_env_steps_trained": 42360, "num_agent_steps_sampled": 23552, "num_agent_steps_trained": 42360, "last_target_update_ts": 23552, "num_target_updates": 45}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -314.98239097806317, "episode_len_mean": 352.18333333333334, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5133896192680732, "mean_inference_ms": 23.085559371657567, "mean_action_processing_ms": 0.13931901746085995, "mean_env_wait_ms": 4.522529816657472, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -314.98239097806317, "episode_len_mean": 352.18333333333334, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5133896192680732, "mean_inference_ms": 23.085559371657567, "mean_action_processing_ms": 0.13931901746085995, "mean_env_wait_ms": 4.522529816657472, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 23552, "num_agent_steps_trained": 42360, "num_env_steps_sampled": 23552, "num_env_steps_trained": 42360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 23552, "agent_timesteps_total": 23552, "timers": {"training_iteration_time_ms": 343.236, "learn_time_ms": 58.775, "learn_throughput": 2041.669, "synch_weights_time_ms": 20.383}, "counters": {"num_env_steps_sampled": 23552, "num_env_steps_trained": 42360, "num_agent_steps_sampled": 23552, "num_agent_steps_trained": 42360, "last_target_update_ts": 23552, "num_target_updates": 45}, "done": false, "episodes_total": 60, "training_iteration": 23, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-39", "timestamp": 1655475999, "time_this_iter_s": 5.4224138259887695, "time_total_s": 109.2876238822937, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 109.2876238822937, "timesteps_since_restore": 0, "iterations_since_restore": 23, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 35.025000000000006, "ram_util_percent": 60.0375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -6.103997707366943, "min_q": -27.71092414855957, "max_q": 21.513172149658203, "mean_td_error": -0.8364167809486389}, "td_error": [0.5356578826904297, 0.3535137176513672, -0.4725151062011719, -4.761415481567383, 0.7436542510986328, 1.9106016159057617, 0.07297325134277344, -6.938385009765625, 0.5356578826904297, -3.481992721557617, -0.46534299850463867, 0.29624366760253906, -0.6187410354614258, 0.31052589416503906, -0.6187410354614258, -0.1961841583251953, 0.6189193725585938, -2.8923845291137695, 1.0090961456298828, 1.0423393249511719, -12.224040031433105, -0.24608516693115234, -0.4777168035507202, -12.050678253173828, 0.04641103744506836, -1.639470100402832, 2.4316611289978027, 0.5356578826904297, -0.02523517608642578, 0.3056306838989258, 0.6428079605102539, 0.6363177299499512, -1.1975688934326172, 0.15326976776123047, -0.31658363342285156, -1.3173398971557617, 1.4536609649658203, -1.6029949188232422, 0.35544395446777344, 0.9153614044189453, 0.6926422119140625, 0.1723160743713379, 0.49068641662597656, -5.700080871582031, 0.30953025817871094, 0.09673500061035156, -1.5686750411987305, 0.31644630432128906, 1.2449264526367188, -1.563368797302246, -4.750274658203125, 0.4748115539550781, 0.7117276191711426, -2.0762939453125, -3.82297420501709, -2.1690502166748047, -3.1854381561279297, -14.193570137023926, -0.9119167327880859, -0.5352783203125, 1.3564403057098389, -0.533747673034668, -0.28687584400177, 0.7344646453857422, -2.1505537033081055, 1.4622135162353516, -2.2106683254241943, -0.6878962516784668, 0.06824278831481934, 2.8693580627441406, -0.8403668403625488, 0.7862300872802734, 0.7020998001098633, -0.4575634002685547, -4.32353401184082, -0.5606060028076172, -1.8478989601135254, -0.04929304122924805, 0.12399482727050781, 0.1823406219482422, -4.437721252441406, 0.33441972732543945, 0.09175682067871094, -2.5685625076293945, 0.5916976928710938, 0.21912193298339844, 0.3845787048339844, -2.453479766845703, 0.4421043395996094, 2.205826759338379, -0.384204626083374, 0.08475494384765625, -8.002941131591797, 0.49591541290283203, 1.1144108772277832, -0.060054779052734375, 0.45679759979248047, -1.3095579147338867, 0.6289615631103516, 0.5265083312988281, 0.9550342559814453, 0.3443889617919922, 1.0122089385986328, 2.7497081756591797, 0.5780887603759766, -1.2355022430419922, 0.4806537628173828, -1.6947779655456543, -1.0059328079223633, -0.6738042831420898, -0.2395920753479004, 0.44927978515625, -0.291351318359375, -12.703864097595215, 0.2455291748046875, 0.4802694320678711, -0.5314102172851562, 0.3536982536315918, -0.43633460998535156, 0.7020998001098633], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 24576, "num_env_steps_trained": 44280, "num_agent_steps_sampled": 24576, "num_agent_steps_trained": 44280, "last_target_update_ts": 24576, "num_target_updates": 47}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -335.1997409245232, "episode_len_mean": 356.984375, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5100893635116717, "mean_inference_ms": 23.137717511398453, "mean_action_processing_ms": 0.13898447057113475, "mean_env_wait_ms": 4.489548385806398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -335.1997409245232, "episode_len_mean": 356.984375, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5100893635116717, "mean_inference_ms": 23.137717511398453, "mean_action_processing_ms": 0.13898447057113475, "mean_env_wait_ms": 4.489548385806398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 24576, "num_agent_steps_trained": 44280, "num_env_steps_sampled": 24576, "num_env_steps_trained": 44280, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 24576, "agent_timesteps_total": 24576, "timers": {"training_iteration_time_ms": 315.277, "learn_time_ms": 58.306, "learn_throughput": 2058.121, "synch_weights_time_ms": 20.088}, "counters": {"num_env_steps_sampled": 24576, "num_env_steps_trained": 44280, "num_agent_steps_sampled": 24576, "num_agent_steps_trained": 44280, "last_target_update_ts": 24576, "num_target_updates": 47}, "done": false, "episodes_total": 64, "training_iteration": 24, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-44", "timestamp": 1655476004, "time_this_iter_s": 4.986911058425903, "time_total_s": 114.2745349407196, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 114.2745349407196, "timesteps_since_restore": 0, "iterations_since_restore": 24, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 34.042857142857144, "ram_util_percent": 60.12857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.892146587371826, "min_q": -28.695043563842773, "max_q": 27.198652267456055, "mean_td_error": -0.1359754204750061}, "td_error": [4.834769248962402, -10.561519622802734, -2.107211112976074, -0.24643802642822266, 1.436105728149414, 0.9283078908920288, -0.2035353183746338, -0.7039165496826172, 1.1986327171325684, -1.0650458335876465, -1.4830893278121948, -1.1604118347167969, -6.173133850097656, 0.24584579467773438, 1.5630836486816406, 0.21049785614013672, 1.9236431121826172, 0.6950838565826416, 1.8618005514144897, -3.0422377586364746, -0.5459365844726562, -0.16376113891601562, 2.0890369415283203, 0.4649028778076172, 0.32610607147216797, -0.3342113494873047, -0.5375833511352539, 1.8378715515136719, 0.2790489196777344, 0.000782012939453125, 1.5906667709350586, -3.0774123668670654, -0.6448307037353516, -1.5624275207519531, 0.6840496063232422, 0.3573780059814453, -4.637779235839844, 4.855714797973633, 0.8714752197265625, 3.031914710998535, -5.109501838684082, 1.9236431121826172, 0.5616350173950195, -7.387589454650879, -0.3094215393066406, -1.0637626647949219, 1.8684329986572266, 0.9413814544677734, 0.1125802993774414, 0.43143463134765625, 2.1342997550964355, -1.7045574188232422, -4.05262565612793, 1.685816764831543, -2.3252944946289062, 2.690147876739502, 0.019132614135742188, 1.1654930114746094, -0.03245353698730469, -0.5312538146972656, -0.32434797286987305, -0.5920848846435547, 1.2588310241699219, -0.6317094564437866, 0.7430219650268555, 1.3511552810668945, 4.855714797973633, 1.6968765258789062, 0.2616004943847656, 0.19301342964172363, 1.0808143615722656, 2.7241668701171875, -1.27308988571167, 0.7087602615356445, 7.672942161560059, -5.069029808044434, 0.5790271759033203, -2.950510025024414, 1.1566450595855713, 0.23558759689331055, 1.2164111137390137, 0.09158134460449219, 1.4105033874511719, 2.491140365600586, 0.8011970520019531, 1.89638090133667, 1.0506935119628906, 1.0239219665527344, 2.201169967651367, 0.20087814331054688, -1.3403244018554688, 2.8405323028564453, -0.00740814208984375, 1.4495840072631836, -1.9879798889160156, 0.16790199279785156, -0.21960163116455078, 1.7268943786621094, -0.052127838134765625, -8.143789291381836, -0.8703937530517578, 0.632298469543457, 1.3835525512695312, 1.0812931060791016, -0.015501022338867188, -9.162199020385742, 1.2791467905044556, 0.7593202590942383, -11.882711410522461, -1.234248161315918, 0.4868316650390625, -4.910322666168213, 0.4234962463378906, 1.6340551376342773, -0.5665829181671143, 0.2106618881225586, 0.8471236228942871, -0.04925727844238281, 0.7681341171264648, -1.680466651916504], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 25600, "num_env_steps_trained": 46200, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 46200, "last_target_update_ts": 25600, "num_target_updates": 49}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -335.1997409245232, "episode_len_mean": 356.984375, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5100893635116717, "mean_inference_ms": 23.137717511398453, "mean_action_processing_ms": 0.13898447057113475, "mean_env_wait_ms": 4.489548385806398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -335.1997409245232, "episode_len_mean": 356.984375, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5100893635116717, "mean_inference_ms": 23.137717511398453, "mean_action_processing_ms": 0.13898447057113475, "mean_env_wait_ms": 4.489548385806398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 46200, "num_env_steps_sampled": 25600, "num_env_steps_trained": 46200, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 25600, "agent_timesteps_total": 25600, "timers": {"training_iteration_time_ms": 308.498, "learn_time_ms": 57.896, "learn_throughput": 2072.666, "synch_weights_time_ms": 20.007}, "counters": {"num_env_steps_sampled": 25600, "num_env_steps_trained": 46200, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 46200, "last_target_update_ts": 25600, "num_target_updates": 49}, "done": false, "episodes_total": 64, "training_iteration": 25, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-49", "timestamp": 1655476009, "time_this_iter_s": 4.798169374465942, "time_total_s": 119.07270431518555, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 119.07270431518555, "timesteps_since_restore": 0, "iterations_since_restore": 25, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.02857142857143, "ram_util_percent": 60.142857142857146}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -11.020171165466309, "min_q": -30.78461265563965, "max_q": 24.433290481567383, "mean_td_error": -1.7685546875}, "td_error": [-22.548912048339844, 0.5599498748779297, 0.09997940063476562, -1.1100883483886719, -8.060897827148438, -1.9506168365478516, 1.7809953689575195, -10.949125289916992, -0.22508621215820312, 1.2761802673339844, -0.6834335327148438, -4.899252891540527, -1.6195011138916016, -23.512853622436523, -2.265871047973633, -0.599395751953125, -1.8853421211242676, -0.1426830291748047, -1.758030891418457, -1.7960232496261597, 2.312262535095215, -0.9791221618652344, -5.4526143074035645, 0.961212158203125, 1.1933708190917969, -1.5419015884399414, -9.758031845092773, 2.9646167755126953, -3.552335739135742, -0.29793548583984375, 1.064138412475586, -0.599395751953125, -0.8454217910766602, -10.794818878173828, -1.3858051300048828, 0.40969085693359375, 0.03209114074707031, -4.961170196533203, -1.2587270736694336, -3.967498779296875, 0.9754447937011719, -0.05330538749694824, -2.899789810180664, -1.7464756965637207, -1.3872578144073486, -0.6797332763671875, 0.4717369079589844, 0.07703399658203125, -1.8356952667236328, -9.158468246459961, -0.5165653228759766, -3.2494418621063232, -2.2448666095733643, -1.3488006591796875, 2.7447214126586914, 0.2639520764350891, -0.73046875, -1.7822997570037842, 0.7803688049316406, 0.9796504974365234, 1.973388671875, -8.357735633850098, -0.5855827331542969, 1.1505184173583984, 0.520421028137207, 1.0741243362426758, -1.3565168380737305, 1.4443509578704834, -2.2448666095733643, 0.8155734539031982, 1.6225776672363281, -1.8373546600341797, -3.790384292602539, 1.8523640632629395, 0.9692592620849609, -2.4852867126464844, 1.3030019998550415, -1.8234338760375977, -6.047463417053223, -2.188483238220215, -2.0737314224243164, -0.4187335968017578, -2.3884992599487305, -1.37469482421875, -0.3139934539794922, -1.1441335678100586, -0.5629825592041016, -8.397405624389648, -1.921351432800293, -4.880373954772949, 0.47194862365722656, -0.11181640625, -2.710721969604492, -4.6132659912109375, 2.0987205505371094, -0.9143037796020508, 0.5521745681762695, 1.2633848190307617, -7.708033561706543, 0.08104658126831055, -0.2827467918395996, -1.8241472244262695, -0.599395751953125, 0.025076866149902344, 0.21601295471191406, -1.1858339309692383, 1.3800373077392578, -1.2049331665039062, -1.7230892181396484, 1.9132232666015625, 0.1809062957763672, 0.04404258728027344, -0.14370346069335938, 0.07735824584960938, -4.710472106933594, 1.749563217163086, -1.219529151916504, -11.615127563476562, -0.9899044036865234, -1.1679515838623047], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 26624, "num_env_steps_trained": 48120, "num_agent_steps_sampled": 26624, "num_agent_steps_trained": 48120, "last_target_update_ts": 26624, "num_target_updates": 51}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -332.5007953729767, "episode_len_mean": 356.1384615384615, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5102489011455312, "mean_inference_ms": 23.150012670732927, "mean_action_processing_ms": 0.1391090093421101, "mean_env_wait_ms": 4.4848132029202645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -332.5007953729767, "episode_len_mean": 356.1384615384615, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5102489011455312, "mean_inference_ms": 23.150012670732927, "mean_action_processing_ms": 0.1391090093421101, "mean_env_wait_ms": 4.4848132029202645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 26624, "num_agent_steps_trained": 48120, "num_env_steps_sampled": 26624, "num_env_steps_trained": 48120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 26624, "agent_timesteps_total": 26624, "timers": {"training_iteration_time_ms": 306.401, "learn_time_ms": 58.071, "learn_throughput": 2066.453, "synch_weights_time_ms": 19.839}, "counters": {"num_env_steps_sampled": 26624, "num_env_steps_trained": 48120, "num_agent_steps_sampled": 26624, "num_agent_steps_trained": 48120, "last_target_update_ts": 26624, "num_target_updates": 51}, "done": false, "episodes_total": 65, "training_iteration": 26, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-54", "timestamp": 1655476014, "time_this_iter_s": 4.7704949378967285, "time_total_s": 123.84319925308228, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 123.84319925308228, "timesteps_since_restore": 0, "iterations_since_restore": 26, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.771428571428572, "ram_util_percent": 60.25714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -12.730961799621582, "min_q": -31.177268981933594, "max_q": 26.56183624267578, "mean_td_error": -2.895949602127075}, "td_error": [-1.2982444763183594, -1.8448691368103027, -10.379581451416016, -1.4986896514892578, -3.6556968688964844, -3.8922996520996094, -2.6985301971435547, -1.4862957000732422, -1.2145462036132812, -8.403054237365723, -2.385200262069702, -3.7978153228759766, -0.06491470336914062, -1.3406505584716797, 0.09623527526855469, -1.8575775623321533, -0.7743148803710938, 0.3794822692871094, -1.281148910522461, 1.062887191772461, 1.031935691833496, -3.3841381072998047, -0.15285110473632812, -0.8985910415649414, -2.5238523483276367, -1.0904064178466797, -0.21782302856445312, -22.20733070373535, 0.3534584045410156, -0.7582855224609375, -1.9592313766479492, 0.2115182876586914, -2.9621477127075195, -1.4240455627441406, -1.4246530532836914, -0.227508544921875, -0.19072914123535156, -0.6277937889099121, -1.2792491912841797, -5.654889106750488, -1.1923332214355469, -2.679781913757324, -1.415700912475586, -3.9251413345336914, -0.9967632293701172, -2.454082489013672, -7.464937210083008, -0.9967632293701172, -3.111495018005371, -8.881165504455566, -1.7958850860595703, -2.284428834915161, -1.1593761444091797, -0.990692138671875, -4.910655975341797, -1.2654857635498047, -24.01394271850586, -3.691822052001953, -2.656508445739746, -1.2128143310546875, -2.2606191635131836, -1.3626041412353516, -1.494910478591919, -1.9177589416503906, -0.7017955780029297, -3.7545013427734375, -25.37553596496582, -0.9536190032958984, -4.545177459716797, -2.861098289489746, -0.33322739601135254, -3.159036636352539, -0.07661175727844238, -4.465527534484863, -6.484988212585449, 0.5962581634521484, -2.849212646484375, -4.830531120300293, -1.3406505584716797, -0.8468294143676758, -0.2414240837097168, -3.5892391204833984, -25.37553596496582, -1.2004070281982422, -5.793536186218262, -1.6319656372070312, -0.7928003072738647, -2.714385986328125, -3.0728511810302734, 0.5666184425354004, -3.016238212585449, -2.0913429260253906, 0.038039207458496094, -1.4709300994873047, -0.21320152282714844, -1.5919952392578125, -4.443647861480713, 0.9442234039306641, -3.119196891784668, -1.5636043548583984, -2.7748985290527344, -6.349447250366211, 0.3959827423095703, -2.0745787620544434, -10.317163467407227, -1.4669132232666016, 0.6254768371582031, -1.4709300994873047, -6.582701683044434, -2.651998519897461, -0.10779762268066406, -1.279531478881836, 0.4877033233642578, -7.950438499450684, -1.296010971069336, -1.8678264617919922, -0.7017955780029297, 1.0321903228759766, 0.9481792449951172, -5.898836612701416], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 27648, "num_env_steps_trained": 50040, "num_agent_steps_sampled": 27648, "num_agent_steps_trained": 50040, "last_target_update_ts": 27648, "num_target_updates": 53}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -329.2397489733438, "episode_len_mean": 355.5970149253731, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5100307762565646, "mean_inference_ms": 23.160537914462072, "mean_action_processing_ms": 0.1388480448811006, "mean_env_wait_ms": 4.470051143327165, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -329.2397489733438, "episode_len_mean": 355.5970149253731, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5100307762565646, "mean_inference_ms": 23.160537914462072, "mean_action_processing_ms": 0.1388480448811006, "mean_env_wait_ms": 4.470051143327165, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 27648, "num_agent_steps_trained": 50040, "num_env_steps_sampled": 27648, "num_env_steps_trained": 50040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 27648, "agent_timesteps_total": 27648, "timers": {"training_iteration_time_ms": 321.809, "learn_time_ms": 58.246, "learn_throughput": 2060.234, "synch_weights_time_ms": 20.083}, "counters": {"num_env_steps_sampled": 27648, "num_env_steps_trained": 50040, "num_agent_steps_sampled": 27648, "num_agent_steps_trained": 50040, "last_target_update_ts": 27648, "num_target_updates": 53}, "done": false, "episodes_total": 67, "training_iteration": 27, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-26-59", "timestamp": 1655476019, "time_this_iter_s": 5.024870872497559, "time_total_s": 128.86807012557983, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 128.86807012557983, "timesteps_since_restore": 0, "iterations_since_restore": 27, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.27142857142857, "ram_util_percent": 60.42857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -10.508787155151367, "min_q": -33.95602035522461, "max_q": 28.01654052734375, "mean_td_error": -1.0265886783599854}, "td_error": [-2.728790283203125, -4.13989782333374, 0.553095817565918, -0.04911041259765625, -3.506669521331787, -2.6833438873291016, -2.5078611373901367, -1.0769329071044922, -2.103663444519043, 0.8429698944091797, 0.5772991180419922, -0.7265586853027344, -1.2455215454101562, -2.5233802795410156, -3.2466273307800293, -1.9605340957641602, -1.3505496978759766, 1.349623441696167, 2.7676916122436523, 0.9183254241943359, -3.218761444091797, -2.092836380004883, -0.42731666564941406, -1.041332721710205, 0.05122947692871094, 0.5738000869750977, -2.130338668823242, 0.45766258239746094, 0.6350183486938477, -0.9690208435058594, -2.3691482543945312, -0.40639495849609375, 0.9308137893676758, 0.18239974975585938, -3.6204423904418945, -9.10520076751709, 0.1589064598083496, 1.5461759567260742, -0.17195701599121094, -2.2402544021606445, -1.233489990234375, -1.685760498046875, -6.301271438598633, -1.0507774353027344, -1.5757389068603516, -0.030893325805664062, 0.023286819458007812, -0.7673091888427734, 0.3846144676208496, -0.7841033935546875, -0.053760528564453125, -0.4954414367675781, -0.09928321838378906, 1.4848709106445312, -1.1286430358886719, 0.985198974609375, -0.628570556640625, -0.6976413726806641, -0.663543701171875, -0.3901796340942383, 0.9263687133789062, 0.6822118759155273, -0.8481216430664062, 0.8196182250976562, 0.5357131958007812, 0.13732147216796875, 0.29255104064941406, -15.551666259765625, -2.041083574295044, -2.9758739471435547, 0.1970386505126953, 0.49300289154052734, -0.06829643249511719, -0.7135086059570312, 0.5788860321044922, -0.052032470703125, 1.5853614807128906, -0.7147449254989624, -1.8106393814086914, -2.8670196533203125, -0.6961393356323242, -2.850767135620117, 1.4138140678405762, 0.6991977691650391, 0.0414276123046875, -0.9077491760253906, 0.38265466690063477, 5.044432640075684, -7.1051435470581055, 1.799081802368164, -10.268470764160156, -0.4587287902832031, 1.0239057540893555, -1.7660757303237915, -3.386500358581543, 0.4626922607421875, -1.2440299987792969, -0.6732826232910156, -4.95625638961792, -17.78578758239746, -1.231393814086914, -4.543369293212891, -1.750112533569336, 12.526721954345703, 0.16149413585662842, -2.2209410667419434, -0.523406982421875, -0.3333702087402344, -1.0292634963989258, 1.0239057540893555, 0.008634567260742188, 0.5250835418701172, 0.1651477813720703, -2.870603561401367, 0.7283563613891602, -0.184844970703125, -1.7230033874511719, 0.7743220329284668, 0.1835479736328125, 0.5549564361572266], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 28672, "num_env_steps_trained": 51960, "num_agent_steps_sampled": 28672, "num_agent_steps_trained": 51960, "last_target_update_ts": 28672, "num_target_updates": 55}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -329.31185526166644, "episode_len_mean": 355.9142857142857, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5093748135002788, "mean_inference_ms": 23.222702186724796, "mean_action_processing_ms": 0.13856757845663267, "mean_env_wait_ms": 4.451719430200515, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -329.31185526166644, "episode_len_mean": 355.9142857142857, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5093748135002788, "mean_inference_ms": 23.222702186724796, "mean_action_processing_ms": 0.13856757845663267, "mean_env_wait_ms": 4.451719430200515, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 28672, "num_agent_steps_trained": 51960, "num_env_steps_sampled": 28672, "num_env_steps_trained": 51960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 28672, "agent_timesteps_total": 28672, "timers": {"training_iteration_time_ms": 315.941, "learn_time_ms": 57.961, "learn_throughput": 2070.375, "synch_weights_time_ms": 19.883}, "counters": {"num_env_steps_sampled": 28672, "num_env_steps_trained": 51960, "num_agent_steps_sampled": 28672, "num_agent_steps_trained": 51960, "last_target_update_ts": 28672, "num_target_updates": 55}, "done": false, "episodes_total": 70, "training_iteration": 28, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-04", "timestamp": 1655476024, "time_this_iter_s": 5.069749355316162, "time_total_s": 133.937819480896, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 133.937819480896, "timesteps_since_restore": 0, "iterations_since_restore": 28, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.342857142857145, "ram_util_percent": 60.557142857142864}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -12.308130264282227, "min_q": -36.14621353149414, "max_q": 23.01085662841797, "mean_td_error": -0.2775912582874298}, "td_error": [-0.15920257568359375, 0.17237377166748047, 2.7827816009521484, 0.3825855255126953, -7.070990085601807, 0.15963363647460938, -1.8169021606445312, 0.9043540954589844, -9.749800682067871, -0.3935699462890625, 0.7724158763885498, -5.223726272583008, -0.29639625549316406, -1.4976577758789062, 0.43368053436279297, -1.0787556171417236, 0.17460918426513672, -1.7643532752990723, 0.8175067901611328, 0.4785423278808594, -0.3370041847229004, 0.7261219024658203, 0.24517822265625, 1.4785404205322266, -0.023773193359375, 0.6284503936767578, -2.9198079109191895, -7.163140296936035, 0.08214759826660156, -0.15386581420898438, -1.962188720703125, -0.17424774169921875, 0.9244956970214844, 1.2071819305419922, 0.7358875274658203, 1.5541949272155762, -0.024271011352539062, 0.5249118804931641, -0.5567855834960938, 2.1590187549591064, 0.9425621032714844, 0.4801959991455078, 0.4801959991455078, 0.5646152496337891, -0.45003700256347656, 1.3999929428100586, 0.8734333515167236, -2.700545310974121, 0.5406303405761719, 2.449472427368164, -5.805395126342773, 0.9302730560302734, 0.007832169532775879, 0.6960716247558594, 0.15059852600097656, 0.02791595458984375, 0.35668373107910156, -0.572941780090332, 0.8261222839355469, 1.3184375762939453, 0.30767154693603516, 0.07218742370605469, 0.2381744384765625, 0.2942075729370117, 1.5455493927001953, 0.5604667663574219, -0.21509838104248047, 2.3096818923950195, 0.8194713592529297, -0.061870574951171875, -3.1659603118896484, -0.04295063018798828, 3.5369796752929688, -5.865535736083984, 1.8902614116668701, 1.5397186279296875, 0.0167694091796875, 0.2644176483154297, 0.8469295501708984, 0.7822177410125732, 0.9339399337768555, 1.177175521850586, -0.5133275985717773, 0.29254913330078125, -0.6293983459472656, 0.033596038818359375, 0.5405845642089844, -1.8472552299499512, 1.6626012325286865, 1.340296745300293, -3.4371204376220703, 0.44649696350097656, -0.7214193344116211, -8.390434265136719, -7.941991329193115, 0.9266033172607422, -1.858119010925293, 0.4338703155517578, 0.5119972229003906, 0.8946666717529297, 0.4608316421508789, 0.3920001983642578, -1.6556816101074219, -0.6523590087890625, 1.235342025756836, 3.383739471435547, 1.1001278162002563, -0.09806346893310547, -1.7363672256469727, -0.28035926818847656, -0.22610759735107422, -0.9938229322433472, -3.6847400665283203, 1.0017662048339844, 1.7638087272644043, 0.7277889251708984, 0.8302059173583984, -1.1400656700134277, 2.520244598388672, -3.2821311950683594], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 29696, "num_env_steps_trained": 53880, "num_agent_steps_sampled": 29696, "num_agent_steps_trained": 53880, "last_target_update_ts": 29696, "num_target_updates": 57}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -337.97496899697734, "episode_len_mean": 358.4342105263158, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5071573272262965, "mean_inference_ms": 23.310874231874966, "mean_action_processing_ms": 0.13858459058753397, "mean_env_wait_ms": 4.413382778651542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -337.97496899697734, "episode_len_mean": 358.4342105263158, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5071573272262965, "mean_inference_ms": 23.310874231874966, "mean_action_processing_ms": 0.13858459058753397, "mean_env_wait_ms": 4.413382778651542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 29696, "num_agent_steps_trained": 53880, "num_env_steps_sampled": 29696, "num_env_steps_trained": 53880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 29696, "agent_timesteps_total": 29696, "timers": {"training_iteration_time_ms": 315.942, "learn_time_ms": 58.712, "learn_throughput": 2043.882, "synch_weights_time_ms": 20.2}, "counters": {"num_env_steps_sampled": 29696, "num_env_steps_trained": 53880, "num_agent_steps_sampled": 29696, "num_agent_steps_trained": 53880, "last_target_update_ts": 29696, "num_target_updates": 57}, "done": false, "episodes_total": 76, "training_iteration": 29, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-10", "timestamp": 1655476030, "time_this_iter_s": 5.217441082000732, "time_total_s": 139.15526056289673, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 139.15526056289673, "timesteps_since_restore": 0, "iterations_since_restore": 29, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.799999999999997, "ram_util_percent": 60.7625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -10.887892723083496, "min_q": -38.8702278137207, "max_q": 29.128324508666992, "mean_td_error": -0.24203893542289734}, "td_error": [0.9027214050292969, 1.1095037460327148, 1.3066864013671875, 0.39232397079467773, 0.14283740520477295, 0.44820308685302734, 0.6977119445800781, -1.7250709533691406, 1.0108575820922852, 0.44366455078125, -4.819704055786133, -7.493362903594971, -0.01587677001953125, 1.0680961608886719, 2.1479616165161133, 2.6071510314941406, 1.450474500656128, -2.558340072631836, 0.34422779083251953, -0.2838325500488281, 0.10957717895507812, -0.12676048278808594, -4.163725852966309, -0.31507301330566406, 2.28955078125, -0.2852604389190674, -0.12420654296875, 1.5898189544677734, -3.810563564300537, 0.8379579186439514, -1.8801002502441406, 2.726853370666504, 0.1082916259765625, -1.1975054740905762, 1.269357681274414, -1.9689021110534668, 1.0931930541992188, 1.3491439819335938, -1.960216999053955, -0.8153295516967773, 2.521280288696289, -1.1272926330566406, 0.3352317810058594, 0.09067344665527344, 1.5564498901367188, -1.1347389221191406, 1.7403488159179688, -1.5317058563232422, -1.1570415496826172, -3.886199951171875, -5.011110782623291, 2.4193954467773438, -1.9980907440185547, 1.5115375518798828, -0.10845184326171875, 0.7788142561912537, 1.1257286071777344, 0.2544898986816406, -8.670852661132812, 1.3006811141967773, 0.23956680297851562, 0.5803170204162598, 1.309614658355713, 2.0604605674743652, -0.4924888610839844, 0.12066650390625, -0.9766578674316406, -0.7523479461669922, -0.3313331604003906, -6.817163467407227, -5.118704795837402, -0.2665672302246094, 1.4052181243896484, -0.3489971160888672, 0.5742998123168945, -0.6466770172119141, 1.2197494506835938, 1.9491496086120605, 0.615229606628418, 0.10602569580078125, 0.3133506774902344, 2.2614917755126953, -0.006229400634765625, 0.4002952575683594, -0.7768282890319824, 1.2623200416564941, -1.117818832397461, 1.6949043273925781, -9.95437240600586, -0.44605445861816406, -0.735260009765625, 1.29595947265625, 1.9588422775268555, -0.3568267822265625, -1.7744770050048828, 2.91166353225708, 2.604489803314209, -1.0713510513305664, 6.600790023803711, -1.7873802185058594, 2.4044837951660156, 3.0566272735595703, -4.968636512756348, -2.4213409423828125, -0.775911808013916, -2.194713592529297, -0.8419537544250488, -3.843142509460449, 1.5333290100097656, 0.8188009262084961, -0.5309810638427734, -2.1852235794067383, 1.0202065706253052, -0.8036079406738281, -0.05545616149902344, 0.4593467712402344, -1.1266899108886719, 2.4780454635620117, 0.6986627578735352, -0.38486480712890625], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 30720, "num_env_steps_trained": 55800, "num_agent_steps_sampled": 30720, "num_agent_steps_trained": 55800, "last_target_update_ts": 30720, "num_target_updates": 59}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -344.51147272977977, "episode_len_mean": 360.5125, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5048883532486464, "mean_inference_ms": 23.351456635927264, "mean_action_processing_ms": 0.13832846251609365, "mean_env_wait_ms": 4.390445250542861, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -344.51147272977977, "episode_len_mean": 360.5125, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5048883532486464, "mean_inference_ms": 23.351456635927264, "mean_action_processing_ms": 0.13832846251609365, "mean_env_wait_ms": 4.390445250542861, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 30720, "num_agent_steps_trained": 55800, "num_env_steps_sampled": 30720, "num_env_steps_trained": 55800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 30720, "agent_timesteps_total": 30720, "timers": {"training_iteration_time_ms": 307.946, "learn_time_ms": 58.166, "learn_throughput": 2063.049, "synch_weights_time_ms": 19.888}, "counters": {"num_env_steps_sampled": 30720, "num_env_steps_trained": 55800, "num_agent_steps_sampled": 30720, "num_agent_steps_trained": 55800, "last_target_update_ts": 30720, "num_target_updates": 59}, "done": false, "episodes_total": 80, "training_iteration": 30, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-15", "timestamp": 1655476035, "time_this_iter_s": 4.922240734100342, "time_total_s": 144.07750129699707, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 144.07750129699707, "timesteps_since_restore": 0, "iterations_since_restore": 30, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.857142857142858, "ram_util_percent": 60.98571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -10.8302001953125, "min_q": -39.618080139160156, "max_q": 29.43520736694336, "mean_td_error": -0.6411697864532471}, "td_error": [0.029588699340820312, -0.1811976432800293, -1.6435332298278809, -0.39022254943847656, 1.7971649169921875, -1.1001911163330078, -0.28314781188964844, -1.2241058349609375, 0.7331693172454834, -1.7962849140167236, 0.6713428497314453, -0.00946807861328125, -0.5084323883056641, 0.8118839263916016, 0.21863937377929688, -4.865875244140625, -0.4865074157714844, -0.8781070709228516, -1.0283756256103516, -0.06789326667785645, -0.9954948425292969, -6.965036392211914, 0.1048746109008789, -0.3385639190673828, -0.8350391387939453, 0.4371757507324219, 1.02569580078125, 1.9662485122680664, 1.585641860961914, -4.136956214904785, 0.0714864730834961, 1.1798810958862305, -4.6917266845703125, 1.8956565856933594, -0.6656756401062012, 0.05202484130859375, 0.33982372283935547, 2.0233545303344727, 0.9148921966552734, 0.07881450653076172, 0.6568293571472168, -4.167425155639648, 1.3357219696044922, -0.3363971710205078, -1.5028629302978516, 0.9028606414794922, 1.6513595581054688, -2.7495946884155273, -2.20438814163208, -1.1497116088867188, 1.4282033443450928, -0.3220481872558594, 0.03963661193847656, -6.078910827636719, 0.9155149459838867, -2.536017894744873, -1.6454811096191406, 0.9209575653076172, -1.3738937377929688, -1.0786018371582031, 0.00247955322265625, -0.9990940093994141, -0.07543182373046875, 0.5685310363769531, 0.7661533355712891, 0.07056903839111328, -2.7357988357543945, -0.08791399002075195, 1.585637092590332, 1.0339365005493164, 3.227569580078125, 0.5275115966796875, 1.036102294921875, -0.4883079528808594, 0.4242095947265625, -0.030323028564453125, 1.9640436172485352, -2.8216400146484375, 2.2415008544921875, -0.5002288818359375, -3.6583266258239746, -2.74273681640625, -0.25928688049316406, -4.478569030761719, 1.3511583805084229, 0.4876370429992676, -0.8180198669433594, -0.2764244079589844, -0.7296352386474609, -1.5342254638671875, -0.07442188262939453, -20.13274574279785, -1.9834752082824707, -0.5349330902099609, -2.7958755493164062, -1.4113292694091797, -3.3578662872314453, 0.4259681701660156, 1.5330560207366943, -8.135587692260742, 0.6665382385253906, -3.0085902214050293, -2.818110466003418, 11.408195495605469, -3.7370452880859375, -0.7700619697570801, -1.0401248931884766, 0.004055023193359375, -0.06827926635742188, -0.42404937744140625, 4.6710205078125, 0.6380901336669922, 0.18724822998046875, 0.03963661193847656, -0.8363609313964844, -0.3619518280029297, 0.3261451721191406, -0.8458766937255859, -3.557485580444336, 0.4514932632446289], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 31744, "num_env_steps_trained": 57720, "num_agent_steps_sampled": 31744, "num_agent_steps_trained": 57720, "last_target_update_ts": 31744, "num_target_updates": 61}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -344.51147272977977, "episode_len_mean": 360.5125, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5048883532486464, "mean_inference_ms": 23.351456635927264, "mean_action_processing_ms": 0.13832846251609365, "mean_env_wait_ms": 4.390445250542861, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -344.51147272977977, "episode_len_mean": 360.5125, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5048883532486464, "mean_inference_ms": 23.351456635927264, "mean_action_processing_ms": 0.13832846251609365, "mean_env_wait_ms": 4.390445250542861, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 31744, "num_agent_steps_trained": 57720, "num_env_steps_sampled": 31744, "num_env_steps_trained": 57720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 31744, "agent_timesteps_total": 31744, "timers": {"training_iteration_time_ms": 296.669, "learn_time_ms": 58.384, "learn_throughput": 2055.347, "synch_weights_time_ms": 19.79}, "counters": {"num_env_steps_sampled": 31744, "num_env_steps_trained": 57720, "num_agent_steps_sampled": 31744, "num_agent_steps_trained": 57720, "last_target_update_ts": 31744, "num_target_updates": 61}, "done": false, "episodes_total": 80, "training_iteration": 31, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-19", "timestamp": 1655476039, "time_this_iter_s": 4.740809679031372, "time_total_s": 148.81831097602844, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 148.81831097602844, "timesteps_since_restore": 0, "iterations_since_restore": 31, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.871428571428574, "ram_util_percent": 61.01428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -11.801657676696777, "min_q": -41.0086784362793, "max_q": 20.246610641479492, "mean_td_error": -1.1593071222305298}, "td_error": [-0.39989662170410156, -2.707282066345215, -5.54755973815918, 0.2962961196899414, 2.204474449157715, -0.03879547119140625, 1.3529706001281738, 1.2903127670288086, -0.8976573944091797, -7.4666314125061035, 0.7207603454589844, -1.4845008850097656, -0.022182464599609375, -0.8423423767089844, 1.7755260467529297, -0.23996639251708984, 0.2595863342285156, -2.2239513397216797, 2.372957229614258, -0.2662353515625, -1.8156166076660156, -0.021593093872070312, 2.5873935222625732, -1.8880538940429688, -0.7224807739257812, 1.0700502395629883, -2.5396065711975098, -0.1564478874206543, -1.0423774719238281, 1.9711112976074219, -0.2667050361633301, -1.0944385528564453, 1.733612060546875, 2.1928911209106445, -10.578139305114746, 6.5472493171691895, -0.13840341567993164, -1.719420313835144, 0.017076492309570312, -1.0913352966308594, -10.245988845825195, 1.7586517333984375, 0.4099082946777344, -2.6942849159240723, -1.7460050582885742, -1.4455986022949219, 0.7893619537353516, 0.8040299415588379, -1.2874374389648438, -18.683866500854492, -1.342747688293457, -0.4054450988769531, -1.0160131454467773, -1.6732673645019531, 1.5789356231689453, -0.9767036437988281, 1.7645044326782227, -10.267801284790039, -1.4803905487060547, -0.4005088806152344, -8.763500213623047, 0.20824813842773438, -1.4527740478515625, -0.3313159942626953, -1.1456937789916992, -6.281518936157227, 0.6986265182495117, -2.1783790588378906, 0.2595863342285156, -1.2211780548095703, 0.6986265182495117, -0.8803424835205078, 0.31591033935546875, 0.21263504028320312, 0.054943084716796875, 0.642977237701416, 0.3781909942626953, 2.624208450317383, -3.307880401611328, 0.3224329948425293, -0.6450740098953247, -1.181417465209961, -1.4918622970581055, -7.656471252441406, 2.956054210662842, -0.3612804412841797, -0.5092849731445312, 0.9539566040039062, 1.3981118202209473, 0.3780231475830078, 0.21547317504882812, -4.680641174316406, 0.9319839477539062, -3.9463539123535156, -2.848400115966797, -1.0115413665771484, -2.152853012084961, -1.852297306060791, 2.995166063308716, -1.0556955337524414, -0.22057342529296875, 0.5441570281982422, 0.19596195220947266, 0.7850303649902344, -0.018774032592773438, -4.577407360076904, -4.010246276855469, -0.04536914825439453, 0.2951641082763672, 0.12893295288085938, -0.41127800941467285, -0.7476863861083984, -7.143662452697754, -0.4473233222961426, -0.7822952270507812, -5.291665077209473, -3.623849868774414, -0.8600521087646484, 1.803227424621582, -10.598528861999512], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 32768, "num_env_steps_trained": 59640, "num_agent_steps_sampled": 32768, "num_agent_steps_trained": 59640, "last_target_update_ts": 32768, "num_target_updates": 63}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -343.1626442745328, "episode_len_mean": 359.5731707317073, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.505098197056643, "mean_inference_ms": 23.383236229219026, "mean_action_processing_ms": 0.1382324720361659, "mean_env_wait_ms": 4.384723959856546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -343.1626442745328, "episode_len_mean": 359.5731707317073, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.505098197056643, "mean_inference_ms": 23.383236229219026, "mean_action_processing_ms": 0.1382324720361659, "mean_env_wait_ms": 4.384723959856546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 32768, "num_agent_steps_trained": 59640, "num_env_steps_sampled": 32768, "num_env_steps_trained": 59640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 32768, "agent_timesteps_total": 32768, "timers": {"training_iteration_time_ms": 321.189, "learn_time_ms": 59.307, "learn_throughput": 2023.372, "synch_weights_time_ms": 20.096}, "counters": {"num_env_steps_sampled": 32768, "num_env_steps_trained": 59640, "num_agent_steps_sampled": 32768, "num_agent_steps_trained": 59640, "last_target_update_ts": 32768, "num_target_updates": 63}, "done": false, "episodes_total": 82, "training_iteration": 32, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-24", "timestamp": 1655476044, "time_this_iter_s": 4.893289804458618, "time_total_s": 153.71160078048706, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 153.71160078048706, "timesteps_since_restore": 0, "iterations_since_restore": 32, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 61.17142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -11.869054794311523, "min_q": -41.440696716308594, "max_q": 28.623632431030273, "mean_td_error": 0.0482412725687027}, "td_error": [-1.2079830169677734, -0.9960260391235352, 1.5138444900512695, 0.8507966995239258, -0.08823776245117188, -1.5199146270751953, 0.5941035747528076, -1.4767837524414062, 1.0198345184326172, 2.45037841796875, 1.570516586303711, -0.3701972961425781, 1.175847053527832, 4.440042018890381, -1.279144287109375, 1.1588401794433594, 1.1289005279541016, 1.0505361557006836, -2.0638389587402344, -2.438337802886963, 0.696319580078125, 0.9039783477783203, 0.21853256225585938, 3.911815643310547, 0.17422962188720703, 0.4634227752685547, 1.55487060546875, 1.0414319038391113, 0.7742691040039062, 0.695220947265625, 0.8868885040283203, 1.557952880859375, -6.584196090698242, -3.0667572021484375, 0.8545253276824951, 0.7781367301940918, 0.4740619659423828, 0.7742691040039062, 0.4369964599609375, 1.8816947937011719, -2.7448959350585938, 1.282700538635254, 1.0464427471160889, -1.6128077507019043, 1.1524028778076172, 1.970529556274414, -0.3410186767578125, 0.7784957885742188, -1.5206985473632812, 0.6600303649902344, -0.001781463623046875, 0.5481071472167969, 0.5455436706542969, 1.101297378540039, 0.29387664794921875, -8.839788436889648, -0.6710758209228516, -1.4435895681381226, 3.430535316467285, 0.115753173828125, 1.504852294921875, 2.336315155029297, -1.5126392841339111, -2.0916881561279297, 0.7642220258712769, -0.057605743408203125, 0.3057670593261719, -0.0973358154296875, 0.7784957885742188, -4.614599227905273, -0.2108478546142578, -0.036869049072265625, 1.7494373321533203, 0.5238132476806641, -1.787550926208496, -3.036264419555664, 0.04449462890625, 1.2207860946655273, 1.3119134902954102, -2.945786237716675, -0.05987739562988281, 0.13191890716552734, 0.09958839416503906, 1.097489356994629, -0.3971366882324219, 1.3135448694229126, -0.036869049072265625, 2.031341552734375, 2.2462329864501953, -0.01692962646484375, 0.2167520523071289, 0.2819786071777344, 0.46024322509765625, 0.8703505992889404, 0.8335185050964355, -3.442415237426758, -4.79611873626709, 1.654003620147705, 1.0268020629882812, -0.5878143310546875, 1.0905017852783203, -0.6532726287841797, -1.7069759368896484, 0.9181623458862305, -0.127105712890625, 0.3850975036621094, -0.8898820877075195, -3.142106056213379, 0.9207496643066406, 0.3850975036621094, 1.3269615173339844, -5.680023193359375, -0.2546367645263672, 0.10036373138427734, 0.794097900390625, 2.1421165466308594, 0.20334529876708984, 2.6229286193847656, -0.7465019226074219, 1.3336219787597656], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 33792, "num_env_steps_trained": 61560, "num_agent_steps_sampled": 33792, "num_agent_steps_trained": 61560, "last_target_update_ts": 33792, "num_target_updates": 65}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -336.2784009593171, "episode_len_mean": 357.4767441860465, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.504509701179609, "mean_inference_ms": 23.42625180777015, "mean_action_processing_ms": 0.1383101626639255, "mean_env_wait_ms": 4.367364959665631, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -336.2784009593171, "episode_len_mean": 357.4767441860465, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.504509701179609, "mean_inference_ms": 23.42625180777015, "mean_action_processing_ms": 0.1383101626639255, "mean_env_wait_ms": 4.367364959665631, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 33792, "num_agent_steps_trained": 61560, "num_env_steps_sampled": 33792, "num_env_steps_trained": 61560, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 33792, "agent_timesteps_total": 33792, "timers": {"training_iteration_time_ms": 333.997, "learn_time_ms": 59.779, "learn_throughput": 2007.405, "synch_weights_time_ms": 19.889}, "counters": {"num_env_steps_sampled": 33792, "num_env_steps_trained": 61560, "num_agent_steps_sampled": 33792, "num_agent_steps_trained": 61560, "last_target_update_ts": 33792, "num_target_updates": 65}, "done": false, "episodes_total": 86, "training_iteration": 33, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-30", "timestamp": 1655476050, "time_this_iter_s": 5.215294599533081, "time_total_s": 158.92689538002014, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 158.92689538002014, "timesteps_since_restore": 0, "iterations_since_restore": 33, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.3, "ram_util_percent": 61.287499999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -14.460097312927246, "min_q": -44.92308807373047, "max_q": 30.25022315979004, "mean_td_error": -1.4524391889572144}, "td_error": [-1.9326540231704712, -2.189457893371582, -0.07343292236328125, -0.4533500671386719, -0.7373589277267456, 1.0505189895629883, -0.4774608612060547, 0.31422996520996094, 0.39205169677734375, -1.9970436096191406, 0.21493148803710938, -0.7635002136230469, -0.37450599670410156, -8.071582794189453, -5.612064361572266, -0.8988981246948242, 2.5002222061157227, 1.0203490257263184, -6.652699947357178, -0.047657012939453125, -4.072762966156006, -9.640886306762695, -0.8254299163818359, -1.3013811111450195, -1.4501657485961914, 1.3356609344482422, -3.551013946533203, -4.19499397277832, 0.34784698486328125, 1.7818593978881836, -3.6537137031555176, -1.8499088287353516, -0.20411014556884766, -5.399162292480469, -1.106191635131836, -2.939756393432617, -0.047657012939453125, -0.4942535161972046, -5.448491096496582, -1.3995451927185059, -0.39850616455078125, -5.115291595458984, -1.2614994049072266, -2.6860008239746094, -7.216937065124512, 1.4844741821289062, -0.007793426513671875, -0.9737129211425781, -4.521717071533203, 0.5480003356933594, -0.18703079223632812, -1.0197792053222656, -2.930562973022461, -4.413771152496338, 2.0793685913085938, -0.33055686950683594, -0.424560546875, 1.0463829040527344, -0.6259026527404785, -0.5301923751831055, -0.5549678802490234, -1.3983001708984375, -1.1732196807861328, -1.2452831268310547, -10.463005065917969, 1.3221378326416016, 0.21229934692382812, -5.827027320861816, 0.546931266784668, -1.4838008880615234, -0.18703079223632812, 0.6615638732910156, -1.885519027709961, -0.43174076080322266, 1.8061084747314453, 1.4654150009155273, -0.9046287536621094, -2.403672218322754, 2.1459908485412598, -4.557926654815674, -2.9457738399505615, -0.5136241912841797, 0.5480003356933594, 2.214315414428711, -1.4809582233428955, -2.51723051071167, -1.549581527709961, 0.6315665245056152, -1.250417709350586, -0.7330436706542969, -0.10379695892333984, 0.15510177612304688, -1.8386878967285156, 1.3356609344482422, -0.2983570098876953, 0.5161094665527344, -2.2947731018066406, -0.3416471481323242, 1.4035892486572266, 1.5320463180541992, 2.649101734161377, -3.9030003547668457, -1.106191635131836, 1.5929069519042969, 1.5503158569335938, -0.18078994750976562, -2.2423839569091797, -23.472017288208008, -0.8304443359375, -1.8459835052490234, -3.7401771545410156, -0.6015853881835938, 1.910726547241211, -0.47835874557495117, 0.7188262939453125, -0.5962333679199219, -1.1889371871948242, -3.115506172180176, -11.006460189819336, -0.13031864166259766], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 34816, "num_env_steps_trained": 63480, "num_agent_steps_sampled": 34816, "num_agent_steps_trained": 63480, "last_target_update_ts": 34816, "num_target_updates": 67}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -334.4678073641327, "episode_len_mean": 356.73333333333335, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5038207855803378, "mean_inference_ms": 23.46690715970542, "mean_action_processing_ms": 0.1380501713286602, "mean_env_wait_ms": 4.349504753601654, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -771.5196890383959, "episode_reward_mean": -334.4678073641327, "episode_len_mean": 356.73333333333335, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5038207855803378, "mean_inference_ms": 23.46690715970542, "mean_action_processing_ms": 0.1380501713286602, "mean_env_wait_ms": 4.349504753601654, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 34816, "num_agent_steps_trained": 63480, "num_env_steps_sampled": 34816, "num_env_steps_trained": 63480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 34816, "agent_timesteps_total": 34816, "timers": {"training_iteration_time_ms": 314.578, "learn_time_ms": 59.405, "learn_throughput": 2020.033, "synch_weights_time_ms": 20.589}, "counters": {"num_env_steps_sampled": 34816, "num_env_steps_trained": 63480, "num_agent_steps_sampled": 34816, "num_agent_steps_trained": 63480, "last_target_update_ts": 34816, "num_target_updates": 67}, "done": false, "episodes_total": 90, "training_iteration": 34, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-35", "timestamp": 1655476055, "time_this_iter_s": 5.124361276626587, "time_total_s": 164.05125665664673, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 164.05125665664673, "timesteps_since_restore": 0, "iterations_since_restore": 34, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.099999999999998, "ram_util_percent": 61.48571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -12.75902271270752, "min_q": -46.82905578613281, "max_q": 15.09543228149414, "mean_td_error": -0.09957312047481537}, "td_error": [0.6772117614746094, -7.206459045410156, -1.9835090637207031, -3.4110665321350098, -0.1803569793701172, -4.102672576904297, 3.1237239837646484, 1.5658760070800781, -0.8261871337890625, 1.4500330686569214, 3.104900360107422, -0.7199420928955078, -0.18954050540924072, 0.6957969665527344, 1.0195932388305664, -0.3240184783935547, 0.16723978519439697, -1.6084814071655273, -0.7117547988891602, 0.7695064544677734, -8.531051635742188, -1.1041460037231445, -0.9196643829345703, -2.082991600036621, 0.5318918228149414, -1.7714881896972656, 0.3872108459472656, 1.4133780002593994, 2.2576112747192383, -0.31820154190063477, 0.9009628295898438, 0.973968505859375, 0.14664268493652344, 2.6439437866210938, 1.0202374458312988, -0.6410640478134155, 1.7832345962524414, 0.7316131591796875, 0.32551002502441406, 0.5224246978759766, 2.2858691215515137, -0.13852310180664062, 0.6101155281066895, 0.5306987762451172, 0.19130516052246094, 1.6403579711914062, -0.023244857788085938, -0.1392078399658203, 0.5037841796875, 3.3693599700927734, -4.0061869621276855, 2.097616195678711, -2.019338607788086, 1.3001441955566406, 1.8024187088012695, 1.3836183547973633, 2.650341033935547, -0.213409423828125, 0.32213878631591797, 0.3031005859375, -0.5992746353149414, -0.23106372356414795, -7.142298698425293, -1.4302864074707031, -0.37241554260253906, 0.16632461547851562, -1.419036865234375, -2.026808738708496, -1.6364588737487793, -2.267354965209961, 0.0249481201171875, -3.2474536895751953, -0.014682769775390625, 0.9274082183837891, 1.0586433410644531, 2.295334815979004, -1.3648815155029297, 2.8334503173828125, 2.2924604415893555, 0.5648279190063477, 0.8849601745605469, 2.1362857818603516, -1.4621291160583496, -2.220831871032715, -0.7081584930419922, 0.45313382148742676, 0.3378448486328125, -0.054891109466552734, 0.48412418365478516, 1.8033485412597656, -0.837479829788208, 3.31927490234375, 1.8218121528625488, 3.5952506065368652, 1.965275764465332, 0.8729677200317383, 1.0096759796142578, 3.303539276123047, -0.4717566967010498, -0.13927841186523438, 1.4359874725341797, 0.05276298522949219, 3.388469696044922, 0.7124495506286621, -0.8719940185546875, -8.675902366638184, 0.016872406005859375, -0.4477729797363281, -5.698818206787109, 1.9043798446655273, -1.2831252813339233, 0.448883056640625, 0.32147789001464844, -12.189778327941895, -0.7043838500976562, 0.1559600830078125, 1.372507095336914, 0.3378448486328125, -1.0172395706176758, 2.2574234008789062], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 35840, "num_env_steps_trained": 65400, "num_agent_steps_sampled": 35840, "num_agent_steps_trained": 65400, "last_target_update_ts": 35840, "num_target_updates": 69}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -334.3882253873063, "episode_len_mean": 356.1276595744681, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5022676270418738, "mean_inference_ms": 23.50766512243534, "mean_action_processing_ms": 0.1377842504246182, "mean_env_wait_ms": 4.33431851139679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -334.3882253873063, "episode_len_mean": 356.1276595744681, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5022676270418738, "mean_inference_ms": 23.50766512243534, "mean_action_processing_ms": 0.1377842504246182, "mean_env_wait_ms": 4.33431851139679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 35840, "num_agent_steps_trained": 65400, "num_env_steps_sampled": 35840, "num_env_steps_trained": 65400, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 35840, "agent_timesteps_total": 35840, "timers": {"training_iteration_time_ms": 298.271, "learn_time_ms": 60.885, "learn_throughput": 1970.92, "synch_weights_time_ms": 20.586}, "counters": {"num_env_steps_sampled": 35840, "num_env_steps_trained": 65400, "num_agent_steps_sampled": 35840, "num_agent_steps_trained": 65400, "last_target_update_ts": 35840, "num_target_updates": 69}, "done": false, "episodes_total": 94, "training_iteration": 35, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-40", "timestamp": 1655476060, "time_this_iter_s": 5.00274920463562, "time_total_s": 169.05400586128235, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 169.05400586128235, "timesteps_since_restore": 0, "iterations_since_restore": 35, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 34.442857142857136, "ram_util_percent": 61.728571428571435}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -11.415940284729004, "min_q": -49.479618072509766, "max_q": 25.2789306640625, "mean_td_error": -0.2956554591655731}, "td_error": [0.8822498321533203, -0.07657241821289062, -2.3361854553222656, -4.860759258270264, -0.6044807434082031, 3.0755462646484375, -0.38693809509277344, 2.625560760498047, 0.8619937896728516, -0.41870880126953125, 0.9856595993041992, 0.07367515563964844, 0.7493438720703125, 0.24550297856330872, 0.14844322204589844, 2.3145484924316406, 2.405975341796875, 0.8521299362182617, -13.495607376098633, 0.4737968444824219, 0.5616531372070312, -10.0496244430542, -5.363490104675293, 1.5515737533569336, 0.9681515693664551, 1.1110032796859741, 1.8800305128097534, -0.9353504180908203, 2.3220720291137695, -1.0518302917480469, 1.8955285549163818, 1.4024772644042969, -9.88004207611084, 1.3352352380752563, -3.60713529586792, 0.5455856323242188, 0.3170661926269531, 0.26471519470214844, -12.228342056274414, 0.26052331924438477, 0.8654060363769531, 0.3806343078613281, -2.1516876220703125, 0.7138214111328125, -0.4019508361816406, -0.19814014434814453, -2.0880298614501953, -0.5738801956176758, 0.9301843643188477, -1.1406745910644531, -1.5018768310546875, 0.9681515693664551, 1.037104606628418, 1.5981597900390625, 1.8800305128097534, 0.2949104309082031, 1.2784614562988281, 0.12035417556762695, -0.6081695556640625, 1.3198847770690918, -0.2796745300292969, 2.686522960662842, 1.5083956718444824, 1.2279787063598633, 0.6255416870117188, -0.6150789260864258, -1.3233680725097656, 0.798202633857727, 2.2840585708618164, 1.996999740600586, 1.101006031036377, 1.8312578201293945, 0.798202633857727, -5.261682510375977, -0.5010585784912109, -0.0797119140625, -0.1031351089477539, 1.51265549659729, 0.6500148773193359, -0.4236907958984375, 0.6436672210693359, 1.7654743194580078, -5.011991024017334, 1.1985931396484375, -0.8489189147949219, -0.2565770149230957, -0.5203394889831543, -0.4220008850097656, -1.6395938396453857, 1.3721847534179688, -1.2634811401367188, -1.2542762756347656, -2.5043411254882812, 1.7219915390014648, 3.6807098388671875, -1.8224267959594727, 1.7829265594482422, 0.16972684860229492, 0.8516943454742432, 0.4112093448638916, -1.2012367248535156, 1.6814613342285156, -1.4074440002441406, -0.5288028717041016, -0.7753486633300781, -0.6356606483459473, -1.5833091735839844, -0.34456872940063477, 0.6020126342773438, -2.5512733459472656, 1.6436767578125, -1.8907032012939453, 1.2201480865478516, -0.6701431274414062, 1.294412612915039, 1.2784614562988281, -3.7167623043060303, 0.29393017292022705, -2.459475040435791, 0.24663591384887695], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 36864, "num_env_steps_trained": 67320, "num_agent_steps_sampled": 36864, "num_agent_steps_trained": 67320, "last_target_update_ts": 36864, "num_target_updates": 71}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -333.12980938444014, "episode_len_mean": 355.9684210526316, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5019785561674374, "mean_inference_ms": 23.520217821338363, "mean_action_processing_ms": 0.13764860054726388, "mean_env_wait_ms": 4.3306059364083875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -333.12980938444014, "episode_len_mean": 355.9684210526316, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5019785561674374, "mean_inference_ms": 23.520217821338363, "mean_action_processing_ms": 0.13764860054726388, "mean_env_wait_ms": 4.3306059364083875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 36864, "num_agent_steps_trained": 67320, "num_env_steps_sampled": 36864, "num_env_steps_trained": 67320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 36864, "agent_timesteps_total": 36864, "timers": {"training_iteration_time_ms": 303.422, "learn_time_ms": 59.846, "learn_throughput": 2005.143, "synch_weights_time_ms": 20.288}, "counters": {"num_env_steps_sampled": 36864, "num_env_steps_trained": 67320, "num_agent_steps_sampled": 36864, "num_agent_steps_trained": 67320, "last_target_update_ts": 36864, "num_target_updates": 71}, "done": false, "episodes_total": 95, "training_iteration": 36, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-45", "timestamp": 1655476065, "time_this_iter_s": 4.769279718399048, "time_total_s": 173.8232855796814, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 173.8232855796814, "timesteps_since_restore": 0, "iterations_since_restore": 36, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.371428571428574, "ram_util_percent": 61.97142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -10.214261054992676, "min_q": -52.419471740722656, "max_q": 31.990478515625, "mean_td_error": 0.16638800501823425}, "td_error": [0.5341377258300781, -0.058310747146606445, -0.42413902282714844, 1.1785659790039062, -0.439056396484375, 0.025440216064453125, -0.5013036727905273, -0.697394847869873, 1.5892186164855957, -0.5223617553710938, 0.9486904144287109, 1.7483024597167969, -3.0434017181396484, 1.9774723052978516, 1.4655051231384277, -0.33721351623535156, -1.8602089881896973, 2.6449031829833984, 1.4900860786437988, -0.7553787231445312, 0.09232139587402344, 1.801447868347168, 0.9891152381896973, -10.368947982788086, 1.8118457794189453, 1.5175228118896484, 0.12572693824768066, -0.46802520751953125, 1.7940921783447266, 0.5221652984619141, 3.3105220794677734, 3.0421552658081055, -7.235851287841797, -0.44713783264160156, 3.6567161083221436, 1.4736576080322266, 3.985062599182129, 0.18025588989257812, 2.241495132446289, 1.8064069747924805, 7.723644256591797, 1.211960792541504, -2.7090539932250977, 0.8983230590820312, 0.9180393218994141, -0.29191017150878906, 1.2898695468902588, 0.2781639099121094, 1.8517837524414062, -23.113868713378906, 2.1786632537841797, 1.3259468078613281, 0.7401571273803711, -0.4881477355957031, -0.697394847869873, 0.48180389404296875, 2.2023887634277344, -3.764921188354492, 0.6647052764892578, -3.782918930053711, 0.3088831901550293, 0.5051126480102539, -1.9396799802780151, 2.711719512939453, 0.6747341156005859, 2.5831708908081055, 1.3459205627441406, 4.562237739562988, 1.8445873260498047, 0.3513965606689453, -0.0967702865600586, 0.6760964393615723, -0.9489593505859375, 1.7483024597167969, 0.7858171463012695, -1.005218505859375, -5.495483875274658, 1.7793917655944824, -3.0251426696777344, 2.995716094970703, 2.244009017944336, -0.446134090423584, 2.252565383911133, 0.7818202972412109, 1.774195671081543, -1.2317218780517578, 1.5839271545410156, 1.8831672668457031, 0.7853702306747437, 0.2054920196533203, 0.19743728637695312, -1.637059211730957, -0.400820255279541, -0.0167694091796875, -2.562000274658203, -0.6476445198059082, 0.552631139755249, 0.38155174255371094, -0.35871315002441406, 0.9636075496673584, 0.1533966064453125, 0.6252422332763672, -7.8477935791015625, 0.4336814880371094, 2.252565383911133, 3.020449161529541, 0.41971778869628906, 0.5957679748535156, 0.016023635864257812, 0.5587730407714844, -0.8911647796630859, -1.2140698432922363, 1.458608627319336, 1.5355949401855469, -0.5739631652832031, 1.537811279296875, -0.5838484764099121, 0.2778434753417969, 0.2515406608581543, -0.43769073486328125], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 37888, "num_env_steps_trained": 69240, "num_agent_steps_sampled": 37888, "num_agent_steps_trained": 69240, "last_target_update_ts": 37888, "num_target_updates": 73}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -331.3678897813115, "episode_len_mean": 355.4795918367347, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5016300734009087, "mean_inference_ms": 23.553476073417805, "mean_action_processing_ms": 0.13766692859252486, "mean_env_wait_ms": 4.32180885696041, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -331.3678897813115, "episode_len_mean": 355.4795918367347, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-63.603835731744766, -56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613], "episode_lengths": [250, 249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5016300734009087, "mean_inference_ms": 23.553476073417805, "mean_action_processing_ms": 0.13766692859252486, "mean_env_wait_ms": 4.32180885696041, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 37888, "num_agent_steps_trained": 69240, "num_env_steps_sampled": 37888, "num_env_steps_trained": 69240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 37888, "agent_timesteps_total": 37888, "timers": {"training_iteration_time_ms": 330.198, "learn_time_ms": 60.727, "learn_throughput": 1976.048, "synch_weights_time_ms": 20.389}, "counters": {"num_env_steps_sampled": 37888, "num_env_steps_trained": 69240, "num_agent_steps_sampled": 37888, "num_agent_steps_trained": 69240, "last_target_update_ts": 37888, "num_target_updates": 73}, "done": false, "episodes_total": 98, "training_iteration": 37, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-50", "timestamp": 1655476070, "time_this_iter_s": 5.082910776138306, "time_total_s": 178.9061963558197, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 178.9061963558197, "timesteps_since_restore": 0, "iterations_since_restore": 37, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.071428571428566, "ram_util_percent": 61.971428571428575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -10.564763069152832, "min_q": -52.652366638183594, "max_q": 27.610525131225586, "mean_td_error": -0.5249670147895813}, "td_error": [-0.0997314453125, -2.3077993392944336, -0.6115665435791016, -2.016357421875, -0.7528743743896484, 0.452545166015625, -1.5828604698181152, 1.992133378982544, 0.12081480026245117, 1.715073585510254, -1.7578811645507812, 0.7099065780639648, -0.4238700866699219, 1.7270307540893555, 0.8687686920166016, -0.0346219539642334, 0.7834205627441406, 0.8008594512939453, -0.006923675537109375, 1.1942634582519531, -0.31786537170410156, 2.117828369140625, -0.29254841804504395, 0.7633724212646484, -0.6853103637695312, -0.2248516082763672, 0.1567997932434082, -3.185565948486328, -3.578296661376953, -2.252963066101074, -9.226146697998047, 1.1093759536743164, -0.5478000640869141, 1.376190185546875, 0.6886019706726074, -0.14229202270507812, -11.322574615478516, -0.7570042014122009, -3.9451446533203125, -2.9081101417541504, 0.9517207145690918, 0.45607757568359375, -1.5472564697265625, 1.7238082885742188, -2.2182159423828125, 1.327387809753418, -0.29778075218200684, 0.7056155204772949, -2.2621078491210938, -7.422359466552734, -1.9371414184570312, -3.311077117919922, -1.0858159065246582, 0.192962646484375, -3.142681121826172, 0.44072985649108887, -0.48259639739990234, 5.37202262878418, -3.212312698364258, -0.44216156005859375, -2.9064178466796875, -1.7469663619995117, 1.3131260871887207, 0.052536964416503906, -10.28477668762207, -0.5972671508789062, 1.7972383499145508, 0.8475098609924316, 0.13083839416503906, 0.7691187858581543, -6.790499210357666, 5.939628601074219, -0.8920497894287109, -0.6761641502380371, 3.203014373779297, 0.6848688125610352, -5.878292083740234, 0.5295190811157227, 5.293083190917969, -0.01093292236328125, -0.8588962554931641, -1.595611572265625, 1.5556583404541016, 2.4374847412109375, -0.7508249282836914, 1.9123010635375977, 0.4163398742675781, -1.139251708984375, 3.5170671939849854, 3.1506989002227783, 0.11505317687988281, 1.235372543334961, 0.7318744659423828, -0.8315310478210449, 0.7169520854949951, 0.7633724212646484, -2.1685752868652344, 1.9247894287109375, -2.1983070373535156, -0.9576301574707031, -1.8603763580322266, -2.648043632507324, 1.9545459747314453, -14.67214584350586, -0.48016357421875, -0.12217092514038086, -0.9059352874755859, 0.6347389221191406, -0.38108062744140625, 6.791318893432617, 1.2751541137695312, -0.16969680786132812, -0.08481359481811523, -0.9059352874755859, 0.3592987060546875, -1.0319147109985352, -3.5447287559509277, -0.315349817276001, 0.690098762512207, 2.2628631591796875], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 38912, "num_env_steps_trained": 71160, "num_agent_steps_sampled": 38912, "num_agent_steps_trained": 71160, "last_target_update_ts": 38912, "num_target_updates": 75}, "sampler_results": {"episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -328.3254562322795, "episode_len_mean": 354.67, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357], "episode_lengths": [249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5005818407485373, "mean_inference_ms": 23.58202784957838, "mean_action_processing_ms": 0.13721817043939302, "mean_env_wait_ms": 4.297317239184764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.939932636916637, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -328.3254562322795, "episode_len_mean": 354.67, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-56.96867588162422, 4.939932636916637, -30.67262065410614, -53.05041531473398, -43.268093913793564, -70.91236478090286, -91.87078366428614, -97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357], "episode_lengths": [249, 217, 241, 249, 240, 277, 267, 266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5005818407485373, "mean_inference_ms": 23.58202784957838, "mean_action_processing_ms": 0.13721817043939302, "mean_env_wait_ms": 4.297317239184764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 38912, "num_agent_steps_trained": 71160, "num_env_steps_sampled": 38912, "num_env_steps_trained": 71160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 38912, "agent_timesteps_total": 38912, "timers": {"training_iteration_time_ms": 308.06, "learn_time_ms": 61.057, "learn_throughput": 1965.373, "synch_weights_time_ms": 20.111}, "counters": {"num_env_steps_sampled": 38912, "num_env_steps_trained": 71160, "num_agent_steps_sampled": 38912, "num_agent_steps_trained": 71160, "last_target_update_ts": 38912, "num_target_updates": 75}, "done": false, "episodes_total": 101, "training_iteration": 38, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-27-55", "timestamp": 1655476075, "time_this_iter_s": 4.932016134262085, "time_total_s": 183.8382124900818, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 183.8382124900818, "timesteps_since_restore": 0, "iterations_since_restore": 38, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.1375, "ram_util_percent": 62.112500000000004}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -9.44653606414795, "min_q": -56.408592224121094, "max_q": 28.308917999267578, "mean_td_error": -0.059446532279253006}, "td_error": [-0.9599189758300781, 0.21531295776367188, 0.2996063232421875, 0.9620113372802734, 1.3977928161621094, -0.3329305648803711, -4.336515426635742, -1.0263595581054688, 0.1757059097290039, -0.4366111755371094, 2.440013885498047, 0.9246616363525391, 3.304185390472412, 2.1140174865722656, 1.3960723876953125, -2.5730957984924316, 1.305701494216919, -9.56500244140625, 1.4557123184204102, 0.4866600036621094, 1.2966156005859375, -2.151571273803711, -2.0614280700683594, -0.46224987506866455, 0.7242703437805176, 0.8152494430541992, 0.8793373107910156, 6.149275779724121, 0.23556280136108398, 2.9595441818237305, -0.7826671600341797, -0.34066009521484375, 1.2398719787597656, 0.6340560913085938, 2.1031017303466797, 2.331319808959961, 1.483942985534668, -0.6142067909240723, -0.1359109878540039, 0.30268287658691406, -1.2783212661743164, -10.606439590454102, -0.3390045166015625, 0.2747764587402344, 1.3038291931152344, -0.45316362380981445, -0.8629555702209473, 1.1413898468017578, -0.13682949542999268, -28.084320068359375, 1.795060157775879, -3.4190025329589844, -0.3741455078125, -0.00011444091796875, 1.2210661172866821, 1.224802017211914, -2.248764991760254, 5.5387983322143555, 0.7862262725830078, 1.3628005981445312, -9.113332748413086, -1.3549623489379883, 2.9760007858276367, 1.1906003952026367, 0.7894790172576904, -1.2825813293457031, 2.1931514739990234, -1.0039920806884766, 2.32183837890625, -1.6946601867675781, 1.3960723876953125, -0.16844987869262695, 0.12721729278564453, -1.8947086334228516, -0.023270845413208008, -2.841597557067871, -3.884431838989258, 2.238649368286133, -4.557741165161133, -1.0975942611694336, 0.2838592529296875, 1.1832361221313477, 2.127866744995117, -0.10536861419677734, 1.4619712829589844, 0.46806633472442627, -0.14146018028259277, 2.3441410064697266, -0.7704775333404541, -1.360569953918457, -2.5238094329833984, 0.15483856201171875, 0.9234354496002197, 0.3815023899078369, 0.9583625793457031, 1.2812366485595703, -0.5785064697265625, 1.1578559875488281, -10.106792449951172, 0.06573486328125, 1.7385706901550293, 0.7242703437805176, 0.16738271713256836, 1.2877388000488281, 7.314296722412109, 1.2143797874450684, 1.28865647315979, -0.864406943321228, 0.6030573844909668, -0.008179187774658203, 0.9409803152084351, 1.0991601943969727, 5.605762481689453, 8.005029678344727, -0.13310003280639648, 1.415557861328125, -1.4454189538955688, 3.1745433807373047, -1.4769039154052734, 1.9953908920288086], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 39936, "num_env_steps_trained": 73080, "num_agent_steps_sampled": 39936, "num_agent_steps_trained": 73080, "last_target_update_ts": 39936, "num_target_updates": 77}, "sampler_results": {"episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -344.6866054865718, "episode_len_mean": 360.83, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669], "episode_lengths": [266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4930239318238735, "mean_inference_ms": 23.72606818874708, "mean_action_processing_ms": 0.13661391802453707, "mean_env_wait_ms": 4.20438821020377, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -344.6866054865718, "episode_len_mean": 360.83, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-97.33431160449982, -114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669], "episode_lengths": [266, 270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4930239318238735, "mean_inference_ms": 23.72606818874708, "mean_action_processing_ms": 0.13661391802453707, "mean_env_wait_ms": 4.20438821020377, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 39936, "num_agent_steps_trained": 73080, "num_env_steps_sampled": 39936, "num_env_steps_trained": 73080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 39936, "agent_timesteps_total": 39936, "timers": {"training_iteration_time_ms": 347.38, "learn_time_ms": 60.917, "learn_throughput": 1969.901, "synch_weights_time_ms": 20.388}, "counters": {"num_env_steps_sampled": 39936, "num_env_steps_trained": 73080, "num_agent_steps_sampled": 39936, "num_agent_steps_trained": 73080, "last_target_update_ts": 39936, "num_target_updates": 77}, "done": false, "episodes_total": 108, "training_iteration": 39, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-01", "timestamp": 1655476081, "time_this_iter_s": 5.462343454360962, "time_total_s": 189.30055594444275, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 189.30055594444275, "timesteps_since_restore": 0, "iterations_since_restore": 39, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.487499999999997, "ram_util_percent": 62.287499999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -8.089983940124512, "min_q": -56.5900993347168, "max_q": 27.66278648376465, "mean_td_error": -0.5954985022544861}, "td_error": [0.6688375473022461, 4.016792297363281, -2.391292095184326, 1.3336315155029297, -10.100845336914062, 0.8187017440795898, 0.9327524900436401, 8.990805625915527, 0.5613625049591064, 1.799269199371338, -0.12384796142578125, -0.7359952926635742, -0.48056602478027344, 1.8260726928710938, 0.03877449035644531, -1.0858879089355469, -1.344320297241211, 1.8826546669006348, -2.241358757019043, 0.2147979736328125, 1.0923137664794922, -0.8896312713623047, 0.3137235641479492, -0.2967414855957031, 0.02396392822265625, -0.20587158203125, 1.3273873329162598, 1.0091209411621094, 0.31226158142089844, -0.8352222442626953, -0.23700332641601562, 2.57550048828125, 2.6598052978515625, 0.7547416687011719, -5.147975921630859, -0.9466724395751953, -0.15167903900146484, -2.181987762451172, -0.14255809783935547, 1.4717178344726562, -1.5974769592285156, 2.8306026458740234, -0.7048509120941162, 1.0650410652160645, -1.3559513092041016, 0.776608943939209, 0.7333288192749023, -0.22354507446289062, 1.7780370712280273, -3.3247580528259277, -0.25144147872924805, -0.45842647552490234, 0.9782562255859375, 4.150899887084961, -0.0687403678894043, -0.5382080078125, -4.964442253112793, -0.303466796875, -4.764150619506836, 0.8534421920776367, -0.1590137481689453, 1.4576325416564941, -1.0728278160095215, -1.6430768966674805, -0.37045955657958984, -0.07852697372436523, 0.003573894500732422, 1.9032559394836426, -2.1383190155029297, 0.16878128051757812, 1.2951478958129883, 0.3488578796386719, -6.369489669799805, 2.913520097732544, -3.3072280883789062, -0.5605659484863281, 2.503110885620117, -1.1825551986694336, -0.15920352935791016, 3.1146352291107178, 1.1625652313232422, -8.764066696166992, 0.7280030250549316, -2.1879425048828125, 0.20132827758789062, -7.53494930267334, 0.8460049629211426, 0.7118139266967773, 2.346506118774414, -1.0587940216064453, 1.799269199371338, -0.5561256408691406, 0.2102644443511963, -3.7276649475097656, 0.45918774604797363, -0.022884368896484375, 2.2798471450805664, -10.087862014770508, 1.8435044288635254, 0.6361825466156006, 0.36374664306640625, -7.1128129959106445, -1.3788681030273438, -6.414146423339844, -1.752680778503418, -1.0965461730957031, -10.790055274963379, -1.0405479669570923, 4.207223892211914, -6.075578689575195, 0.6971349716186523, -0.8432273864746094, -1.4823129177093506, -19.250244140625, -0.45688343048095703, -1.4445667266845703, 1.7256107330322266, 3.4991512298583984, -0.41377878189086914, 1.9518303871154785], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 40960, "num_env_steps_trained": 75000, "num_agent_steps_sampled": 40960, "num_agent_steps_trained": 75000, "last_target_update_ts": 40960, "num_target_updates": 79}, "sampler_results": {"episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -348.83743274360893, "episode_len_mean": 362.31, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161], "episode_lengths": [270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927569767582468, "mean_inference_ms": 23.73438105149296, "mean_action_processing_ms": 0.1366799804384136, "mean_env_wait_ms": 4.191612961022935, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -348.83743274360893, "episode_len_mean": 362.31, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-114.29999992251396, -134.08634646236897, -97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161], "episode_lengths": [270, 283, 273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927569767582468, "mean_inference_ms": 23.73438105149296, "mean_action_processing_ms": 0.1366799804384136, "mean_env_wait_ms": 4.191612961022935, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 40960, "num_agent_steps_trained": 75000, "num_env_steps_sampled": 40960, "num_env_steps_trained": 75000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 40960, "agent_timesteps_total": 40960, "timers": {"training_iteration_time_ms": 289.61, "learn_time_ms": 59.722, "learn_throughput": 2009.324, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 40960, "num_env_steps_trained": 75000, "num_agent_steps_sampled": 40960, "num_agent_steps_trained": 75000, "last_target_update_ts": 40960, "num_target_updates": 79}, "done": false, "episodes_total": 109, "training_iteration": 40, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-06", "timestamp": 1655476086, "time_this_iter_s": 4.700047731399536, "time_total_s": 194.00060367584229, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 194.00060367584229, "timesteps_since_restore": 0, "iterations_since_restore": 40, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.68333333333333, "ram_util_percent": 62.416666666666664}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -9.416769027709961, "min_q": -58.24538803100586, "max_q": 29.46265411376953, "mean_td_error": -1.0612293481826782}, "td_error": [0.3805009126663208, -2.0629539489746094, 1.7317562103271484, 0.20213937759399414, 0.30982303619384766, 2.2400500774383545, 0.375970721244812, 1.411149024963379, 0.011814117431640625, -8.57304859161377, -0.49303627014160156, 0.3680286407470703, -1.0329742431640625, 0.24290847778320312, 3.079587936401367, -0.7103061676025391, 1.9252376556396484, -20.771944046020508, -4.003923416137695, -2.4536855220794678, -1.6793327331542969, 1.9801883697509766, -0.08893871307373047, 5.837439060211182, -0.2858600616455078, -0.25824737548828125, 1.0751876831054688, -0.11006736755371094, 1.2460603713989258, -0.3015151619911194, -1.9775323867797852, -9.368562698364258, -0.5423603057861328, 0.3433723449707031, -0.0116729736328125, 0.4279416799545288, 1.8518733978271484, 1.6646206378936768, 0.7464609146118164, -0.09750890731811523, 0.048070430755615234, -0.8999595642089844, 3.060789108276367, -7.218090057373047, 1.3997058868408203, 0.5323095321655273, -5.951528549194336, -0.6670850515365601, -0.9634609222412109, -0.6722598075866699, -4.98118782043457, -0.0129852294921875, 0.77618408203125, -0.13515758514404297, -0.37532997131347656, -1.3588566780090332, -0.10201215744018555, -1.2198486328125, -1.0118656158447266, -0.24650192260742188, -0.3027857840061188, 1.2377071380615234, 2.0537471771240234, 0.13030457496643066, 1.2512683868408203, 0.7683258056640625, -0.29644012451171875, -0.00237274169921875, -1.3041419982910156, 2.898082733154297, -1.712921142578125, 0.43733978271484375, -2.408334732055664, -0.3026142120361328, -0.16923606395721436, 0.25899219512939453, 1.6739025115966797, -2.141630172729492, 0.15854263305664062, -7.319618225097656, 0.15826988220214844, -6.408270835876465, -0.8087253570556641, -0.21121978759765625, -0.40618896484375, -0.8407363891601562, -1.1744966506958008, -1.4412527084350586, -1.5262460708618164, -1.395909309387207, -2.0391478538513184, -6.931733131408691, -1.2180004119873047, 0.11213302612304688, -2.688383102416992, 0.11142945289611816, -1.3376649618148804, 0.42561817169189453, -8.912601470947266, -1.1210193634033203, 0.6903781890869141, -1.1086859703063965, -17.377643585205078, -0.542442798614502, -1.7538604736328125, 0.6751499176025391, 1.212289810180664, 0.19641494750976562, -7.534845352172852, -1.2180004119873047, 0.3321666717529297, -0.26183509826660156, 0.7240142822265625, -1.4789810180664062, -8.831610679626465, 1.5989227294921875, -4.2436065673828125, 0.9437656402587891, 1.570284366607666, -0.8229368925094604], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 41984, "num_env_steps_trained": 76920, "num_agent_steps_sampled": 41984, "num_agent_steps_trained": 76920, "last_target_update_ts": 41984, "num_target_updates": 81}, "sampler_results": {"episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -353.9707838243246, "episode_len_mean": 364.23, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651], "episode_lengths": [273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927898223033378, "mean_inference_ms": 23.773545106297355, "mean_action_processing_ms": 0.1368575870473693, "mean_env_wait_ms": 4.175177864518189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -353.9707838243246, "episode_len_mean": 364.23, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-97.04902757704258, -87.76591709256172, -82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651], "episode_lengths": [273, 258, 272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4927898223033378, "mean_inference_ms": 23.773545106297355, "mean_action_processing_ms": 0.1368575870473693, "mean_env_wait_ms": 4.175177864518189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 41984, "num_agent_steps_trained": 76920, "num_env_steps_sampled": 41984, "num_env_steps_trained": 76920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 41984, "agent_timesteps_total": 41984, "timers": {"training_iteration_time_ms": 308.556, "learn_time_ms": 61.275, "learn_throughput": 1958.383, "synch_weights_time_ms": 20.187}, "counters": {"num_env_steps_sampled": 41984, "num_env_steps_trained": 76920, "num_agent_steps_sampled": 41984, "num_agent_steps_trained": 76920, "last_target_update_ts": 41984, "num_target_updates": 81}, "done": false, "episodes_total": 111, "training_iteration": 41, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-11", "timestamp": 1655476091, "time_this_iter_s": 4.923687934875488, "time_total_s": 198.92429161071777, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 198.92429161071777, "timesteps_since_restore": 0, "iterations_since_restore": 41, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.75714285714286, "ram_util_percent": 62.58571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -9.237146377563477, "min_q": -59.11833953857422, "max_q": 30.64531898498535, "mean_td_error": -1.0426701307296753}, "td_error": [-0.9668006896972656, -0.76092529296875, 0.7391719818115234, 0.4006943702697754, -3.5534515380859375, -0.20435047149658203, 2.576589584350586, -2.3332571983337402, -0.05092573165893555, -11.582763671875, -1.1924371719360352, 1.0115857124328613, -0.07688522338867188, 1.432424545288086, 1.3975715637207031, 1.9295635223388672, -5.926089286804199, -1.3268780708312988, -6.462711811065674, -1.1497039794921875, 1.2047042846679688, -1.3379112482070923, -0.9164047241210938, -5.097667694091797, -0.12414932250976562, 1.143547534942627, -0.3891868591308594, -1.1524066925048828, -0.3257235288619995, 1.5665721893310547, 0.918426513671875, -0.7315216064453125, -0.30121612548828125, 0.5601165294647217, -0.25991058349609375, -2.047356605529785, -2.1239185333251953, -0.3914957046508789, 0.7573347091674805, 2.0891189575195312, -0.26519107818603516, 0.2656593322753906, 1.432424545288086, -5.021486759185791, 0.29423999786376953, -0.8030866384506226, -11.544235229492188, -1.1732511520385742, -1.8865890502929688, -0.2291395664215088, 0.5364594459533691, 1.2779655456542969, -1.2643518447875977, -1.6150054931640625, -0.5082187652587891, 0.6763267517089844, -1.3546618223190308, -15.885429382324219, -0.38870811462402344, -1.7349109649658203, 0.12421035766601562, 0.1608896255493164, -7.962360382080078, -0.047168731689453125, 0.5601165294647217, -0.5836927890777588, -0.17611193656921387, 1.0169191360473633, 0.15882492065429688, 0.5356035232543945, -1.1341254711151123, 1.9163799285888672, 1.2693166732788086, 0.2334918975830078, -1.861379623413086, -0.6213401556015015, -0.2682199478149414, -0.2205219268798828, -0.12973344326019287, -0.07480621337890625, -0.7344350814819336, -0.6989448070526123, -2.872683048248291, -0.692561149597168, -0.40696603059768677, 0.7551589012145996, -1.1017835140228271, -0.8902139663696289, -1.5855026245117188, 1.3268260955810547, -1.0215473175048828, 0.7922725677490234, -0.7432994842529297, -0.46955204010009766, -0.6260280609130859, 1.0396652221679688, 0.07664036750793457, 0.09539794921875, -1.4111804962158203, -11.853403091430664, -17.885496139526367, -6.2282609939575195, 0.21670913696289062, -0.7128715515136719, 1.9295635223388672, 4.504999160766602, 0.8267860412597656, -1.729013442993164, 4.099010467529297, 0.7296657562255859, -4.277787685394287, -1.7746553421020508, -0.2670307159423828, -0.5812071561813354, -1.476661205291748, 0.5388603210449219, -0.7256498336791992, -1.1668882369995117, -0.5411586761474609, -0.2236623764038086], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 43008, "num_env_steps_trained": 78840, "num_agent_steps_sampled": 43008, "num_agent_steps_trained": 78840, "last_target_update_ts": 43008, "num_target_updates": 83}, "sampler_results": {"episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -354.5958359647542, "episode_len_mean": 364.56, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379], "episode_lengths": [272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4925881680901595, "mean_inference_ms": 23.815320052135785, "mean_action_processing_ms": 0.13681336022403148, "mean_env_wait_ms": 4.145886103437875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": -5.680944465100765, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -354.5958359647542, "episode_len_mean": 364.56, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-82.09489224106073, -107.76287601143122, -100.82929656654596, -65.7739914059639, -125.81533570587635, -247.9109934195876, -234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379], "episode_lengths": [272, 283, 286, 266, 303, 342, 318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4925881680901595, "mean_inference_ms": 23.815320052135785, "mean_action_processing_ms": 0.13681336022403148, "mean_env_wait_ms": 4.145886103437875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 43008, "num_agent_steps_trained": 78840, "num_env_steps_sampled": 43008, "num_env_steps_trained": 78840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 43008, "agent_timesteps_total": 43008, "timers": {"training_iteration_time_ms": 318.699, "learn_time_ms": 60.583, "learn_throughput": 1980.759, "synch_weights_time_ms": 20.829}, "counters": {"num_env_steps_sampled": 43008, "num_env_steps_trained": 78840, "num_agent_steps_sampled": 43008, "num_agent_steps_trained": 78840, "last_target_update_ts": 43008, "num_target_updates": 83}, "done": false, "episodes_total": 113, "training_iteration": 42, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-16", "timestamp": 1655476096, "time_this_iter_s": 5.312474489212036, "time_total_s": 204.2367660999298, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 204.2367660999298, "timesteps_since_restore": 0, "iterations_since_restore": 42, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 28.975, "ram_util_percent": 62.775}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -9.085686683654785, "min_q": -53.76209259033203, "max_q": 32.423004150390625, "mean_td_error": -1.4337748289108276}, "td_error": [-1.2006778717041016, -0.8435173034667969, 3.776561737060547, -1.2017908096313477, 0.15278267860412598, 2.035907745361328, -4.466357231140137, 0.7923669815063477, 0.03934001922607422, -1.0917797088623047, -0.8447113037109375, -1.3857812881469727, -0.16217613220214844, 0.37760257720947266, -0.20853424072265625, -0.5927904844284058, -0.336392879486084, 0.8803672790527344, -0.7576376795768738, -6.470050811767578, -3.0916881561279297, 1.050703525543213, 0.2238006591796875, -0.4942493438720703, -0.08922576904296875, -0.19544410705566406, 0.438448429107666, -0.6969528198242188, -9.794942855834961, 0.33588409423828125, 0.08860015869140625, -1.7388629913330078, -2.90895414352417, -3.9601850509643555, -0.790215015411377, -1.4536209106445312, -1.0592842102050781, -1.795302152633667, 0.27591896057128906, -13.29529094696045, 1.0909781455993652, -6.516822814941406, -0.688575267791748, -1.9536588191986084, -3.483074188232422, -0.20033502578735352, -12.955180168151855, -0.3452186584472656, -11.977214813232422, -1.6886677742004395, -14.46966552734375, -0.6611995697021484, -10.934972763061523, -7.996707916259766, -7.078481197357178, -2.148171901702881, -0.2979612350463867, -2.3524131774902344, -0.8294944763183594, -0.20295822620391846, -0.8415160179138184, -2.550992965698242, -0.1056671142578125, 0.5120162963867188, 0.1161355972290039, -0.7722320556640625, 2.3370566368103027, -2.50164794921875, -0.1232452392578125, 0.5233211517333984, -1.1109793186187744, -0.6368011236190796, -0.7021160125732422, 0.2510337829589844, 1.6624107360839844, -4.148082733154297, 0.8863215446472168, 2.296184539794922, 0.4804649353027344, -2.2964420318603516, 0.8146353960037231, -0.9837026596069336, -1.530050277709961, -1.779919147491455, 0.5895333290100098, -0.9572219848632812, -1.3756146430969238, -3.232656478881836, 6.818110466003418, -0.2768211364746094, -0.2317047119140625, 0.1609973907470703, -3.219900131225586, 0.031253814697265625, -0.040572166442871094, 1.6905193328857422, 2.8199596405029297, 0.5393600463867188, 1.7424039840698242, 0.2555227279663086, -0.06433606147766113, -0.44355297088623047, -2.469784736633301, -7.358837127685547, -0.31540489196777344, -3.472163677215576, 0.27730369567871094, 3.3734569549560547, -4.363641738891602, 0.16356277465820312, -14.231138229370117, 0.7187404632568359, -1.1277971267700195, 0.8863215446472168, -0.7439563274383545, -0.7864208221435547, -0.14153961837291718, 0.4740772247314453, -0.715395450592041, -0.6738777160644531], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 44032, "num_env_steps_trained": 80760, "num_agent_steps_sampled": 44032, "num_agent_steps_trained": 80760, "last_target_update_ts": 44032, "num_target_updates": 85}, "sampler_results": {"episode_reward_max": 4.834490858018398, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -361.1009416352957, "episode_len_mean": 365.96, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992], "episode_lengths": [318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48957197095517513, "mean_inference_ms": 23.928684855284583, "mean_action_processing_ms": 0.1363420591118412, "mean_env_wait_ms": 4.09579109478574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.834490858018398, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -361.1009416352957, "episode_len_mean": 365.96, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-234.13093196600676, -305.9479857906699, -297.28550731390715, -266.78066032379866, -269.3139506280422, -304.4177119284868, -213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992], "episode_lengths": [318, 349, 375, 363, 372, 351, 347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48957197095517513, "mean_inference_ms": 23.928684855284583, "mean_action_processing_ms": 0.1363420591118412, "mean_env_wait_ms": 4.09579109478574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 44032, "num_agent_steps_trained": 80760, "num_env_steps_sampled": 44032, "num_env_steps_trained": 80760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 44032, "agent_timesteps_total": 44032, "timers": {"training_iteration_time_ms": 332.614, "learn_time_ms": 62.243, "learn_throughput": 1927.918, "synch_weights_time_ms": 20.389}, "counters": {"num_env_steps_sampled": 44032, "num_env_steps_trained": 80760, "num_agent_steps_sampled": 44032, "num_agent_steps_trained": 80760, "last_target_update_ts": 44032, "num_target_updates": 85}, "done": false, "episodes_total": 119, "training_iteration": 43, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-22", "timestamp": 1655476102, "time_this_iter_s": 5.337336540222168, "time_total_s": 209.57410264015198, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 209.57410264015198, "timesteps_since_restore": 0, "iterations_since_restore": 43, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.9375, "ram_util_percent": 62.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.9805378913879395, "min_q": -61.29561996459961, "max_q": 27.0694580078125, "mean_td_error": -0.3323543667793274}, "td_error": [1.05344557762146, 1.6158027648925781, 2.474490165710449, 3.1997222900390625, -0.05825042724609375, 0.45534801483154297, -0.6616659164428711, -0.28211748600006104, 0.683171272277832, -6.775245666503906, 2.2356338500976562, -5.603664875030518, 0.1353895664215088, -0.2500762939453125, 2.2648744583129883, -0.6677250862121582, -0.44973933696746826, -0.1495511531829834, -10.841911315917969, -1.301137924194336, -0.7139797210693359, 4.229433059692383, 3.2039527893066406, 1.1651229858398438, 3.07684326171875, 0.26076316833496094, 3.653135299682617, -6.300799369812012, -2.187894821166992, 0.30830955505371094, 0.9124259948730469, -8.511812210083008, -2.3411855697631836, 0.6823887825012207, 1.5623722076416016, 2.4949445724487305, 0.44391441345214844, -1.1354808807373047, -20.26292610168457, 0.8140270709991455, -1.6661195755004883, 1.2843093872070312, -0.41398876905441284, 0.3983231782913208, -2.719907760620117, 4.0453596115112305, 4.02595329284668, 1.4208416938781738, 1.0131475925445557, 2.839601516723633, -0.4723339080810547, -3.8043880462646484, -0.4062690734863281, 0.910308837890625, 0.43045806884765625, -0.7890663146972656, -0.5689430236816406, 0.8644843101501465, -0.1406698226928711, -9.795272827148438, 1.3355674743652344, 10.215263366699219, -2.3571953773498535, 1.8209848403930664, -7.211368560791016, 1.4512429237365723, 0.5694675445556641, -0.8118476867675781, 3.327096939086914, 1.1592521667480469, -0.03326606750488281, 1.1162676811218262, -13.248600959777832, 0.043097853660583496, 1.393564224243164, 0.5796089172363281, 0.13039827346801758, -0.5533161163330078, 0.8643474578857422, 2.4692983627319336, 1.5793647766113281, -1.8176536560058594, 1.8132514953613281, 2.2648744583129883, -2.2513914108276367, -1.7672853469848633, 1.256211280822754, 2.8807830810546875, 1.2374677658081055, -0.31308794021606445, -4.169536590576172, 0.006603240966796875, 2.171891212463379, -5.924931526184082, 1.1057767868041992, -0.455169677734375, 0.34616947174072266, 5.294166564941406, -0.1189422607421875, -0.3739309310913086, -1.08204984664917, -0.769723653793335, -2.107219696044922, 0.22014018893241882, -0.3566715717315674, 1.3400001525878906, -0.08024024963378906, 2.0722389221191406, -2.1967830657958984, 2.3720321655273438, 1.4041194915771484, 1.0039844512939453, -1.1777677536010742, -9.281002044677734, -3.3657398223876953, 4.210437774658203, 3.0894699096679688, 0.7678327560424805, 0.9757356643676758, -6.831989288330078], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 45056, "num_env_steps_trained": 82680, "num_agent_steps_sampled": 45056, "num_agent_steps_trained": 82680, "last_target_update_ts": 45056, "num_target_updates": 87}, "sampler_results": {"episode_reward_max": 4.834490858018398, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -357.27363834910096, "episode_len_mean": 363.53, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623], "episode_lengths": [347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48702674110294547, "mean_inference_ms": 24.046914725426156, "mean_action_processing_ms": 0.1358622274643882, "mean_env_wait_ms": 4.06550402508528, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.834490858018398, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -357.27363834910096, "episode_len_mean": 363.53, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-213.3389279693365, -340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623], "episode_lengths": [347, 368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48702674110294547, "mean_inference_ms": 24.046914725426156, "mean_action_processing_ms": 0.1358622274643882, "mean_env_wait_ms": 4.06550402508528, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 45056, "num_agent_steps_trained": 82680, "num_env_steps_sampled": 45056, "num_env_steps_trained": 82680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 45056, "agent_timesteps_total": 45056, "timers": {"training_iteration_time_ms": 330.125, "learn_time_ms": 62.268, "learn_throughput": 1927.149, "synch_weights_time_ms": 20.299}, "counters": {"num_env_steps_sampled": 45056, "num_env_steps_trained": 82680, "num_agent_steps_sampled": 45056, "num_agent_steps_trained": 82680, "last_target_update_ts": 45056, "num_target_updates": 87}, "done": false, "episodes_total": 125, "training_iteration": 44, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-27", "timestamp": 1655476107, "time_this_iter_s": 5.28662109375, "time_total_s": 214.86072373390198, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 214.86072373390198, "timesteps_since_restore": 0, "iterations_since_restore": 44, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.557142857142853, "ram_util_percent": 62.95714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.141273021697998, "min_q": -62.97713088989258, "max_q": 30.007766723632812, "mean_td_error": -0.7861166596412659}, "td_error": [2.1461925506591797, -6.1241559982299805, 0.7720413208007812, 0.8526887893676758, -22.031517028808594, -1.7961502075195312, -0.3911933898925781, 0.55145263671875, -3.4710893630981445, -1.7321624755859375, -0.848873496055603, 0.3299105167388916, -2.1658363342285156, 1.1229629516601562, -0.6797285079956055, 0.8353147506713867, -0.5375766754150391, 0.09401148557662964, -2.687528610229492, 0.11817550659179688, -7.205558776855469, -0.6512546539306641, -1.7649164199829102, 0.6529600620269775, -0.1863250732421875, 0.5516815185546875, -0.9221794605255127, -0.9560279846191406, 0.3056368827819824, 0.5092744827270508, 1.5160694122314453, -0.05740928649902344, -1.0359935760498047, 1.8458061218261719, 0.9034271240234375, 0.7620811462402344, 0.4874444007873535, -1.8600025177001953, 0.7678470611572266, 2.0207672119140625, -2.991964340209961, -1.3608918190002441, -0.29848408699035645, 3.022623062133789, 1.4941349029541016, 0.2770695686340332, -1.4166526794433594, -0.1402425765991211, -0.6720161437988281, -1.034635066986084, -1.7710685729980469, -2.0435352325439453, -1.759213924407959, 0.5437639951705933, 1.012115240097046, -2.24686336517334, -0.7788162231445312, -1.3022931814193726, 0.5657081604003906, 0.0536036491394043, -1.0488471984863281, -1.3499031066894531, 0.5446109771728516, -0.5983123779296875, 0.8723268508911133, 0.31268882751464844, -1.5566444396972656, -1.9478340148925781, -0.9082546234130859, -1.4966297149658203, -0.23698997497558594, 0.23913192749023438, -2.2422165870666504, -1.0092039108276367, 1.0110955238342285, 0.910487174987793, -0.10431146621704102, 2.5657386779785156, 0.3862171173095703, -1.014617919921875, 0.23059844970703125, 1.3246022462844849, -1.427506923675537, 1.1721935272216797, -1.9844399690628052, -1.2778658866882324, -0.3913234770298004, 1.4790191650390625, -1.5682978630065918, -1.0985050201416016, 0.27851414680480957, -0.40041446685791016, -4.180545806884766, -2.1936373710632324, 0.025088787078857422, 0.9617691040039062, -5.780119895935059, -2.820798873901367, 3.0518550872802734, -0.8658351898193359, -1.8314323425292969, -1.2261894941329956, 0.009419828653335571, -1.4068527221679688, -0.2122020721435547, 0.2682914733886719, -1.57693612575531, -4.546839714050293, 0.07907092571258545, -0.8118381500244141, -0.8033651113510132, 0.2732124328613281, -2.0173988342285156, -1.0951423645019531, -1.5264406204223633, -0.8572959899902344, 0.9960269927978516, -1.0419316291809082, -1.9796357154846191, -2.0820095539093018], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 46080, "num_env_steps_trained": 84600, "num_agent_steps_sampled": 46080, "num_agent_steps_trained": 84600, "last_target_update_ts": 46080, "num_target_updates": 89}, "sampler_results": {"episode_reward_max": 4.834490858018398, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -355.1539533533156, "episode_len_mean": 362.56, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953], "episode_lengths": [368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48686843822245757, "mean_inference_ms": 24.06582731470465, "mean_action_processing_ms": 0.13593875585433773, "mean_env_wait_ms": 4.0632719178564525, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.834490858018398, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -355.1539533533156, "episode_len_mean": 362.56, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-340.5154685154557, -191.7911937609315, -480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953], "episode_lengths": [368, 332, 426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48686843822245757, "mean_inference_ms": 24.06582731470465, "mean_action_processing_ms": 0.13593875585433773, "mean_env_wait_ms": 4.0632719178564525, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 46080, "num_agent_steps_trained": 84600, "num_env_steps_sampled": 46080, "num_env_steps_trained": 84600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 46080, "agent_timesteps_total": 46080, "timers": {"training_iteration_time_ms": 291.561, "learn_time_ms": 61.971, "learn_throughput": 1936.393, "synch_weights_time_ms": 20.289}, "counters": {"num_env_steps_sampled": 46080, "num_env_steps_trained": 84600, "num_agent_steps_sampled": 46080, "num_agent_steps_trained": 84600, "last_target_update_ts": 46080, "num_target_updates": 89}, "done": false, "episodes_total": 126, "training_iteration": 45, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-32", "timestamp": 1655476112, "time_this_iter_s": 4.669081449508667, "time_total_s": 219.52980518341064, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 219.52980518341064, "timesteps_since_restore": 0, "iterations_since_restore": 45, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.07142857142857, "ram_util_percent": 63.10000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -8.713356971740723, "min_q": -64.16506958007812, "max_q": 27.220949172973633, "mean_td_error": -0.9048159122467041}, "td_error": [0.2397480010986328, 0.3529074192047119, -1.323472499847412, 2.112987518310547, -2.5419836044311523, -1.0027379989624023, 1.6196460723876953, 0.30953216552734375, -2.2371673583984375, -0.1174929141998291, 0.1414775848388672, -3.334718704223633, 0.5228371620178223, 0.8169021606445312, -2.4655513763427734, 3.0644731521606445, -0.3416767120361328, 2.6649436950683594, 0.17432022094726562, 0.31157588958740234, 0.11885738372802734, -0.07142353057861328, -0.1263446807861328, -2.7432937622070312, -23.68762969970703, -0.9461498260498047, 1.5707428455352783, -0.8483848571777344, -0.31310439109802246, -6.288549423217773, 0.2501220703125, -11.470791816711426, 0.3500685691833496, -0.8197841644287109, -1.4993419647216797, 0.5663261413574219, 3.4496994018554688, 2.0863866806030273, 1.0313599109649658, 0.10315513610839844, -0.13590049743652344, -0.6200695037841797, -14.858476638793945, 0.7850189208984375, 0.68267822265625, -2.9513087272644043, 0.9803104400634766, 0.7690553665161133, 0.18137407302856445, 0.7252507209777832, -0.4349902868270874, 0.9868545532226562, 3.239583969116211, -0.619391918182373, 0.5021591186523438, -1.410860538482666, -0.6642329692840576, 0.7129535675048828, 0.7196464538574219, 1.0198068618774414, 0.2405223846435547, 1.9499092102050781, 3.192953109741211, 0.3627786636352539, 1.5076751708984375, 1.0390865802764893, -36.96472930908203, 3.246703624725342, -1.23162841796875, 0.6235144138336182, 2.267446517944336, -0.6218352317810059, 0.7608665227890015, -3.5789260864257812, -3.80084228515625, 3.6415786743164062, 3.144890785217285, -9.727092742919922, -0.26481151580810547, 0.1929788589477539, 1.6111526489257812, -1.7019598484039307, 0.04180908203125, -0.6531515121459961, 1.2145719528198242, 0.21602821350097656, -6.849491119384766, -0.6229763031005859, 0.17432022094726562, -7.622685432434082, 1.2709741592407227, 2.0114388465881348, 0.23314619064331055, -0.4752507209777832, 1.6174240112304688, 0.2709369659423828, 1.917740821838379, 0.9150596857070923, -0.09402728080749512, 0.4559783935546875, -0.20374488830566406, -0.8260860443115234, 0.7495460510253906, -8.542154312133789, -0.33414649963378906, -0.15384483337402344, -0.139495849609375, -1.8443158864974976, -10.450301170349121, 0.21602821350097656, 1.74908447265625, -0.16759681701660156, 0.1706371307373047, 1.0667381286621094, -2.8566036224365234, 0.16329002380371094, 1.0021874904632568, 3.7461700439453125, 0.4345436096191406, -1.557856559753418], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 47104, "num_env_steps_trained": 86520, "num_agent_steps_sampled": 47104, "num_agent_steps_trained": 86520, "last_target_update_ts": 47104, "num_target_updates": 91}, "sampler_results": {"episode_reward_max": 15.686992041766644, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -351.2072475389391, "episode_len_mean": 361.01, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644], "episode_lengths": [426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4866531730428252, "mean_inference_ms": 24.12640009700734, "mean_action_processing_ms": 0.13525934825614438, "mean_env_wait_ms": 4.054499984743932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 15.686992041766644, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -351.2072475389391, "episode_len_mean": 361.01, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-480.63434556126595, -385.4925422668457, -304.1880097463727, -313.6274915486574, -414.6578908935189, -587.6824223101139, -552.3510484918952, -373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644], "episode_lengths": [426, 392, 374, 368, 366, 424, 434, 390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4866531730428252, "mean_inference_ms": 24.12640009700734, "mean_action_processing_ms": 0.13525934825614438, "mean_env_wait_ms": 4.054499984743932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 47104, "num_agent_steps_trained": 86520, "num_env_steps_sampled": 47104, "num_env_steps_trained": 86520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 47104, "agent_timesteps_total": 47104, "timers": {"training_iteration_time_ms": 313.593, "learn_time_ms": 62.313, "learn_throughput": 1925.764, "synch_weights_time_ms": 20.288}, "counters": {"num_env_steps_sampled": 47104, "num_env_steps_trained": 86520, "num_agent_steps_sampled": 47104, "num_agent_steps_trained": 86520, "last_target_update_ts": 47104, "num_target_updates": 91}, "done": false, "episodes_total": 128, "training_iteration": 46, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-37", "timestamp": 1655476117, "time_this_iter_s": 4.94047212600708, "time_total_s": 224.47027730941772, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 224.47027730941772, "timesteps_since_restore": 0, "iterations_since_restore": 46, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.05714285714286, "ram_util_percent": 63.17142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -6.295466899871826, "min_q": -60.49982833862305, "max_q": 36.56721496582031, "mean_td_error": -0.46170032024383545}, "td_error": [0.5321388244628906, -7.862264633178711, 1.781015396118164, -0.6067630052566528, -1.802459716796875, -1.916396141052246, -0.9199028015136719, 1.8632822036743164, -3.310370445251465, 1.3074054718017578, 0.5947227478027344, -1.3260612487792969, -1.175323486328125, 1.0597972869873047, 0.34827232360839844, 2.019345760345459, 0.7563724517822266, 0.04613214731216431, -1.1360549926757812, -0.13239669799804688, -0.3545036315917969, -0.2802753448486328, 1.9590697288513184, -1.5656120777130127, 0.5625808238983154, 0.3341712951660156, 2.7356557846069336, 0.47347450256347656, 0.3742837905883789, -4.003990173339844, -1.7121920585632324, -0.5917148590087891, 1.3673592805862427, -0.24802207946777344, 1.2070579528808594, 2.189589023590088, -12.886636734008789, 5.378230094909668, -1.2039955854415894, 1.2727775573730469, 3.609790802001953, 0.9883990287780762, -0.1658158302307129, -3.381481170654297, -2.194101333618164, 1.5703182220458984, 2.1281280517578125, 1.025770664215088, 1.4881205558776855, 0.11768150329589844, 1.1205947399139404, 0.8734245300292969, 0.8286590576171875, 1.2997159957885742, 0.11768150329589844, -0.08572864532470703, 1.7052955627441406, -0.0017323493957519531, 0.24885940551757812, -0.3687858581542969, 0.585827112197876, 0.03998422622680664, 0.49300384521484375, -0.34502649307250977, 0.004518747329711914, 0.8935317993164062, 4.190444469451904, -1.3689193725585938, 0.8194997310638428, -1.3623888492584229, -0.9670381546020508, -1.9387370347976685, -0.14432859420776367, -2.8997840881347656, -5.100064754486084, 1.328115463256836, -0.49053382873535156, 0.8597297668457031, 1.8293228149414062, -0.3325662612915039, 0.628082275390625, 0.8409652709960938, -0.3958110809326172, -13.226179122924805, 0.36190688610076904, -0.15921270847320557, -0.15129469335079193, 1.3540706634521484, -1.9399434328079224, -0.07781028747558594, 1.0866622924804688, -22.65230941772461, -4.187351226806641, 2.354048728942871, -0.212457537651062, -1.0446767807006836, 1.4701544046401978, 1.6221923828125, -1.1641182899475098, 0.5872726440429688, -1.5474233627319336, 0.29361891746520996, 0.5173606872558594, 0.32338809967041016, 0.6338005065917969, 0.3528401851654053, 0.49939918518066406, -1.4726181030273438, -0.5708475112915039, -1.3703441619873047, -1.3646466732025146, 0.3060455322265625, -0.039580345153808594, -0.71923828125, -0.4587509036064148, -3.0927886962890625, 0.11531448364257812, -3.433720588684082, 0.5588688850402832, -2.176093816757202], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 48128, "num_env_steps_trained": 88440, "num_agent_steps_sampled": 48128, "num_agent_steps_trained": 88440, "last_target_update_ts": 48128, "num_target_updates": 93}, "sampler_results": {"episode_reward_max": 15.686992041766644, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -326.93102461539206, "episode_len_mean": 351.8, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433], "episode_lengths": [390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48716546262516075, "mean_inference_ms": 24.234124388959764, "mean_action_processing_ms": 0.1358346613347101, "mean_env_wait_ms": 4.040458164983145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 15.686992041766644, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -326.93102461539206, "episode_len_mean": 351.8, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-373.9904374629259, -332.00771340727806, -597.0174463391304, -354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433], "episode_lengths": [390, 380, 431, 385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48716546262516075, "mean_inference_ms": 24.234124388959764, "mean_action_processing_ms": 0.1358346613347101, "mean_env_wait_ms": 4.040458164983145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 48128, "num_agent_steps_trained": 88440, "num_env_steps_sampled": 48128, "num_env_steps_trained": 88440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 48128, "agent_timesteps_total": 48128, "timers": {"training_iteration_time_ms": 329.862, "learn_time_ms": 62.495, "learn_throughput": 1920.14, "synch_weights_time_ms": 20.489}, "counters": {"num_env_steps_sampled": 48128, "num_env_steps_trained": 88440, "num_agent_steps_sampled": 48128, "num_agent_steps_trained": 88440, "last_target_update_ts": 48128, "num_target_updates": 93}, "done": false, "episodes_total": 135, "training_iteration": 47, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-42", "timestamp": 1655476122, "time_this_iter_s": 5.28282618522644, "time_total_s": 229.75310349464417, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 229.75310349464417, "timesteps_since_restore": 0, "iterations_since_restore": 47, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.95, "ram_util_percent": 63.375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -4.277283191680908, "min_q": -66.98589324951172, "max_q": 41.271087646484375, "mean_td_error": -0.33519071340560913}, "td_error": [1.2653274536132812, -0.838597297668457, -0.744926929473877, -0.5295600891113281, -0.4394111633300781, -2.561969757080078, -0.7776865363121033, 3.525266647338867, -0.234954833984375, 0.18150663375854492, 0.4111289978027344, 2.3877029418945312, -2.3718948364257812, -0.7110805511474609, -3.2539405822753906, -2.071216583251953, 1.1224775314331055, 0.7750759124755859, 1.6383576393127441, -2.7057065963745117, 0.8745689392089844, -1.2073421478271484, 0.5484678745269775, -1.124969482421875, -4.322687149047852, 1.3399910926818848, 2.7185020446777344, -1.1438274383544922, 2.044260263442993, -11.218822479248047, 0.19717884063720703, -1.6703319549560547, 0.30513930320739746, -0.2715950012207031, -7.608780860900879, 1.8941688537597656, 6.311711311340332, 0.03774714469909668, 0.5019416809082031, 0.3650951385498047, -1.9899768829345703, -0.7019062042236328, -8.351383209228516, -0.916905403137207, 0.03880500793457031, 1.8051986694335938, 2.5646400451660156, 1.6411528587341309, 0.6721234321594238, 0.44975733757019043, -0.5364494323730469, -0.2551044225692749, -2.1249465942382812, 10.265453338623047, -1.0317792892456055, -2.1986169815063477, -2.0140838623046875, -0.29217529296875, -1.088613510131836, -2.2947731018066406, -0.7892608642578125, -1.655080795288086, 0.29452085494995117, -0.544785737991333, 2.951361894607544, -1.981693983078003, -1.4125070571899414, -0.5261540412902832, -0.2786121368408203, 2.0213966369628906, -1.7554130554199219, 0.49295616149902344, 0.5681447982788086, 1.5506210327148438, -3.0259780883789062, -1.0318851470947266, 0.8564910888671875, 0.12015151977539062, 0.03257560729980469, -0.8922119140625, -1.8488426208496094, 0.653839111328125, 0.008337020874023438, -0.6859899163246155, 0.3960726261138916, -0.7306052446365356, 1.3110309839248657, -0.602637767791748, 1.6272335052490234, -1.823204755783081, 1.6759037971496582, -0.9955129623413086, -0.9471817016601562, -0.9659029245376587, -0.47333574295043945, 0.23845481872558594, 0.5614776611328125, -0.6808428764343262, -1.5463929176330566, 0.9185123443603516, -1.9379444122314453, 1.0728726387023926, -3.4306728839874268, -1.4392051696777344, -0.1295415759086609, 1.0893573760986328, 2.4921696186065674, -1.2373323440551758, -1.3340187072753906, -2.224165916442871, 2.4858510494232178, 1.5277338027954102, -0.03846001625061035, -0.9285998344421387, -1.1250200271606445, -0.5292797088623047, -2.846550941467285, -0.7939167022705078, 2.1229052543640137, -0.38085079193115234], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 49152, "num_env_steps_trained": 90360, "num_agent_steps_sampled": 49152, "num_agent_steps_trained": 90360, "last_target_update_ts": 49152, "num_target_updates": 95}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -316.057407509014, "episode_len_mean": 347.76, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422], "episode_lengths": [385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48688148305425494, "mean_inference_ms": 24.259701989361297, "mean_action_processing_ms": 0.1354872133375269, "mean_env_wait_ms": 4.034641960898354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -316.057407509014, "episode_len_mean": 347.76, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-354.1107833907008, -600.0813776105642, -464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422], "episode_lengths": [385, 434, 406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48688148305425494, "mean_inference_ms": 24.259701989361297, "mean_action_processing_ms": 0.1354872133375269, "mean_env_wait_ms": 4.034641960898354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 49152, "num_agent_steps_trained": 90360, "num_env_steps_sampled": 49152, "num_env_steps_trained": 90360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 49152, "agent_timesteps_total": 49152, "timers": {"training_iteration_time_ms": 324.745, "learn_time_ms": 62.576, "learn_throughput": 1917.682, "synch_weights_time_ms": 20.289}, "counters": {"num_env_steps_sampled": 49152, "num_env_steps_trained": 90360, "num_agent_steps_sampled": 49152, "num_agent_steps_trained": 90360, "last_target_update_ts": 49152, "num_target_updates": 95}, "done": false, "episodes_total": 138, "training_iteration": 48, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-48", "timestamp": 1655476128, "time_this_iter_s": 5.053839206695557, "time_total_s": 234.80694270133972, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 234.80694270133972, "timesteps_since_restore": 0, "iterations_since_restore": 48, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.3, "ram_util_percent": 63.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -4.419163703918457, "min_q": -68.41657257080078, "max_q": 34.89426040649414, "mean_td_error": -0.29478269815444946}, "td_error": [1.8865585327148438, 0.3212699890136719, -0.8309593200683594, -0.6966065168380737, -7.763425827026367, 0.35070401430130005, -0.08840179443359375, -1.944976806640625, -0.14217138290405273, 2.8037941455841064, -0.6907358169555664, 0.0179135799407959, 1.7187461853027344, 1.0912079811096191, -0.7539525032043457, -0.3667144775390625, 1.4133386611938477, 0.2794222831726074, 0.43747663497924805, -1.2937297821044922, 0.2702661156654358, 0.5674055814743042, -0.11344403028488159, 1.953974723815918, 0.42790651321411133, -0.019350051879882812, -0.04154151678085327, -0.0005025863647460938, -0.031565189361572266, -0.8873519897460938, -7.640345573425293, 1.4991455078125, 0.04619789123535156, -2.162944793701172, -1.0604686737060547, 0.4749317169189453, -0.685279369354248, 1.219369888305664, 2.865537643432617, 0.2770204544067383, 0.7710494995117188, 0.28787684440612793, -4.148532867431641, 2.9926576614379883, -1.3498122692108154, 0.3759899139404297, -1.1542739868164062, 3.4916810989379883, 1.0323562622070312, -1.2121796607971191, -0.8796653747558594, -0.21583795547485352, 0.8321213722229004, -4.418676376342773, 2.0624332427978516, 0.4975166320800781, -0.33046531677246094, 2.350238800048828, 0.40959930419921875, 1.0323562622070312, 0.4301527738571167, -1.7664813995361328, 1.0025992393493652, -1.4943456649780273, -2.5562524795532227, 1.0735621452331543, 1.4688202142715454, -0.7944126129150391, 0.376802921295166, 0.12147283554077148, 1.4487075805664062, -3.069493293762207, 1.8217105865478516, 0.4967234134674072, 1.7000813484191895, 0.1514577865600586, -1.1471748352050781, -0.1320917010307312, 0.8589115142822266, 0.20086193084716797, -1.063821792602539, -0.7132205963134766, -0.6148051023483276, 2.419940233230591, -0.7259540557861328, -1.9234790802001953, -0.36280059814453125, 0.707305908203125, 1.5848941802978516, 1.1267967224121094, -7.456693649291992, 2.083004951477051, 2.867868423461914, 1.3805389404296875, -0.18994426727294922, -2.79083251953125, -0.5234609246253967, -16.78990936279297, -0.07976555824279785, -2.864187240600586, 0.43747663497924805, 3.8184947967529297, -1.8866214752197266, -0.5937881469726562, 1.1827030181884766, 0.7751026153564453, 0.09084177017211914, -0.0846567153930664, 3.0947647094726562, -12.275686264038086, 2.7989892959594727, -1.5609521865844727, 1.5574932098388672, -3.897245407104492, -1.612985610961914, 0.7058877944946289, 0.3879528045654297, 0.33769798278808594, 0.15078115463256836, -0.19741249084472656], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 50176, "num_env_steps_trained": 92280, "num_agent_steps_sampled": 50176, "num_agent_steps_trained": 92280, "last_target_update_ts": 50176, "num_target_updates": 97}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -311.2676531179249, "episode_len_mean": 345.82, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913], "episode_lengths": [406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48651281348506026, "mean_inference_ms": 24.275170678391884, "mean_action_processing_ms": 0.13553101512723653, "mean_env_wait_ms": 4.036223166002392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -311.2676531179249, "episode_len_mean": 345.82, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-464.6607708260417, -544.8565733358264, -595.1871078684926, -639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913], "episode_lengths": [406, 450, 442, 445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48651281348506026, "mean_inference_ms": 24.275170678391884, "mean_action_processing_ms": 0.13553101512723653, "mean_env_wait_ms": 4.036223166002392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 50176, "num_agent_steps_trained": 92280, "num_env_steps_sampled": 50176, "num_env_steps_trained": 92280, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 50176, "agent_timesteps_total": 50176, "timers": {"training_iteration_time_ms": 312.009, "learn_time_ms": 63.486, "learn_throughput": 1890.186, "synch_weights_time_ms": 20.289}, "counters": {"num_env_steps_sampled": 50176, "num_env_steps_trained": 92280, "num_agent_steps_sampled": 50176, "num_agent_steps_trained": 92280, "last_target_update_ts": 50176, "num_target_updates": 97}, "done": false, "episodes_total": 140, "training_iteration": 49, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-53", "timestamp": 1655476133, "time_this_iter_s": 4.919290065765381, "time_total_s": 239.7262327671051, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 239.7262327671051, "timesteps_since_restore": 0, "iterations_since_restore": 49, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.725, "ram_util_percent": 63.612500000000004}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -9.59228801727295, "min_q": -69.13203430175781, "max_q": 35.52238845825195, "mean_td_error": -0.7188398838043213}, "td_error": [-0.2242722511291504, 1.9446420669555664, -0.48975610733032227, 0.8187260031700134, -0.6875791549682617, -6.180051803588867, -0.23771095275878906, -0.6263751983642578, -0.7473306655883789, -0.022064208984375, -7.788860321044922, 1.5558338165283203, 0.1436614990234375, -0.27086639404296875, -0.9612445831298828, 1.8004837036132812, -1.6197052001953125, 0.6090812683105469, 0.35872554779052734, 2.5265626907348633, -11.649154663085938, -0.3884878158569336, 0.03986377269029617, 0.4591735601425171, -0.12254524230957031, -0.6218280792236328, 0.35408926010131836, 0.8909540176391602, -6.108429908752441, -0.4230918884277344, -0.7180023193359375, -0.11952972412109375, -0.3186793327331543, -1.723785400390625, -0.7331908941268921, 1.2103404998779297, 0.02600860595703125, -0.8632035255432129, -0.42469704151153564, -0.6609106063842773, 2.860158920288086, 1.1760215759277344, 2.621929168701172, 0.057712554931640625, -3.387340545654297, -1.4653434753417969, 0.25299835205078125, -1.2844785451889038, -0.25112152099609375, -0.8874837756156921, -4.194234371185303, 0.6751842498779297, -0.79656982421875, 1.9900388717651367, 3.0314483642578125, -3.244792938232422, 0.29357147216796875, -1.3122045993804932, 0.11865997314453125, -3.393784523010254, -1.7401485443115234, 1.6016721725463867, -7.467288970947266, -0.09100914001464844, 0.4074726104736328, -1.1065044403076172, -0.0398406982421875, -0.0197601318359375, 0.21739673614501953, -0.7955780029296875, -0.0038366317749023438, -5.2820048332214355, -0.3077573776245117, -14.383441925048828, 1.1380724906921387, -0.963652491569519, -0.7708110809326172, -1.6871223449707031, -0.752044677734375, 0.1458883285522461, 1.5810432434082031, 2.2135348320007324, -3.2486324310302734, -1.4842872619628906, 1.841902732849121, 0.7595291137695312, -0.9806138873100281, -0.7071533203125, 1.6068248748779297, 0.08263540267944336, 2.458498001098633, 2.1225662231445312, 0.7167253494262695, 1.4561982154846191, 1.8248271942138672, -1.2631645202636719, -1.6818866729736328, 0.36702919006347656, 0.09584522247314453, -7.02070426940918, 0.9897518157958984, 17.374475479125977, 2.387462615966797, -8.691368103027344, 1.1768569946289062, -1.628880500793457, -0.7065114974975586, -4.109289646148682, -4.3054656982421875, 0.18049001693725586, -2.145308494567871, -6.3235368728637695, -0.1377248764038086, 0.30686116218566895, -8.75750732421875, -0.5266799926757812, -0.18940353393554688, 0.837763786315918, 1.2899503707885742, -2.990304946899414], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 51200, "num_env_steps_trained": 94200, "num_agent_steps_sampled": 51200, "num_agent_steps_trained": 94200, "last_target_update_ts": 51200, "num_target_updates": 99}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -305.74350064203145, "episode_len_mean": 343.15, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704], "episode_lengths": [445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4867938807158012, "mean_inference_ms": 24.30587099313009, "mean_action_processing_ms": 0.13530611991230068, "mean_env_wait_ms": 4.0317141912523615, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -305.74350064203145, "episode_len_mean": 343.15, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-639.3484534397721, -477.399957485497, -610.9790332838893, -566.8818531706929, -499.81830144673586, -214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704], "episode_lengths": [445, 423, 439, 411, 408, 336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4867938807158012, "mean_inference_ms": 24.30587099313009, "mean_action_processing_ms": 0.13530611991230068, "mean_env_wait_ms": 4.0317141912523615, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 51200, "num_agent_steps_trained": 94200, "num_env_steps_sampled": 51200, "num_env_steps_trained": 94200, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 51200, "agent_timesteps_total": 51200, "timers": {"training_iteration_time_ms": 326.107, "learn_time_ms": 62.793, "learn_throughput": 1911.033, "synch_weights_time_ms": 20.488}, "counters": {"num_env_steps_sampled": 51200, "num_env_steps_trained": 94200, "num_agent_steps_sampled": 51200, "num_agent_steps_trained": 94200, "last_target_update_ts": 51200, "num_target_updates": 99}, "done": false, "episodes_total": 143, "training_iteration": 50, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-28-58", "timestamp": 1655476138, "time_this_iter_s": 5.077071905136108, "time_total_s": 244.8033046722412, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 244.8033046722412, "timesteps_since_restore": 0, "iterations_since_restore": 50, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.8, "ram_util_percent": 63.75714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.237274169921875, "min_q": -70.04766845703125, "max_q": 30.961902618408203, "mean_td_error": -0.16109345853328705}, "td_error": [2.207202911376953, 1.2184820175170898, -2.532146453857422, -0.9224417209625244, 0.3820774555206299, -0.36603546142578125, -0.1589679718017578, 0.4623425006866455, -0.7093982696533203, -4.427799224853516, -0.056288719177246094, -0.9402732849121094, 0.7742118835449219, -0.6386504173278809, -1.9986028671264648, 0.5072841644287109, -0.3943023681640625, 0.4517173767089844, -0.21020519733428955, -0.4539151191711426, -14.195362091064453, -0.489501953125, 0.824152946472168, -1.7080774307250977, -0.25174713134765625, 0.3084897994995117, -0.01629638671875, -2.100559949874878, 1.2844572067260742, -1.2960853576660156, 0.9709968566894531, -0.09142303466796875, 0.7594897747039795, 6.248018264770508, -0.25476837158203125, -1.2960853576660156, -1.194906234741211, -2.480558395385742, -0.8631229400634766, 1.0476226806640625, 0.4850947856903076, 1.1458348035812378, 2.934173583984375, 2.8298864364624023, -6.9369683265686035, -0.7927910685539246, 0.5031177997589111, 0.3627920150756836, -3.173220157623291, 0.679193377494812, 0.30132007598876953, -0.8409695625305176, 0.45252037048339844, -0.8740290403366089, -1.918722152709961, 0.3974275588989258, 1.709904670715332, -1.633713722229004, 0.8440022468566895, 2.3405160903930664, 1.3182520866394043, -0.0004029273986816406, -0.17667007446289062, 1.8850021362304688, 0.5887298583984375, 1.018869400024414, -0.19038009643554688, 1.9571685791015625, 0.0896596908569336, -0.121124267578125, -0.3045731782913208, -0.4609532356262207, 0.08456611633300781, 4.905269622802734, 0.829345703125, -2.2279562950134277, -1.1374473571777344, 1.7210302352905273, 0.3587212562561035, 1.4901432991027832, 1.791475772857666, 0.14964675903320312, 0.45162105560302734, 1.4177584648132324, 2.3141632080078125, 0.34143662452697754, -0.7382049560546875, 1.2854671478271484, 0.7890597581863403, 1.5578436851501465, 3.177093505859375, 0.2526334524154663, 0.8100481033325195, -0.48453712463378906, -2.0233728885650635, -7.166050910949707, 0.4779752492904663, 0.377685546875, 0.22671377658843994, 2.958202600479126, -2.654439926147461, -8.12154769897461, -3.0190036296844482, 0.18471527099609375, 4.020742416381836, 0.5022506713867188, -0.14476120471954346, 1.045309066772461, 0.8016462326049805, 0.9431407451629639, -2.381366729736328, 0.08121109008789062, 2.0949411392211914, -0.16974830627441406, 0.25790125131607056, -5.629701614379883, 0.16611862182617188, -3.0056867599487305, -1.9507026672363281, 1.8394641876220703], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 52224, "num_env_steps_trained": 96120, "num_agent_steps_sampled": 52224, "num_agent_steps_trained": 96120, "last_target_update_ts": 52224, "num_target_updates": 101}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -279.8794153735042, "episode_len_mean": 334.7, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331], "episode_lengths": [336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4883175164895474, "mean_inference_ms": 24.381952140823678, "mean_action_processing_ms": 0.13538184032556025, "mean_env_wait_ms": 4.032186087585206, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -279.8794153735042, "episode_len_mean": 334.7, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-214.66328638792038, -655.4860143214464, -337.84890538454056, -113.77358540892601, -325.5429407581687, -667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331], "episode_lengths": [336, 443, 359, 294, 355, 426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4883175164895474, "mean_inference_ms": 24.381952140823678, "mean_action_processing_ms": 0.13538184032556025, "mean_env_wait_ms": 4.032186087585206, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 52224, "num_agent_steps_trained": 96120, "num_env_steps_sampled": 52224, "num_env_steps_trained": 96120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 52224, "agent_timesteps_total": 52224, "timers": {"training_iteration_time_ms": 320.041, "learn_time_ms": 63.949, "learn_throughput": 1876.481, "synch_weights_time_ms": 20.202}, "counters": {"num_env_steps_sampled": 52224, "num_env_steps_trained": 96120, "num_agent_steps_sampled": 52224, "num_agent_steps_trained": 96120, "last_target_update_ts": 52224, "num_target_updates": 101}, "done": false, "episodes_total": 148, "training_iteration": 51, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-03", "timestamp": 1655476143, "time_this_iter_s": 5.197762489318848, "time_total_s": 250.00106716156006, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 250.00106716156006, "timesteps_since_restore": 0, "iterations_since_restore": 51, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.7375, "ram_util_percent": 63.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.628176689147949, "min_q": -68.2302017211914, "max_q": 31.65528106689453, "mean_td_error": 0.5284764766693115}, "td_error": [0.5733485221862793, -0.9004478454589844, 1.1348700523376465, -1.5057868957519531, -0.17501068115234375, 1.2574043273925781, 0.9201774597167969, 3.540609836578369, -0.2584099769592285, 0.5911202430725098, 3.2494678497314453, -0.26568603515625, -1.115700602531433, -0.4050273895263672, 0.9278659820556641, 0.5209636688232422, 2.908328056335449, 2.2514686584472656, -1.834376335144043, 0.4357490539550781, 2.913867950439453, 2.875699996948242, 1.937953233718872, 0.2781972885131836, 1.606752872467041, -1.0566234588623047, -13.430660247802734, 2.800863265991211, 2.2683792114257812, -0.2818632125854492, 2.5805883407592773, -0.18246173858642578, 3.782055377960205, 0.5969715118408203, 0.2404003143310547, 2.0367236137390137, 1.6728076934814453, -0.5161724090576172, 6.633131980895996, 0.42224979400634766, -3.7661590576171875, -5.441593170166016, 2.4770240783691406, 0.9595842361450195, 1.50093412399292, 1.3105573654174805, -0.9679489135742188, 1.5019149780273438, 0.9973430633544922, 2.9867987632751465, 1.7345547676086426, 0.3478125333786011, 0.9755220413208008, -5.924287796020508, -0.7183876037597656, -0.8523063659667969, 0.22571945190429688, 3.052387237548828, 0.231353759765625, -0.7024250030517578, 0.8780803680419922, -7.104948043823242, -0.39467430114746094, -1.0191383361816406, 2.4516191482543945, 1.5206433534622192, 0.7416729927062988, -1.0566234588623047, -5.443082809448242, -0.651702880859375, 0.3212776184082031, 1.3403420448303223, 1.4401021003723145, -0.0010471343994140625, -0.4324173927307129, -5.148804664611816, 3.529219150543213, -8.744112014770508, 3.8315162658691406, 0.237748384475708, 2.8882265090942383, -2.0813827514648438, -0.11712241172790527, -1.9171257019042969, 0.3680577278137207, -0.49793434143066406, 2.4623241424560547, 1.8823518753051758, -2.248612642288208, 1.4444260597229004, 0.8613662719726562, 4.6865739822387695, 1.7142887115478516, 0.9383162260055542, -0.291806697845459, -5.289218902587891, 0.4750785827636719, -1.6801986694335938, -2.537485122680664, -0.8854179382324219, -0.05467367172241211, 1.5170135498046875, 1.8333637714385986, 43.66831970214844, -5.093310356140137, 0.6635599136352539, 1.1538810729980469, -0.4371504783630371, 2.7448630332946777, 0.06444936990737915, -1.8560676574707031, 0.49426060914993286, 0.2243802547454834, 2.8670711517333984, -2.8944149017333984, -0.9020233154296875, -3.3889636993408203, 1.7972793579101562, 2.39182710647583, 3.1949501037597656], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 53248, "num_env_steps_trained": 98040, "num_agent_steps_sampled": 53248, "num_agent_steps_trained": 98040, "last_target_update_ts": 53248, "num_target_updates": 103}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -269.4782214215398, "episode_len_mean": 330.48, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822], "episode_lengths": [426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4883531509709214, "mean_inference_ms": 24.408035366161048, "mean_action_processing_ms": 0.13532833779369452, "mean_env_wait_ms": 4.031446629893874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -269.4782214215398, "episode_len_mean": 330.48, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822], "episode_lengths": [426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4883531509709214, "mean_inference_ms": 24.408035366161048, "mean_action_processing_ms": 0.13532833779369452, "mean_env_wait_ms": 4.031446629893874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 53248, "num_agent_steps_trained": 98040, "num_env_steps_sampled": 53248, "num_env_steps_trained": 98040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 53248, "agent_timesteps_total": 53248, "timers": {"training_iteration_time_ms": 327.755, "learn_time_ms": 65.282, "learn_throughput": 1838.188, "synch_weights_time_ms": 20.689}, "counters": {"num_env_steps_sampled": 53248, "num_env_steps_trained": 98040, "num_agent_steps_sampled": 53248, "num_agent_steps_trained": 98040, "last_target_update_ts": 53248, "num_target_updates": 103}, "done": false, "episodes_total": 153, "training_iteration": 52, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-09", "timestamp": 1655476149, "time_this_iter_s": 5.130116701126099, "time_total_s": 255.13118386268616, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 255.13118386268616, "timesteps_since_restore": 0, "iterations_since_restore": 52, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.557142857142853, "ram_util_percent": 63.699999999999996}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -6.738367080688477, "min_q": -73.10034942626953, "max_q": 27.91411590576172, "mean_td_error": 0.026222070679068565}, "td_error": [0.8291168212890625, 3.288364887237549, 1.1627540588378906, 0.12551641464233398, -0.3932814598083496, 1.015467643737793, 0.20979690551757812, 0.8161182403564453, 1.537571907043457, 1.9299087524414062, -6.572463035583496, 1.1361751556396484, 0.7063980102539062, 0.1482926309108734, 3.796846389770508, -0.08834120631217957, -0.4525470733642578, -0.5346786975860596, -0.15801119804382324, 2.354940414428711, -0.06600278615951538, 0.2858257293701172, -0.681429386138916, -0.3307819366455078, -0.8965950012207031, 1.2679634094238281, 0.6322755813598633, -0.15825116634368896, 0.18135452270507812, -7.210658073425293, 2.0339393615722656, -0.05599212646484375, -0.2696094512939453, 1.513768196105957, 0.3338203430175781, 0.30118560791015625, 2.186375617980957, 2.673403739929199, 1.1861532926559448, -2.842805862426758, 0.7576804161071777, 1.1114513874053955, -0.20302200317382812, 0.7559280395507812, -0.1841583251953125, -0.2161712646484375, -0.5138930082321167, -4.335434436798096, 1.0118696689605713, 1.7943792343139648, 0.4282989501953125, 4.502590179443359, 0.7827250957489014, -1.9106979370117188, -0.1204977035522461, -1.7829852104187012, 0.6737251281738281, 0.6591215133666992, 2.7025413513183594, -5.6706719398498535, 1.7240619659423828, 2.2698071002960205, 0.8268465995788574, 1.1751961708068848, 0.5502967834472656, -1.1041831970214844, -2.0791053771972656, -1.4124977588653564, -0.4485816955566406, 0.05628490447998047, 0.12727069854736328, 0.18856430053710938, 1.1310651302337646, 0.017391204833984375, 0.28845787048339844, -0.4709019660949707, -2.984201431274414, -1.3679838180541992, 3.012126922607422, -9.06466293334961, 3.6170239448547363, 0.39572954177856445, 0.9610834121704102, -0.025534868240356445, 1.7277641296386719, -0.08120250701904297, 4.124730110168457, 0.24834060668945312, -1.323270320892334, -0.3088951110839844, 0.9480307102203369, -0.20728683471679688, -0.8052148818969727, 5.149892807006836, -0.3843849301338196, -1.7823848724365234, -0.33880019187927246, -0.33855628967285156, -0.4525470733642578, -0.0904080867767334, 0.6873898506164551, -1.134709358215332, -5.802516937255859, 0.3338432312011719, 0.5037870407104492, -2.8178086280822754, 1.7936768531799316, 0.12727069854736328, -0.0035698413848876953, -0.102386474609375, -4.511030197143555, 2.6334893703460693, -0.30779600143432617, 0.6498594284057617, -1.0035369396209717, -2.8463821411132812, -2.09683895111084, 1.8800811767578125, 2.5045313835144043, -1.9947319030761719], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 54272, "num_env_steps_trained": 99960, "num_agent_steps_sampled": 54272, "num_agent_steps_trained": 99960, "last_target_update_ts": 54272, "num_target_updates": 105}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -269.4782214215398, "episode_len_mean": 330.48, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822], "episode_lengths": [426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4883531509709214, "mean_inference_ms": 24.408035366161048, "mean_action_processing_ms": 0.13532833779369452, "mean_env_wait_ms": 4.031446629893874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -269.4782214215398, "episode_len_mean": 330.48, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-667.4432587623596, -159.5682072713971, -574.1130737364292, -471.7048772647977, -468.91694696992636, -771.5196890383959, -353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822], "episode_lengths": [426, 322, 429, 405, 432, 450, 385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4883531509709214, "mean_inference_ms": 24.408035366161048, "mean_action_processing_ms": 0.13532833779369452, "mean_env_wait_ms": 4.031446629893874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 54272, "num_agent_steps_trained": 99960, "num_env_steps_sampled": 54272, "num_env_steps_trained": 99960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 54272, "agent_timesteps_total": 54272, "timers": {"training_iteration_time_ms": 303.592, "learn_time_ms": 64.208, "learn_throughput": 1868.933, "synch_weights_time_ms": 20.289}, "counters": {"num_env_steps_sampled": 54272, "num_env_steps_trained": 99960, "num_agent_steps_sampled": 54272, "num_agent_steps_trained": 99960, "last_target_update_ts": 54272, "num_target_updates": 105}, "done": false, "episodes_total": 153, "training_iteration": 53, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-14", "timestamp": 1655476154, "time_this_iter_s": 4.795497894287109, "time_total_s": 259.92668175697327, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 259.92668175697327, "timesteps_since_restore": 0, "iterations_since_restore": 53, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.52857142857143, "ram_util_percent": 63.75714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.539885520935059, "min_q": -67.61338806152344, "max_q": 23.283039093017578, "mean_td_error": 0.07041317969560623}, "td_error": [1.8551197052001953, -0.67193603515625, 1.4136219024658203, -1.0157747268676758, -4.490422248840332, 0.6623954772949219, -0.06813240051269531, 3.7908878326416016, 0.9101753234863281, 0.9847679138183594, -3.2009191513061523, 1.1696934700012207, 0.6773563623428345, 2.1127824783325195, 0.9109601974487305, 0.2747955322265625, 0.14010000228881836, 1.2687482833862305, 0.6810404062271118, 0.5760736465454102, 1.377549171447754, 2.6691503524780273, 2.341200113296509, -11.695781707763672, -0.8174037933349609, 0.1980762481689453, 1.8666486740112305, 0.6132346391677856, 0.5557425022125244, -1.9773826599121094, -0.7795085906982422, -6.222914695739746, 0.5279364585876465, 0.4839944839477539, 0.7744655609130859, -0.21584415435791016, -6.393486022949219, 1.2654695510864258, -6.252178192138672, -0.4736824035644531, 0.4671134948730469, 0.4245939254760742, 1.3613910675048828, 1.3375282287597656, 2.222069263458252, 1.3045234680175781, 0.18883943557739258, -0.029119491577148438, -0.005099773406982422, 1.003286361694336, -0.8193979263305664, 1.3375282287597656, -0.19623565673828125, 2.5640029907226562, -0.11487245559692383, -0.6427364349365234, 2.372783660888672, -1.7841835021972656, 0.3666590452194214, -0.2971611022949219, 2.0349960327148438, 1.0691053867340088, 0.4624443054199219, -0.9285778999328613, 0.17960548400878906, 1.1024360656738281, 1.1792850494384766, -0.14212417602539062, 1.0428571701049805, 1.187326431274414, 1.1005656719207764, 0.5013408660888672, -5.380805969238281, -1.4044618606567383, 0.5528383255004883, 0.3195180892944336, 0.8114442825317383, -3.8499631881713867, 0.1629014015197754, 0.6080722808837891, -1.605649471282959, -0.3224668502807617, 0.5485458374023438, 0.8399143218994141, 0.4390130043029785, 0.9377541542053223, 0.5732269287109375, -6.744144439697266, -0.31993579864501953, 0.5293369293212891, 0.7045192718505859, 3.1840434074401855, -0.3047199845314026, 7.076057434082031, -0.43190860748291016, -0.6382865905761719, 0.49666595458984375, 1.8515539169311523, 5.073780059814453, 0.8565127849578857, 1.0419254302978516, -1.0251874923706055, -1.034933090209961, -1.8750922679901123, 1.5008468627929688, 0.08299827575683594, -0.39871692657470703, 3.0608482360839844, 0.5498442649841309, 2.464158058166504, -1.6157894134521484, -0.8043136596679688, -1.0359468460083008, 2.034334182739258, -0.10543966293334961, 0.372103214263916, -0.17996978759765625, -7.195655822753906, 1.144866943359375, 1.227952003479004], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 55296, "num_env_steps_trained": 101880, "num_agent_steps_sampled": 55296, "num_agent_steps_trained": 101880, "last_target_update_ts": 55296, "num_target_updates": 107}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -247.0185198854655, "episode_len_mean": 322.37, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097], "episode_lengths": [385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4882726026569448, "mean_inference_ms": 24.442218068832016, "mean_action_processing_ms": 0.13524869943084633, "mean_env_wait_ms": 4.031530377106604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -247.0185198854655, "episode_len_mean": 322.37, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-353.7369299829006, -478.8675340935588, -703.072984546423, -601.6491485238075, -770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097], "episode_lengths": [385, 394, 450, 422, 450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4882726026569448, "mean_inference_ms": 24.442218068832016, "mean_action_processing_ms": 0.13524869943084633, "mean_env_wait_ms": 4.031530377106604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 55296, "num_agent_steps_trained": 101880, "num_env_steps_sampled": 55296, "num_env_steps_trained": 101880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 55296, "agent_timesteps_total": 55296, "timers": {"training_iteration_time_ms": 325.661, "learn_time_ms": 65.089, "learn_throughput": 1843.621, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 55296, "num_env_steps_trained": 101880, "num_agent_steps_sampled": 55296, "num_agent_steps_trained": 101880, "last_target_update_ts": 55296, "num_target_updates": 107}, "done": false, "episodes_total": 159, "training_iteration": 54, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-19", "timestamp": 1655476159, "time_this_iter_s": 5.361288070678711, "time_total_s": 265.287969827652, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 265.287969827652, "timesteps_since_restore": 0, "iterations_since_restore": 54, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.225, "ram_util_percent": 63.849999999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -4.5100178718566895, "min_q": -64.58551025390625, "max_q": 30.86273765563965, "mean_td_error": -0.43482670187950134}, "td_error": [-0.8646869659423828, -0.7255630493164062, 1.6605017185211182, 0.9591312408447266, 1.9730539321899414, -0.7963123321533203, -6.113210678100586, -1.0109872817993164, -0.5063625574111938, 2.636834144592285, 1.5119380950927734, 1.3112989664077759, -0.274566650390625, 2.1064186096191406, -9.227676391601562, 1.4058690071105957, 0.10998821258544922, -0.3094062805175781, -0.12012481689453125, 0.2080373764038086, 0.8042523860931396, 1.1585216522216797, 0.01416778564453125, 0.36332643032073975, -0.8444452285766602, 1.0783967971801758, -0.6501789093017578, 1.5397828817367554, 0.050856590270996094, 0.23059940338134766, 3.1399126052856445, 0.3934829831123352, 1.6325130462646484, -8.505573272705078, 2.500462532043457, -0.15535975992679596, 0.5200958251953125, 2.2866108417510986, -0.8209109306335449, -0.20601749420166016, 1.0567359924316406, -2.9003658294677734, 0.9119648933410645, 1.3205327987670898, 0.39456844329833984, 0.6567301750183105, 3.7896080017089844, 1.3174123764038086, 1.5745009183883667, -0.3785979747772217, 2.040959358215332, 2.0025248527526855, 1.790154218673706, 0.6385726928710938, 0.5274114608764648, 0.16414260864257812, -1.4995290040969849, 0.7886577844619751, -2.8838038444519043, 1.1855354309082031, -0.10784482955932617, 1.096928358078003, -2.5968470573425293, 1.112874984741211, -2.738136053085327, -0.7468304634094238, -1.0854616165161133, 1.0345544815063477, 0.07473468780517578, 1.308523178100586, -1.7055963277816772, 1.114457130432129, -39.39892578125, -3.2518060207366943, 0.31148743629455566, 2.1064186096191406, 1.0948047637939453, 1.2505531311035156, -0.5328845977783203, -1.3944129943847656, -0.3748207092285156, 2.3232522010803223, 2.054107666015625, 0.9103102684020996, -7.240024566650391, -0.9013271331787109, 0.19764494895935059, 2.920971393585205, -9.432097434997559, -1.401270866394043, -2.574291229248047, -1.5546822547912598, 1.8033652305603027, -1.7313652038574219, 2.059323787689209, -0.030994415283203125, 2.482542037963867, 6.763944625854492, -0.8728666305541992, 1.1094989776611328, 0.7553186416625977, 1.5716743469238281, 2.0737781524658203, 0.08912169933319092, 1.6434266567230225, -2.473020553588867, -0.09924232959747314, -0.6000887155532837, 0.47303056716918945, -6.648591041564941, 0.9350614547729492, 0.3932981491088867, 0.66839599609375, 0.8204355239868164, -8.01086139678955, 1.9310646057128906, -1.156437873840332, -9.203807830810547, 0.46371138095855713, -0.2256631851196289], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 56320, "num_env_steps_trained": 103800, "num_agent_steps_sampled": 56320, "num_agent_steps_trained": 103800, "last_target_update_ts": 56320, "num_target_updates": 109}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -228.13143770821392, "episode_len_mean": 315.08, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256], "episode_lengths": [450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49026860960084434, "mean_inference_ms": 24.467057932318113, "mean_action_processing_ms": 0.13558497122281474, "mean_env_wait_ms": 4.038700385096877, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -827.8801461905241, "episode_reward_mean": -228.13143770821392, "episode_len_mean": 315.08, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-770.2502933219075, -159.76828007400036, -205.87081703543663, -240.640664935112, -554.0050807446241, -348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256], "episode_lengths": [450, 302, 337, 339, 435, 358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49026860960084434, "mean_inference_ms": 24.467057932318113, "mean_action_processing_ms": 0.13558497122281474, "mean_env_wait_ms": 4.038700385096877, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 56320, "num_agent_steps_trained": 103800, "num_env_steps_sampled": 56320, "num_env_steps_trained": 103800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 56320, "agent_timesteps_total": 56320, "timers": {"training_iteration_time_ms": 314.21, "learn_time_ms": 64.421, "learn_throughput": 1862.75, "synch_weights_time_ms": 20.397}, "counters": {"num_env_steps_sampled": 56320, "num_env_steps_trained": 103800, "num_agent_steps_sampled": 56320, "num_agent_steps_trained": 103800, "last_target_update_ts": 56320, "num_target_updates": 109}, "done": false, "episodes_total": 163, "training_iteration": 55, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-24", "timestamp": 1655476164, "time_this_iter_s": 5.044187545776367, "time_total_s": 270.33215737342834, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 270.33215737342834, "timesteps_since_restore": 0, "iterations_since_restore": 55, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.985714285714284, "ram_util_percent": 63.785714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -7.420158863067627, "min_q": -64.85357666015625, "max_q": 29.804059982299805, "mean_td_error": -0.3251742124557495}, "td_error": [-9.895101547241211, 2.0755863189697266, -0.1457204818725586, -8.49959945678711, 0.37405502796173096, 1.4331388473510742, 1.4912738800048828, 0.34207916259765625, -0.4996929168701172, 0.8221549987792969, 0.04385805130004883, -2.5024735927581787, 1.2434215545654297, -0.5764040946960449, 0.6761592626571655, -0.40273571014404297, 0.7283294200897217, -0.6628389358520508, 2.1580448150634766, 1.141737937927246, -0.05690598487854004, 0.742314338684082, 3.20552134513855, 1.3424835205078125, -0.0074310302734375, 0.3554811477661133, 0.2403569221496582, 0.49707984924316406, 0.7236504554748535, 0.8404806852340698, 0.05134296417236328, -7.728549957275391, 0.5422430038452148, -0.9606256484985352, -1.0670976638793945, 0.5662078857421875, 0.8043842315673828, -12.991168022155762, 0.8991329669952393, 1.748873233795166, -0.8399965763092041, 0.05662846565246582, -0.028921127319335938, 0.8175897598266602, -0.14856624603271484, -5.838979721069336, 1.2201919555664062, 0.17286360263824463, -0.6173267364501953, 0.329164981842041, -2.3368916511535645, 2.7582740783691406, -1.5907917022705078, -0.4911060333251953, 1.5300641059875488, -0.9939584732055664, 1.5655174255371094, 3.684968948364258, 0.5581274032592773, 0.04725170135498047, -0.9604768753051758, -0.040660858154296875, -1.1822586059570312, 1.0016775131225586, -0.4131488800048828, -0.25745677947998047, 0.20212721824645996, 0.14653587341308594, -0.8658097982406616, 1.9304313659667969, 2.2900619506835938, 1.0976817607879639, -0.32089805603027344, -10.314861297607422, 0.03395390510559082, -0.8474235534667969, 0.6060933470726013, 0.8218770027160645, 2.247042179107666, 0.9753913879394531, 0.7875759601593018, 1.8031997680664062, 0.5269603729248047, 0.6271305084228516, 0.06824421882629395, -2.959136962890625, 0.5599460601806641, -3.0360450744628906, -1.717612385749817, 0.0686807632446289, 1.4804601669311523, 0.1702404022216797, 0.0700225830078125, -0.6204602718353271, 0.3400564193725586, 0.7347183227539062, -0.2934403419494629, 1.6923370361328125, 0.5100765228271484, 0.8118149042129517, -6.225554466247559, -0.47161388397216797, -0.4747443199157715, -1.1047096252441406, 0.6272125244140625, 0.647141695022583, -0.1829071044921875, 0.303570032119751, 1.31219482421875, 2.1248016357421875, -1.3247566223144531, -0.15557098388671875, 1.3535289764404297, 0.3147006034851074, -0.5251989364624023, -9.68191909790039, -0.49097251892089844, -0.04310798645019531, -0.3722963333129883, -1.37249755859375], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 57344, "num_env_steps_trained": 105720, "num_agent_steps_sampled": 57344, "num_agent_steps_trained": 105720, "last_target_update_ts": 57344, "num_target_updates": 111}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -842.9557582736015, "episode_reward_mean": -220.21023672647775, "episode_len_mean": 311.64, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817], "episode_lengths": [358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4903404307574597, "mean_inference_ms": 24.51460939405011, "mean_action_processing_ms": 0.1354223555506224, "mean_env_wait_ms": 4.041044624945401, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -842.9557582736015, "episode_reward_mean": -220.21023672647775, "episode_len_mean": 311.64, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-348.37206020206213, -90.38954615592957, -436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817], "episode_lengths": [358, 296, 374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4903404307574597, "mean_inference_ms": 24.51460939405011, "mean_action_processing_ms": 0.1354223555506224, "mean_env_wait_ms": 4.041044624945401, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 57344, "num_agent_steps_trained": 105720, "num_env_steps_sampled": 57344, "num_env_steps_trained": 105720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 57344, "agent_timesteps_total": 57344, "timers": {"training_iteration_time_ms": 313.164, "learn_time_ms": 65.183, "learn_throughput": 1840.982, "synch_weights_time_ms": 20.589}, "counters": {"num_env_steps_sampled": 57344, "num_env_steps_trained": 105720, "num_agent_steps_sampled": 57344, "num_agent_steps_trained": 105720, "last_target_update_ts": 57344, "num_target_updates": 111}, "done": false, "episodes_total": 168, "training_iteration": 56, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-29", "timestamp": 1655476169, "time_this_iter_s": 5.082920074462891, "time_total_s": 275.41507744789124, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 275.41507744789124, "timesteps_since_restore": 0, "iterations_since_restore": 56, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.2, "ram_util_percent": 63.78571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.865375995635986, "min_q": -76.23070526123047, "max_q": 27.706865310668945, "mean_td_error": -1.4526031017303467}, "td_error": [0.15228843688964844, -4.1314616203308105, -28.153934478759766, -8.682708740234375, -0.24149608612060547, -0.6725559234619141, -0.31412506103515625, 0.9372079372406006, -1.0021677017211914, -1.1237940788269043, -0.6287078857421875, -9.149982452392578, 0.05228996276855469, -1.6851553916931152, -1.6639466285705566, -0.36879873275756836, -0.40350341796875, -1.9984779357910156, -0.07157611846923828, 0.8563563823699951, 0.5991935729980469, 0.05400848388671875, 2.4426956176757812, 0.6788425445556641, -0.9841670989990234, -3.2508468627929688, 0.44496726989746094, 0.35968780517578125, -1.1987247467041016, -1.072340965270996, -1.8926358222961426, 1.823862075805664, 0.15148401260375977, -1.6715631484985352, 1.1393547058105469, 0.5499496459960938, -0.14422035217285156, -0.2366347312927246, 1.447890281677246, -0.2588319778442383, -1.0033273696899414, -0.4910116195678711, -0.5187578201293945, -2.100388526916504, 0.3354778289794922, -14.198596954345703, -1.9100570678710938, 1.1283044815063477, 1.742501974105835, -6.0628252029418945, 1.0626683235168457, -19.125518798828125, 1.7761764526367188, -0.6550350189208984, -3.1704626083374023, -8.40087890625, 0.9348292350769043, 0.27706044912338257, -1.4129104614257812, -0.20650768280029297, -2.0020179748535156, 0.4302635192871094, 0.10567760467529297, -0.9133377075195312, -0.2537398338317871, -0.3513965606689453, 0.5155167579650879, -1.3505840301513672, -2.739900588989258, 0.6251087188720703, 0.18964195251464844, -0.081695556640625, 1.0349149703979492, 1.9806442260742188, -1.6190719604492188, -0.039537906646728516, -0.9941288232803345, -3.2325611114501953, -0.5145292282104492, -0.23958873748779297, -1.4242620468139648, -1.7580795288085938, -0.3719291687011719, -0.6016159057617188, 2.0126004219055176, 0.1119842529296875, 0.7282261848449707, -0.4428344964981079, 0.05400848388671875, -0.3242168426513672, -0.8420124053955078, -2.7242279052734375, -1.4473457336425781, -0.12537479400634766, -7.0420026779174805, -3.599790573120117, -1.2979774475097656, -0.48476696014404297, -0.9029855728149414, -0.554316520690918, -4.931230545043945, -0.7394227981567383, 0.09279918670654297, -6.6407976150512695, 0.7068080902099609, 0.3005645275115967, -0.47156524658203125, 0.10039424896240234, -0.7929925918579102, -3.0081229209899902, -0.29440879821777344, 0.3415851593017578, -11.736812591552734, -2.4219446182250977, -0.500216007232666, 0.1380290985107422, -0.7204456329345703, -0.5437431335449219, -2.6233158111572266, 1.2312378883361816], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 58368, "num_env_steps_trained": 107640, "num_agent_steps_sampled": 58368, "num_agent_steps_trained": 107640, "last_target_update_ts": 58368, "num_target_updates": 113}, "sampler_results": {"episode_reward_max": 16.064785823225975, "episode_reward_min": -842.9557582736015, "episode_reward_mean": -216.28746629595756, "episode_len_mean": 309.29, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515], "episode_lengths": [374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4906592411938637, "mean_inference_ms": 24.51227151638247, "mean_action_processing_ms": 0.1353668833861527, "mean_env_wait_ms": 4.041903396787532, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 16.064785823225975, "episode_reward_min": -842.9557582736015, "episode_reward_mean": -216.28746629595756, "episode_len_mean": 309.29, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-436.83212894946337, -546.5047858804464, -352.54223054647446, -386.1553025096655, -287.5349088534713, -624.6984187141061, -563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515], "episode_lengths": [374, 418, 356, 386, 360, 433, 404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4906592411938637, "mean_inference_ms": 24.51227151638247, "mean_action_processing_ms": 0.1353668833861527, "mean_env_wait_ms": 4.041903396787532, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 58368, "num_agent_steps_trained": 107640, "num_env_steps_sampled": 58368, "num_env_steps_trained": 107640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 58368, "agent_timesteps_total": 58368, "timers": {"training_iteration_time_ms": 311.383, "learn_time_ms": 65.702, "learn_throughput": 1826.438, "synch_weights_time_ms": 20.389}, "counters": {"num_env_steps_sampled": 58368, "num_env_steps_trained": 107640, "num_agent_steps_sampled": 58368, "num_agent_steps_trained": 107640, "last_target_update_ts": 58368, "num_target_updates": 113}, "done": false, "episodes_total": 170, "training_iteration": 57, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-35", "timestamp": 1655476175, "time_this_iter_s": 4.992938041687012, "time_total_s": 280.40801548957825, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 280.40801548957825, "timesteps_since_restore": 0, "iterations_since_restore": 57, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.575, "ram_util_percent": 63.824999999999996}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.565893530845642, "min_q": -66.732666015625, "max_q": 32.21049880981445, "mean_td_error": 0.020968429744243622}, "td_error": [0.6029253005981445, 0.9789600372314453, 1.484527826309204, -0.4479331970214844, -2.142068862915039, 0.1298370361328125, 2.1779632568359375, -1.0816375017166138, 0.3725277781486511, 0.38256072998046875, 2.692643404006958, 2.6163787841796875, 0.25898027420043945, 1.8804473876953125, -1.2934684753417969, -7.50837516784668, -0.3929789066314697, 1.065352439880371, -0.5487532615661621, 1.7068748474121094, 0.6027493476867676, -0.2134995460510254, -2.131509780883789, -0.33092451095581055, -13.688392639160156, 0.9086454510688782, -0.19060897827148438, 0.6465643048286438, -3.737895965576172, -2.0659217834472656, -0.4791991710662842, -0.24676513671875, 0.17210769653320312, 2.226902961730957, -0.6730642318725586, -0.06153750419616699, 0.2668040990829468, 0.09875106811523438, 2.9088034629821777, 0.7859573364257812, -3.258270502090454, 0.35207051038742065, 0.8024210929870605, 4.16231632232666, 1.7612133026123047, 6.207948207855225, -0.1819777488708496, -0.9387502670288086, 2.559734344482422, -2.873368263244629, 0.29910802841186523, -1.8699884414672852, 0.8246819972991943, 0.7829504013061523, 0.45623013377189636, 1.301285743713379, 0.06904983520507812, 2.1315298080444336, 1.2928695678710938, 0.7655048370361328, 0.25763559341430664, -0.6892642974853516, 0.021295547485351562, -0.2973899841308594, -0.6665761470794678, 0.5281600952148438, 2.3006811141967773, 2.225849151611328, 0.4763617515563965, -0.8451746702194214, 0.38546741008758545, -0.75640869140625, -0.7449171543121338, 1.5743322372436523, 0.030307769775390625, -0.2700004577636719, 0.8653303384780884, -0.0875420868396759, 1.3286519050598145, 2.5367698669433594, 1.501204490661621, -0.41162967681884766, 0.8528308868408203, 2.4492931365966797, -3.342717170715332, -0.2527751922607422, 0.0006257891654968262, -7.238901138305664, 1.1549696922302246, 2.4182491302490234, 0.002223491668701172, 1.8459405899047852, 0.4432487487792969, 0.03754234313964844, 1.74808669090271, 0.11099481582641602, -2.2294387817382812, 0.05318760871887207, 0.4686698913574219, 1.5592727661132812, 0.6710915565490723, 0.03658175468444824, -2.3938827514648438, 2.094602584838867, 0.9437494277954102, -2.3608226776123047, -0.033446311950683594, -2.2754383087158203, -0.5644021034240723, -2.4335689544677734, 0.5839419364929199, -4.112608909606934, 0.02688455581665039, 0.7822494506835938, 1.350198745727539, 0.5044517517089844, -6.779688835144043, 1.2562599182128906, 1.438389778137207, 2.0579299926757812], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 59392, "num_env_steps_trained": 109560, "num_agent_steps_sampled": 59392, "num_agent_steps_trained": 109560, "last_target_update_ts": 59392, "num_target_updates": 115}, "sampler_results": {"episode_reward_max": 24.038616441190243, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -199.49919537000358, "episode_len_mean": 302.37, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087], "episode_lengths": [404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49214163453878923, "mean_inference_ms": 24.548963928162934, "mean_action_processing_ms": 0.13533131875074672, "mean_env_wait_ms": 4.054180856053796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 24.038616441190243, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -199.49919537000358, "episode_len_mean": 302.37, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-563.1608481556177, -478.4999104514718, -463.5899873301387, -369.5694286748767, -200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087], "episode_lengths": [404, 407, 396, 393, 278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49214163453878923, "mean_inference_ms": 24.548963928162934, "mean_action_processing_ms": 0.13533131875074672, "mean_env_wait_ms": 4.054180856053796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 59392, "num_agent_steps_trained": 109560, "num_env_steps_sampled": 59392, "num_env_steps_trained": 109560, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 59392, "agent_timesteps_total": 59392, "timers": {"training_iteration_time_ms": 334.241, "learn_time_ms": 68.268, "learn_throughput": 1757.782, "synch_weights_time_ms": 21.089}, "counters": {"num_env_steps_sampled": 59392, "num_env_steps_trained": 109560, "num_agent_steps_sampled": 59392, "num_agent_steps_trained": 109560, "last_target_update_ts": 59392, "num_target_updates": 115}, "done": false, "episodes_total": 176, "training_iteration": 58, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-40", "timestamp": 1655476180, "time_this_iter_s": 5.358444452285767, "time_total_s": 285.766459941864, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 285.766459941864, "timesteps_since_restore": 0, "iterations_since_restore": 58, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 36.2125, "ram_util_percent": 63.96249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.1120219230651855, "min_q": -76.37672424316406, "max_q": 24.235477447509766, "mean_td_error": -0.3212999403476715}, "td_error": [3.559199333190918, 0.39455699920654297, 0.8059880137443542, -0.9077198505401611, -6.968740463256836, -32.57514190673828, -0.45328912138938904, 0.9680109024047852, 1.4425697326660156, -0.04469585418701172, 1.3566474914550781, 0.0784902572631836, 5.688621520996094, -5.202098846435547, -0.02257061004638672, -9.40473747253418, 0.38327980041503906, -2.9945783615112305, 0.5332673788070679, 1.4916744232177734, 1.4845757484436035, -5.529690742492676, 1.2713313102722168, 0.4438209533691406, -0.12154579162597656, 0.29990386962890625, 4.881919860839844, -5.87835168838501, -6.804496765136719, 1.8373894691467285, -3.4827823638916016, 2.24350643157959, 1.8528461456298828, 0.04681956768035889, -0.1332714557647705, 0.41963624954223633, -0.5084198713302612, -4.110293388366699, 4.678016662597656, 0.3987410068511963, 3.3644495010375977, -2.307828426361084, 2.0972633361816406, -0.01891922950744629, 0.871002197265625, 0.1845226287841797, 0.29747986793518066, 0.11162424087524414, -0.06634283065795898, 2.0772666931152344, 3.1698713302612305, 0.5252418518066406, 0.5780181884765625, -1.3702279329299927, 0.11636924743652344, -3.0182089805603027, -1.6952601671218872, -0.0502781867980957, 1.3624780178070068, -1.3100500106811523, 1.1849136352539062, 2.0085716247558594, -8.399849891662598, 0.3201639652252197, -0.44573974609375, 1.819976806640625, 1.4900003671646118, 1.3503875732421875, -5.14013671875, 0.2175922393798828, 1.1783885955810547, 0.3939170837402344, 4.033946990966797, -1.7383766174316406, -0.8463649749755859, -5.877330303192139, 0.7296347618103027, -0.552515983581543, 0.3811378479003906, 2.463552474975586, -3.6585206985473633, 5.916545867919922, 0.3895127773284912, 4.266984939575195, 3.3393759727478027, 0.7059164047241211, 0.25617027282714844, 2.394084930419922, 0.3847484588623047, 0.8233695030212402, -4.253039360046387, -0.1224832534790039, 0.5898294448852539, -1.3362493515014648, -1.7084393501281738, 2.426093339920044, -5.070981025695801, -0.4428272247314453, 1.0264899730682373, 0.8406029939651489, 2.6441287994384766, 0.9931610822677612, -0.6828746795654297, -0.5241355895996094, -0.6237554550170898, 0.39795684814453125, 0.11447429656982422, 0.7795886993408203, 9.478645324707031, 1.2994937896728516, 0.8925676345825195, 0.29083919525146484, 2.6367568969726562, 0.4384746551513672, -9.410202026367188, -7.362374305725098, -0.4164695739746094, 2.9152679443359375, -0.2849297523498535, 0.19147300720214844], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 60416, "num_env_steps_trained": 111480, "num_agent_steps_sampled": 60416, "num_agent_steps_trained": 111480, "last_target_update_ts": 60416, "num_target_updates": 117}, "sampler_results": {"episode_reward_max": 24.038616441190243, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -183.29615915045142, "episode_len_mean": 296.87, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854], "episode_lengths": [278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4941241860442734, "mean_inference_ms": 24.55008616503027, "mean_action_processing_ms": 0.13518772845278682, "mean_env_wait_ms": 4.058623293422594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 24.038616441190243, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -183.29615915045142, "episode_len_mean": 296.87, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-200.45441786199808, -377.9645942673087, -134.6966094225645, -173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854], "episode_lengths": [278, 366, 292, 310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4941241860442734, "mean_inference_ms": 24.55008616503027, "mean_action_processing_ms": 0.13518772845278682, "mean_env_wait_ms": 4.058623293422594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 60416, "num_agent_steps_trained": 111480, "num_env_steps_sampled": 60416, "num_env_steps_trained": 111480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 60416, "agent_timesteps_total": 60416, "timers": {"training_iteration_time_ms": 324.903, "learn_time_ms": 65.82, "learn_throughput": 1823.159, "synch_weights_time_ms": 21.143}, "counters": {"num_env_steps_sampled": 60416, "num_env_steps_trained": 111480, "num_agent_steps_sampled": 60416, "num_agent_steps_trained": 111480, "last_target_update_ts": 60416, "num_target_updates": 117}, "done": false, "episodes_total": 180, "training_iteration": 59, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-45", "timestamp": 1655476185, "time_this_iter_s": 5.175379037857056, "time_total_s": 290.94183897972107, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 290.94183897972107, "timesteps_since_restore": 0, "iterations_since_restore": 59, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 34.84285714285714, "ram_util_percent": 64.1}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -5.786012649536133, "min_q": -78.10494995117188, "max_q": 28.832426071166992, "mean_td_error": 0.4556741714477539}, "td_error": [0.09418058395385742, -1.1759414672851562, 2.6801671981811523, 0.7924289703369141, -0.9430990219116211, 2.2778964042663574, 0.6488620042800903, 1.6182613372802734, -0.9123516082763672, 0.6796417236328125, 3.006385326385498, -0.05905723571777344, 1.2502186298370361, 0.3802495002746582, 0.3235359191894531, 1.6096301078796387, 0.5664222240447998, 3.8290443420410156, 1.6598906517028809, 0.7478513717651367, 1.128920555114746, 0.05689287185668945, -1.290262222290039, -0.6075725555419922, -8.189802169799805, -0.7557525634765625, 0.6628093719482422, 1.48653244972229, 1.9302077293395996, -0.0189971923828125, 1.8698757886886597, 2.3295063972473145, 2.5124785900115967, 0.8227121829986572, 0.9469146728515625, 0.019128799438476562, 0.08543252944946289, 0.5835437774658203, -8.465505599975586, 1.9305355548858643, 1.212702751159668, 1.3731379508972168, 0.35436439514160156, 5.071479320526123, 0.06923675537109375, 0.5698795318603516, -1.9986572265625, 0.686495304107666, 2.0908467769622803, 0.38230276107788086, 0.2825469970703125, 0.4900984764099121, 0.38857388496398926, 1.051149606704712, 1.739829182624817, -1.1803226470947266, 0.5983200073242188, 1.2339897155761719, 0.8632581830024719, 2.9684066772460938, 0.4150123596191406, -5.848495006561279, 0.8832907676696777, 0.43077659606933594, 1.5786123275756836, -0.5188126564025879, 2.9684066772460938, -1.0713844299316406, 0.7385294437408447, 0.8976383209228516, 2.113353729248047, 2.9894447326660156, 2.9054222106933594, 0.9448871612548828, 2.7172787189483643, 1.2783317565917969, 2.379746913909912, 0.3004574775695801, -1.0713844299316406, 1.0543136596679688, 0.7396547794342041, 1.5790462493896484, 0.7000064849853516, 1.450881004333496, -2.562128782272339, -0.06589245796203613, 1.546256184577942, -5.382017612457275, 0.6097345352172852, 0.20230579376220703, 0.9941089153289795, 0.981093168258667, -1.7130074501037598, 0.5689201354980469, 2.561336040496826, 1.4133520126342773, 0.7450393438339233, 0.21685314178466797, 1.8967063426971436, 0.1145792007446289, -0.1356496810913086, 3.3773555755615234, -1.9621400833129883, 1.8704595565795898, -1.1364455223083496, -0.022161483764648438, 0.6526017189025879, 1.0435690879821777, 1.0612192153930664, -4.982317924499512, 0.039127349853515625, -0.27169227600097656, 1.6094142198562622, -0.1809825897216797, 1.8077116012573242, 1.2514417171478271, 0.02259477972984314, -7.483789443969727, 0.6996464729309082, 0.37923192977905273], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 61440, "num_env_steps_trained": 113400, "num_agent_steps_sampled": 61440, "num_agent_steps_trained": 113400, "last_target_update_ts": 61440, "num_target_updates": 119}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -178.63836924038827, "episode_len_mean": 295.37, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477], "episode_lengths": [310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49417283967589865, "mean_inference_ms": 24.561606274574874, "mean_action_processing_ms": 0.13515526272138437, "mean_env_wait_ms": 4.058446716750852, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -178.63836924038827, "episode_len_mean": 295.37, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-173.06477459520102, -131.90738563239574, -340.93688233941793, -199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477], "episode_lengths": [310, 290, 366, 311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49417283967589865, "mean_inference_ms": 24.561606274574874, "mean_action_processing_ms": 0.13515526272138437, "mean_env_wait_ms": 4.058446716750852, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 61440, "num_agent_steps_trained": 113400, "num_env_steps_sampled": 61440, "num_env_steps_trained": 113400, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 61440, "agent_timesteps_total": 61440, "timers": {"training_iteration_time_ms": 314.714, "learn_time_ms": 64.712, "learn_throughput": 1854.377, "synch_weights_time_ms": 20.511}, "counters": {"num_env_steps_sampled": 61440, "num_env_steps_trained": 113400, "num_agent_steps_sampled": 61440, "num_agent_steps_trained": 113400, "last_target_update_ts": 61440, "num_target_updates": 119}, "done": false, "episodes_total": 183, "training_iteration": 60, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-51", "timestamp": 1655476191, "time_this_iter_s": 5.035118103027344, "time_total_s": 295.9769570827484, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 295.9769570827484, "timesteps_since_restore": 0, "iterations_since_restore": 60, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.142857142857146, "ram_util_percent": 64.0142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -2.987384557723999, "min_q": -64.13783264160156, "max_q": 29.75990104675293, "mean_td_error": 0.17956939339637756}, "td_error": [-0.31813812255859375, -0.3485398292541504, 0.2516815662384033, 1.2930574417114258, -0.4830055236816406, 0.24826812744140625, 1.042786717414856, 2.0934128761291504, -1.747964859008789, 8.181737899780273, -1.9603407382965088, 2.6038076877593994, -5.631380081176758, 2.461545944213867, -4.578891754150391, 0.8815145492553711, 1.765864372253418, 0.3964195251464844, 1.131032943725586, 0.8877735137939453, 0.42022228240966797, 5.58514404296875, -0.46291160583496094, 1.3509750366210938, 1.4896161556243896, 1.5293149948120117, -0.562108039855957, 1.2093658447265625, 0.2833366394042969, -0.3659019470214844, 1.2380542755126953, -1.5954780578613281, -0.9795174598693848, -0.26815223693847656, 1.6040725708007812, -0.5743598937988281, 0.3311413526535034, -5.9738640785217285, -7.007294654846191, -6.341451644897461, 3.0866012573242188, -0.0753474235534668, 0.8843350410461426, 1.8948521614074707, -2.6007442474365234, 1.0255107879638672, -5.261691570281982, -0.37574031949043274, 0.9277658462524414, 0.096893310546875, -0.58868408203125, 2.3744964599609375, 0.5783061981201172, -1.8881607055664062, 1.2515077590942383, -0.30570411682128906, 3.5602712631225586, 0.20160913467407227, 0.988123893737793, 0.576840877532959, -4.462334632873535, 1.6710395812988281, 1.1789982318878174, 0.14822006225585938, -8.541679382324219, 2.1686630249023438, 0.5806608200073242, 0.23482465744018555, 1.6710395812988281, -0.6024055480957031, 0.4886021614074707, 1.7109436988830566, 0.5728473663330078, -0.711054801940918, 0.3908417224884033, -0.5030431747436523, 1.4298019409179688, 1.6847953796386719, 0.5414650440216064, 3.391543388366699, 0.53326416015625, 3.984041213989258, -0.1527242660522461, 0.4870023727416992, 6.961097717285156, -7.67546272277832, 0.876251220703125, -0.9784507751464844, -0.01263427734375, 1.3036813735961914, 2.364264488220215, -3.7103147506713867, 0.38488101959228516, -0.052898406982421875, 0.9881534576416016, -0.32758426666259766, 1.1353702545166016, 0.7336525917053223, 0.9279136657714844, -0.6146647930145264, 1.183903694152832, 0.6515989303588867, 1.0976200103759766, 0.19395065307617188, 0.37626147270202637, 0.1458902359008789, 2.421062469482422, -8.724908828735352, -2.0384225845336914, 0.8797626495361328, 0.5224027633666992, -1.8790779113769531, 0.5455303192138672, 2.9294850826263428, 1.3281259536743164, 0.6209216117858887, 0.4966707229614258, -0.19628986716270447, 0.7264642715454102, 4.636878967285156], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 62464, "num_env_steps_trained": 115320, "num_agent_steps_sampled": 62464, "num_agent_steps_trained": 115320, "last_target_update_ts": 62464, "num_target_updates": 121}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -172.39803078480065, "episode_len_mean": 292.77, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634], "episode_lengths": [311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49467983015293143, "mean_inference_ms": 24.585149958093428, "mean_action_processing_ms": 0.1350798386055059, "mean_env_wait_ms": 4.063996208918546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -172.39803078480065, "episode_len_mean": 292.77, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-199.01614398509264, -192.76902655512094, -236.6927774399519, -553.6822322905064, -827.8801461905241, -36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634], "episode_lengths": [311, 313, 315, 424, 450, 278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49467983015293143, "mean_inference_ms": 24.585149958093428, "mean_action_processing_ms": 0.1350798386055059, "mean_env_wait_ms": 4.063996208918546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 62464, "num_agent_steps_trained": 115320, "num_env_steps_sampled": 62464, "num_env_steps_trained": 115320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 62464, "agent_timesteps_total": 62464, "timers": {"training_iteration_time_ms": 318.46, "learn_time_ms": 65.402, "learn_throughput": 1834.804, "synch_weights_time_ms": 20.483}, "counters": {"num_env_steps_sampled": 62464, "num_env_steps_trained": 115320, "num_agent_steps_sampled": 62464, "num_agent_steps_trained": 115320, "last_target_update_ts": 62464, "num_target_updates": 121}, "done": false, "episodes_total": 186, "training_iteration": 61, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-29-56", "timestamp": 1655476196, "time_this_iter_s": 5.02080774307251, "time_total_s": 300.9977648258209, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 300.9977648258209, "timesteps_since_restore": 0, "iterations_since_restore": 61, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.5, "ram_util_percent": 63.925}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -4.014755725860596, "min_q": -79.06312561035156, "max_q": 31.490625381469727, "mean_td_error": 0.8574433922767639}, "td_error": [1.5906939506530762, 2.815525531768799, 0.30127429962158203, -0.8254356384277344, 4.751562118530273, 2.62290096282959, 0.9637565612792969, 1.4508819580078125, -0.8815581798553467, 4.040184020996094, -0.8455276489257812, -0.36777687072753906, -0.7466030120849609, 0.6699333190917969, 0.46108484268188477, -2.1826019287109375, 0.9356396198272705, 5.455406188964844, 1.7463178634643555, 1.216033935546875, -0.7922196388244629, 0.5870680809020996, -2.59906005859375, 0.934546709060669, 1.4862926006317139, 0.5853123664855957, 1.214630126953125, -0.11619925498962402, 2.407496929168701, 3.5548057556152344, 2.815525531768799, -1.2857208251953125, 4.881925582885742, 0.40494728088378906, 0.09820917248725891, 0.4036083221435547, -5.719724178314209, -0.8865256309509277, 1.2935891151428223, 4.052215576171875, 2.5109214782714844, 0.21732616424560547, -2.4341907501220703, 1.77642822265625, 2.3464484214782715, 1.4968235492706299, 0.23388004302978516, -1.2771472930908203, -0.6159887313842773, 0.5442123413085938, 1.0100483894348145, 0.6942062377929688, -11.040281295776367, -4.977899551391602, 5.193264007568359, 4.851106643676758, 2.0761070251464844, -0.08937549591064453, 3.2959628105163574, 0.5698823928833008, -2.758571147918701, -0.9497661590576172, -4.1857404708862305, 0.5220868587493896, 0.2630605697631836, 15.035642623901367, -1.6974773406982422, 0.5182886123657227, 0.24716949462890625, 1.3521407842636108, -0.09686470031738281, -1.2793867588043213, 7.364450454711914, 0.24085140228271484, 0.05456352233886719, 1.8148293495178223, 1.4473838806152344, 1.2246675491333008, 0.43271946907043457, 1.0863418579101562, 4.193561553955078, 1.8842778205871582, 1.9357929229736328, -0.4930260181427002, 0.665313720703125, 3.3056068420410156, 1.6034369468688965, 0.2129058837890625, 1.6237742900848389, -2.0072216987609863, 3.2524032592773438, -0.29782676696777344, 3.639664888381958, 1.6310583353042603, 4.277687072753906, 0.20290613174438477, 2.9606494903564453, 2.2487735748291016, 0.3390235900878906, -0.023916244506835938, -2.1993627548217773, 1.8619928359985352, -5.109905242919922, -2.1377744674682617, 0.2161540985107422, -0.3494377136230469, 5.551163673400879, -0.5739879608154297, 0.38194847106933594, 2.4653568267822266, 1.3804283142089844, 0.16057252883911133, 1.4160614013671875, 0.5547804832458496, 2.6224818229675293, 0.7331657409667969, 0.17253613471984863, -0.5244140625, -0.23392963409423828, 1.8399901390075684], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 63488, "num_env_steps_trained": 117240, "num_agent_steps_sampled": 63488, "num_agent_steps_trained": 117240, "last_target_update_ts": 63488, "num_target_updates": 123}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -159.4845715240389, "episode_len_mean": 288.43, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255], "episode_lengths": [278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49521156617377377, "mean_inference_ms": 24.591737474046276, "mean_action_processing_ms": 0.13531070971118064, "mean_env_wait_ms": 4.070451710900374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -159.4845715240389, "episode_len_mean": 288.43, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-36.35641786456108, -272.240515910089, -193.91344366967678, -214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255], "episode_lengths": [278, 327, 315, 341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.49521156617377377, "mean_inference_ms": 24.591737474046276, "mean_action_processing_ms": 0.13531070971118064, "mean_env_wait_ms": 4.070451710900374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 63488, "num_agent_steps_trained": 117240, "num_env_steps_sampled": 63488, "num_env_steps_trained": 117240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 63488, "agent_timesteps_total": 63488, "timers": {"training_iteration_time_ms": 332.501, "learn_time_ms": 66.429, "learn_throughput": 1806.449, "synch_weights_time_ms": 20.189}, "counters": {"num_env_steps_sampled": 63488, "num_env_steps_trained": 117240, "num_agent_steps_sampled": 63488, "num_agent_steps_trained": 117240, "last_target_update_ts": 63488, "num_target_updates": 123}, "done": false, "episodes_total": 191, "training_iteration": 62, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-01", "timestamp": 1655476201, "time_this_iter_s": 5.301062822341919, "time_total_s": 306.29882764816284, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 306.29882764816284, "timesteps_since_restore": 0, "iterations_since_restore": 62, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.2125, "ram_util_percent": 63.9}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -8.395414352416992, "min_q": -79.72300720214844, "max_q": 25.97483253479004, "mean_td_error": -1.1189277172088623}, "td_error": [-0.9472234845161438, 1.5968303680419922, 6.604724884033203, -0.9876327514648438, -1.245295524597168, 1.0546188354492188, 11.05221176147461, -0.25813865661621094, 1.010162353515625, -0.37865447998046875, -2.18148136138916, -3.1090636253356934, -0.8615188598632812, 0.7021160125732422, 1.3391436338424683, 2.067319869995117, 1.4216880798339844, -0.43158626556396484, -0.5813817977905273, -0.5440564155578613, -0.9934399127960205, 0.40473103523254395, -0.8962769508361816, -0.22892868518829346, -0.9624481201171875, -0.4349327087402344, 0.41556787490844727, 3.0330114364624023, 2.349506378173828, -1.3114776611328125, -0.8697881698608398, -0.4807090759277344, 0.07979583740234375, 1.526627540588379, 0.13579988479614258, 0.17522239685058594, -1.1678028106689453, -1.001367211341858, -24.41229248046875, 1.1801536083221436, -1.8296318054199219, -3.1128642559051514, -0.1559772491455078, -0.5544748306274414, -1.5470085144042969, -1.208475112915039, -0.9871129393577576, -77.08931732177734, 0.3894205093383789, 1.49363374710083, -1.230107307434082, 0.0055027008056640625, 1.0330162048339844, -0.170166015625, -1.1405372619628906, -1.1752662658691406, 0.33250319957733154, -0.026645660400390625, -0.8316650390625, -0.7829704284667969, 1.7633476257324219, -0.9040899276733398, 0.20226001739501953, -0.023664355278015137, -2.0469284057617188, 0.5289597511291504, -0.23422187566757202, 1.54248046875, -1.5320720672607422, 0.6150150299072266, -3.6425704956054688, -4.27821159362793, -0.2980051040649414, 1.80987548828125, 1.5788154602050781, -2.2489089965820312, -1.4789600372314453, 0.14719772338867188, 1.5143585205078125, -0.08538365364074707, -1.2540664672851562, 0.44318675994873047, -0.8692789077758789, 1.7636680603027344, -0.21794986724853516, -0.31583523750305176, -0.3900146484375, 0.2822732925415039, -8.121682167053223, -0.564997673034668, -7.575823783874512, 1.5373878479003906, 1.320406198501587, 0.3665428161621094, -0.1473560333251953, 1.0080375671386719, -4.634792327880859, -0.9985246658325195, -2.256094455718994, -1.9841465950012207, 0.7298612594604492, -0.059085845947265625, 0.890449047088623, -1.067030906677246, 0.2844080924987793, 0.4103870391845703, -0.6742095947265625, 11.05221176147461, 0.9508904218673706, -1.1971054077148438, -0.2508392333984375, 0.5003976821899414, -1.4696540832519531, 0.14142704010009766, 1.8797531127929688, -12.889595985412598, 0.5708551406860352, -7.838310241699219, 0.18183135986328125, -0.0138092041015625], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 64512, "num_env_steps_trained": 119160, "num_agent_steps_sampled": 64512, "num_agent_steps_trained": 119160, "last_target_update_ts": 64512, "num_target_updates": 125}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -155.76462742894887, "episode_len_mean": 286.28, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418], "episode_lengths": [341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4967488029322224, "mean_inference_ms": 24.602933358923092, "mean_action_processing_ms": 0.13535656146324337, "mean_env_wait_ms": 4.075817144949966, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -155.76462742894887, "episode_len_mean": 286.28, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-214.83870511502028, -175.0801814198494, -5.680944465100765, -645.9601811617613, -225.12889360636473, -65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418], "episode_lengths": [341, 331, 246, 443, 323, 278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4967488029322224, "mean_inference_ms": 24.602933358923092, "mean_action_processing_ms": 0.13535656146324337, "mean_env_wait_ms": 4.075817144949966, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 64512, "num_agent_steps_trained": 119160, "num_env_steps_sampled": 64512, "num_env_steps_trained": 119160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 64512, "agent_timesteps_total": 64512, "timers": {"training_iteration_time_ms": 315.495, "learn_time_ms": 66.893, "learn_throughput": 1793.913, "synch_weights_time_ms": 20.593}, "counters": {"num_env_steps_sampled": 64512, "num_env_steps_trained": 119160, "num_agent_steps_sampled": 64512, "num_agent_steps_trained": 119160, "last_target_update_ts": 64512, "num_target_updates": 125}, "done": false, "episodes_total": 194, "training_iteration": 63, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-07", "timestamp": 1655476207, "time_this_iter_s": 5.095547199249268, "time_total_s": 311.3943748474121, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 311.3943748474121, "timesteps_since_restore": 0, "iterations_since_restore": 63, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.757142857142863, "ram_util_percent": 63.94285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.8695719242095947, "min_q": -77.42434692382812, "max_q": 31.70882797241211, "mean_td_error": 1.4395790100097656}, "td_error": [4.538068771362305, 0.8512735366821289, 3.338674545288086, -0.47917938232421875, 1.1696891784667969, 0.7505292892456055, 2.4686508178710938, 0.9679379463195801, 1.820220947265625, 1.8718109130859375, 4.471072196960449, 3.2110159397125244, 3.3525333404541016, 2.9099345207214355, 0.8021533489227295, -0.29239821434020996, 0.21483707427978516, -0.1862773895263672, 2.203263282775879, 0.3073453903198242, 2.8496367931365967, 2.3460235595703125, 2.1752359867095947, 22.204030990600586, 2.4235384464263916, 1.7347679138183594, -0.42477989196777344, 4.439623832702637, 3.1177117824554443, 0.19377422332763672, 2.070918083190918, 0.033397674560546875, 2.0968260765075684, 1.7755813598632812, -1.2595386505126953, 1.1793079376220703, 2.0929031372070312, 1.0428038835525513, -0.40912508964538574, 1.3196020126342773, 0.5616493225097656, 0.1401834487915039, 0.4140043258666992, 2.7588858604431152, 0.5998024940490723, -0.9942138195037842, 0.659332275390625, 1.5020101070404053, 4.337429046630859, 0.2779083251953125, 4.027553558349609, -0.7063083648681641, 0.799839973449707, -2.742898941040039, 0.25858116149902344, 2.292447090148926, 1.9285292625427246, 0.7365756034851074, 5.472015380859375, -1.3250808715820312, -0.23526573181152344, 3.1713576316833496, 1.9172418117523193, 1.4187440872192383, 3.7988739013671875, -0.06512451171875, -5.842439651489258, 3.456491470336914, 1.843155860900879, 0.5349826812744141, -0.19564199447631836, 0.8954176902770996, 1.4695005416870117, -0.21843433380126953, 0.3330228328704834, 1.714010238647461, -1.0333003997802734, 2.5734949111938477, 11.382734298706055, -4.077327728271484, 3.035003662109375, 3.1909446716308594, 1.0974617004394531, -6.728887557983398, -0.7551803588867188, 1.9656333923339844, 1.4998196363449097, -2.5123939514160156, 5.472015380859375, 0.8006191253662109, 2.6439552307128906, 1.327898383140564, -0.23786306381225586, 0.37508392333984375, -1.3958606719970703, -0.2460174560546875, 2.626913070678711, -0.9873881936073303, 2.178622245788574, 2.1341521739959717, -1.0261907577514648, -1.0259532928466797, 1.6709492206573486, 2.0992679595947266, 1.0131540298461914, 4.057991981506348, 1.1421587467193604, 0.7076539993286133, 14.686687469482422, -5.550159931182861, 1.8023786544799805, 2.1672096252441406, 1.7844505310058594, 0.8352413177490234, -0.3514213562011719, -0.9283218383789062, 1.7118721008300781, 2.076766014099121, -0.6026496887207031, 1.8607292175292969], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 65536, "num_env_steps_trained": 121080, "num_agent_steps_sampled": 65536, "num_agent_steps_trained": 121080, "last_target_update_ts": 65536, "num_target_updates": 127}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -152.89828287504614, "episode_len_mean": 284.38, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612], "episode_lengths": [278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.498079477775409, "mean_inference_ms": 24.60796793186595, "mean_action_processing_ms": 0.13527437731827224, "mean_env_wait_ms": 4.080546591379098, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -152.89828287504614, "episode_len_mean": 284.38, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-65.40036556869745, -131.56700121611357, -428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612], "episode_lengths": [278, 279, 393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.498079477775409, "mean_inference_ms": 24.60796793186595, "mean_action_processing_ms": 0.13527437731827224, "mean_env_wait_ms": 4.080546591379098, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 65536, "num_agent_steps_trained": 121080, "num_env_steps_sampled": 65536, "num_env_steps_trained": 121080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 65536, "agent_timesteps_total": 65536, "timers": {"training_iteration_time_ms": 334.188, "learn_time_ms": 66.116, "learn_throughput": 1814.99, "synch_weights_time_ms": 20.789}, "counters": {"num_env_steps_sampled": 65536, "num_env_steps_trained": 121080, "num_agent_steps_sampled": 65536, "num_agent_steps_trained": 121080, "last_target_update_ts": 65536, "num_target_updates": 127}, "done": false, "episodes_total": 199, "training_iteration": 64, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-12", "timestamp": 1655476212, "time_this_iter_s": 5.3346922397613525, "time_total_s": 316.72906708717346, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 316.72906708717346, "timesteps_since_restore": 0, "iterations_since_restore": 64, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.0875, "ram_util_percent": 64.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -2.711989402770996, "min_q": -81.64433288574219, "max_q": 31.974157333374023, "mean_td_error": -0.6150011420249939}, "td_error": [-0.4424092769622803, -0.5965652465820312, -0.3705645799636841, 1.2200746536254883, -2.182528495788574, -1.2230114936828613, -1.1661386489868164, 0.513824462890625, 2.9974708557128906, 1.6457204818725586, -1.1084632873535156, -0.3885231018066406, -2.1920371055603027, 1.7097890377044678, -2.185192584991455, 0.5301399230957031, -10.557914733886719, 0.474639892578125, 2.0565242767333984, -0.831416130065918, -2.264930009841919, 1.7473430633544922, 1.1449508666992188, 0.0801544189453125, 0.8172860145568848, -7.233263969421387, 1.8964414596557617, 0.8880786895751953, -5.088227272033691, 1.510777473449707, -0.0855865478515625, -1.438798189163208, -0.776461124420166, 0.6340594291687012, 0.4493374824523926, -5.391940116882324, 1.2823734283447266, -0.6494198441505432, -1.8944506645202637, 3.061563491821289, -0.15931320190429688, 0.21685338020324707, 1.2665107250213623, -0.49793052673339844, 0.43348413705825806, 0.9083795547485352, 0.5139369964599609, 0.04840588569641113, -0.13207483291625977, 0.6160144805908203, -6.837198257446289, -0.31661224365234375, -5.181361675262451, -0.0551910400390625, 0.4440889358520508, 0.08130788803100586, -0.5859079360961914, 1.657283067703247, -0.7305946350097656, -0.8971424102783203, 0.5478860139846802, 1.571091651916504, -0.03295326232910156, 1.3787059783935547, 1.707590103149414, 0.34529972076416016, -0.3907318115234375, -0.25698328018188477, -5.922722816467285, 0.2608301639556885, 2.0766000747680664, 0.5031728744506836, -2.143759250640869, 2.3440418243408203, -5.86768913269043, -0.5033059120178223, 0.13521766662597656, -0.13120603561401367, -1.1746976375579834, 2.091470718383789, 0.07352781295776367, -1.333160400390625, 1.0536479949951172, -8.664759635925293, -0.04598426818847656, -7.703359603881836, 0.22751474380493164, -0.5857253074645996, -0.34374427795410156, 2.0031027793884277, -0.2667884826660156, -0.3577045202255249, 0.4326486587524414, 1.544301986694336, 1.1990776062011719, -2.296550750732422, 1.9080619812011719, 0.5329265594482422, -1.2760162353515625, 0.15188217163085938, 0.15894174575805664, 1.5801630020141602, -0.09200859069824219, -6.3859100341796875, -2.612917900085449, -0.5572738647460938, 0.9620046615600586, 0.2951093912124634, -0.012078523635864258, 1.1803650856018066, -0.2981843650341034, -2.7559661865234375, 0.8423595428466797, -0.2521357536315918, -0.7820110321044922, -15.576301574707031, 1.3165254592895508, 1.1923084259033203, 0.99853515625, -3.178068161010742], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 66560, "num_env_steps_trained": 123000, "num_agent_steps_sampled": 66560, "num_agent_steps_trained": 123000, "last_target_update_ts": 66560, "num_target_updates": 129}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -151.53185499690474, "episode_len_mean": 283.7, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064], "episode_lengths": [393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4985808819424999, "mean_inference_ms": 24.624709027732994, "mean_action_processing_ms": 0.13552180987225962, "mean_env_wait_ms": 4.083978501135146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -151.53185499690474, "episode_len_mean": 283.7, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-428.78310772031546, -37.55636561661959, -267.38026916235685, -123.45581996440887, -666.4342969506979, -80.72307253628969, -373.5850150510669, -512.4170373082161, -309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064], "episode_lengths": [393, 261, 324, 291, 438, 297, 352, 414, 352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4985808819424999, "mean_inference_ms": 24.624709027732994, "mean_action_processing_ms": 0.13552180987225962, "mean_env_wait_ms": 4.083978501135146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 66560, "num_agent_steps_trained": 123000, "num_env_steps_sampled": 66560, "num_env_steps_trained": 123000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 66560, "agent_timesteps_total": 66560, "timers": {"training_iteration_time_ms": 315.22, "learn_time_ms": 66.839, "learn_throughput": 1795.352, "synch_weights_time_ms": 20.688}, "counters": {"num_env_steps_sampled": 66560, "num_env_steps_trained": 123000, "num_agent_steps_sampled": 66560, "num_agent_steps_trained": 123000, "last_target_update_ts": 66560, "num_target_updates": 129}, "done": false, "episodes_total": 201, "training_iteration": 65, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-17", "timestamp": 1655476217, "time_this_iter_s": 5.110264778137207, "time_total_s": 321.83933186531067, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 321.83933186531067, "timesteps_since_restore": 0, "iterations_since_restore": 65, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.17142857142857, "ram_util_percent": 64.08571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -2.295992136001587, "min_q": -80.64004516601562, "max_q": 30.73871612548828, "mean_td_error": -0.3196592926979065}, "td_error": [0.07228374481201172, -1.6838569641113281, -0.37702369689941406, -0.5851044654846191, -0.7795562744140625, 1.330611228942871, 1.9847934246063232, -0.9358565807342529, 1.005692481994629, -0.3853120803833008, -1.3538312911987305, 0.3775033950805664, 1.2249016761779785, 4.925793647766113, -0.38585472106933594, 0.5042257308959961, -1.1060981750488281, 0.8203024864196777, -1.2521848678588867, -1.8536558151245117, -1.2278847694396973, 2.595531463623047, 0.19663429260253906, -1.5925445556640625, -1.8331947326660156, -0.35183143615722656, -0.6448211669921875, -2.5085792541503906, -1.2805633544921875, -1.4503097534179688, -1.8800249099731445, -9.592432022094727, -0.9207296371459961, -0.6078680753707886, 0.4270610809326172, 1.3709564208984375, -1.2672085762023926, -0.03356170654296875, 0.7828183174133301, 0.19829118251800537, -1.068704605102539, -0.6159572601318359, 0.789607048034668, -0.02823472023010254, 0.02953052520751953, -10.202812194824219, -0.5980224609375, 0.2235240936279297, -3.1732711791992188, -0.12263870239257812, 0.22075748443603516, -1.4616384506225586, -0.08341407775878906, -1.0479068756103516, -0.20284271240234375, -5.598193168640137, -0.9204607009887695, 0.6005696058273315, -0.5145249366760254, -1.7058448791503906, 0.6019172668457031, 0.3375215530395508, -0.4515209197998047, -0.9757099151611328, -1.238245964050293, -0.8312907218933105, -2.1514110565185547, 1.1763551235198975, -0.6859531402587891, -0.9020843505859375, -0.5558767318725586, 0.46777915954589844, 0.0420680046081543, -0.3283548355102539, 4.925793647766113, 0.8349454402923584, -0.4290890693664551, -0.7402012348175049, -7.61905574798584, 0.11536026000976562, -0.2833366394042969, 0.09308481216430664, -0.4337806701660156, -1.0383453369140625, 0.022047042846679688, -0.5216977596282959, -1.961334228515625, 2.4004974365234375, 0.7833013534545898, 0.31217169761657715, -0.5866343975067139, 0.46234989166259766, -0.3218388557434082, -0.5686531066894531, 2.089716911315918, 0.0007252693176269531, -0.3387279510498047, -0.4844179153442383, 2.780181884765625, -4.627140045166016, -0.3126790523529053, 2.933365821838379, -0.7369709014892578, 0.614781379699707, -0.39900779724121094, -1.4185752868652344, -0.876060962677002, -0.25521230697631836, 0.6971397399902344, 1.3035778999328613, -0.7075786590576172, -0.4502382278442383, 0.28388500213623047, 4.515948295593262, -0.9765157699584961, 3.0981483459472656, -1.2663421630859375, 2.407876491546631, 1.7939486503601074, 5.573247909545898], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 67584, "num_env_steps_trained": 124920, "num_agent_steps_sampled": 67584, "num_agent_steps_trained": 124920, "last_target_update_ts": 67584, "num_target_updates": 131}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -130.42098805762828, "episode_len_mean": 276.33, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593], "episode_lengths": [352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5006072454057133, "mean_inference_ms": 24.646081541630306, "mean_action_processing_ms": 0.13543920170510748, "mean_env_wait_ms": 4.095896520155568, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -130.42098805762828, "episode_len_mean": 276.33, "episodes_this_iter": 8, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-309.06824816018343, -452.6532062962651, -26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593], "episode_lengths": [352, 393, 263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5006072454057133, "mean_inference_ms": 24.646081541630306, "mean_action_processing_ms": 0.13543920170510748, "mean_env_wait_ms": 4.095896520155568, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 67584, "num_agent_steps_trained": 124920, "num_env_steps_sampled": 67584, "num_env_steps_trained": 124920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 67584, "agent_timesteps_total": 67584, "timers": {"training_iteration_time_ms": 325.949, "learn_time_ms": 67.152, "learn_throughput": 1786.999, "synch_weights_time_ms": 20.688}, "counters": {"num_env_steps_sampled": 67584, "num_env_steps_trained": 124920, "num_agent_steps_sampled": 67584, "num_agent_steps_trained": 124920, "last_target_update_ts": 67584, "num_target_updates": 131}, "done": false, "episodes_total": 209, "training_iteration": 66, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-23", "timestamp": 1655476223, "time_this_iter_s": 5.336113691329956, "time_total_s": 327.1754455566406, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 327.1754455566406, "timesteps_since_restore": 0, "iterations_since_restore": 66, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.975, "ram_util_percent": 64.0125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -6.290882587432861, "min_q": -81.5519027709961, "max_q": 32.253257751464844, "mean_td_error": -0.2846789062023163}, "td_error": [-0.525172233581543, -11.928838729858398, 0.3014545440673828, 2.7457504272460938, 1.0578536987304688, -0.14460229873657227, 0.4608125686645508, -6.573328971862793, 1.2444572448730469, 1.3987369537353516, 1.2465118169784546, 8.048792839050293, -0.8162689208984375, 0.8549747467041016, 1.8603706359863281, -0.4796628952026367, 0.06770706176757812, -0.9317772388458252, -2.510021686553955, -0.3003120422363281, 0.3574686050415039, -2.408646583557129, -0.4445762634277344, 1.6018407344818115, -1.0733771324157715, 0.8651466369628906, -1.2876510620117188, 0.6763200759887695, -0.9357223510742188, -0.43372535705566406, -0.2952146530151367, 1.27178955078125, -0.839127242565155, 1.0410442352294922, 0.910029411315918, 1.5400447845458984, 0.1387627124786377, -0.32793426513671875, 0.36603832244873047, -0.5633840560913086, 1.01580810546875, -0.6218900680541992, 1.896104335784912, 0.6541481018066406, 0.7009432315826416, -1.0621376037597656, -1.1648178100585938, 0.17626380920410156, 0.586148738861084, -1.3382415771484375, -0.8945450782775879, -0.5563099384307861, -0.25388145446777344, 0.5460128784179688, 0.6434211730957031, 0.8296890258789062, 1.5912647247314453, -0.8848280906677246, -3.148749351501465, 0.2978782653808594, 0.7911090850830078, -3.3384780883789062, -0.6971611380577087, 0.5769844055175781, -1.7287979125976562, 1.4634361267089844, 0.465944766998291, -0.5102367401123047, -0.7268438339233398, 0.4083824157714844, -1.4736328125, -1.6370887756347656, -0.3641777038574219, 0.0234527587890625, -0.4445762634277344, -1.4112892150878906, -5.789150238037109, -0.6101517677307129, -0.23622488975524902, -0.1914234161376953, 1.5314369201660156, 0.36151885986328125, 1.2585821151733398, 0.6651229858398438, 0.42023754119873047, -1.8211047649383545, -1.1124687194824219, 0.3976287841796875, -5.602198600769043, 0.7618188858032227, -9.477170944213867, 1.1231632232666016, 0.8722019195556641, -0.2482597827911377, -6.985755920410156, 1.321542739868164, 1.0055351257324219, 0.1430072784423828, 6.583648204803467, -0.6957229971885681, 1.0162544250488281, 0.9213871955871582, 0.7440147399902344, -4.9942779541015625, 0.37656354904174805, -0.37966346740722656, -0.08336448669433594, 1.255478858947754, 0.5410652160644531, -0.4132099151611328, -1.0466337203979492, -0.8384609222412109, -0.6616268157958984, 1.4535369873046875, 1.2583513259887695, -0.4420280456542969, -0.2962303161621094, -1.2960293292999268, -1.5710883140563965, 0.9728050231933594], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 68608, "num_env_steps_trained": 126840, "num_agent_steps_sampled": 68608, "num_agent_steps_trained": 126840, "last_target_update_ts": 68608, "num_target_updates": 133}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -123.03391545630991, "episode_len_mean": 273.55, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854], "episode_lengths": [263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5013266154555324, "mean_inference_ms": 24.653711268106154, "mean_action_processing_ms": 0.13539139652369156, "mean_env_wait_ms": 4.100488632213402, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -123.03391545630991, "episode_len_mean": 273.55, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-26.715781532227993, -220.6043771803379, -272.9206208512187, -343.85051783174276, -78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854], "episode_lengths": [263, 301, 344, 331, 271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5013266154555324, "mean_inference_ms": 24.653711268106154, "mean_action_processing_ms": 0.13539139652369156, "mean_env_wait_ms": 4.100488632213402, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 68608, "num_agent_steps_trained": 126840, "num_env_steps_sampled": 68608, "num_env_steps_trained": 126840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 68608, "agent_timesteps_total": 68608, "timers": {"training_iteration_time_ms": 312.372, "learn_time_ms": 67.89, "learn_throughput": 1767.557, "synch_weights_time_ms": 20.387}, "counters": {"num_env_steps_sampled": 68608, "num_env_steps_trained": 126840, "num_agent_steps_sampled": 68608, "num_agent_steps_trained": 126840, "last_target_update_ts": 68608, "num_target_updates": 133}, "done": false, "episodes_total": 211, "training_iteration": 67, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-28", "timestamp": 1655476228, "time_this_iter_s": 5.147915840148926, "time_total_s": 332.32336139678955, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 332.32336139678955, "timesteps_since_restore": 0, "iterations_since_restore": 67, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.657142857142862, "ram_util_percent": 64.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.7103140354156494, "min_q": -78.48912048339844, "max_q": 32.2578125, "mean_td_error": -0.013277308084070683}, "td_error": [1.0601096153259277, -1.2639069557189941, -0.1384134292602539, -2.703277587890625, -1.4184335470199585, 0.6290721893310547, -1.3984193801879883, -0.09330463409423828, 4.8260345458984375, -0.06140339374542236, -1.5165257453918457, 0.06900858879089355, -0.3860664367675781, 0.9031562805175781, 0.7021923065185547, 0.6228351593017578, 0.06467437744140625, -0.4601325988769531, 1.8130826950073242, 0.4977397918701172, 0.48645973205566406, -0.18170166015625, -0.4848322868347168, 1.8408660888671875, -0.8896322250366211, 0.5619018077850342, 2.0807151794433594, 0.44474101066589355, -0.7622289657592773, 4.0084052085876465, 0.3353729248046875, 0.32964515686035156, 0.7527028918266296, -0.5686283111572266, -0.3068714141845703, -0.2361239194869995, 0.9008229970932007, 3.059239387512207, -1.1250886917114258, -3.170884609222412, 0.1819906234741211, -1.5599842071533203, -0.5967869162559509, 1.099705457687378, -2.159210205078125, 0.8455257415771484, 4.6964874267578125, -0.3753312826156616, 1.3044891357421875, 0.9819831848144531, 1.1707525253295898, 0.5925092697143555, -1.2639069557189941, 0.37803664803504944, -0.23128604888916016, 3.6488609313964844, 3.9036121368408203, -0.0532989501953125, 2.533418655395508, 0.3121986389160156, -2.9730148315429688, 0.24748802185058594, -0.990875244140625, 0.03188800811767578, -0.7603321075439453, 3.6488609313964844, 0.6665658950805664, 7.877773761749268, -0.16924381256103516, 0.022551536560058594, 0.013261795043945312, -0.9579243659973145, 0.7300577163696289, 1.5599784851074219, 0.44279325008392334, 0.7617435455322266, -8.318986892700195, -8.358060836791992, -0.13330960273742676, 0.351654052734375, 0.5354042053222656, -0.3796806335449219, -1.1589345932006836, 1.8647499084472656, 1.5911979675292969, 1.0443534851074219, -0.6451549530029297, -1.9649286270141602, 1.0648281574249268, 0.351348876953125, 1.1009926795959473, -13.80774974822998, -0.35030174255371094, 3.82354736328125, -0.005116462707519531, 0.5568399429321289, -0.9261417388916016, -0.4523801803588867, 0.626446008682251, 0.6631803512573242, -0.17961883544921875, 1.484466552734375, 0.78125, -1.2863025665283203, 1.4806413650512695, 1.8432998657226562, -0.9883852005004883, 0.17461633682250977, 0.34907007217407227, -0.2543983459472656, 0.6416473388671875, -0.947871208190918, -5.491424560546875, -0.2677478790283203, -3.014285087585449, -0.22332763671875, -0.3678398132324219, -0.29022836685180664, 2.067058563232422, -8.561935424804688], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 69632, "num_env_steps_trained": 128760, "num_agent_steps_sampled": 69632, "num_agent_steps_trained": 128760, "last_target_update_ts": 69632, "num_target_updates": 135}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -115.02347218416631, "episode_len_mean": 270.91, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082], "episode_lengths": [271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5019404122143444, "mean_inference_ms": 24.641982818342655, "mean_action_processing_ms": 0.1354215749893308, "mean_env_wait_ms": 4.1015016830555995, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -115.02347218416631, "episode_len_mean": 270.91, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-78.8132535815239, -209.8630284741521, 4.834490858018398, -480.0850225239992, -168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082], "episode_lengths": [271, 308, 251, 387, 320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5019404122143444, "mean_inference_ms": 24.641982818342655, "mean_action_processing_ms": 0.1354215749893308, "mean_env_wait_ms": 4.1015016830555995, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 69632, "num_agent_steps_trained": 128760, "num_env_steps_sampled": 69632, "num_env_steps_trained": 128760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 69632, "agent_timesteps_total": 69632, "timers": {"training_iteration_time_ms": 313.65, "learn_time_ms": 67.451, "learn_throughput": 1779.076, "synch_weights_time_ms": 20.488}, "counters": {"num_env_steps_sampled": 69632, "num_env_steps_trained": 128760, "num_agent_steps_sampled": 69632, "num_agent_steps_trained": 128760, "last_target_update_ts": 69632, "num_target_updates": 135}, "done": false, "episodes_total": 215, "training_iteration": 68, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-33", "timestamp": 1655476233, "time_this_iter_s": 5.118553876876831, "time_total_s": 337.4419152736664, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 337.4419152736664, "timesteps_since_restore": 0, "iterations_since_restore": 68, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.075, "ram_util_percent": 64.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -3.0579824447631836, "min_q": -80.48863983154297, "max_q": 31.448074340820312, "mean_td_error": -0.7876278162002563}, "td_error": [-2.316987991333008, 0.8480749130249023, -1.3233133554458618, -0.46673583984375, -0.3376016616821289, 0.6680679321289062, -2.4162750244140625, -0.6496372222900391, -1.3914947509765625, -5.782990455627441, -0.8092365264892578, -0.7485885620117188, -10.375431060791016, -1.0560779571533203, 0.570258378982544, -0.8948650360107422, 3.7411603927612305, -0.2867698669433594, 0.09561920166015625, -0.6529542207717896, -13.44375228881836, -0.05836200714111328, 2.0238194465637207, 0.37421703338623047, -0.4521675109863281, 0.14019775390625, 2.0238194465637207, 1.814432144165039, -1.2031701803207397, -1.8549423217773438, -0.7135765552520752, 0.11674880981445312, 2.396820068359375, 0.7443013191223145, -1.1999363899230957, 1.062516450881958, 0.11885738372802734, -1.361682415008545, -2.3105154037475586, -1.3823972940444946, -8.01588249206543, -0.8459315299987793, -1.4336614608764648, 0.41430187225341797, 0.05733013153076172, -0.6555566787719727, -1.9107823371887207, -0.7309417724609375, 1.324899673461914, -0.8984603881835938, -1.2220821380615234, 2.542792320251465, 1.6980628967285156, -0.40866851806640625, -0.5764484405517578, -0.7615680694580078, -1.8521614074707031, -0.2762908935546875, -0.43142127990722656, 0.3329620361328125, -0.24988877773284912, 1.0104389190673828, -0.09271526336669922, -1.4685096740722656, 10.604410171508789, -0.2611122131347656, 2.1631274223327637, -1.8110427856445312, -0.6707229614257812, -2.1306419372558594, 0.18994474411010742, -5.223278045654297, -0.3675362467765808, -0.5011215209960938, -0.4942953586578369, 1.614310622215271, 5.163888931274414, 0.1279296875, -0.8238058090209961, -0.9792728424072266, -0.6470763683319092, -0.7606143951416016, -0.5139427185058594, 0.061797142028808594, 1.3444786071777344, 0.5993092060089111, -2.6335182189941406, 1.0883102416992188, 0.1810240000486374, -0.546051025390625, -0.1260981559753418, -13.833464622497559, -0.8183002471923828, -0.8574075698852539, -17.486248016357422, -0.4209728240966797, 0.4202737808227539, -1.656510829925537, 1.7963943481445312, -1.669060230255127, 0.32254743576049805, -0.921269416809082, 1.3223142623901367, -9.347101211547852, 0.8027992248535156, -2.8535470962524414, -0.3380250930786133, -1.6709327697753906, 0.15456295013427734, -1.253006935119629, -0.767035722732544, 0.11614465713500977, -1.6295948028564453, 1.391082763671875, 0.16756248474121094, 0.5497407913208008, 0.0015268325805664062, -0.6496372222900391, -1.0072669982910156, 2.1714305877685547], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 70656, "num_env_steps_trained": 130680, "num_agent_steps_sampled": 70656, "num_agent_steps_trained": 130680, "last_target_update_ts": 70656, "num_target_updates": 137}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -106.92850244507194, "episode_len_mean": 267.56, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991], "episode_lengths": [320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5029264470124228, "mean_inference_ms": 24.672633519946093, "mean_action_processing_ms": 0.13548823357932785, "mean_env_wait_ms": 4.107713635413598, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -106.92850244507194, "episode_len_mean": 267.56, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-168.71325355768204, -354.69535522162914, -196.35267308354378, -329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991], "episode_lengths": [320, 346, 315, 325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5029264470124228, "mean_inference_ms": 24.672633519946093, "mean_action_processing_ms": 0.13548823357932785, "mean_env_wait_ms": 4.107713635413598, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 70656, "num_agent_steps_trained": 130680, "num_env_steps_sampled": 70656, "num_env_steps_trained": 130680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 70656, "agent_timesteps_total": 70656, "timers": {"training_iteration_time_ms": 363.152, "learn_time_ms": 67.481, "learn_throughput": 1778.272, "synch_weights_time_ms": 20.901}, "counters": {"num_env_steps_sampled": 70656, "num_env_steps_trained": 130680, "num_agent_steps_sampled": 70656, "num_agent_steps_trained": 130680, "last_target_update_ts": 70656, "num_target_updates": 137}, "done": false, "episodes_total": 219, "training_iteration": 69, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-39", "timestamp": 1655476239, "time_this_iter_s": 5.544430494308472, "time_total_s": 342.98634576797485, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 342.98634576797485, "timesteps_since_restore": 0, "iterations_since_restore": 69, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 27.7125, "ram_util_percent": 64.01249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 4.1064558029174805, "min_q": -83.37451934814453, "max_q": 31.70570945739746, "mean_td_error": -1.1426819562911987}, "td_error": [0.05230903625488281, -1.7219109535217285, 0.1175537109375, -0.8654756546020508, -4.67716121673584, 0.5835303068161011, -0.5951213836669922, -1.639080286026001, -4.171754837036133, -8.096439361572266, 0.21384620666503906, -2.514995574951172, -0.3155198097229004, 0.0785675048828125, 0.18104839324951172, 0.8967700004577637, -0.44681644439697266, -4.675439834594727, -1.0871076583862305, 0.0004436969757080078, -0.41901588439941406, -23.2643985748291, 0.06599044799804688, -1.2104229927062988, -0.58197021484375, 0.35132408142089844, 0.10483193397521973, -0.7617902755737305, -0.7647132873535156, 0.3701601028442383, -1.1467407941818237, 0.024507522583007812, -0.21391677856445312, 0.18434715270996094, 0.22344017028808594, -7.950649261474609, -0.45067262649536133, -0.24399948120117188, -0.1382007598876953, -6.509760856628418, -1.5566437244415283, 2.1651058197021484, -1.213674545288086, -0.7123918533325195, -0.11621856689453125, -0.3338031768798828, -0.11234664916992188, -0.5405445098876953, -5.747201442718506, -0.8304824829101562, -2.303783655166626, 0.9475717544555664, -0.7527294158935547, -0.06335639953613281, -0.5850229263305664, 0.60888671875, -0.10243034362792969, 0.43264341354370117, -0.9614639282226562, 0.07311058044433594, -0.5793323516845703, -1.1270999908447266, 0.11095809936523438, -1.9106369018554688, -1.332122802734375, -1.697888970375061, 0.05654191970825195, 1.0292959213256836, -5.369922637939453, -0.00023651123046875, -0.4142947196960449, 2.075061798095703, -2.9814515113830566, -1.09340238571167, -0.805084228515625, 0.05554771423339844, -0.6163754463195801, -1.718780517578125, 0.4392070770263672, 0.5821845531463623, -8.664932250976562, -1.1970577239990234, 0.23479604721069336, -1.3711557388305664, -1.1270685195922852, -0.27333641052246094, 0.7765278816223145, -0.8874015808105469, 1.4862565994262695, -1.9658269882202148, -2.372377395629883, -9.483789443969727, 0.0867919921875, -0.3072800636291504, 0.2424001693725586, -1.3140792846679688, -6.950624942779541, -0.8289551734924316, -0.6707210540771484, -1.9381237030029297, 0.634047269821167, 0.8623719215393066, 0.1489572525024414, 1.947089672088623, -0.9629158973693848, 0.13938570022583008, 0.3435821533203125, -0.48923683166503906, 0.6775150299072266, -1.1787478923797607, 0.29605019092559814, -7.937982559204102, -0.2933673858642578, 1.5119678974151611, 1.0026779174804688, -0.37537431716918945, -0.21376419067382812, -0.44672393798828125, 1.9857420921325684, -0.23013973236083984], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 71680, "num_env_steps_trained": 132600, "num_agent_steps_sampled": 71680, "num_agent_steps_trained": 132600, "last_target_update_ts": 71680, "num_target_updates": 139}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -100.23169617652893, "episode_len_mean": 265.1, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128], "episode_lengths": [325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.504504589539462, "mean_inference_ms": 24.6726260190909, "mean_action_processing_ms": 0.1355053404986359, "mean_env_wait_ms": 4.1128383716818915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -100.23169617652893, "episode_len_mean": 265.1, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-329.03320563584566, -179.83381183445454, -66.51811999827623, -1.370428390800953, -153.32307288050652, 15.686992041766644, -58.56988115608692, -24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128], "episode_lengths": [325, 309, 270, 250, 304, 241, 252, 248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.504504589539462, "mean_inference_ms": 24.6726260190909, "mean_action_processing_ms": 0.1355053404986359, "mean_env_wait_ms": 4.1128383716818915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 71680, "num_agent_steps_trained": 132600, "num_env_steps_sampled": 71680, "num_env_steps_trained": 132600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 71680, "agent_timesteps_total": 71680, "timers": {"training_iteration_time_ms": 361.962, "learn_time_ms": 67.419, "learn_throughput": 1779.908, "synch_weights_time_ms": 20.188}, "counters": {"num_env_steps_sampled": 71680, "num_env_steps_trained": 132600, "num_agent_steps_sampled": 71680, "num_agent_steps_trained": 132600, "last_target_update_ts": 71680, "num_target_updates": 139}, "done": false, "episodes_total": 222, "training_iteration": 70, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-45", "timestamp": 1655476245, "time_this_iter_s": 5.534775733947754, "time_total_s": 348.5211215019226, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 348.5211215019226, "timesteps_since_restore": 0, "iterations_since_restore": 70, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.637500000000003, "ram_util_percent": 63.975}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.5374929904937744, "min_q": -84.5796890258789, "max_q": 31.794414520263672, "mean_td_error": -0.4537357687950134}, "td_error": [-0.4235419034957886, -0.42745304107666016, 0.4512815475463867, 0.11919736862182617, -0.5492720603942871, 0.2660026550292969, -0.9375905990600586, 0.5622692108154297, 2.678162097930908, 0.5777182579040527, 0.21451568603515625, 2.6439313888549805, 0.5016465783119202, 0.8521442413330078, 0.17799997329711914, -1.3714370727539062, 0.4810028076171875, 0.1426551342010498, -6.897751808166504, 1.0825729370117188, 0.6367053985595703, 0.08029747009277344, -8.640450477600098, -1.2262649536132812, -2.3157081604003906, -0.3778071403503418, 0.07083606719970703, -1.6487207412719727, -0.8957939147949219, -0.579010009765625, 0.3030405044555664, 0.2444324493408203, 15.219929695129395, 0.6699123382568359, 0.2929191589355469, 0.37818676233291626, -1.1671242713928223, -0.6052632331848145, -6.158540725708008, 0.7439088821411133, 0.5650291442871094, -0.47809600830078125, -1.500701904296875, -0.4964485168457031, -0.6502590179443359, -0.7658681869506836, 0.9445571899414062, 2.8730907440185547, -0.4114227294921875, -2.473710060119629, -61.02803421020508, -0.552978515625, 0.6420252323150635, 0.686457633972168, 0.6580162048339844, 0.4361753463745117, 0.7359828948974609, 0.8236007690429688, -0.5017774105072021, 0.0992891788482666, -0.3036842346191406, 0.7032756805419922, 0.3300762176513672, -0.3147740364074707, 0.04384422302246094, -2.5176782608032227, -0.42711687088012695, -0.3507504463195801, -0.2705674171447754, -0.1477057933807373, -0.2851085662841797, -0.9402601718902588, -1.901254415512085, 3.063915252685547, 2.626415252685547, -1.2765989303588867, 0.7573466300964355, 2.5298633575439453, -0.40958404541015625, 0.5016465783119202, 1.7410173416137695, -1.2117843627929688, -8.097471237182617, 1.0180165767669678, -0.6223492622375488, 0.19414901733398438, 1.1691417694091797, 1.2192401885986328, 0.7916660308837891, 0.5933494567871094, 0.5501060485839844, 0.9687938690185547, -0.7276401519775391, -0.6519865989685059, -0.25135231018066406, 0.5112766027450562, -3.620547294616699, -10.309440612792969, -0.9921307563781738, 1.0529212951660156, 2.0710318088531494, 0.14178180694580078, 0.2884349822998047, -0.04327583312988281, -0.4229087829589844, 2.2245965003967285, 0.2225666046142578, 0.04414987564086914, -2.1767613887786865, 0.5337162017822266, 1.9465522766113281, 1.0542681217193604, 1.2796049118041992, 1.1682186126708984, 1.1599032878875732, 18.581329345703125, -0.9512052536010742, -0.6537976264953613, 1.1061325073242188, -1.533367395401001], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 72704, "num_env_steps_trained": 134520, "num_agent_steps_sampled": 72704, "num_agent_steps_trained": 134520, "last_target_update_ts": 72704, "num_target_updates": 141}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -99.71651645354926, "episode_len_mean": 263.59, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174], "episode_lengths": [248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5066917494372669, "mean_inference_ms": 24.680125099379197, "mean_action_processing_ms": 0.13547723448255225, "mean_env_wait_ms": 4.12194287731119, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -99.71651645354926, "episode_len_mean": 263.59, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-24.4473941847682, -312.3146409392357, -7.788462154567242, -89.24554003030062, -107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174], "episode_lengths": [248, 330, 242, 260, 285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5066917494372669, "mean_inference_ms": 24.680125099379197, "mean_action_processing_ms": 0.13547723448255225, "mean_env_wait_ms": 4.12194287731119, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 72704, "num_agent_steps_trained": 134520, "num_env_steps_sampled": 72704, "num_env_steps_trained": 134520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 72704, "agent_timesteps_total": 72704, "timers": {"training_iteration_time_ms": 330.489, "learn_time_ms": 68.169, "learn_throughput": 1760.343, "synch_weights_time_ms": 20.488}, "counters": {"num_env_steps_sampled": 72704, "num_env_steps_trained": 134520, "num_agent_steps_sampled": 72704, "num_agent_steps_trained": 134520, "last_target_update_ts": 72704, "num_target_updates": 141}, "done": false, "episodes_total": 229, "training_iteration": 71, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-51", "timestamp": 1655476251, "time_this_iter_s": 5.664838790893555, "time_total_s": 354.18596029281616, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 354.18596029281616, "timesteps_since_restore": 0, "iterations_since_restore": 71, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.987500000000004, "ram_util_percent": 63.9875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.26216596364974976, "min_q": -81.6843032836914, "max_q": 27.273008346557617, "mean_td_error": -1.1233667135238647}, "td_error": [0.24276113510131836, -1.9172821044921875, -1.388925552368164, -0.15523004531860352, 0.20446133613586426, 0.5645794868469238, 0.6392908096313477, -2.8831787109375, -0.07194900512695312, -0.4159364700317383, 1.5835789442062378, -1.1200103759765625, 0.03274965286254883, 0.11374926567077637, -0.23221302032470703, -0.9564590454101562, 1.2592573165893555, -1.0146589279174805, -1.0590362548828125, -1.5458297729492188, -2.3749122619628906, 0.0043659210205078125, -0.701171875, 0.46437835693359375, 0.12106549739837646, -0.5150833129882812, -0.58624267578125, 1.124460220336914, -0.6227660179138184, 0.14612102508544922, -2.6741504669189453, -2.3455891609191895, -2.454273223876953, 0.11202049255371094, -1.200556755065918, -6.7684783935546875, 0.2926442623138428, -0.6399326324462891, -0.02527618408203125, -0.3321571350097656, 6.317600250244141, 0.5320053100585938, 1.2349649667739868, -0.3235912322998047, -0.8212060928344727, -0.7154008150100708, -1.5632591247558594, -0.7728214263916016, -0.328765869140625, -6.240900039672852, -0.5156803131103516, 0.014759063720703125, -0.17638778686523438, -79.6843032836914, -1.1091399192810059, -0.21828842163085938, -0.21256637573242188, -0.7936840057373047, 0.43677520751953125, -1.0398788452148438, 0.6286430358886719, -0.8821916580200195, -0.9853734970092773, -0.8897266387939453, -0.6345715522766113, -2.8107738494873047, 0.028525352478027344, 0.49163150787353516, 0.046549320220947266, 2.527080535888672, -0.6581211090087891, 0.6673336029052734, -1.8434104919433594, -1.7430620193481445, 1.0834159851074219, 1.9639396667480469, -1.2103755474090576, -0.4752769470214844, -0.5238523483276367, -0.11514091491699219, -0.1461029052734375, 0.40239429473876953, -0.8352832794189453, 1.5118122100830078, 0.5757713317871094, -5.327943801879883, -0.8370161056518555, 0.6673336029052734, 0.29694366455078125, -1.694565773010254, 1.2029314041137695, -1.5885009765625, 0.6900644302368164, 0.07061004638671875, 0.7652053833007812, -0.3446369171142578, -0.49422264099121094, -0.8070878982543945, 0.37775886058807373, -0.21875572204589844, 0.26744651794433594, 0.5555448532104492, 0.9411334991455078, -4.272621154785156, -0.7375564575195312, -1.2616252899169922, -0.7974929809570312, 0.14565277099609375, 0.804046630859375, 0.15248918533325195, -1.2477750778198242, -0.6954154968261719, 0.9789867401123047, -0.045424461364746094, -1.9645843505859375, -3.920192241668701, -0.02187204360961914, 0.13968610763549805, 0.22946476936340332, 0.08974647521972656], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 73728, "num_env_steps_trained": 136440, "num_agent_steps_sampled": 73728, "num_agent_steps_trained": 136440, "last_target_update_ts": 73728, "num_target_updates": 143}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -98.78658134594559, "episode_len_mean": 262.68, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896], "episode_lengths": [285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5071936586677714, "mean_inference_ms": 24.681509892509506, "mean_action_processing_ms": 0.13536943414802163, "mean_env_wait_ms": 4.125130646434854, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -98.78658134594559, "episode_len_mean": 262.68, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-107.24554013460875, -11.399999864399433, 16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896], "episode_lengths": [285, 246, 229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5071936586677714, "mean_inference_ms": 24.681509892509506, "mean_action_processing_ms": 0.13536943414802163, "mean_env_wait_ms": 4.125130646434854, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 73728, "num_agent_steps_trained": 136440, "num_env_steps_sampled": 73728, "num_env_steps_trained": 136440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 73728, "agent_timesteps_total": 73728, "timers": {"training_iteration_time_ms": 347.038, "learn_time_ms": 67.873, "learn_throughput": 1767.997, "synch_weights_time_ms": 20.688}, "counters": {"num_env_steps_sampled": 73728, "num_env_steps_trained": 136440, "num_agent_steps_sampled": 73728, "num_agent_steps_trained": 136440, "last_target_update_ts": 73728, "num_target_updates": 143}, "done": false, "episodes_total": 233, "training_iteration": 72, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-30-56", "timestamp": 1655476256, "time_this_iter_s": 5.324631929397583, "time_total_s": 359.51059222221375, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 359.51059222221375, "timesteps_since_restore": 0, "iterations_since_restore": 72, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.9375, "ram_util_percent": 63.8125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.44204628467559814, "min_q": -86.93219757080078, "max_q": 27.2034912109375, "mean_td_error": -1.234514594078064}, "td_error": [-0.06025123596191406, -2.6825313568115234, 0.4101734161376953, -0.16220712661743164, 0.21091222763061523, 0.2587003707885742, 1.58076810836792, -16.776166915893555, 0.41594982147216797, -0.9837875366210938, 0.5675573348999023, 0.3840532898902893, -2.3088760375976562, 1.5905656814575195, -0.7036457061767578, -6.772655487060547, 1.676623821258545, -0.2267169952392578, 0.5305806398391724, -0.6247024536132812, 5.955738067626953, -1.1330604553222656, -16.98772621154785, 0.4995603561401367, -0.4527962803840637, 0.48285675048828125, 0.009290218353271484, -0.24513864517211914, -0.34114837646484375, -6.355680465698242, -0.0027370452880859375, 4.507620811462402, 1.0799999237060547, 0.8817367553710938, -2.7449989318847656, -0.5253715515136719, -0.9145221710205078, 0.46734094619750977, -0.8554172515869141, -0.1126251220703125, 0.2802886962890625, 2.3394250869750977, -0.4146108627319336, 0.5080037117004395, -0.5665111541748047, 5.443174362182617, -3.549391746520996, 0.02854156494140625, -7.356005668640137, 0.7958354949951172, 0.08800077438354492, -0.2913169860839844, -2.4840340614318848, -0.9930572509765625, 1.1131048202514648, -1.8177986145019531, 0.11942100524902344, 0.7414042949676514, 0.17309284210205078, -0.08084917068481445, 0.08593940734863281, 0.02617645263671875, -0.6387481689453125, 0.06602096557617188, -0.4767112731933594, -0.5018186569213867, -84.93219757080078, 0.7231636047363281, 1.6492419242858887, 0.026833534240722656, -0.8768768310546875, 0.06348419189453125, 3.763172149658203, 0.8558673858642578, 1.1259722709655762, 22.039249420166016, 0.3217191696166992, -6.064980506896973, -0.6258754730224609, -0.4168210029602051, -0.10239219665527344, 1.7543702125549316, 0.4773368835449219, 0.8784761428833008, -0.913081169128418, 0.12271976470947266, 0.9377031326293945, -0.4218864440917969, 1.4592657089233398, 0.030136585235595703, 0.12306849658489227, 0.1692943572998047, 1.1934008598327637, 1.0222206115722656, -11.72758674621582, -1.1529011726379395, -0.5535335540771484, 1.01129150390625, -0.545896053314209, 0.3926563262939453, -0.4193253517150879, -0.9837875366210938, -0.5768904685974121, 0.22842025756835938, 0.6089730262756348, -0.8667545318603516, -0.1707010269165039, 0.032012939453125, -5.320529460906982, -17.179672241210938, -1.1106810569763184, 0.13559985160827637, -6.080667495727539, -1.8177986145019531, 0.7048781514167786, 2.0995311737060547, 0.36050158739089966, -0.23717498779296875, -0.48158979415893555, -1.0475530624389648], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 74752, "num_env_steps_trained": 138360, "num_agent_steps_sampled": 74752, "num_agent_steps_trained": 138360, "last_target_update_ts": 74752, "num_target_updates": 145}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -98.5437650156021, "episode_len_mean": 262.49, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992], "episode_lengths": [229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5076248461028451, "mean_inference_ms": 24.70758349156697, "mean_action_processing_ms": 0.13531689795537707, "mean_env_wait_ms": 4.129497682882624, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -98.5437650156021, "episode_len_mean": 262.49, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [16.064785823225975, -28.84554012864828, -202.87313226610422, -201.20437114685774, -274.01235074549913, -43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992], "episode_lengths": [229, 246, 322, 301, 324, 258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5076248461028451, "mean_inference_ms": 24.70758349156697, "mean_action_processing_ms": 0.13531689795537707, "mean_env_wait_ms": 4.129497682882624, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 74752, "num_agent_steps_trained": 138360, "num_env_steps_sampled": 74752, "num_env_steps_trained": 138360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 74752, "agent_timesteps_total": 74752, "timers": {"training_iteration_time_ms": 323.905, "learn_time_ms": 69.027, "learn_throughput": 1738.453, "synch_weights_time_ms": 20.088}, "counters": {"num_env_steps_sampled": 74752, "num_env_steps_trained": 138360, "num_agent_steps_sampled": 74752, "num_agent_steps_trained": 138360, "last_target_update_ts": 74752, "num_target_updates": 145}, "done": false, "episodes_total": 235, "training_iteration": 73, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-02", "timestamp": 1655476262, "time_this_iter_s": 5.22145938873291, "time_total_s": 364.73205161094666, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 364.73205161094666, "timesteps_since_restore": 0, "iterations_since_restore": 73, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.0625, "ram_util_percent": 63.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.485482782125473, "min_q": -88.34048461914062, "max_q": 31.708147048950195, "mean_td_error": -0.17905181646347046}, "td_error": [0.8266177177429199, -4.085407257080078, 0.30841732025146484, -6.247646331787109, -0.5752639770507812, 0.28558921813964844, 0.9611148834228516, -2.6439857482910156, 0.15257740020751953, 0.10823249816894531, -0.830322265625, 0.9532852172851562, -0.43459463119506836, -0.26233959197998047, -0.1342153549194336, 0.8019688129425049, 0.9490909576416016, 0.4589042663574219, 0.6928539276123047, -0.009492874145507812, 0.23352813720703125, -0.14003562927246094, -0.7603635787963867, 0.034210205078125, -0.7896041870117188, 0.9929428100585938, 0.3191537857055664, -1.6957213878631592, -0.4970517158508301, -0.1625838279724121, -0.15584659576416016, 1.0621669292449951, 0.42459964752197266, -0.04075002670288086, 0.6864643096923828, -0.01801776885986328, -0.8419456481933594, 1.1217536926269531, 0.20895838737487793, -0.4265688359737396, 1.1362533569335938, 0.050253868103027344, 16.682117462158203, 0.39008474349975586, 1.6989011764526367, 0.2733931541442871, 0.7916069030761719, 0.5889225006103516, 0.8864130973815918, -0.017324447631835938, -0.7516913414001465, 0.8370895385742188, 0.02984619140625, 1.2107486724853516, 0.15635371208190918, -0.20226550102233887, -0.26773786544799805, -0.1378769874572754, 0.4260072708129883, 1.5630149841308594, 0.7444415092468262, 0.5572185516357422, -8.086956024169922, 0.1260051727294922, 0.2699568271636963, -1.3359184265136719, -0.2970600128173828, -1.0337251424789429, -0.8499794006347656, 0.7531447410583496, -0.3128187656402588, 0.5606040954589844, 0.17328643798828125, -0.8389205932617188, 0.6548004150390625, 0.6752777099609375, 0.49700355529785156, 0.2596778869628906, 0.6222343444824219, 1.0337915420532227, -2.1646804809570312, 0.41984081268310547, 6.988421440124512, 0.012950897216796875, 0.5124342441558838, 0.2806253433227539, -0.5997390747070312, 0.9375381469726562, -0.6138708591461182, 0.15572357177734375, -9.066207885742188, 0.33214569091796875, 0.2192096710205078, -0.1707324981689453, -16.088794708251953, 2.3111562728881836, 0.39853477478027344, -8.7371826171875, 0.5689969062805176, 1.206573486328125, 0.8483142852783203, -0.9108867645263672, 0.5981245040893555, 0.2552957534790039, 1.6769040822982788, 1.9866924285888672, 1.0086097717285156, -0.5683116912841797, -0.16572141647338867, 0.05419731140136719, -0.7325165271759033, 1.9935874938964844, -0.19896364212036133, -0.1415414810180664, -7.887955665588379, -0.805778980255127, 0.16252422332763672, 0.9049372673034668, 0.17364120483398438, -6.987156867980957], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 75776, "num_env_steps_trained": 140280, "num_agent_steps_sampled": 75776, "num_agent_steps_trained": 140280, "last_target_update_ts": 75776, "num_target_updates": 147}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -92.15078061960638, "episode_len_mean": 260.18, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365], "episode_lengths": [258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5105793479113843, "mean_inference_ms": 24.709765152515406, "mean_action_processing_ms": 0.1354789252398395, "mean_env_wait_ms": 4.138019225500992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -92.15078061960638, "episode_len_mean": 260.18, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-43.21682318300009, -487.2394719943404, -521.8329092636704, -40.18539181351662, -79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365], "episode_lengths": [258, 382, 391, 246, 277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5105793479113843, "mean_inference_ms": 24.709765152515406, "mean_action_processing_ms": 0.1354789252398395, "mean_env_wait_ms": 4.138019225500992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 75776, "num_agent_steps_trained": 140280, "num_env_steps_sampled": 75776, "num_env_steps_trained": 140280, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 75776, "agent_timesteps_total": 75776, "timers": {"training_iteration_time_ms": 337.782, "learn_time_ms": 69.594, "learn_throughput": 1724.295, "synch_weights_time_ms": 20.588}, "counters": {"num_env_steps_sampled": 75776, "num_env_steps_trained": 140280, "num_agent_steps_sampled": 75776, "num_agent_steps_trained": 140280, "last_target_update_ts": 75776, "num_target_updates": 147}, "done": false, "episodes_total": 240, "training_iteration": 74, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-07", "timestamp": 1655476267, "time_this_iter_s": 5.313628435134888, "time_total_s": 370.04568004608154, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 370.04568004608154, "timesteps_since_restore": 0, "iterations_since_restore": 74, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.02857142857143, "ram_util_percent": 63.699999999999996}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.4430038928985596, "min_q": -86.17866516113281, "max_q": 30.50785255432129, "mean_td_error": -0.3790854811668396}, "td_error": [1.4391508102416992, 1.011861801147461, -0.3907318115234375, -5.289776802062988, -0.5169610977172852, -1.6073951721191406, 0.7814383506774902, -1.8638725280761719, 0.897343635559082, -0.38039064407348633, 0.1845569610595703, -1.685103416442871, -0.19154691696166992, 0.3930528163909912, 1.5723114013671875, 0.7421207427978516, -1.1193218231201172, -0.029784202575683594, -0.5678539276123047, -0.8428816199302673, -0.9487628936767578, -0.7061421871185303, 0.47916603088378906, 1.366826057434082, -6.409193515777588, 0.3462696075439453, 2.9700212478637695, -3.62396240234375e-05, -1.303725242614746, -0.043030738830566406, 3.0412864685058594, 0.4415912628173828, -0.08277702331542969, 0.07570886611938477, 1.3812963962554932, 0.876317024230957, 0.3843502998352051, 1.7594753503799438, -0.2943248748779297, 0.48050498962402344, 0.03350639343261719, -1.161233901977539, 1.8353369235992432, 0.6378369331359863, -0.4631385803222656, -0.28572654724121094, -0.6225738525390625, -0.8001003265380859, -0.46322059631347656, -0.5016565322875977, 0.478118896484375, -0.5289726257324219, -0.028478145599365234, -0.31554222106933594, -0.7325711250305176, -0.9730663299560547, -0.4080345630645752, -0.30077552795410156, -1.0058941841125488, -0.11568450927734375, -7.553471565246582, -0.7408657073974609, -1.0729436874389648, -1.784836769104004, -0.47612953186035156, -0.21949195861816406, -0.08830022811889648, -0.000415802001953125, -0.009090423583984375, -0.4836444854736328, -0.7365322113037109, -0.5390539169311523, -1.7104792594909668, -0.1453838348388672, -0.6528129577636719, -0.7293777465820312, -0.11638450622558594, -0.8589925765991211, 1.061535120010376, -2.105815887451172, 1.5332469940185547, 1.0492353439331055, 0.000759124755859375, -0.1672811508178711, -0.8788909912109375, 0.004469394683837891, -0.9807415008544922, -0.17046737670898438, 0.3339061737060547, -0.06449639797210693, -0.8914104700088501, 1.1521095037460327, 0.24861693382263184, -0.15237188339233398, -0.7171783447265625, -0.1103057861328125, 1.2985897064208984, -1.1147937774658203, 0.4401051998138428, -0.056458473205566406, 0.5528006553649902, -0.4471607208251953, -2.214702606201172, 0.1492633819580078, -0.5627384185791016, -1.7294740676879883, 0.14328384399414062, -6.844603538513184, -0.13725852966308594, 0.23034000396728516, -0.5434222221374512, 1.3047914505004883, -0.2160172462463379, -0.08365631103515625, -4.782266616821289, -1.6703720092773438, -0.4462871551513672, -0.3263130187988281, -0.5152130126953125, 0.22542572021484375], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 76800, "num_env_steps_trained": 142200, "num_agent_steps_sampled": 76800, "num_agent_steps_trained": 142200, "last_target_update_ts": 76800, "num_target_updates": 149}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -83.9692757844925, "episode_len_mean": 257.98, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627], "episode_lengths": [277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5113851302435883, "mean_inference_ms": 24.704446370882206, "mean_action_processing_ms": 0.1353909924766805, "mean_env_wait_ms": 4.143701114083746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -83.9692757844925, "episode_len_mean": 257.98, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-79.62925004959106, -18.667000845074654, -83.74518483132124, 14.20775556564331, -367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627], "episode_lengths": [277, 237, 289, 232, 324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5113851302435883, "mean_inference_ms": 24.704446370882206, "mean_action_processing_ms": 0.1353909924766805, "mean_env_wait_ms": 4.143701114083746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 76800, "num_agent_steps_trained": 142200, "num_env_steps_sampled": 76800, "num_env_steps_trained": 142200, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 76800, "agent_timesteps_total": 76800, "timers": {"training_iteration_time_ms": 325.578, "learn_time_ms": 69.701, "learn_throughput": 1721.639, "synch_weights_time_ms": 20.689}, "counters": {"num_env_steps_sampled": 76800, "num_env_steps_trained": 142200, "num_agent_steps_sampled": 76800, "num_agent_steps_trained": 142200, "last_target_update_ts": 76800, "num_target_updates": 149}, "done": false, "episodes_total": 244, "training_iteration": 75, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-12", "timestamp": 1655476272, "time_this_iter_s": 5.181052923202515, "time_total_s": 375.22673296928406, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 375.22673296928406, "timesteps_since_restore": 0, "iterations_since_restore": 75, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.862499999999997, "ram_util_percent": 63.7625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.8080823421478271, "min_q": -90.72123718261719, "max_q": 30.7479190826416, "mean_td_error": -0.2614898681640625}, "td_error": [-2.018291711807251, -0.33466148376464844, -1.2504825592041016, 0.23657798767089844, -0.23182368278503418, -1.0813713073730469, -0.763641357421875, -1.764817237854004, -0.11877012252807617, -0.948516845703125, -0.9216060638427734, 0.07807350158691406, -1.675882339477539, -1.031449317932129, 0.26401233673095703, -1.330946922302246, 1.3272974491119385, 3.5629923343658447, -0.5863218307495117, 0.7417740821838379, 0.24362850189208984, -2.826404571533203, -0.32636117935180664, -0.7413272857666016, 1.8186874389648438, -0.8025579452514648, -2.4721126556396484, 2.167552947998047, -1.3853874206542969, -0.7885532379150391, -1.4410982131958008, -0.8910808563232422, -0.4905672073364258, -0.4002113342285156, -6.102042198181152, 0.790820837020874, 0.021989822387695312, -1.1061534881591797, 1.894643783569336, 0.3792991638183594, 0.14035415649414062, -0.43790721893310547, -0.347503662109375, -1.1087265014648438, -0.8305234909057617, -0.4087181091308594, -0.3318023681640625, 1.0405402183532715, -0.41815185546875, 0.21907424926757812, 11.470112800598145, 1.2224311828613281, -1.496572494506836, 0.9481124877929688, -1.0219764709472656, -0.961700439453125, -0.8516483306884766, -0.27082133293151855, -0.36745643615722656, -1.5779848098754883, -1.3182668685913086, -0.35588836669921875, -0.6296920776367188, -1.552384376525879, -0.752117395401001, -1.0037145614624023, -10.779382705688477, -0.8052377700805664, -0.8766975402832031, -1.4266834259033203, -0.2628645896911621, 2.722484588623047, -0.4355897903442383, -0.5196323394775391, -0.5122795104980469, -1.7245573997497559, -0.5731043815612793, 0.38486242294311523, 1.7774009704589844, 2.369203567504883, 0.2529563903808594, -0.8776443004608154, -1.299046516418457, 0.017968177795410156, -0.6152963638305664, 0.4200921058654785, -1.0025825500488281, -0.30684661865234375, -0.8813591003417969, 7.376112937927246, 1.3584041595458984, -0.07532405853271484, 0.1451873779296875, -0.5512900352478027, -0.43658447265625, -1.2656002044677734, -0.4432382583618164, 0.3222513198852539, 0.41998863220214844, -0.2146892547607422, -1.0193767547607422, 0.1634223461151123, -0.6229877471923828, -0.8399982452392578, 0.13150978088378906, -1.1066646575927734, -0.5080547332763672, -0.22422218322753906, -0.2796363830566406, 0.9558744430541992, 0.34726715087890625, 1.0353693962097168, -0.22444629669189453, -0.878232479095459, -0.5063705444335938, 0.5958366394042969, 0.1470412015914917, -1.4912691116333008, 3.260272979736328, -0.6874771118164062], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 77824, "num_env_steps_trained": 144120, "num_agent_steps_sampled": 77824, "num_agent_steps_trained": 144120, "last_target_update_ts": 77824, "num_target_updates": 151}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -87.81954982377589, "episode_len_mean": 258.56, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364], "episode_lengths": [324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5121446379332272, "mean_inference_ms": 24.71560758264802, "mean_action_processing_ms": 0.13530256307225952, "mean_env_wait_ms": 4.149028904939474, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -87.81954982377589, "episode_len_mean": 258.56, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-367.19655967503786, -28.619703590869904, -7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364], "episode_lengths": [324, 258, 226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5121446379332272, "mean_inference_ms": 24.71560758264802, "mean_action_processing_ms": 0.13530256307225952, "mean_env_wait_ms": 4.149028904939474, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 77824, "num_agent_steps_trained": 144120, "num_env_steps_sampled": 77824, "num_env_steps_trained": 144120, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 77824, "agent_timesteps_total": 77824, "timers": {"training_iteration_time_ms": 333.189, "learn_time_ms": 68.816, "learn_throughput": 1743.773, "synch_weights_time_ms": 20.49}, "counters": {"num_env_steps_sampled": 77824, "num_env_steps_trained": 144120, "num_agent_steps_sampled": 77824, "num_agent_steps_trained": 144120, "last_target_update_ts": 77824, "num_target_updates": 151}, "done": false, "episodes_total": 248, "training_iteration": 76, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-18", "timestamp": 1655476278, "time_this_iter_s": 5.26124119758606, "time_total_s": 380.4879741668701, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 380.4879741668701, "timesteps_since_restore": 0, "iterations_since_restore": 76, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.925, "ram_util_percent": 63.725}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.08952153474092484, "min_q": -86.83039093017578, "max_q": 28.808801651000977, "mean_td_error": -0.4725891649723053}, "td_error": [-0.6119003295898438, 2.4231462478637695, 0.24715518951416016, -7.218994140625, 1.673140048980713, -0.7022042274475098, -0.4653959274291992, 0.8140625953674316, 0.7817764282226562, -0.6098575592041016, 2.8061752319335938, -1.9628362655639648, -0.8326601982116699, -0.1608428955078125, -0.033057212829589844, -1.385358214378357, 2.465106964111328, -0.10832834243774414, -0.406768798828125, -35.75676727294922, 0.07671642303466797, -0.110137939453125, 0.4993007183074951, 0.01056814193725586, 1.0451765060424805, -42.701812744140625, 1.6812553405761719, 0.19463717937469482, -0.6108684539794922, 0.3945789337158203, 0.9558944702148438, 1.3073711395263672, 0.47405004501342773, -0.12036895751953125, 2.2693958282470703, -0.4311408996582031, -0.5707607269287109, 0.3118934631347656, 2.3703079223632812, -0.3257904052734375, -0.2757924795150757, -0.6030616760253906, -0.20143508911132812, -0.25860595703125, 0.050022125244140625, -0.6981716156005859, -0.5249996185302734, 0.19346141815185547, 0.2326064109802246, -1.1720128059387207, -8.086551666259766, 0.32913970947265625, -0.04300689697265625, -0.06714916229248047, 0.09558355808258057, -0.12929344177246094, 1.1798548698425293, 1.3624536991119385, 2.0924911499023438, -2.824939727783203, -0.7139377593994141, 2.4515724182128906, 3.4729390144348145, 0.7334985733032227, -0.49243736267089844, -1.396906852722168, 0.3720560073852539, 0.191070556640625, 1.6873893737792969, -0.08254289627075195, 0.3200187683105469, 0.9454269409179688, -0.5854110717773438, 0.06859111785888672, 0.04888725280761719, 5.91888427734375, 0.3310732841491699, -4.502677917480469, 1.0568151473999023, 10.223688125610352, -0.008150100708007812, -0.17101478576660156, 0.7866668701171875, -0.4038810729980469, 0.7698700428009033, 0.037189483642578125, 1.0147781372070312, 0.5324926376342773, -10.27873706817627, 17.33026885986328, -1.1452016830444336, -0.33769989013671875, 3.2104811668395996, -0.08999443054199219, 0.9835693836212158, -0.5963125228881836, 0.4303097724914551, -0.014455795288085938, 0.04266834259033203, 1.6703529357910156, 1.5484466552734375, 0.2167353630065918, 0.3546111583709717, -0.5686640739440918, -0.2877979278564453, -0.15221786499023438, -10.498112678527832, -0.7342243194580078, 1.4832391738891602, 1.5508952140808105, -0.10749626159667969, -0.40627098083496094, 0.6079006195068359, -0.6773214340209961, -1.291513442993164, -0.11912155151367188, 0.9494266510009766, -0.9874076843261719, -0.556671142578125, 0.8272099494934082], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 78848, "num_env_steps_trained": 146040, "num_agent_steps_sampled": 78848, "num_agent_steps_trained": 146040, "last_target_update_ts": 78848, "num_target_updates": 153}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -83.52998587615788, "episode_len_mean": 257.08, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771], "episode_lengths": [226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5132649327585032, "mean_inference_ms": 24.715085377684918, "mean_action_processing_ms": 0.13520825812920745, "mean_env_wait_ms": 4.154399705322456, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -83.52998587615788, "episode_len_mean": 257.08, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-7.10000005364418, -87.93660382181406, -116.34246992319822, -3.378729209303856, -50.36014811694622, -629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771], "episode_lengths": [226, 262, 295, 229, 232, 427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5132649327585032, "mean_inference_ms": 24.715085377684918, "mean_action_processing_ms": 0.13520825812920745, "mean_env_wait_ms": 4.154399705322456, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 78848, "num_agent_steps_trained": 146040, "num_env_steps_sampled": 78848, "num_env_steps_trained": 146040, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 78848, "agent_timesteps_total": 78848, "timers": {"training_iteration_time_ms": 317.784, "learn_time_ms": 69.686, "learn_throughput": 1722.012, "synch_weights_time_ms": 20.904}, "counters": {"num_env_steps_sampled": 78848, "num_env_steps_trained": 146040, "num_agent_steps_sampled": 78848, "num_agent_steps_trained": 146040, "last_target_update_ts": 78848, "num_target_updates": 153}, "done": false, "episodes_total": 250, "training_iteration": 77, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-23", "timestamp": 1655476283, "time_this_iter_s": 4.9618730545043945, "time_total_s": 385.4498472213745, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 385.4498472213745, "timesteps_since_restore": 0, "iterations_since_restore": 77, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.8, "ram_util_percent": 63.72857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.44662436842918396, "min_q": -89.82936096191406, "max_q": 29.316635131835938, "mean_td_error": -0.3313641846179962}, "td_error": [-0.777557373046875, 0.16959381103515625, 0.5052461624145508, 3.0180578231811523, -1.8177375793457031, 2.340719223022461, -0.5471458435058594, -2.1832923889160156, 0.01813507080078125, -0.9315943717956543, 0.804584264755249, -0.18947219848632812, -0.18339157104492188, -0.17173826694488525, 1.3176345825195312, 0.7928085327148438, -0.8461112976074219, 0.04996681213378906, -0.9942073822021484, -1.9195594787597656, 0.46274280548095703, 0.40962982177734375, 0.2910308837890625, -0.11065673828125, -0.11262893676757812, 0.9774346351623535, 0.09842205047607422, -1.4696369171142578, -0.24616193771362305, 0.445648193359375, -1.0083389282226562, -5.5384721755981445, -0.9364409446716309, 0.07361030578613281, 0.4154750108718872, -0.9016423225402832, 2.246746063232422, 0.036830902099609375, 0.23033523559570312, 13.535467147827148, -0.21286678314208984, -0.4789152145385742, 0.15875983238220215, -0.2582111358642578, -0.07003974914550781, -0.7149271965026855, -1.619490385055542, 0.4148721694946289, 1.3345909118652344, -0.8301975727081299, 7.368533134460449, 0.22500848770141602, -0.5098190307617188, 0.8706130981445312, -0.3758401870727539, -7.219978332519531, 0.07670116424560547, -4.813669204711914, 0.01854419708251953, -6.382172107696533, -0.4382648468017578, 0.12304496765136719, -0.5732383728027344, -0.9078545570373535, -2.3735134601593018, 0.018535614013671875, -1.226724624633789, -2.0495986938476562, 2.695619583129883, 0.3350639343261719, 1.0898990631103516, -0.41370296478271484, -0.97882080078125, 0.10103893280029297, 0.1927814483642578, 0.07996559143066406, -0.8243434429168701, -8.024789810180664, -0.4649953842163086, -0.1288604736328125, -1.662588119506836, -2.8722219467163086, -1.2729215621948242, -1.1654601097106934, 0.7941598892211914, -0.03419017791748047, 1.4913063049316406, -1.6179656982421875, 0.7495448589324951, -0.4400715231895447, 3.3528289794921875, 0.08054542541503906, -4.925408363342285, -6.774839878082275, 1.0442333221435547, -0.34038543701171875, -1.2772579193115234, 0.5805530548095703, 0.7811508178710938, -0.514404296875, 1.6226050853729248, -0.8416638374328613, -0.2173480987548828, -0.02029132843017578, 6.79838228225708, 1.3693389892578125, -1.0634336471557617, 1.2910895347595215, -0.137637197971344, -6.259906768798828, -0.6545133590698242, -2.003403425216675, -1.9064655303955078, -0.6006202697753906, -0.7002582550048828, -0.9676830768585205, -0.4302024841308594, -1.1781816482543945, -1.1883392333984375, 0.7811508178710938], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 79872, "num_env_steps_trained": 147960, "num_agent_steps_sampled": 79872, "num_agent_steps_trained": 147960, "last_target_update_ts": 79872, "num_target_updates": 155}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -81.38954727753998, "episode_len_mean": 256.36, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235], "episode_lengths": [427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.514290457489943, "mean_inference_ms": 24.708590615699407, "mean_action_processing_ms": 0.135216594362974, "mean_env_wait_ms": 4.159685553183685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -81.38954727753998, "episode_len_mean": 256.36, "episodes_this_iter": 5, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-629.2699145376682, -176.19774302840233, 12.41063541918993, -20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235], "episode_lengths": [427, 320, 198, 247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.514290457489943, "mean_inference_ms": 24.708590615699407, "mean_action_processing_ms": 0.135216594362974, "mean_env_wait_ms": 4.159685553183685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 79872, "num_agent_steps_trained": 147960, "num_env_steps_sampled": 79872, "num_env_steps_trained": 147960, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 79872, "agent_timesteps_total": 79872, "timers": {"training_iteration_time_ms": 319.905, "learn_time_ms": 70.025, "learn_throughput": 1713.679, "synch_weights_time_ms": 21.089}, "counters": {"num_env_steps_sampled": 79872, "num_env_steps_trained": 147960, "num_agent_steps_sampled": 79872, "num_agent_steps_trained": 147960, "last_target_update_ts": 79872, "num_target_updates": 155}, "done": false, "episodes_total": 255, "training_iteration": 78, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-28", "timestamp": 1655476288, "time_this_iter_s": 5.255648136138916, "time_total_s": 390.7054953575134, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 390.7054953575134, "timesteps_since_restore": 0, "iterations_since_restore": 78, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.728571428571435, "ram_util_percent": 63.67142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 4.5873332023620605, "min_q": -89.82559967041016, "max_q": 30.186302185058594, "mean_td_error": 0.34491702914237976}, "td_error": [0.18625158071517944, 0.7777805328369141, -0.37080860137939453, 0.0754852294921875, -0.14195775985717773, 1.2227783203125, 0.5134067535400391, 0.7381415367126465, -0.0681142807006836, 0.3885316848754883, 0.7251852750778198, -1.7176458835601807, 1.8911457061767578, -0.13553333282470703, 0.7608671188354492, -0.17206573486328125, -5.759843826293945, 0.16847562789916992, 0.7107219696044922, 1.1003646850585938, 0.2482776641845703, 0.9998127222061157, 1.0737274885177612, 1.0956916809082031, 16.1633243560791, -0.7306818962097168, 0.3542194366455078, 1.37172269821167, 0.2378101348876953, 2.0947866439819336, -0.6379318237304688, -0.08564376831054688, -0.6652648448944092, 0.7369537353515625, 0.28635501861572266, 0.6272430419921875, 0.04961204528808594, 3.665538787841797, -0.49686574935913086, -1.0492057800292969, 0.49802589416503906, -0.02178478240966797, 0.9595651626586914, 0.7381415367126465, 1.956964135169983, 0.548248291015625, 0.2826347351074219, 0.9510359764099121, 1.4283556938171387, 0.5602502822875977, 0.5053825378417969, -0.04479217529296875, 0.6835479736328125, -0.5840177536010742, -0.106658935546875, 0.27541065216064453, 0.4626932144165039, 0.7825374603271484, 0.49802589416503906, 1.2193603515625, 0.7260532379150391, 0.567746639251709, -0.29124975204467773, 0.5519828796386719, 0.46527862548828125, 0.26717090606689453, 0.5108642578125, 1.0297374725341797, 0.08655834197998047, 1.191904067993164, -0.20065832138061523, -0.04341554641723633, 1.4295806884765625, 1.7013955116271973, 0.9266672134399414, -2.8704073429107666, -9.67068099975586, -6.537355422973633, -0.37744712829589844, 0.7206048965454102, 0.8039264678955078, 0.3509368896484375, 2.3825531005859375, -1.89239501953125, 3.2834036350250244, 0.4013023376464844, 0.5602502822875977, -0.24101734161376953, 0.4747486114501953, 1.120351791381836, 0.46872901916503906, 0.5796451568603516, 0.20015335083007812, -1.2028968334197998, -0.22847938537597656, 1.6845388412475586, -0.4405021667480469, 0.39853954315185547, 0.5397834777832031, -0.1320173740386963, 0.045165061950683594, 0.29967451095581055, 0.9881820678710938, -0.21466410160064697, -1.5599641799926758, 1.308194637298584, 0.18532180786132812, 1.704787254333496, 2.6928253173828125, -0.09845352172851562, -15.645263671875, -1.5470390319824219, -0.8775362968444824, 7.028682708740234, 8.29658031463623, 0.4381065368652344, 0.955718994140625, 0.042632102966308594, 0.7364139556884766, -0.5107812881469727], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 80896, "num_env_steps_trained": 149880, "num_agent_steps_sampled": 80896, "num_agent_steps_trained": 149880, "last_target_update_ts": 80896, "num_target_updates": 157}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -81.2001341547072, "episode_len_mean": 256.04, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383], "episode_lengths": [247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5150880161345983, "mean_inference_ms": 24.72463840899252, "mean_action_processing_ms": 0.13519955670580233, "mean_env_wait_ms": 4.164910099601513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -81.2001341547072, "episode_len_mean": 256.04, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-20.499999962747097, -72.10957659780979, 3.1000000536441803, -136.00880306214094, -43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383], "episode_lengths": [247, 267, 178, 274, 203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5150880161345983, "mean_inference_ms": 24.72463840899252, "mean_action_processing_ms": 0.13519955670580233, "mean_env_wait_ms": 4.164910099601513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 80896, "num_agent_steps_trained": 149880, "num_env_steps_sampled": 80896, "num_env_steps_trained": 149880, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 80896, "agent_timesteps_total": 80896, "timers": {"training_iteration_time_ms": 329.033, "learn_time_ms": 68.663, "learn_throughput": 1747.678, "synch_weights_time_ms": 20.888}, "counters": {"num_env_steps_sampled": 80896, "num_env_steps_trained": 149880, "num_agent_steps_sampled": 80896, "num_agent_steps_trained": 149880, "last_target_update_ts": 80896, "num_target_updates": 157}, "done": false, "episodes_total": 258, "training_iteration": 79, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-34", "timestamp": 1655476294, "time_this_iter_s": 5.268919229507446, "time_total_s": 395.9744145870209, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 395.9744145870209, "timesteps_since_restore": 0, "iterations_since_restore": 79, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.887499999999996, "ram_util_percent": 63.6875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.9557982087135315, "min_q": -90.10826873779297, "max_q": 26.95237922668457, "mean_td_error": -0.12157335877418518}, "td_error": [0.5431041717529297, 0.7521266937255859, -0.4008145332336426, -6.94635009765625, -0.6164722442626953, -1.1838464736938477, -0.2001180648803711, 0.021005630493164062, -0.5252494812011719, -6.256412506103516, -0.21081876754760742, -0.5462121963500977, -0.7926206588745117, 1.0438737869262695, 4.3860321044921875, 3.0051193237304688, -1.788522720336914, 0.1351337432861328, -0.565887451171875, 0.3522663116455078, -5.363968849182129, -0.24922943115234375, -0.46251678466796875, -0.35243165493011475, -0.3267364501953125, 0.02384662628173828, -1.9700660705566406, 1.1960945129394531, 0.18447113037109375, -0.39731332659721375, -1.2357356548309326, 0.3715381622314453, -0.5549368858337402, 0.18611526489257812, 1.0492668151855469, -0.7574105262756348, -0.3827381134033203, 0.07790565490722656, -0.140899658203125, -0.20729827880859375, -3.7015914916992188, 0.5074672698974609, -5.262248992919922, 0.21960854530334473, 0.7689533233642578, -0.22347551584243774, 1.885411262512207, -0.1952202320098877, -3.214996337890625, 0.08293771743774414, 3.009675979614258, -0.37508106231689453, 0.6677532196044922, 0.6970252990722656, 1.0845699310302734, 0.298919677734375, 0.8849780559539795, 0.24888145923614502, 0.7767257690429688, -0.4481163024902344, 1.26019287109375, 1.416947841644287, 0.6714572906494141, -5.780523300170898, 0.5175285339355469, 3.535799980163574, -4.771060943603516, -0.4075126647949219, 1.2108831405639648, 3.690593719482422, -0.25241661071777344, 2.0427141189575195, 0.5079154968261719, 0.5942058563232422, -7.198973178863525, 15.17905044555664, 0.5074672698974609, 4.7461113929748535, -2.7987656593322754, 0.3872661590576172, -0.03730487823486328, 3.092256546020508, 0.13149261474609375, -0.14587652683258057, 0.7406387329101562, 5.1821441650390625, 0.04462432861328125, -0.11109495162963867, 0.45853137969970703, 0.4223308563232422, -0.6164722442626953, -0.2920045852661133, 0.02198314666748047, -6.638795852661133, -0.061923980712890625, -6.744264602661133, 0.1266021728515625, 4.670480728149414, 0.14648771286010742, -0.4059009552001953, -1.0044193267822266, -6.304538726806641, -0.34566593170166016, 0.43456268310546875, -0.8244638442993164, 0.26796579360961914, 0.40722084045410156, 0.09042072296142578, 0.13713455200195312, 1.754791259765625, 4.341365814208984, 0.9557056427001953, -4.209019184112549, -0.570941686630249, 0.5981206893920898, -5.846233367919922, 0.256134033203125, 0.14244937896728516, 0.7755947113037109, 0.70672607421875], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 81920, "num_env_steps_trained": 151800, "num_agent_steps_sampled": 81920, "num_agent_steps_trained": 151800, "last_target_update_ts": 81920, "num_target_updates": 159}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -88.08588225863873, "episode_len_mean": 257.83, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161], "episode_lengths": [203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5155499888925101, "mean_inference_ms": 24.746691163240257, "mean_action_processing_ms": 0.1351049774350024, "mean_env_wait_ms": 4.169606597430513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -88.08588225863873, "episode_len_mean": 257.83, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-43.5999998152256, -172.24156760424376, -117.35617545992136, 12.913220070302486, -842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161], "episode_lengths": [203, 297, 284, 230, 450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5155499888925101, "mean_inference_ms": 24.746691163240257, "mean_action_processing_ms": 0.1351049774350024, "mean_env_wait_ms": 4.169606597430513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 81920, "num_agent_steps_trained": 151800, "num_env_steps_sampled": 81920, "num_env_steps_trained": 151800, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 81920, "agent_timesteps_total": 81920, "timers": {"training_iteration_time_ms": 329.798, "learn_time_ms": 68.224, "learn_throughput": 1758.909, "synch_weights_time_ms": 20.688}, "counters": {"num_env_steps_sampled": 81920, "num_env_steps_trained": 151800, "num_agent_steps_sampled": 81920, "num_agent_steps_trained": 151800, "last_target_update_ts": 81920, "num_target_updates": 159}, "done": false, "episodes_total": 262, "training_iteration": 80, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-39", "timestamp": 1655476299, "time_this_iter_s": 5.329006195068359, "time_total_s": 401.30342078208923, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 401.30342078208923, "timesteps_since_restore": 0, "iterations_since_restore": 80, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.5625, "ram_util_percent": 63.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.816481113433838, "min_q": -72.7510757446289, "max_q": 31.800500869750977, "mean_td_error": -0.14202922582626343}, "td_error": [-5.736571788787842, -0.7563130855560303, 0.08414077758789062, 4.757852554321289, 1.3291702270507812, 0.4428062438964844, -0.7680482864379883, 2.2443971633911133, 4.501609802246094, -1.097224235534668, 0.7095108032226562, -0.03796958923339844, -1.0690135955810547, 0.6056451797485352, 2.363872528076172, -0.3845341205596924, 1.0199966430664062, 0.945704460144043, 0.41033935546875, 0.03798103332519531, -0.30608534812927246, -0.5988197326660156, 1.6106605529785156, -1.0570182800292969, -0.111663818359375, -10.73039436340332, 0.7205982208251953, -5.769601821899414, 0.04260063171386719, -1.0361757278442383, -18.519325256347656, -0.016254425048828125, 1.3611440658569336, -0.7129783630371094, 0.18210315704345703, -1.0003314018249512, 0.6657218933105469, -13.318169593811035, 0.5488708019256592, 0.15002727508544922, -0.15546607971191406, -0.46910667419433594, 1.025556206703186, -1.3536138534545898, -0.7382259368896484, -0.6336259841918945, 0.4664039611816406, -0.008358001708984375, 1.0077438354492188, 0.37177276611328125, -0.06139850616455078, -2.0781946182250977, 0.0975797176361084, -1.7929229736328125, 0.39896678924560547, 0.5581398010253906, -0.4129161834716797, 0.5225958824157715, -1.6766128540039062, -0.7460117340087891, 5.624177932739258, 0.08446311950683594, -0.042862892150878906, 3.333317756652832, -0.8555095195770264, 2.6845932006835938, -0.2537059783935547, -0.39511537551879883, 7.261775493621826, 0.5133819580078125, 0.012754440307617188, -1.0460796356201172, 1.493459701538086, 0.2004222869873047, -7.107242584228516, -0.3820314407348633, 0.26249027252197266, -1.5276126861572266, 14.105796813964844, 0.3817138671875, 1.4618654251098633, 4.911279678344727, -0.6743297576904297, -1.1818437576293945, 0.44233036041259766, 0.7820549011230469, -0.45324134826660156, 0.8413009643554688, 0.23190593719482422, 0.05172586441040039, 0.08613014221191406, 0.48476696014404297, 0.13599586486816406, -0.155853271484375, -0.12658309936523438, -0.15361404418945312, 0.11316871643066406, -1.1149921417236328, -0.40955209732055664, 0.043079376220703125, 0.024402618408203125, -0.3917694091796875, 0.2561206817626953, -0.3504800796508789, 0.6132087707519531, 0.11522865295410156, -0.22661972045898438, -0.3445453643798828, 0.8121433258056641, -1.5664820671081543, 0.4731297492980957, -2.17899751663208, -0.23453712463378906, 1.5096893310546875, -2.594747543334961, -0.4438290596008301, 0.05669975280761719, 0.07489967346191406, 1.7636528015136719, -0.10502052307128906], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 82944, "num_env_steps_trained": 153720, "num_agent_steps_sampled": 82944, "num_agent_steps_trained": 153720, "last_target_update_ts": 82944, "num_target_updates": 161}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -95.64847960270941, "episode_len_mean": 259.61, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304], "episode_lengths": [450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.516469437474901, "mean_inference_ms": 24.7326808758269, "mean_action_processing_ms": 0.13512797509342955, "mean_env_wait_ms": 4.1714193005086715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -95.64847960270941, "episode_len_mean": 259.61, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-842.9557582736015, -18.77475666999817, -56.85617547482252, 10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304], "episode_lengths": [450, 258, 231, 188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.516469437474901, "mean_inference_ms": 24.7326808758269, "mean_action_processing_ms": 0.13512797509342955, "mean_env_wait_ms": 4.1714193005086715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 82944, "num_agent_steps_trained": 153720, "num_env_steps_sampled": 82944, "num_env_steps_trained": 153720, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 82944, "agent_timesteps_total": 82944, "timers": {"training_iteration_time_ms": 324.482, "learn_time_ms": 70.57, "learn_throughput": 1700.437, "synch_weights_time_ms": 20.487}, "counters": {"num_env_steps_sampled": 82944, "num_env_steps_trained": 153720, "num_agent_steps_sampled": 82944, "num_agent_steps_trained": 153720, "last_target_update_ts": 82944, "num_target_updates": 161}, "done": false, "episodes_total": 266, "training_iteration": 81, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-45", "timestamp": 1655476305, "time_this_iter_s": 5.284250259399414, "time_total_s": 406.58767104148865, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 406.58767104148865, "timesteps_since_restore": 0, "iterations_since_restore": 81, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.650000000000006, "ram_util_percent": 63.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.90118408203125, "min_q": -89.9247817993164, "max_q": 28.668581008911133, "mean_td_error": -0.10114552080631256}, "td_error": [0.1457977294921875, -1.055227279663086, 2.29022216796875, -6.009831428527832, 3.574540376663208, 5.256757736206055, -0.15740966796875, 0.3898916244506836, 0.035858154296875, -0.16624164581298828, -0.5785179138183594, -0.4040565490722656, 0.7858848571777344, 0.562138557434082, 1.2343864440917969, 0.11181449890136719, 0.12449359893798828, 1.8604717254638672, -0.2816276550292969, -0.525787353515625, -0.6220664978027344, 7.406553268432617, -1.2309293746948242, 0.45941781997680664, 0.5037651062011719, 0.21062278747558594, -0.11983895301818848, 0.5800657272338867, 2.064605712890625, -0.11179518699645996, 6.17291259765625, 0.2311573028564453, 0.9386489391326904, -0.4811592102050781, -1.1005439758300781, -0.3991798162460327, 1.019195556640625, 1.6156930923461914, 0.6608200073242188, -3.9702489376068115, 0.3739347457885742, -1.492380142211914, -0.4364461898803711, -5.578540325164795, 0.57183837890625, -11.781810760498047, 0.8032560348510742, -4.0975542068481445, -0.7589874267578125, 0.3436131477355957, -0.41320228576660156, 0.23720741271972656, -1.3108062744140625, -0.2210378646850586, 19.771743774414062, -1.6373767852783203, 0.7858848571777344, -0.42120361328125, 0.9440999031066895, 1.556549072265625, -0.532905101776123, 1.4183349609375, -0.3805255889892578, 0.4203147888183594, -0.11185073852539062, -26.893287658691406, -0.9935302734375, -0.22889089584350586, 0.14405250549316406, -0.11653280258178711, -1.1064186096191406, -0.7891254425048828, -0.121368408203125, 1.7317728996276855, 0.5160865783691406, 0.24769246578216553, 1.4407405853271484, 0.23908329010009766, -0.22048330307006836, 2.414340019226074, 0.18331527709960938, 0.3048896789550781, 8.656624794006348, -9.759035110473633, -0.5397968292236328, -1.1792802810668945, -0.24086570739746094, 1.3027782440185547, -1.173248291015625, 0.7827968597412109, 0.4140205383300781, -0.5055742263793945, 2.0802464485168457, -7.045564651489258, -0.674713134765625, -0.5911421775817871, -0.8435497283935547, 1.1219139099121094, -0.9073772430419922, -0.06051921844482422, 0.22491073608398438, -0.7263803482055664, 2.288501739501953, 6.508240699768066, -0.9482479095458984, -0.8454093933105469, 0.41211938858032227, -0.6916790008544922, -0.17453765869140625, -4.906569004058838, 1.3546028137207031, 1.2586753368377686, -0.5000247955322266, -2.347135066986084, 0.31436920166015625, 0.5953083038330078, -0.3707270622253418, 0.2638356685638428, -0.08944129943847656, -0.4213294982910156], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 83968, "num_env_steps_trained": 155640, "num_agent_steps_sampled": 83968, "num_agent_steps_trained": 155640, "last_target_update_ts": 83968, "num_target_updates": 163}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -95.00908418148757, "episode_len_mean": 259.56, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782], "episode_lengths": [188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176705409750275, "mean_inference_ms": 24.741911154530108, "mean_action_processing_ms": 0.13545948932585603, "mean_env_wait_ms": 4.178521930405964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -872.4867796897888, "episode_reward_mean": -95.00908418148757, "episode_len_mean": 259.56, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [10.371612168848515, -41.09999991953373, 24.038616441190243, -872.4867796897888, 18.93894934654236, 3.8393149450421333, -88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782], "episode_lengths": [188, 231, 237, 450, 233, 233, 251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5176705409750275, "mean_inference_ms": 24.741911154530108, "mean_action_processing_ms": 0.13545948932585603, "mean_env_wait_ms": 4.178521930405964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 83968, "num_agent_steps_trained": 155640, "num_env_steps_sampled": 83968, "num_env_steps_trained": 155640, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 83968, "agent_timesteps_total": 83968, "timers": {"training_iteration_time_ms": 322.02, "learn_time_ms": 69.342, "learn_throughput": 1730.564, "synch_weights_time_ms": 20.785}, "counters": {"num_env_steps_sampled": 83968, "num_env_steps_trained": 155640, "num_agent_steps_sampled": 83968, "num_agent_steps_trained": 155640, "last_target_update_ts": 83968, "num_target_updates": 163}, "done": false, "episodes_total": 269, "training_iteration": 82, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-50", "timestamp": 1655476310, "time_this_iter_s": 5.119296312332153, "time_total_s": 411.7069673538208, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 411.7069673538208, "timesteps_since_restore": 0, "iterations_since_restore": 82, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.55714285714286, "ram_util_percent": 63.71428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -2.8311877250671387, "min_q": -90.35659790039062, "max_q": 26.781190872192383, "mean_td_error": -0.7775682806968689}, "td_error": [1.060316562652588, -1.4388580322265625, -1.2859830856323242, 0.18077659606933594, -0.8236790895462036, 12.127998352050781, 0.5503807067871094, -3.2768893241882324, -13.160679817199707, -3.1098480224609375, -2.953298568725586, -0.2113335132598877, -0.036490440368652344, -0.9856300354003906, -1.8203668594360352, 0.34255170822143555, -2.1129584312438965, 0.21749114990234375, -0.011816978454589844, -0.038311004638671875, 2.404465675354004, 1.7166485786437988, -12.933537483215332, -1.7570806741714478, 0.1298847198486328, -0.32378411293029785, -2.937744140625, 0.029233932495117188, -0.4317154884338379, 2.097195625305176, -3.3747291564941406, 0.21943044662475586, -2.4881935119628906, 0.025429725646972656, 0.4387702941894531, -0.3682708740234375, -0.15396881103515625, -9.479846954345703, 0.06364917755126953, 0.6252179145812988, 0.05536937713623047, -2.961305618286133, -1.237534523010254, 0.4689674377441406, -18.405179977416992, -2.787506103515625, -0.5817670822143555, -1.5886249542236328, -0.7837562561035156, -0.7132463455200195, -3.0259170532226562, 0.2006549835205078, -0.19387054443359375, -0.23459434509277344, 0.6647586822509766, 0.49106788635253906, -6.7020673751831055, 0.6568336486816406, -0.7896907329559326, -3.5851898193359375, 0.8052692413330078, 0.37505435943603516, -0.39217567443847656, -3.8913707733154297, -6.95469856262207, 0.8551056385040283, -0.5201377868652344, 0.4078655242919922, 0.6456022262573242, -0.6206150054931641, 0.3080778121948242, 0.32451772689819336, 1.3785476684570312, 0.33341360092163086, 0.5503807067871094, -0.1670665740966797, 2.404465675354004, -0.28426551818847656, 0.2521853446960449, -1.5779190063476562, 0.7461032867431641, -0.11661529541015625, -3.0259170532226562, -0.17658424377441406, 0.8947229385375977, -0.1456160545349121, 0.051550865173339844, 0.7396445274353027, 0.10952377319335938, 0.610931396484375, 0.29135704040527344, 0.9316422939300537, 0.20835304260253906, -0.6217641830444336, -0.7626667022705078, -0.7509043216705322, 0.0738687515258789, -0.39217567443847656, 1.865309715270996, -0.6724004745483398, -0.361053466796875, 0.8083286285400391, 9.455196380615234, -0.33950138092041016, 0.5158100128173828, -3.3607425689697266, -0.3877875804901123, -6.175670623779297, 1.7045302391052246, -1.4146270751953125, 0.30941009521484375, -5.591426849365234, 0.17963218688964844, -0.9991570711135864, 0.2305159568786621, -0.8769073486328125, 0.29046154022216797, -0.04545783996582031, -0.40810394287109375, 3.4059224128723145], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 84992, "num_env_steps_trained": 157560, "num_agent_steps_sampled": 84992, "num_agent_steps_trained": 157560, "last_target_update_ts": 84992, "num_target_updates": 165}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -859.2712689936161, "episode_reward_mean": -92.41865885742008, "episode_len_mean": 259.07, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602], "episode_lengths": [251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5181825681017063, "mean_inference_ms": 24.75008607578131, "mean_action_processing_ms": 0.13501444713489894, "mean_env_wait_ms": 4.183146699466663, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -859.2712689936161, "episode_reward_mean": -92.41865885742008, "episode_len_mean": 259.07, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-88.67078398168087, -77.47217133641243, -11.24521991610527, 4.3246834725141525, -170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602], "episode_lengths": [251, 275, 254, 215, 306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5181825681017063, "mean_inference_ms": 24.75008607578131, "mean_action_processing_ms": 0.13501444713489894, "mean_env_wait_ms": 4.183146699466663, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 84992, "num_agent_steps_trained": 157560, "num_env_steps_sampled": 84992, "num_env_steps_trained": 157560, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 84992, "agent_timesteps_total": 84992, "timers": {"training_iteration_time_ms": 329.248, "learn_time_ms": 69.098, "learn_throughput": 1736.671, "synch_weights_time_ms": 20.664}, "counters": {"num_env_steps_sampled": 84992, "num_env_steps_trained": 157560, "num_agent_steps_sampled": 84992, "num_agent_steps_trained": 157560, "last_target_update_ts": 84992, "num_target_updates": 165}, "done": false, "episodes_total": 275, "training_iteration": 83, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-31-55", "timestamp": 1655476315, "time_this_iter_s": 5.266840934753418, "time_total_s": 416.9738082885742, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 416.9738082885742, "timesteps_since_restore": 0, "iterations_since_restore": 83, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 31.312500000000004, "ram_util_percent": 63.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.5222308039665222, "min_q": -88.08129119873047, "max_q": 29.961641311645508, "mean_td_error": -0.14498426020145416}, "td_error": [0.0446624755859375, 1.0586719512939453, -2.32319712638855, 1.8957977294921875, -0.5471277236938477, -0.6035566329956055, 0.4154500961303711, 1.08626127243042, -0.7452535629272461, -1.8557872772216797, -0.7375268936157227, 1.0875091552734375, 0.3353567123413086, -0.6606197357177734, 1.8136730194091797, 1.7978324890136719, -0.6559557914733887, -0.34505653381347656, 0.9321365356445312, 1.4804039001464844, 0.8408708572387695, 0.3434467315673828, -2.1651792526245117, 7.031283855438232, -0.43573808670043945, -0.1188497543334961, 0.2880401611328125, 0.024193763732910156, -0.14402389526367188, -3.2876663208007812, -0.05374908447265625, 0.19623088836669922, -0.057117462158203125, 0.45578908920288086, 0.04883575439453125, 0.6289730072021484, -1.5839118957519531, -0.4226665496826172, 3.143024444580078, 0.1769256591796875, 0.1038351058959961, -1.6719112396240234, 0.25932395458221436, -2.082636833190918, -6.055133819580078, -0.8853340148925781, 0.15205097198486328, 0.175797700881958, 4.300512313842773, -1.5647225379943848, 0.7580571174621582, -0.7177505493164062, -0.12860107421875, -0.7931537628173828, 0.03431439399719238, -0.5508241653442383, 1.3963899612426758, -0.8408699035644531, -1.041609525680542, 0.12048721313476562, -1.7553777694702148, 1.6481499671936035, 0.16789817810058594, -2.716642379760742, 0.5339443683624268, 1.0089340209960938, 0.8795723915100098, -0.7909946441650391, -1.2876052856445312, -0.655303955078125, -0.2120668888092041, 0.246002197265625, 0.9601349830627441, 2.2515363693237305, -1.0262956619262695, -0.07074928283691406, -0.7125911712646484, -0.16057968139648438, 0.03674888610839844, -7.771413803100586, 1.0924925804138184, 0.9321365356445312, 0.2169189453125, -0.0008196830749511719, 0.09177017211914062, -1.1026573181152344, -0.4552898406982422, -0.3408021926879883, -0.01032257080078125, 11.455846786499023, 0.5339443683624268, -0.05744171142578125, 0.9125139713287354, 0.306884765625, 0.07603931427001953, 0.45578908920288086, -0.1508922576904297, 0.014739036560058594, 0.15892791748046875, -0.03676891326904297, 0.034820556640625, 1.140893578529358, 1.1334705352783203, -1.546940803527832, -0.9899444580078125, 0.10170841217041016, -0.2404632568359375, -1.1935482025146484, -0.42014503479003906, -2.2703170776367188, -2.0617799758911133, -2.345123291015625, -0.06120491027832031, -2.3246326446533203, 0.39903736114501953, -0.49981117248535156, -0.6336202621459961, -12.888874053955078, 4.1421051025390625, -0.890660285949707], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 86016, "num_env_steps_trained": 159480, "num_agent_steps_sampled": 86016, "num_agent_steps_trained": 159480, "last_target_update_ts": 86016, "num_target_updates": 167}, "sampler_results": {"episode_reward_max": 43.46222202479839, "episode_reward_min": -859.2712689936161, "episode_reward_mean": -91.1146891925484, "episode_len_mean": 258.48, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778], "episode_lengths": [306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5191688972990147, "mean_inference_ms": 24.754760797098346, "mean_action_processing_ms": 0.13524923454021884, "mean_env_wait_ms": 4.185945310486938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 43.46222202479839, "episode_reward_min": -859.2712689936161, "episode_reward_mean": -91.1146891925484, "episode_len_mean": 258.48, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-170.1238448768854, 43.46222202479839, -181.26809951663017, -109.53075305372477, -44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778], "episode_lengths": [306, 226, 297, 263, 254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5191688972990147, "mean_inference_ms": 24.754760797098346, "mean_action_processing_ms": 0.13524923454021884, "mean_env_wait_ms": 4.185945310486938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 86016, "num_agent_steps_trained": 159480, "num_env_steps_sampled": 86016, "num_env_steps_trained": 159480, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 86016, "agent_timesteps_total": 86016, "timers": {"training_iteration_time_ms": 316.556, "learn_time_ms": 70.068, "learn_throughput": 1712.613, "synch_weights_time_ms": 20.495}, "counters": {"num_env_steps_sampled": 86016, "num_env_steps_trained": 159480, "num_agent_steps_sampled": 86016, "num_agent_steps_trained": 159480, "last_target_update_ts": 86016, "num_target_updates": 167}, "done": false, "episodes_total": 279, "training_iteration": 84, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-00", "timestamp": 1655476320, "time_this_iter_s": 5.036985397338867, "time_total_s": 422.0107936859131, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 422.0107936859131, "timesteps_since_restore": 0, "iterations_since_restore": 84, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.51428571428571, "ram_util_percent": 63.642857142857146}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -3.6667401790618896, "min_q": -79.14614868164062, "max_q": 29.35179901123047, "mean_td_error": -0.06636721640825272}, "td_error": [0.6719776391983032, 0.44635581970214844, 0.12694168090820312, -0.1484813690185547, -0.46889781951904297, 7.97866153717041, -0.6132755279541016, -0.863555908203125, -1.0925827026367188, -35.27643966674805, 0.44759178161621094, -0.7282619476318359, 0.2409801483154297, 5.664638519287109, 1.8651847839355469, -2.0441818237304688, 0.29466819763183594, 0.5131416320800781, -0.33343982696533203, -0.6722478866577148, 0.7519645690917969, 0.10434722900390625, 0.5194282531738281, 0.5403294563293457, 1.5327949523925781, 0.4501457214355469, 0.3310394287109375, 2.6587705612182617, -0.7814817428588867, 0.3857612609863281, 0.7026252746582031, 1.051666259765625, -1.0075111389160156, 0.027833938598632812, 0.9266409873962402, -0.10689640045166016, 0.20947265625, -1.3763961791992188, 1.4425239562988281, 0.2934598922729492, 0.7883319854736328, 0.55511474609375, 0.055648863315582275, 0.9050683975219727, 0.297945499420166, 0.015367507934570312, -7.273870944976807, 0.42636585235595703, 14.683937072753906, 0.5137176513671875, 1.0559463500976562, 0.13115692138671875, 0.09385490417480469, -0.24044132232666016, 0.8352681398391724, 0.6283645629882812, -0.12302780151367188, 2.5558319091796875, -0.3213520050048828, 6.877154350280762, -1.4879264831542969, 1.4775581359863281, -6.326455116271973, 0.3007044792175293, 0.8283963203430176, -0.6623640060424805, 1.0977258682250977, -0.45171356201171875, 0.4578282833099365, 1.0707931518554688, 0.26569557189941406, 0.15878868103027344, 0.49100542068481445, 0.4313068389892578, -35.27643966674805, 0.4214048385620117, -0.33197689056396484, 3.2108211517333984, 0.9232129454612732, 0.8439455032348633, -0.2570323944091797, 1.3906669616699219, 0.03846263885498047, 0.006777048110961914, -3.1033058166503906, 1.2188739776611328, 3.733835220336914, 1.1512384414672852, -1.9894485473632812, 0.4912528991699219, 0.11369514465332031, 0.8782081604003906, -0.13792800903320312, 1.3906669616699219, -2.8430404663085938, -7.826193332672119, 0.939262866973877, 3.0555458068847656, 2.0008583068847656, -0.4366607666015625, 0.22413063049316406, 0.4903409481048584, -0.9217414855957031, 0.6214523315429688, 2.6518936157226562, -0.09407711029052734, 0.05935096740722656, 20.488079071044922, 0.36719417572021484, 0.6206321716308594, -0.14090251922607422, -3.76611328125, -0.6168899536132812, -0.6655368804931641, -0.043529510498046875, -0.8513603210449219, 0.6214523315429688, 0.10046768188476562, -1.1913833618164062, -0.30124950408935547], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 87040, "num_env_steps_trained": 161400, "num_agent_steps_sampled": 87040, "num_agent_steps_trained": 161400, "last_target_update_ts": 87040, "num_target_updates": 169}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -95.37698883920908, "episode_len_mean": 259.01, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593], "episode_lengths": [254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5200180307378779, "mean_inference_ms": 24.76766148125214, "mean_action_processing_ms": 0.13519368385507238, "mean_env_wait_ms": 4.1934762042808, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -95.37698883920908, "episode_len_mean": 259.01, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-44.37475647777319, 4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593], "episode_lengths": [254, 242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5200180307378779, "mean_inference_ms": 24.76766148125214, "mean_action_processing_ms": 0.13519368385507238, "mean_env_wait_ms": 4.1934762042808, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 87040, "num_agent_steps_trained": 161400, "num_env_steps_sampled": 87040, "num_env_steps_trained": 161400, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 87040, "agent_timesteps_total": 87040, "timers": {"training_iteration_time_ms": 318.106, "learn_time_ms": 69.027, "learn_throughput": 1738.45, "synch_weights_time_ms": 20.789}, "counters": {"num_env_steps_sampled": 87040, "num_env_steps_trained": 161400, "num_agent_steps_sampled": 87040, "num_agent_steps_trained": 161400, "last_target_update_ts": 87040, "num_target_updates": 169}, "done": false, "episodes_total": 283, "training_iteration": 85, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-06", "timestamp": 1655476326, "time_this_iter_s": 5.200869798660278, "time_total_s": 427.21166348457336, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 427.21166348457336, "timesteps_since_restore": 0, "iterations_since_restore": 85, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.362500000000004, "ram_util_percent": 63.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.1952825784683228, "min_q": -91.16387939453125, "max_q": 28.105493545532227, "mean_td_error": -0.3418964445590973}, "td_error": [0.529973030090332, 0.2562990188598633, 0.57867431640625, 7.62939453125e-05, -1.6195911169052124, -1.2999305725097656, 0.5422992706298828, -1.198822021484375, 0.2562990188598633, 0.575897216796875, 0.6810379028320312, -5.011954307556152, -0.3176593780517578, 1.909886360168457, 0.987335205078125, 1.183957815170288, 0.3969097137451172, 0.3549041748046875, -0.45703792572021484, -0.7136287689208984, 0.5181198120117188, -0.5218477249145508, -0.6994705200195312, -1.1688880920410156, 0.3232383728027344, -0.7200469970703125, 0.2948131561279297, 2.731395721435547, 0.8421430587768555, 0.030858993530273438, -0.3046989440917969, -0.4463768005371094, 0.3156561851501465, 0.3567047119140625, -0.18529796600341797, -1.198822021484375, -0.41962766647338867, -0.4972515106201172, 0.6745567321777344, -0.9751651287078857, 0.1441192626953125, -0.5506129264831543, -1.7900619506835938, 0.7117347717285156, -0.48539257049560547, -0.4645404815673828, -0.5288572311401367, -6.744113922119141, -1.1590538024902344, -0.26168060302734375, 1.0357284545898438, 0.11934852600097656, -0.22567367553710938, 0.025503158569335938, -0.15291404724121094, -0.3032493591308594, -0.8000917434692383, 0.7556858062744141, 0.10652542114257812, -1.6369438171386719, -0.12406635284423828, -0.3007962703704834, 1.7636127471923828, 0.4442129135131836, 0.03558158874511719, 0.7827348709106445, 0.40224456787109375, 6.824784755706787, -0.9477510452270508, 0.08141422271728516, -0.051166534423828125, 0.10372352600097656, 0.7368812561035156, 0.25321006774902344, -0.5550384521484375, 0.14653682708740234, -1.0038986206054688, 0.006890296936035156, -0.18419647216796875, -0.72998046875, 1.1495041847229004, 0.08263778686523438, -0.08286571502685547, -1.236713171005249, 0.731144905090332, -0.06531667709350586, -1.3690071105957031, -0.07610702514648438, -5.174100399017334, 18.94063949584961, 0.44985198974609375, -0.41550731658935547, -0.6707954406738281, -0.36506080627441406, 0.1946430206298828, 0.16584396362304688, -0.05670928955078125, 0.06060791015625, -0.7136287689208984, -20.84218978881836, -0.3610076904296875, -16.102519989013672, -0.17206096649169922, -1.445220947265625, 0.4511394500732422, -2.0970077514648438, -0.19157886505126953, -0.46895790100097656, 0.18445587158203125, -1.0882797241210938, -0.5684270858764648, -0.7774076461791992, 0.5216710567474365, -1.7023439407348633, 7.375188827514648, 0.6600446701049805, 0.06379032135009766, 0.06696796417236328, -1.069045066833496, -7.079155445098877], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 88064, "num_env_steps_trained": 163320, "num_agent_steps_sampled": 88064, "num_agent_steps_trained": 163320, "last_target_update_ts": 88064, "num_target_updates": 171}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -94.70436345212161, "episode_len_mean": 258.67, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244], "episode_lengths": [242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5203876522033252, "mean_inference_ms": 24.767393000977727, "mean_action_processing_ms": 0.13535040605513493, "mean_env_wait_ms": 4.194525741569481, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -94.70436345212161, "episode_len_mean": 258.67, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [4.034773714840412, 18.464785754680634, 25.292027182877064, -411.32624658197165, 7.207755491137505, 5.41063541918993, -345.278571896255, 16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244], "episode_lengths": [242, 210, 234, 384, 244, 184, 333, 208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5203876522033252, "mean_inference_ms": 24.767393000977727, "mean_action_processing_ms": 0.13535040605513493, "mean_env_wait_ms": 4.194525741569481, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 88064, "num_agent_steps_trained": 163320, "num_env_steps_sampled": 88064, "num_env_steps_trained": 163320, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 88064, "agent_timesteps_total": 88064, "timers": {"training_iteration_time_ms": 320.292, "learn_time_ms": 69.82, "learn_throughput": 1718.709, "synch_weights_time_ms": 20.789}, "counters": {"num_env_steps_sampled": 88064, "num_env_steps_trained": 163320, "num_agent_steps_sampled": 88064, "num_agent_steps_trained": 163320, "last_target_update_ts": 88064, "num_target_updates": 171}, "done": false, "episodes_total": 284, "training_iteration": 86, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-11", "timestamp": 1655476331, "time_this_iter_s": 5.033629417419434, "time_total_s": 432.2452929019928, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 432.2452929019928, "timesteps_since_restore": 0, "iterations_since_restore": 86, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.22857142857143, "ram_util_percent": 63.68571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.2865631580352783, "min_q": -90.69059753417969, "max_q": 26.93356704711914, "mean_td_error": -0.3266892433166504}, "td_error": [0.18658733367919922, -0.6873672008514404, 0.2037672996520996, 0.7978725433349609, -0.3583488464355469, 0.6317520141601562, -8.029851913452148, 2.6988260746002197, 0.7784566879272461, -0.6386384963989258, 0.6355628967285156, 0.1701183319091797, 0.1713418960571289, 1.0796184539794922, -0.2719874382019043, 9.34017276763916, 0.9496536254882812, 0.5684719085693359, 0.7851982116699219, -1.2072315216064453, 2.70819091796875, 0.3043975830078125, 1.139439582824707, 0.14555644989013672, 0.6432633399963379, 2.6422042846679688, 0.14987945556640625, 0.7006077766418457, 0.35355567932128906, -0.4946708679199219, -0.14477157592773438, 0.031253814697265625, -0.33753204345703125, 0.8127670288085938, 1.1576099395751953, 0.5534791946411133, 0.656585693359375, -7.370204925537109, -3.9947681427001953, 0.11332511901855469, -2.577298164367676, 3.103178024291992, 0.6257095336914062, -0.5352268218994141, 0.16455459594726562, -62.563568115234375, -4.501677513122559, 0.2126903533935547, 0.49967193603515625, 0.9151675701141357, 0.9466934204101562, 0.09599566459655762, 4.020382881164551, -0.4374117851257324, -0.061901092529296875, -0.30933427810668945, 0.09260225296020508, -0.36249351501464844, -0.3179178237915039, 0.9762754440307617, -6.640506744384766, 0.3934907913208008, 0.4056377410888672, 0.2061748504638672, -0.29032373428344727, 0.5559988021850586, 0.12114906311035156, 0.7106876373291016, 1.1883049011230469, -2.1671886444091797, 0.5002329349517822, 2.213168144226074, 1.6336641311645508, 0.11791419982910156, 0.5959701538085938, -0.06404829025268555, 0.09618949890136719, -0.12671279907226562, 2.5952224731445312, -0.004025459289550781, -5.129626274108887, 0.016304969787597656, -0.32888269424438477, 1.0898933410644531, 0.862828254699707, 0.31556129455566406, 1.8522233963012695, 1.4521141052246094, 2.7550957202911377, 0.6832771301269531, 1.5645427703857422, 0.819267749786377, 0.6871731281280518, -0.9020366668701172, 0.5001926422119141, 0.6002650260925293, 0.3334364891052246, 0.618290901184082, 1.3665566444396973, 1.1369171142578125, -0.12293815612792969, -1.306182861328125, 0.043923377990722656, -0.28350067138671875, 1.9406585693359375, 3.7914962768554688, -0.4039773941040039, 0.22887277603149414, 1.5160980224609375, 0.7367830276489258, 1.3094873428344727, 0.23044395446777344, 0.17293930053710938, 2.6024246215820312, -0.08052968978881836, -1.5624198913574219, -0.8848972320556641, 0.1428070068359375, 0.14371299743652344, -7.312538146972656], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 89088, "num_env_steps_trained": 165240, "num_agent_steps_sampled": 89088, "num_agent_steps_trained": 165240, "last_target_update_ts": 89088, "num_target_updates": 173}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -93.05516922920943, "episode_len_mean": 257.65, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313], "episode_lengths": [208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5222609553340748, "mean_inference_ms": 24.78837114739778, "mean_action_processing_ms": 0.1351169366606687, "mean_env_wait_ms": 4.2068350920421835, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -93.05516922920943, "episode_len_mean": 257.65, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [16.610635548830032, -76.04121170192957, -71.08539178222418, -239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313], "episode_lengths": [208, 272, 225, 327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5222609553340748, "mean_inference_ms": 24.78837114739778, "mean_action_processing_ms": 0.1351169366606687, "mean_env_wait_ms": 4.2068350920421835, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 89088, "num_agent_steps_trained": 165240, "num_env_steps_sampled": 89088, "num_env_steps_trained": 165240, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 89088, "agent_timesteps_total": 89088, "timers": {"training_iteration_time_ms": 341.092, "learn_time_ms": 71.7, "learn_throughput": 1673.635, "synch_weights_time_ms": 21.304}, "counters": {"num_env_steps_sampled": 89088, "num_env_steps_trained": 165240, "num_agent_steps_sampled": 89088, "num_agent_steps_trained": 165240, "last_target_update_ts": 89088, "num_target_updates": 173}, "done": false, "episodes_total": 291, "training_iteration": 87, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-17", "timestamp": 1655476337, "time_this_iter_s": 5.327352523803711, "time_total_s": 437.5726454257965, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 437.5726454257965, "timesteps_since_restore": 0, "iterations_since_restore": 87, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 32.1625, "ram_util_percent": 63.712500000000006}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.6411564350128174, "min_q": -85.19096374511719, "max_q": 26.66864013671875, "mean_td_error": -0.13349682092666626}, "td_error": [-0.37619471549987793, 0.09525108337402344, 0.44501590728759766, 0.7561426162719727, 0.5627679824829102, -1.088083267211914, 0.9683704376220703, 0.28641462326049805, -0.4543781280517578, -0.23920536041259766, 0.060512542724609375, 0.11006927490234375, 1.1265134811401367, -0.7969779968261719, 0.5088157653808594, -3.544952392578125, 1.3066864013671875, 0.031620025634765625, -0.08824658393859863, -0.1411590576171875, -0.012800216674804688, 20.452991485595703, 0.031645774841308594, -0.5816764831542969, -0.2075796127319336, 0.18010807037353516, 0.3272113800048828, 1.1226387023925781, 0.6954927444458008, -0.2666645050048828, 0.5379085540771484, 0.447357177734375, 1.4894123077392578, -16.760414123535156, -6.826337814331055, -0.6348972320556641, -0.6782541275024414, 0.34556102752685547, 0.6175956726074219, -0.8737201690673828, 1.257059097290039, -0.09614849090576172, 0.43053436279296875, 0.5205965042114258, 0.0776667594909668, 0.4460010528564453, -1.4806747436523438, 2.282710552215576, 1.4198455810546875, 0.5409154891967773, 0.6301383972167969, -0.4640369415283203, -0.3421916961669922, 0.41924095153808594, -0.5592918395996094, -0.6934428215026855, -9.045251846313477, 0.37582874298095703, 0.20588970184326172, 0.9311332702636719, 0.7515964508056641, 0.7275323867797852, -1.3865814208984375, 0.3899059295654297, 0.1392955780029297, -0.8130569458007812, 0.7705373764038086, 0.19045400619506836, 0.45532989501953125, -0.3883209228515625, 0.5522394180297852, -9.876791000366211, -0.00415802001953125, 1.0388221740722656, -0.0045108795166015625, 0.45261192321777344, 0.309299111366272, 1.5247421264648438, 0.1701183319091797, -0.8420939445495605, 2.4386520385742188, 0.43780517578125, -1.4830665588378906, -0.7308120727539062, -7.917139053344727, -0.0004177093505859375, 0.35001373291015625, 2.2935638427734375, -1.9448165893554688, -6.661914825439453, 1.3131752014160156, 0.10100412368774414, 1.587289810180664, 1.269439697265625, -0.20349502563476562, -2.833765983581543, 0.20998382568359375, 0.9683704376220703, -0.12696170806884766, 0.4129514694213867, -0.9822425842285156, 0.21517658233642578, 0.9178555011749268, 1.343245506286621, -4.208711624145508, 2.313540458679199, 0.2547464370727539, 4.915624618530273, -0.2268390655517578, -0.6338815689086914, 4.0107574462890625, 0.12122249603271484, -0.6259174346923828, 0.4610910415649414, 0.8040332794189453, 0.3364744186401367, -4.877796173095703, -0.013494491577148438, 1.0350942611694336, -0.6075081825256348], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 90112, "num_env_steps_trained": 167160, "num_agent_steps_sampled": 90112, "num_agent_steps_trained": 167160, "last_target_update_ts": 90112, "num_target_updates": 175}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -92.88982564248144, "episode_len_mean": 257.43, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612], "episode_lengths": [327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5226990949803278, "mean_inference_ms": 24.786410110276197, "mean_action_processing_ms": 0.1352792034688381, "mean_env_wait_ms": 4.207807250057041, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -92.88982564248144, "episode_len_mean": 257.43, "episodes_this_iter": 3, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-239.8201068714261, -128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612], "episode_lengths": [327, 280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5226990949803278, "mean_inference_ms": 24.786410110276197, "mean_action_processing_ms": 0.1352792034688381, "mean_env_wait_ms": 4.207807250057041, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 90112, "num_agent_steps_trained": 167160, "num_env_steps_sampled": 90112, "num_env_steps_trained": 167160, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 90112, "agent_timesteps_total": 90112, "timers": {"training_iteration_time_ms": 312.176, "learn_time_ms": 71.292, "learn_throughput": 1683.217, "synch_weights_time_ms": 21.488}, "counters": {"num_env_steps_sampled": 90112, "num_env_steps_trained": 167160, "num_agent_steps_sampled": 90112, "num_agent_steps_trained": 167160, "last_target_update_ts": 90112, "num_target_updates": 175}, "done": false, "episodes_total": 294, "training_iteration": 88, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-22", "timestamp": 1655476342, "time_this_iter_s": 5.135804176330566, "time_total_s": 442.7084496021271, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 442.7084496021271, "timesteps_since_restore": 0, "iterations_since_restore": 88, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 38.58571428571429, "ram_util_percent": 63.857142857142854}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 1.5572646856307983, "min_q": -92.46734619140625, "max_q": 24.118026733398438, "mean_td_error": 0.677815854549408}, "td_error": [-0.22909832000732422, 5.2860870361328125, -1.416304588317871, -0.7149868011474609, -0.0821828842163086, -0.1267681121826172, -0.7091436386108398, -0.13321924209594727, 1.6633682250976562, -0.46053504943847656, 1.2479476928710938, 0.019039630889892578, -2.5666589736938477, 0.4510002136230469, 0.38089466094970703, -0.09961128234863281, 0.12443351745605469, -1.1139230728149414, -0.5237522125244141, -0.16688156127929688, -0.6789913177490234, 0.024824142456054688, 15.334800720214844, 4.059089660644531, 5.867526054382324, -0.360595703125, 0.35343360900878906, -1.2399654388427734, -1.3898324966430664, 0.2776031494140625, -1.3126678466796875, 1.7136306762695312, -0.2147369384765625, -0.9110507965087891, 0.5782017707824707, -0.6802272796630859, -1.0942716598510742, 2.7579164505004883, 6.599052429199219, 6.003662109375, -0.6807575225830078, -0.8849525451660156, 1.0930633544921875, 0.3474693298339844, -0.9577960968017578, -0.5016169548034668, 0.7640509605407715, 1.6081581115722656, -0.5727672576904297, 2.4549999237060547, -23.94982147216797, 0.06785202026367188, -0.5807726383209229, -2.263782501220703, -0.19272089004516602, -0.2537803649902344, -1.3667030334472656, 2.735830307006836, -0.7911911010742188, -0.4386787414550781, -7.0457258224487305, 13.330179214477539, 1.5442852973937988, -0.8544483184814453, -0.6690349578857422, 0.44588470458984375, 0.5992908477783203, -0.7033500671386719, 0.1353311538696289, 0.40169477462768555, 0.4516477584838867, -2.4013633728027344, -0.9828176498413086, 0.11529350280761719, -1.329716682434082, 0.22275733947753906, -0.4400157928466797, 0.872642993927002, 15.278719902038574, 0.024946212768554688, -10.648584365844727, -1.3466472625732422, 6.300468444824219, -0.5062398910522461, 1.5881023406982422, 0.401031494140625, -0.9886665344238281, -0.20580005645751953, -1.0225677490234375, 0.401031494140625, 0.09259796142578125, 0.06394028663635254, 4.91871452331543, -0.4887208938598633, 10.834388732910156, -0.8179636001586914, -0.19194495677947998, -0.31287145614624023, -1.3542327880859375, -0.9681081771850586, -0.8940029144287109, -1.21209716796875, -0.4859333038330078, -1.3542327880859375, -0.2512855529785156, 1.6081581115722656, 14.874307632446289, -0.516444206237793, 4.226165771484375, -0.5164384841918945, 0.6936616897583008, -0.9355106353759766, -0.567540168762207, 15.475984573364258, 15.065328598022461, -0.18465089797973633, 1.4400396347045898, -0.9120159149169922, -0.27978992462158203, -0.8331127166748047], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 91136, "num_env_steps_trained": 169080, "num_agent_steps_sampled": 91136, "num_agent_steps_trained": 169080, "last_target_update_ts": 91136, "num_target_updates": 177}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -90.41462457247079, "episode_len_mean": 256.43, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102], "episode_lengths": [280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5228621857695755, "mean_inference_ms": 24.78717162432904, "mean_action_processing_ms": 0.13531440407088416, "mean_env_wait_ms": 4.208546902241383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -90.41462457247079, "episode_len_mean": 256.43, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-128.96423929929733, 22.036068990826607, -110.34951266646385, -522.9566605314612, -47.824578918516636, -12.500000052154064, -147.41771192103624, -3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102], "episode_lengths": [280, 236, 279, 372, 244, 245, 295, 225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5228621857695755, "mean_inference_ms": 24.78717162432904, "mean_action_processing_ms": 0.13531440407088416, "mean_env_wait_ms": 4.208546902241383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 91136, "num_agent_steps_trained": 169080, "num_env_steps_sampled": 91136, "num_env_steps_trained": 169080, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 91136, "agent_timesteps_total": 91136, "timers": {"training_iteration_time_ms": 319.921, "learn_time_ms": 70.942, "learn_throughput": 1691.526, "synch_weights_time_ms": 21.389}, "counters": {"num_env_steps_sampled": 91136, "num_env_steps_trained": 169080, "num_agent_steps_sampled": 91136, "num_agent_steps_trained": 169080, "last_target_update_ts": 91136, "num_target_updates": 177}, "done": false, "episodes_total": 295, "training_iteration": 89, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-27", "timestamp": 1655476347, "time_this_iter_s": 5.044332027435303, "time_total_s": 447.7527816295624, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 447.7527816295624, "timesteps_since_restore": 0, "iterations_since_restore": 89, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 39.675000000000004, "ram_util_percent": 63.8125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -2.393658399581909, "min_q": -82.09503173828125, "max_q": 27.41900634765625, "mean_td_error": 0.05670035630464554}, "td_error": [2.7784972190856934, 0.699275016784668, -0.1781291961669922, 4.980609893798828, 0.3911876678466797, 0.6487932205200195, 0.5232906341552734, -0.3037071228027344, -6.88947868347168, -0.22175025939941406, 0.09599590301513672, 2.1215744018554688, 0.4145164489746094, -22.788814544677734, -7.235872268676758, 0.2575416564941406, 0.280364990234375, -0.6219158172607422, -0.6211090087890625, -0.08959197998046875, 0.62961745262146, 1.399271011352539, -9.364896774291992, -0.22209548950195312, 4.384151458740234, 0.47040557861328125, -0.41294193267822266, 0.4189434051513672, 0.20665359497070312, -0.4989933967590332, -1.7334823608398438, -0.17305755615234375, -0.2025604248046875, -0.11378955841064453, -0.22614479064941406, -0.23607730865478516, 0.4095726013183594, -0.26673221588134766, 0.37552452087402344, -0.11826038360595703, 0.15469741821289062, -0.9263572692871094, 0.3705015182495117, 0.7533719539642334, -0.24286651611328125, -0.31708335876464844, 1.1577444076538086, 0.5596103668212891, 0.20386695861816406, 0.01126861572265625, 0.40731048583984375, 0.13927268981933594, -0.4133749008178711, -0.19992971420288086, -1.458608627319336, -0.05819511413574219, -0.4289970397949219, 1.447493553161621, -0.5288944244384766, -0.2798304557800293, 3.0357818603515625, -1.3315377235412598, -0.38944149017333984, -0.04012489318847656, 0.4145164489746094, -0.20953774452209473, -1.0336809158325195, 0.03735995292663574, -0.13277053833007812, 0.6335668563842773, -1.9024362564086914, 4.290271759033203, 1.5848731994628906, -0.3667621612548828, -0.1450958251953125, -10.021492004394531, -0.06272411346435547, 0.31233692169189453, 0.3748016357421875, -0.03793907165527344, 0.4145164489746094, 0.40915870666503906, -2.869330883026123, 0.564793586730957, -0.2075939178466797, 0.5722026824951172, 0.9710617065429688, 4.518394470214844, -0.22209548950195312, 1.912050724029541, 3.9635214805603027, -1.6948471069335938, -0.24286651611328125, -0.4989933967590332, 0.20492172241210938, -0.15203094482421875, 0.012631416320800781, 0.11358928680419922, -0.3566551208496094, 0.09770059585571289, -0.8522891998291016, 0.3843507766723633, 9.593246459960938, 0.11332321166992188, 0.2940950393676758, 23.284053802490234, -0.3465232849121094, 0.5045499801635742, -0.5044088363647461, -1.601383090019226, -7.295100212097168, 0.46678638458251953, -0.3896350860595703, -0.2992668151855469, 7.816267013549805, 0.10368156433105469, 1.355098009109497, 1.7754783630371094, 0.19834280014038086, 0.3658933639526367], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 92160, "num_env_steps_trained": 171000, "num_agent_steps_sampled": 92160, "num_agent_steps_trained": 171000, "last_target_update_ts": 92160, "num_target_updates": 179}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -92.02094920396804, "episode_len_mean": 255.92, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014], "episode_lengths": [225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5241907956244295, "mean_inference_ms": 24.791009415835475, "mean_action_processing_ms": 0.13522336082004766, "mean_env_wait_ms": 4.2188655869300415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -92.02094920396804, "episode_len_mean": 255.92, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-3.789364516735077, -31.861536502838135, 16.374430797994137, 6.60000005364418, -122.75617557018995, -63.63093186169863, -32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014], "episode_lengths": [225, 255, 237, 228, 294, 253, 246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5241907956244295, "mean_inference_ms": 24.791009415835475, "mean_action_processing_ms": 0.13522336082004766, "mean_env_wait_ms": 4.2188655869300415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 92160, "num_agent_steps_trained": 171000, "num_env_steps_sampled": 92160, "num_env_steps_trained": 171000, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 92160, "agent_timesteps_total": 92160, "timers": {"training_iteration_time_ms": 342.998, "learn_time_ms": 70.612, "learn_throughput": 1699.417, "synch_weights_time_ms": 20.807}, "counters": {"num_env_steps_sampled": 92160, "num_env_steps_trained": 171000, "num_agent_steps_sampled": 92160, "num_agent_steps_trained": 171000, "last_target_update_ts": 92160, "num_target_updates": 179}, "done": false, "episodes_total": 302, "training_iteration": 90, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-33", "timestamp": 1655476353, "time_this_iter_s": 5.568962335586548, "time_total_s": 453.3217439651489, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 453.3217439651489, "timesteps_since_restore": 0, "iterations_since_restore": 90, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 36.9875, "ram_util_percent": 63.787499999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -1.6832358837127686, "min_q": -95.32819366455078, "max_q": 27.595006942749023, "mean_td_error": -0.9383490085601807}, "td_error": [0.34230804443359375, 0.86785888671875, -0.3261059522628784, 0.9591464996337891, 0.7185287475585938, 0.0028617382049560547, 2.1579952239990234, 1.8744087219238281, -2.2368717193603516, -1.7615258693695068, 0.6061439514160156, 0.0877690315246582, -1.9865188598632812, 0.15187835693359375, 0.45965576171875, -1.7507095336914062, -0.21810483932495117, 0.72412109375, 1.3493156433105469, 1.7191009521484375, 0.16139936447143555, -0.31037473678588867, -3.227229118347168, -0.3864908218383789, 1.2084083557128906, 0.7099418640136719, 0.7187843322753906, -0.25757813453674316, 1.3087921142578125, 1.5003738403320312, 1.008413314819336, -0.00772857666015625, 5.574148178100586, -0.07899284362792969, -0.5461597442626953, 0.3694162368774414, -3.1520543098449707, 0.6022167205810547, 0.2651386260986328, 1.2249927520751953, 0.6215286254882812, 3.338459014892578, -0.007188320159912109, 1.4972944259643555, -0.4843416213989258, 1.538365364074707, -0.43595218658447266, 0.2969794273376465, 0.501896858215332, 1.037592887878418, -9.835798263549805, 0.7789154052734375, -0.4911617040634155, 1.215768814086914, -4.19975471496582, 1.1016578674316406, 0.9448633193969727, -0.26645326614379883, 0.3148322105407715, 0.7723064422607422, 0.6921248435974121, 1.9839930534362793, 0.46633052825927734, -0.8500490188598633, 0.04542350769042969, -1.9001846313476562, -0.8685712814331055, 1.4065113067626953, 0.5129318237304688, 0.9641084671020508, -1.0296783447265625, -4.088220596313477, 0.2983563542366028, -0.4687919616699219, 0.6157121658325195, -92.50137329101562, 0.28961181640625, -0.16615724563598633, -0.1335163116455078, -2.1874923706054688, -11.157512664794922, 0.19016361236572266, -0.14229297637939453, 1.505849838256836, -0.5229682922363281, 0.3551826477050781, -6.089488506317139, 1.2311954498291016, -2.191295623779297, 0.8664579391479492, 1.5428237915039062, 0.09446859359741211, 0.005089759826660156, -1.6633338928222656, -5.958457946777344, -0.20207786560058594, 0.8517255783081055, 0.34006357192993164, -3.7512378692626953, 0.8269596099853516, -0.5063536167144775, 0.26119136810302734, 1.0634536743164062, -0.1753988265991211, 0.18404769897460938, -6.364681243896484, 0.5662097930908203, 2.299022674560547, 0.09917545318603516, 5.765020370483398, 1.0917224884033203, 0.5813980102539062, -1.8307571411132812, 0.2883646488189697, -1.1814069747924805, -0.686185359954834, -0.29554319381713867, -2.031524658203125, -0.3671603202819824, 0.7586555480957031], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 93184, "num_env_steps_trained": 172920, "num_agent_steps_sampled": 93184, "num_agent_steps_trained": 172920, "last_target_update_ts": 93184, "num_target_updates": 181}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -99.5418344154954, "episode_len_mean": 257.85, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371], "episode_lengths": [246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5257193645016036, "mean_inference_ms": 24.784752253818134, "mean_action_processing_ms": 0.13531121063543045, "mean_env_wait_ms": 4.221626878200282, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -99.5418344154954, "episode_len_mean": 257.85, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-32.76700086146593, 32.46344202011824, -55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371], "episode_lengths": [246, 217, 250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5257193645016036, "mean_inference_ms": 24.784752253818134, "mean_action_processing_ms": 0.13531121063543045, "mean_env_wait_ms": 4.221626878200282, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 93184, "num_agent_steps_trained": 172920, "num_env_steps_sampled": 93184, "num_env_steps_trained": 172920, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 93184, "agent_timesteps_total": 93184, "timers": {"training_iteration_time_ms": 326.25, "learn_time_ms": 71.925, "learn_throughput": 1668.405, "synch_weights_time_ms": 20.889}, "counters": {"num_env_steps_sampled": 93184, "num_env_steps_trained": 172920, "num_agent_steps_sampled": 93184, "num_agent_steps_trained": 172920, "last_target_update_ts": 93184, "num_target_updates": 181}, "done": false, "episodes_total": 308, "training_iteration": 91, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-38", "timestamp": 1655476358, "time_this_iter_s": 5.332825660705566, "time_total_s": 458.6545696258545, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 458.6545696258545, "timesteps_since_restore": 0, "iterations_since_restore": 91, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 33.24285714285714, "ram_util_percent": 63.942857142857136}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 3.0797247886657715, "min_q": -82.30829620361328, "max_q": 26.764875411987305, "mean_td_error": 0.12635162472724915}, "td_error": [-7.736139297485352, 0.85552978515625, -6.705423355102539, -0.02059650421142578, 1.9010343551635742, 14.144993782043457, 0.3707742691040039, -1.1319007873535156, 0.975341796875, -0.22649765014648438, -6.119525909423828, 0.09099960327148438, -0.0399627685546875, 0.6943130493164062, -0.0825967788696289, 2.3294143676757812, 0.03757476806640625, -0.781714916229248, -0.21523809432983398, 0.704376220703125, -0.1401195526123047, -1.7131233215332031, 0.8560686111450195, 0.021150588989257812, -0.10302257537841797, -0.3789093494415283, 0.08908271789550781, 1.6553473472595215, -2.261922836303711, -0.04807853698730469, -0.09844017028808594, 0.45330238342285156, 1.3057479858398438, 0.9808349609375, 0.4376983642578125, 1.1689071655273438, -18.02262306213379, 1.6712570190429688, 0.15256929397583008, -0.3340492248535156, -2.6298723220825195, 0.09644651412963867, 0.4534893035888672, 0.3539161682128906, -0.03126120567321777, 0.17895984649658203, -3.1002345085144043, -0.24682998657226562, 0.5407247543334961, 0.04052448272705078, -1.7342262268066406, -0.20064163208007812, 0.5411930084228516, 0.9524364471435547, -0.2173919677734375, 0.45526123046875, 0.08564090728759766, -0.173095703125, -0.012349605560302734, -0.011981964111328125, 0.20028316974639893, 0.3020801544189453, -0.9161734580993652, 7.533683776855469, 0.18071365356445312, -4.041335105895996, 6.629302978515625, 7.857751846313477, -0.03182220458984375, 0.599700927734375, 0.7524404525756836, -0.01800060272216797, -5.356895446777344, 0.23687130212783813, 1.4847041368484497, -0.24127578735351562, 0.44672536849975586, 0.4529903531074524, 1.6931253671646118, -0.08400201797485352, 1.2793807983398438, -0.16715145111083984, -0.23549652099609375, -3.5663299560546875, 0.23912811279296875, 0.07790565490722656, 0.44037342071533203, 1.6613941192626953, 0.3941841125488281, 0.41274261474609375, 0.23231270909309387, 0.3012237548828125, 0.1124868392944336, -0.3384275436401367, -0.35549354553222656, -0.2560997009277344, 0.12677001953125, 0.3657569885253906, -4.652225494384766, 0.3610401153564453, 0.5047931671142578, -0.4732780456542969, -0.22863388061523438, -1.017246127128601, 0.5671634674072266, -0.21940040588378906, 0.09233474731445312, 1.1941384077072144, -1.6608562469482422, 0.22014236450195312, 0.2412118911743164, 0.5533552169799805, -2.71966552734375, 1.1261224746704102, 21.990793228149414, 0.4032402038574219, -0.06875896453857422, 0.6406974792480469, -0.1807422637939453, 0.005299568176269531], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 94208, "num_env_steps_trained": 174840, "num_agent_steps_sampled": 94208, "num_agent_steps_trained": 174840, "last_target_update_ts": 94208, "num_target_updates": 183}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -107.19742232412099, "episode_len_mean": 260.39, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933], "episode_lengths": [250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.525950052305081, "mean_inference_ms": 24.79823931718852, "mean_action_processing_ms": 0.13523134304591827, "mean_env_wait_ms": 4.22425294294107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -107.19742232412099, "episode_len_mean": 260.39, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-55.477636344730854, -67.4816090837121, 14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933], "episode_lengths": [250, 277, 232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.525950052305081, "mean_inference_ms": 24.79823931718852, "mean_action_processing_ms": 0.13523134304591827, "mean_env_wait_ms": 4.22425294294107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 94208, "num_agent_steps_trained": 174840, "num_env_steps_sampled": 94208, "num_env_steps_trained": 174840, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 94208, "agent_timesteps_total": 94208, "timers": {"training_iteration_time_ms": 321.547, "learn_time_ms": 73.564, "learn_throughput": 1631.234, "synch_weights_time_ms": 21.485}, "counters": {"num_env_steps_sampled": 94208, "num_env_steps_trained": 174840, "num_agent_steps_sampled": 94208, "num_agent_steps_trained": 174840, "last_target_update_ts": 94208, "num_target_updates": 183}, "done": false, "episodes_total": 310, "training_iteration": 92, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-44", "timestamp": 1655476364, "time_this_iter_s": 5.0515899658203125, "time_total_s": 463.7061595916748, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 463.7061595916748, "timesteps_since_restore": 0, "iterations_since_restore": 92, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 38.39999999999999, "ram_util_percent": 63.912499999999994}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -3.785766839981079, "min_q": -94.57660675048828, "max_q": 26.38924217224121, "mean_td_error": -1.6675974130630493}, "td_error": [-0.2511601448059082, -0.38962793350219727, -3.1663665771484375, -15.457918167114258, -4.322101593017578, -0.35633373260498047, 1.5964288711547852, -0.156097412109375, -0.08668994903564453, 2.1738600730895996, -0.7042427062988281, -2.1628189086914062, -0.4332704544067383, 0.21471786499023438, 2.1738600730895996, 0.20557498931884766, 0.48172760009765625, 0.06070423126220703, 0.2793397903442383, 0.47315216064453125, -0.450897216796875, 0.2621595859527588, -0.6211700439453125, -0.3072013854980469, -0.5862298011779785, -5.166168212890625, -5.808276653289795, -0.23049259185791016, 2.2859649658203125, -10.777694702148438, -0.9036283493041992, -1.0741512775421143, -0.44251251220703125, 0.5538444519042969, -0.30635690689086914, -0.5279998779296875, 1.8866310119628906, -0.017160415649414062, -0.15155792236328125, -5.905019760131836, -0.07755279541015625, -0.8341064453125, -19.484460830688477, 0.8842601776123047, -4.52980899810791, -0.28737688064575195, -0.2550992965698242, -92.57660675048828, 0.5729198455810547, 0.12823009490966797, 0.235870361328125, -0.3202857971191406, 1.2378578186035156, -2.87447452545166, -0.8447761535644531, -4.903417587280273, 0.3510417938232422, -2.5005531311035156, -0.675750732421875, 0.16716766357421875, -0.2618980407714844, 0.24625778198242188, -0.6646194458007812, -0.39167022705078125, 0.20452117919921875, -0.7999954223632812, 0.9630565643310547, 0.185760498046875, 0.17872238159179688, -2.2847862243652344, -0.3887777328491211, 0.15420150756835938, 0.9819221496582031, -0.7576236724853516, -5.267848968505859, -0.6430587768554688, -0.08509063720703125, 0.2817816734313965, 1.3988533020019531, -1.0549697875976562, 0.13236236572265625, 0.6341625452041626, 0.18885231018066406, -0.36079323291778564, 0.11928260326385498, -2.488250732421875, -0.04838895797729492, -0.42072057723999023, -0.5209579467773438, -0.027460098266601562, -0.49298095703125, 0.04500770568847656, 1.9372978210449219, -0.8728008270263672, -0.5151662826538086, 0.09263801574707031, -0.1936044692993164, 0.6884431838989258, 0.3389854431152344, -3.541534423828125, 0.6513967514038086, -0.5068874359130859, 0.4036874771118164, 0.7419700622558594, -4.101932048797607, -0.1839122772216797, 0.8679485321044922, 0.19768905639648438, -1.9789543151855469, 1.013777732849121, 0.4168577194213867, -3.679398536682129, 0.4228782653808594, -2.1628189086914062, -0.6001434326171875, -0.3552532196044922, -0.695770263671875, -3.0113582611083984, 0.5350704193115234, -0.07353973388671875], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 95232, "num_env_steps_trained": 176760, "num_agent_steps_sampled": 95232, "num_agent_steps_trained": 176760, "last_target_update_ts": 95232, "num_target_updates": 185}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -106.48180738441646, "episode_len_mean": 260.13, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496], "episode_lengths": [232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5266533957879351, "mean_inference_ms": 24.803518808720245, "mean_action_processing_ms": 0.13519028160986019, "mean_env_wait_ms": 4.226616534397224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -106.48180738441646, "episode_len_mean": 260.13, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [14.048043139278889, -8.886780224740505, -0.7266240119934082, 20.765688605606556, 4.310635231435299, 10.929050348699093, 9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496], "episode_lengths": [232, 255, 211, 213, 230, 217, 222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5266533957879351, "mean_inference_ms": 24.803518808720245, "mean_action_processing_ms": 0.13519028160986019, "mean_env_wait_ms": 4.226616534397224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 95232, "num_agent_steps_trained": 176760, "num_env_steps_sampled": 95232, "num_env_steps_trained": 176760, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 95232, "agent_timesteps_total": 95232, "timers": {"training_iteration_time_ms": 329.749, "learn_time_ms": 71.469, "learn_throughput": 1679.053, "synch_weights_time_ms": 20.985}, "counters": {"num_env_steps_sampled": 95232, "num_env_steps_trained": 176760, "num_agent_steps_sampled": 95232, "num_agent_steps_trained": 176760, "last_target_update_ts": 95232, "num_target_updates": 185}, "done": false, "episodes_total": 312, "training_iteration": 93, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-49", "timestamp": 1655476369, "time_this_iter_s": 5.1805925369262695, "time_total_s": 468.8867521286011, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 468.8867521286011, "timesteps_since_restore": 0, "iterations_since_restore": 93, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 34.714285714285715, "ram_util_percent": 63.88571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": -0.33205896615982056, "min_q": -94.63731384277344, "max_q": 25.85438346862793, "mean_td_error": -0.3752518594264984}, "td_error": [0.8008406162261963, 0.21123600006103516, 0.32857799530029297, -0.6808242797851562, -0.49477195739746094, 4.630622863769531, -0.48593926429748535, -0.4197072982788086, -0.3448343276977539, -0.19197750091552734, -0.32335853576660156, 0.8800387382507324, -2.298699378967285, -6.228557586669922, 0.32853221893310547, 0.38894081115722656, 2.501089096069336, 0.30834197998046875, 0.2777423858642578, -0.3986701965332031, 1.0607070922851562, 1.8945274353027344, 0.12291717529296875, -1.126974105834961, -1.0640830993652344, -0.3096637725830078, 15.629487037658691, 4.154987335205078, 1.7797164916992188, -3.8036117553710938, -0.2255725860595703, -1.2526817321777344, 0.9375259876251221, 0.23653125762939453, -24.266700744628906, -1.6594266891479492, 0.49553775787353516, -0.12470817565917969, -1.0862503051757812, 1.9185256958007812, -3.6088180541992188, -3.7731263637542725, 0.1340045928955078, -0.07385444641113281, -0.5387229919433594, 0.019382476806640625, -0.059386253356933594, 0.41225528717041016, -8.678022384643555, -0.2925894260406494, 0.7165319919586182, 0.6097097396850586, -0.5815238952636719, -5.063972473144531, -0.5454998016357422, 0.040203094482421875, 1.928816556930542, -0.9968528747558594, -0.10149574279785156, 0.1378779411315918, -3.2880191802978516, -0.21617698669433594, 0.40706348419189453, -0.08820343017578125, -0.10288047790527344, -1.670186996459961, -0.1137237548828125, 5.405019760131836, 0.704867959022522, 0.9030293226242065, 0.2468419075012207, -2.1549644470214844, 0.6436491012573242, 0.2794342041015625, 1.2539255619049072, 0.6547346115112305, -0.1677265167236328, 0.31563568115234375, 0.31836605072021484, 1.8606719970703125, 0.439786434173584, -0.3228888511657715, -0.4476289749145508, -0.13713550567626953, -0.07060527801513672, -0.647477388381958, 0.156890869140625, -0.33765220642089844, 0.024501800537109375, -0.174713134765625, -1.0640830993652344, -0.4226522445678711, 0.26262760162353516, 4.630622863769531, -0.4757661819458008, 0.13154029846191406, 0.1925492286682129, 0.4969959259033203, 0.6488513946533203, 3.6163063049316406, 0.7876396179199219, 0.25220608711242676, 0.3397693634033203, 0.2648277282714844, -2.122241973876953, 0.7486057281494141, 0.5575635433197021, -8.8211669921875, 0.02325439453125, 0.7912893295288086, -0.08437156677246094, -3.421536445617676, -13.796619415283203, -0.43190765380859375, 0.1312847137451172, 0.1729726791381836, -2.918020248413086, -0.5245609283447266, -0.6333894729614258, 0.1784210205078125], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 96256, "num_env_steps_trained": 178680, "num_agent_steps_sampled": 96256, "num_agent_steps_trained": 178680, "last_target_update_ts": 96256, "num_target_updates": 187}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -106.52648495167495, "episode_len_mean": 260.47, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752], "episode_lengths": [222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5277713621857086, "mean_inference_ms": 24.790802950219458, "mean_action_processing_ms": 0.13502529736869776, "mean_env_wait_ms": 4.23239997379898, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -106.52648495167495, "episode_len_mean": 260.47, "episodes_this_iter": 6, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [9.56478600203991, -28.880654953420162, -26.200000159442425, 5.000000104308128, -59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752], "episode_lengths": [222, 255, 249, 231, 242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5277713621857086, "mean_inference_ms": 24.790802950219458, "mean_action_processing_ms": 0.13502529736869776, "mean_env_wait_ms": 4.23239997379898, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 96256, "num_agent_steps_trained": 178680, "num_env_steps_sampled": 96256, "num_env_steps_trained": 178680, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 96256, "agent_timesteps_total": 96256, "timers": {"training_iteration_time_ms": 358.955, "learn_time_ms": 72.081, "learn_throughput": 1664.8, "synch_weights_time_ms": 21.305}, "counters": {"num_env_steps_sampled": 96256, "num_env_steps_trained": 178680, "num_agent_steps_sampled": 96256, "num_agent_steps_trained": 178680, "last_target_update_ts": 96256, "num_target_updates": 187}, "done": false, "episodes_total": 318, "training_iteration": 94, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-32-54", "timestamp": 1655476374, "time_this_iter_s": 5.479717493057251, "time_total_s": 474.3664696216583, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 474.3664696216583, "timesteps_since_restore": 0, "iterations_since_restore": 94, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 35.525, "ram_util_percent": 63.9875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.501978874206543, "min_q": -77.73234558105469, "max_q": 23.671300888061523, "mean_td_error": -0.5232557654380798}, "td_error": [0.18735885620117188, -4.256681442260742, 0.2079601287841797, -0.22135639190673828, 1.2118301391601562, -1.276991605758667, -1.837849497795105, -5.95451545715332, -0.4751434326171875, 0.5934398174285889, -0.2846989631652832, 0.24130916595458984, -1.7338333129882812, 0.18976783752441406, 1.5121593475341797, -0.02723979949951172, -1.7631111145019531, -4.5731987953186035, 0.028017044067382812, -4.107757568359375, -1.9844155311584473, -3.1142959594726562, -0.037217140197753906, 0.5705575942993164, -0.7050971984863281, -0.7922325134277344, -0.8196697235107422, 0.08450841903686523, -0.19655990600585938, -1.1211681365966797, 0.3160114288330078, -0.2612886428833008, -0.18802642822265625, 0.212371826171875, -0.5073509216308594, 0.18027496337890625, -3.890918731689453, 1.4905035495758057, -1.6359505653381348, 0.1259136199951172, 0.07024097442626953, -0.22055339813232422, -0.7458286285400391, -0.29102039337158203, -0.6402864456176758, -1.2718772888183594, 0.40090370178222656, 0.002365589141845703, -0.13146209716796875, 0.18808650970458984, -1.5905189514160156, -0.14629554748535156, 1.7263813018798828, -0.12197303771972656, 0.2806282043457031, 0.13150787353515625, -0.6566848754882812, 0.3633136749267578, 0.02862262725830078, -0.593745231628418, 0.4353904724121094, -0.11635637283325195, -0.6299209594726562, 0.07572078704833984, -1.1402130126953125, 0.5515308380126953, 0.31279945373535156, -0.20326995849609375, -0.8418688774108887, -0.6450300216674805, -4.931753158569336, 0.1453847885131836, -0.030389785766601562, 0.3475360870361328, -5.66928768157959, -8.85528564453125, -0.15364933013916016, 0.5931382179260254, -5.298234939575195, -1.4365730285644531, 0.5336322784423828, -0.38032329082489014, -0.12771129608154297, -1.6273080110549927, 1.304099678993225, 0.11413955688476562, 0.35388946533203125, 1.717282772064209, 0.6606874465942383, -0.07890701293945312, 0.4778757095336914, 0.3175182342529297, -1.2213687896728516, -0.7254714965820312, -1.9659461975097656, 0.046092987060546875, 1.4762077331542969, 0.6681127548217773, 1.0678119659423828, 0.642364501953125, 0.7929298877716064, -0.3622875213623047, 0.15768146514892578, 0.1661968231201172, 2.3343753814697266, -0.5047097206115723, -0.9770021438598633, -0.13388347625732422, 0.3405189514160156, 0.7929298877716064, -1.0094833374023438, -0.031707763671875, -0.3550090789794922, 0.0005741119384765625, -1.2216758728027344, 0.37180519104003906, 0.5846347808837891, -0.21611976623535156, -1.3923873901367188, -0.05763864517211914], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 97280, "num_env_steps_trained": 180600, "num_agent_steps_sampled": 97280, "num_agent_steps_trained": 180600, "last_target_update_ts": 97280, "num_target_updates": 189}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -106.19478459022939, "episode_len_mean": 260.19, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815], "episode_lengths": [242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5275049336195796, "mean_inference_ms": 24.801383263717526, "mean_action_processing_ms": 0.13488881678461678, "mean_env_wait_ms": 4.2359161067285065, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -106.19478459022939, "episode_len_mean": 260.19, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-59.47475638985634, 17.7132201269269, -46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815], "episode_lengths": [242, 206, 270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5275049336195796, "mean_inference_ms": 24.801383263717526, "mean_action_processing_ms": 0.13488881678461678, "mean_env_wait_ms": 4.2359161067285065, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 97280, "num_agent_steps_trained": 180600, "num_env_steps_sampled": 97280, "num_env_steps_trained": 180600, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 97280, "agent_timesteps_total": 97280, "timers": {"training_iteration_time_ms": 304.683, "learn_time_ms": 70.996, "learn_throughput": 1690.243, "synch_weights_time_ms": 21.389}, "counters": {"num_env_steps_sampled": 97280, "num_env_steps_trained": 180600, "num_agent_steps_sampled": 97280, "num_agent_steps_trained": 180600, "last_target_update_ts": 97280, "num_target_updates": 189}, "done": false, "episodes_total": 322, "training_iteration": 95, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-33-00", "timestamp": 1655476380, "time_this_iter_s": 5.256351947784424, "time_total_s": 479.62282156944275, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 479.62282156944275, "timesteps_since_restore": 0, "iterations_since_restore": 95, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 39.0, "ram_util_percent": 63.9}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.930439829826355, "min_q": -94.57682037353516, "max_q": 25.331584930419922, "mean_td_error": 0.09927894175052643}, "td_error": [-2.0356712341308594, 0.31702232360839844, 0.4881315231323242, -0.7126598358154297, 0.46265602111816406, -4.953726768493652, 0.4382820129394531, 0.6592807769775391, 0.07158851623535156, 0.8203220367431641, 0.11597251892089844, 0.16541865468025208, -1.0743083953857422, 0.3554115295410156, -0.3871612548828125, 0.598175048828125, 0.18288230895996094, -0.9403848648071289, 1.7285642623901367, -0.7293701171875, 0.6155052185058594, 1.2521839141845703, 0.14161109924316406, 0.6343317031860352, -0.5447856187820435, -1.1663503646850586, -0.706268310546875, -1.2614078521728516, 0.4197540283203125, 0.1509861946105957, 1.024235725402832, -0.6931357383728027, -0.35668087005615234, 0.5124797821044922, 1.2585382461547852, 8.503494262695312, 0.12336540222167969, -0.41698217391967773, -0.8687650561332703, -0.357114315032959, -0.259857177734375, 0.1920642852783203, 0.5430154800415039, 0.3174400329589844, 0.9377403259277344, 0.486785888671875, 0.786067008972168, 0.5566978454589844, 0.016694068908691406, 4.2747063636779785, 0.20422935485839844, 0.1216268539428711, -0.41678476333618164, -0.22885894775390625, 0.20716476440429688, 0.9339637756347656, -0.06711959838867188, -4.797475814819336, 0.025866031646728516, -0.8264849185943604, 1.030975341796875, 2.2999038696289062, -0.13573932647705078, 0.07847881317138672, -0.3547782897949219, 0.40128135681152344, 0.7249908447265625, -0.9342402219772339, -0.27079200744628906, -0.4425849914550781, 0.3466987609863281, 0.46155548095703125, -0.4755687713623047, 0.47383368015289307, 0.40823936462402344, 0.9240598678588867, -0.1040802001953125, -0.7612557411193848, 0.1663074493408203, 0.3590078353881836, 0.6041355133056641, -0.378875732421875, 1.6037063598632812, -1.3959262371063232, -0.2185373306274414, 0.5430154800415039, 0.06383895874023438, -0.03493309020996094, 2.3479971885681152, -0.2238025665283203, 0.49536895751953125, -1.2677936553955078, 0.6211929321289062, 0.2993955612182617, -1.1553916931152344, -0.5554046630859375, -0.13619613647460938, 0.1850900650024414, 0.3961181640625, 2.544121742248535, 0.6208391189575195, 0.39966583251953125, 0.2226276397705078, 0.42476844787597656, 0.71087646484375, 2.6091532707214355, 0.011419296264648438, 0.1278057098388672, -0.31841087341308594, 0.05103874206542969, 0.29560136795043945, -0.5991144180297852, -0.5278129577636719, -0.4067668914794922, 0.4578704833984375, -1.0521049499511719, 0.827458381652832, 0.7493982315063477, -6.416215896606445, -1.6509366035461426], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 98304, "num_env_steps_trained": 182520, "num_agent_steps_sampled": 98304, "num_agent_steps_trained": 182520, "last_target_update_ts": 98304, "num_target_updates": 191}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -105.56451234549284, "episode_len_mean": 260.08, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815, 21.765688180923462, -0.4999999701976776], "episode_lengths": [270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210, 243, 194]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5277621884946319, "mean_inference_ms": 24.803186428519716, "mean_action_processing_ms": 0.13484392113294283, "mean_env_wait_ms": 4.236120085493404, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -105.56451234549284, "episode_len_mean": 260.08, "episodes_this_iter": 2, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-46.054247222840786, -468.78998743742704, -178.94842018187046, 1.100000023841858, 13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815, 21.765688180923462, -0.4999999701976776], "episode_lengths": [270, 373, 298, 188, 223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210, 243, 194]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5277621884946319, "mean_inference_ms": 24.803186428519716, "mean_action_processing_ms": 0.13484392113294283, "mean_env_wait_ms": 4.236120085493404, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 98304, "num_agent_steps_trained": 182520, "num_env_steps_sampled": 98304, "num_env_steps_trained": 182520, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 98304, "agent_timesteps_total": 98304, "timers": {"training_iteration_time_ms": 322.883, "learn_time_ms": 70.882, "learn_throughput": 1692.966, "synch_weights_time_ms": 21.313}, "counters": {"num_env_steps_sampled": 98304, "num_env_steps_trained": 182520, "num_agent_steps_sampled": 98304, "num_agent_steps_trained": 182520, "last_target_update_ts": 98304, "num_target_updates": 191}, "done": false, "episodes_total": 324, "training_iteration": 96, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-33-05", "timestamp": 1655476385, "time_this_iter_s": 5.124628305435181, "time_total_s": 484.74744987487793, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 484.74744987487793, "timesteps_since_restore": 0, "iterations_since_restore": 96, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 38.728571428571435, "ram_util_percent": 63.91428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 2.66882061958313, "min_q": -81.17037200927734, "max_q": 25.92975616455078, "mean_td_error": -0.3023255467414856}, "td_error": [-1.7096271514892578, -1.7258195877075195, -0.3732767105102539, -0.9166450500488281, 0.06223297119140625, -0.6156597137451172, 0.4215364456176758, -0.08911800384521484, 1.296142578125, 0.10497570037841797, -1.5402488708496094, 1.6676712036132812, 0.04271507263183594, -0.3866691589355469, 1.33642578125, 1.1001815795898438, -0.2558097839355469, 0.06903934478759766, -2.373994827270508, -0.7671890258789062, 4.111061096191406, -0.23802757263183594, 3.4535694122314453, 0.1971721649169922, 0.8573055267333984, -0.5614223480224609, -0.38855743408203125, 0.29523468017578125, -11.991186141967773, -0.5388813018798828, -25.2208309173584, -2.553450584411621, -2.510801315307617, 1.627187728881836, -0.03550529479980469, 0.6365060806274414, 0.16219329833984375, 0.1700000762939453, -0.15370750427246094, -0.24954938888549805, 0.2130746841430664, 0.24460601806640625, 2.644023895263672, 0.9476861953735352, 0.967620849609375, 0.3547201156616211, 0.16970443725585938, 0.4610781669616699, 0.12001609802246094, 2.9532546997070312, -0.9286994934082031, -0.4024486541748047, -0.2228412628173828, -0.6734046936035156, -2.036031723022461, 0.6583833694458008, 0.8226909637451172, -1.155501365661621, -1.8277511596679688, 13.75448226928711, 0.24188899993896484, -0.11612224578857422, -0.16170120239257812, -0.14695072174072266, -6.14422607421875, -0.11978340148925781, 0.1961040496826172, -0.290191650390625, 1.0973854064941406, 0.019380569458007812, 0.18836212158203125, -10.229108810424805, 0.17468738555908203, -0.8915338516235352, 0.2807788848876953, -0.08373069763183594, 0.4041023254394531, -1.9313287734985352, -0.1791534423828125, 0.17543601989746094, 0.9065933227539062, -0.17952251434326172, 2.6700592041015625, -1.3872909545898438, 0.09434700012207031, 0.12067222595214844, 4.172353744506836, 0.3452749252319336, -0.26960182189941406, -0.66558837890625, -1.2269622087478638, 11.069196701049805, -0.9997768402099609, 0.41285228729248047, -0.4014616012573242, 0.6888847351074219, 0.39252662658691406, -0.3528280258178711, -0.6351656913757324, -0.4665050506591797, 1.1537885665893555, -0.33124256134033203, 0.4140338897705078, 0.7732086181640625, -0.6054630279541016, -0.2635536193847656, 0.5202865600585938, 0.5351028442382812, -10.446884155273438, -0.09702587127685547, 0.5012836456298828, 2.3261215686798096, 0.23153305053710938, -9.529342651367188, -0.5248194932937622, 0.4170360565185547, -0.3988971710205078, 3.3342132568359375, 0.3727140426635742, -0.9133419990539551], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 99328, "num_env_steps_trained": 184440, "num_agent_steps_sampled": 99328, "num_agent_steps_trained": 184440, "last_target_update_ts": 99328, "num_target_updates": 193}, "sampler_results": {"episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -108.31301583081483, "episode_len_mean": 260.47, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815, 21.765688180923462, -0.4999999701976776, -294.5844891741872, -732.152892768383, 22.765688583254814, 36.4286900088191], "episode_lengths": [223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210, 243, 194, 311, 445, 198, 214]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5279393060426143, "mean_inference_ms": 24.81722785530576, "mean_action_processing_ms": 0.13505359588456423, "mean_env_wait_ms": 4.240799365390574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.7751430273056, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -108.31301583081483, "episode_len_mean": 260.47, "episodes_this_iter": 4, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [13.010635524988174, 41.7751430273056, 4.1000000312924385, 8.228313982486725, -394.9059835895896, -97.29475649446249, 2.9308495298027992, -13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815, 21.765688180923462, -0.4999999701976776, -294.5844891741872, -732.152892768383, 22.765688583254814, 36.4286900088191], "episode_lengths": [223, 231, 226, 177, 355, 286, 226, 220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210, 243, 194, 311, 445, 198, 214]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5279393060426143, "mean_inference_ms": 24.81722785530576, "mean_action_processing_ms": 0.13505359588456423, "mean_env_wait_ms": 4.240799365390574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 99328, "num_agent_steps_trained": 184440, "num_env_steps_sampled": 99328, "num_env_steps_trained": 184440, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 99328, "agent_timesteps_total": 99328, "timers": {"training_iteration_time_ms": 335.869, "learn_time_ms": 71.372, "learn_throughput": 1681.343, "synch_weights_time_ms": 21.008}, "counters": {"num_env_steps_sampled": 99328, "num_env_steps_trained": 184440, "num_agent_steps_sampled": 99328, "num_agent_steps_trained": 184440, "last_target_update_ts": 99328, "num_target_updates": 193}, "done": false, "episodes_total": 328, "training_iteration": 97, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-33-11", "timestamp": 1655476391, "time_this_iter_s": 5.325778245925903, "time_total_s": 490.07322812080383, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 490.07322812080383, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 30.6125, "ram_util_percent": 63.925}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0010000000474974513, "mean_q": 0.9100444912910461, "min_q": -90.04307556152344, "max_q": 26.22695541381836, "mean_td_error": -0.6383563876152039}, "td_error": [-1.0204811096191406, -0.7502365112304688, -1.0898265838623047, 2.5171585083007812, -0.16624164581298828, -5.962640762329102, -1.4173927307128906, 3.357868194580078, -1.1140403747558594, -0.6977291107177734, -2.175344467163086, 2.8082237243652344, -4.278439521789551, -2.353076934814453, -0.32997703552246094, -0.6712579727172852, -0.2803072929382324, -0.7433815002441406, 0.10203266143798828, -0.3847923278808594, -0.15481948852539062, 0.2061939239501953, -0.21331024169921875, -3.2100563049316406, -1.5473213195800781, -0.6223907470703125, -7.245830535888672, -0.6415367126464844, -0.5751724243164062, 1.3533611297607422, -0.5555553436279297, -0.4130096435546875, -0.5502071380615234, -2.2670297622680664, -1.5115909576416016, -1.917074203491211, 2.0636801719665527, -1.5473213195800781, 0.159454345703125, -0.8960933685302734, -2.007650852203369, 3.381072998046875, -0.7640914916992188, -0.9185812473297119, -1.200007438659668, 0.02170562744140625, -0.04026031494140625, -0.09820365905761719, -0.6415367126464844, -0.2135906219482422, -0.16513633728027344, -0.4074993133544922, -0.4759235382080078, -0.7944507598876953, 0.5517349243164062, -0.3459510803222656, -0.3476686477661133, -1.5583724975585938, -0.7553482055664062, 0.2074127197265625, 1.5916786193847656, -0.2904539108276367, -9.257650375366211, -5.146457672119141, -0.1508922576904297, -0.34148597717285156, -0.9138469696044922, 0.21692371368408203, -0.12005043029785156, 3.3657875061035156, 0.6793928146362305, -0.045566558837890625, -0.632843017578125, 0.20553207397460938, -0.9295558929443359, -0.2594566345214844, -1.5741424560546875, -6.618630409240723, 1.6154632568359375, -0.03324127197265625, -0.34316253662109375, -2.353076934814453, -0.8473739624023438, -0.3161001205444336, -0.010329842567443848, -0.7502365112304688, -0.3022041320800781, -1.1256942749023438, -1.0086021423339844, -0.25733470916748047, -1.5228614807128906, 0.44481658935546875, 2.371706008911133, -1.3916034698486328, -0.9867091178894043, -0.19606590270996094, -0.35501956939697266, 2.301454544067383, -0.2689955234527588, 0.8440561294555664, 1.3869338035583496, -0.3414754867553711, -0.30666160583496094, -1.1638851165771484, 0.7857685089111328, -0.23720645904541016, 0.028318405151367188, -0.35095977783203125, 0.12064552307128906, -0.44178009033203125, -0.36934375762939453, 0.07986640930175781, -1.9563312530517578, -3.418558120727539, -0.3657703399658203, -0.46686553955078125, -0.06558036804199219, -0.48366832733154297, -0.6624469757080078, -2.353076934814453], "custom_metrics": {}, "num_agent_steps_trained": 120}}, "num_env_steps_sampled": 100352, "num_env_steps_trained": 186360, "num_agent_steps_sampled": 100352, "num_agent_steps_trained": 186360, "last_target_update_ts": 100352, "num_target_updates": 195}, "sampler_results": {"episode_reward_max": 41.34771081805229, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -113.9510124977678, "episode_len_mean": 262.21, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815, 21.765688180923462, -0.4999999701976776, -294.5844891741872, -732.152892768383, 22.765688583254814, 36.4286900088191, 15.700902715325356, -256.70145566761494, -96.66014819592237, -682.1970454081893, 15.6132200807333, -1.799999862909317, 20.08906165510416], "episode_lengths": [220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210, 243, 194, 311, 445, 198, 214, 201, 318, 272, 424, 231, 234, 218]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5300896101754714, "mean_inference_ms": 24.813217536690022, "mean_action_processing_ms": 0.1349171466083623, "mean_env_wait_ms": 4.249640279028981, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 41.34771081805229, "episode_reward_min": -868.2904402017593, "episode_reward_mean": -113.9510124977678, "episode_len_mean": 262.21, "episodes_this_iter": 7, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-13.799097247421741, 41.34771081805229, 16.014122493565083, 18.421270817518234, -113.55617574602365, -168.12317672371864, 18.513220086693764, -110.31415602564812, -14.40000008046627, -129.66393091529608, -443.34673760831356, 18.349584579467773, 1.7999998554587364, 15.864785686135292, 17.27534580975771, 19.57542134821415, -6.799999862909317, 7.900000117719173, -28.974756374955177, -42.774756491184235, -816.011344358325, 23.683171704411507, 18.212462790310383, -88.44554012268782, 11.282085172832012, 22.341533981263638, -859.2712689936161, -691.1966974437237, 12.228314064443111, 10.15932672470808, -407.73520056158304, -651.3621259778738, -213.549808293581, 10.26478597521782, -18.846442595124245, 13.613220117986202, 9.910635516047478, 18.266743130981922, -112.55239281058311, -507.7475176602602, -3.5999999344348907, -58.20093605667353, 13.934410616755486, 5.20000009983778, 8.89999982714653, 11.000000149011612, 4.700000137090683, -868.2904402017593, 22.887782230973244, 19.022173322737217, -64.18539188057184, 25.575421035289764, 30.06390354037285, -115.27078387141228, -97.66014835238457, -328.820592418313, -128.59224473685026, 14.51063547283411, 0.10000000149011612, 7.700000129640102, 36.38695928454399, -340.2192038744688, -5.176144428551197, 7.910635367035866, 3.0000000447034836, 15.121270954608917, -825.6326148957014, 22.466878198087215, 12.40775528550148, -25.77763621509075, -339.73011919111013, -40.17217154800892, -580.3468052819371, -326.89396038651466, -438.9683893173933, -44.99775131046772, -6.400000147521496, -19.135214276611805, 3.4000000655651093, 10.210635639727116, 22.50373511761427, 1.600000061094761, 17.393099755048752, -44.44951302558184, 17.64705230295658, 7.428313851356506, 12.028314009308815, 21.765688180923462, -0.4999999701976776, -294.5844891741872, -732.152892768383, 22.765688583254814, 36.4286900088191, 15.700902715325356, -256.70145566761494, -96.66014819592237, -682.1970454081893, 15.6132200807333, -1.799999862909317, 20.08906165510416], "episode_lengths": [220, 231, 243, 214, 283, 286, 237, 287, 247, 269, 353, 231, 240, 202, 232, 222, 232, 224, 237, 257, 450, 235, 228, 246, 230, 219, 450, 431, 203, 202, 356, 420, 321, 193, 251, 208, 191, 215, 295, 363, 220, 271, 227, 218, 233, 235, 227, 450, 220, 193, 229, 226, 232, 274, 262, 313, 266, 195, 222, 227, 224, 330, 225, 238, 213, 220, 450, 238, 237, 216, 337, 232, 425, 347, 370, 268, 233, 238, 219, 239, 234, 235, 227, 268, 237, 214, 210, 243, 194, 311, 445, 198, 214, 201, 318, 272, 424, 231, 234, 218]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5300896101754714, "mean_inference_ms": 24.813217536690022, "mean_action_processing_ms": 0.1349171466083623, "mean_env_wait_ms": 4.249640279028981, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 16, "num_agent_steps_sampled": 100352, "num_agent_steps_trained": 186360, "num_env_steps_sampled": 100352, "num_env_steps_trained": 186360, "num_env_steps_sampled_this_iter": 1024, "num_env_steps_trained_this_iter": 1920, "timesteps_total": 100352, "agent_timesteps_total": 100352, "timers": {"training_iteration_time_ms": 327.429, "learn_time_ms": 69.754, "learn_throughput": 1720.338, "synch_weights_time_ms": 20.489}, "counters": {"num_env_steps_sampled": 100352, "num_env_steps_trained": 186360, "num_agent_steps_sampled": 100352, "num_agent_steps_trained": 186360, "last_target_update_ts": 100352, "num_target_updates": 195}, "done": true, "episodes_total": 335, "training_iteration": 98, "trial_id": "f0de0_00010", "experiment_id": "95e3ce98027f4f4fb5b435186d1a1811", "date": "2022-06-17_17-33-16", "timestamp": 1655476396, "time_this_iter_s": 5.47312068939209, "time_total_s": 495.5463488101959, "pid": 12816, "hostname": "EIS7Y0J022", "node_ip": "127.0.0.1", "config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 16, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.001, "train_batch_size": 120, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": 450, "soft_horizon": false, "no_done_at_end": false, "env": "homm_env_tiny_trivial", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf2", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Box([0 0 0 ... 0 0 0], [7 7 7 ... 1 1 1], (1060,), int64)", "Discrete(8)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": -1, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "ray.rllib.utils.replay_buffers.MultiAgentPrioritizedReplayBuffer", "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "replay_batch_size": 120}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": false, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 495.5463488101959, "timesteps_since_restore": 0, "iterations_since_restore": 98, "warmup_time": 16.824970483779907, "perf": {"cpu_util_percent": 29.9625, "ram_util_percent": 63.8875}}
